[
  {
    "paper_id": "014CgNPAGy",
    "title": "On the Role of Momentum in the Implicit Bias of Gradient Descent for Diagonal Linear Networks",
    "std_review": {
      "summary": "The paper provides a novel theoretical analysis of the implicit bias of momentum-based optimizers (Heavy Ball and Nesterov Accelerated Gradient) in diagonal linear networks, showing that they converge to wider minima associated with better generalization compared to Gradient Descent. The authors derive explicit conditions for these biases and support their findings with empirical evidence. While the results are specific to diagonal linear networks, the work contributes valuable insights into the generalization performance of momentum-based methods. Overall, the paper is well‑structured, theoretically rigorous, and empirically convincing, leading to an acceptance recommendation.",
      "strengths": [
        "Novel theoretical analysis of implicit bias for momentum-based optimizers in diagonal linear networks.",
        "Derives explicit conditions for convergence to solutions with lower training and generalization error.",
        "Comprehensive empirical evaluation demonstrating practical implications.",
        "Grounded in rigorous mathematical derivations, enhancing credibility."
      ],
      "weaknesses": [
        "Results are specific to diagonal linear networks, limiting generalizability.",
        "Assumes idealized conditions (exact initialization) that may not hold in real-world scenarios.",
        "Empirical evaluation limited to a narrow set of hyperparameters and datasets.",
        "Does not explore trade-offs between convergence speed and generalization."
      ],
      "questions": [
        "How do the findings generalize to more complex network architectures beyond diagonal linear networks?",
        "What are the robustness of the theoretical conditions to variations in initialization and noise?",
        "Can the empirical results be extended to different datasets and hyperparameter settings?",
        "What are the trade-offs between convergence speed and generalization for momentum-based methods in practical applications?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "01ep65umEr",
    "title": "TeLLMe what you see: Using LLMs to Explain Neurons in Vision Models",
    "std_review": {
      "summary": "The paper proposes using large language models to generate natural language explanations for neuron activations, offering a novel approach to model interpretability. While it provides more intuitive and context-aware explanations than traditional visualization techniques, it faces challenges such as high computational cost and potential biases in the LLM. The method shows promise but its practical scalability and reliability need further consideration.",
      "strengths": [
        "Enhanced interpretability through context-aware LLM-generated explanations.",
        "Potential scalability to larger models and datasets.",
        "Richer explanations by capturing semantic relationships and context."
      ],
      "weaknesses": [
        "Significant computational cost and resource demands compared to existing visualization methods.",
        "Risk of inheriting biases from the training data, affecting explanation reliability.",
        "Complexity in evaluating explanation quality due to the lack of straightforward metrics."
      ],
      "questions": [
        "How can the computational cost be mitigated to improve scalability?",
        "What strategies can be employed to reduce potential biases in LLM-generated explanations?",
        "What additional metrics or evaluation methods can be used to assess the quality of the explanations beyond correlation measures?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "02f3mUtqnM",
    "title": "Hybrid LLM: Cost-Efficient and Quality-Aware Query Routing",
    "std_review": {
      "summary": "The paper proposes a router system that dynamically selects between small and large language models based on query difficulty, using three designs (deterministic, probabilistic, and probabilistic with data transformation). It demonstrates that routing to smaller models can maintain acceptable quality, offering a practical solution for resource-constrained environments. The review finds the approach innovative, well-evaluated, and practically relevant, though it notes some scalability and generalizability concerns.",
      "strengths": [
        "Innovative routing mechanism for dynamic model selection",
        "Comprehensive exploration of multiple router designs",
        "Empirical validation of cost-quality trade-offs",
        "Practical insights for real-world deployment"
      ],
      "weaknesses": [
        "Assumptions in deterministic model selection may oversimplify query characteristics",
        "Scalability challenges in training routers for each LLM pair",
        "Limited generalizability to other models or domains",
        "Potential need for additional benchmarks to strengthen empirical evidence"
      ],
      "questions": [
        "How can the deterministic approach be extended to better capture nuanced query characteristics?",
        "What scalability strategies could be employed to reduce the computational cost of training routers for multiple LLM pairs?",
        "How do the proposed router designs perform across a broader range of LLMs and domains?",
        "Could additional benchmarks or comparisons with other state-of-the-art approaches further validate the router's effectiveness?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "02Ug9N8DCI",
    "title": "GateLoop: Fully Data-Controlled Linear Recurrence for Sequence Modeling",
    "std_review": {
      "summary": "GateLoop introduces a fully data-controlled linear recurrence mechanism for sequence modeling, designed to retain memory indefinitely without fixed-decay forgetting. It leverages a surrogate attention mechanism to dynamically adjust state transitions based on input data, enabling the model to maintain long-term dependencies. Empirical results demonstrate competitive performance on language modeling tasks, outperforming traditional fixed-decay recurrent models like S4 and S5. The paper presents a novel approach with strong theoretical foundations and practical implementations, though further validation across diverse tasks is recommended.",
      "strengths": [
        "Infinite memory capacity: Retains information indefinitely, addressing the forgetting problem of fixed-decay models.",
        "Data-controlled state transitions: State transitions are explicitly defined by data-dependent parameters, providing clear mechanisms for preserving or updating information.",
        "Scalable computational complexity: Parallelized associative scan computation reduces complexity to O(l log l), making it feasible for longer sequences and larger model dimensions."
      ],
      "weaknesses": [
        "Complexity of parameter tuning: Data-controlled nature may require careful tuning of α and β parameters.",
        "Potential overhead: Implementation of surrogate attention and parallelized scan may introduce additional computational overhead.",
        "Limited expressivity compared to attention models: Despite improvements, expressivity may still be limited relative to sophisticated attention-based models."
      ],
      "questions": [
        "How robust are the performance gains of GateLoop across a broader range of language modeling tasks and datasets?",
        "What are the long-term stability and convergence properties of the model when applied to very long sequences?",
        "How does the surrogate attention mechanism compare to traditional attention mechanisms in terms of expressivity and computational cost?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "030cjlZm4a",
    "title": "Learning predictive checklists with",
    "std_review": {
      "summary": "The paper presents a novel method for generating interpretable checklists from machine learning models, particularly useful in medical settings. It introduces a fairness regularizer to ensure balanced treatment across sensitive groups, enhancing transparency and trust. Empirical experiments demonstrate the method's effectiveness in improving interpretability without significant performance loss, suggesting its potential for clinical deployment. Despite some scalability concerns, the approach is well-suited for high-stakes domains where interpretability is crucial.",
      "strengths": [
        "Introduces a unique approach to generating interpretable checklists from complex models.",
        "Ensures fairness in checklist generation, addressing equitable treatment across demographic groups.",
        "Provides strong empirical evidence of improved interpretability without compromising model performance."
      ],
      "weaknesses": [
        "Interpretability may be limited for highly complex or non-linear models.",
        "Exponential memory complexity could restrict applicability to large-scale datasets.",
        "Effectiveness may be domain-specific, raising questions about generalizability."
      ],
      "questions": [
        "How does the method handle highly complex or non-linear models to ensure meaningful interpretability?",
        "What strategies can be employed to mitigate the exponential memory complexity for large-scale applications?",
        "How can the method be adapted for use in domains beyond healthcare where interpretability requirements differ?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "04UvXg4CvW",
    "title": "EPIC: Compressing Deep GNNs via Expressive Power Gap-Induced Knowledge Distillation",
    "std_review": {
      "summary": "The paper introduces EPIC, a novel loss function for compressing deep GNNs into shallow MLPs by capturing both epistemic and entropic uncertainties. EPIC significantly outperforms existing distillation techniques, especially in inductive settings, while reducing computational costs. Despite some practical concerns like hyperparameter tuning and computational overhead, the innovative approach and strong theoretical foundation justify its acceptance.",
      "strengths": [
        "Introduces a unique loss function combining epistemic and entropic consistency.",
        "Demonstrates superior performance over existing distillation methods, particularly in inductive scenarios.",
        "Provides a solid theoretical justification for the proposed approach."
      ],
      "weaknesses": [
        "Hyperparameter tuning issues may lead to suboptimal results.",
        "Comparisons to GNN-to-MLP frameworks may be unfair due to unsuitable baseline architectures.",
        "Computational cost of estimating EPIC bounds could limit practical applicability."
      ],
      "questions": [
        "How can the computational overhead of EPIC be mitigated for very large-scale graphs?",
        "What empirical evidence supports the tightness and reliability of the EPIC bounds?",
        "How does EPIC perform when distilling shallow GNN teachers compared to deep ones?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "06lrITXVAx",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a novel dropout method tailored for bilevel optimization, addressing overfitting in hierarchical optimization problems. Theoretical analysis links dropout to the bilevel objective, and empirical results on a data cleaning task show competitive performance compared to early stopping. The authors provide strong theoretical backing and practical validation, leading to an acceptance recommendation.",
      "strengths": [
        "Introduces a novel dropout method for bilevel optimization.",
        "Provides a solid theoretical foundation linking dropout to bilevel convergence.",
        "Demonstrates empirical effectiveness on a data cleaning task."
      ],
      "weaknesses": [
        "The bilevel optimization framework may be complex and challenging to implement.",
        "Empirical evaluation is limited to a single task, potentially restricting generalizability.",
        "Theoretical assumptions may limit the broad applicability of the convergence results."
      ],
      "questions": [
        "How does the proposed dropout method scale to more complex bilevel optimization problems?",
        "What are the practical guidelines for selecting the dropout rate in different bilevel settings?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "06mzMua9Rw",
    "title": "A Trust Region Approach for Few-Shot Sim-to-Real Reinforcement Learning",
    "std_review": {
      "summary": "The paper introduces FOOD, an offline RL algorithm that tackles sim-to-real transfer by formulating a trust-region objective to align state-action-state-visitation distributions with the target policy. Empirical results across multiple simulation and real-world robotic tasks show significant improvements in sample efficiency and transfer performance compared to existing baselines. The theoretical contribution is novel, providing a guarantee for near-optimal performance under dynamics mismatch. Despite promising results, concerns about computational complexity, sensitivity to regularization metrics, and the lack of ablation studies on the regularization strategy remain.",
      "strengths": [
        "Novel trust-region objective for sim-to-real transfer",
        "Robust regularization strategy based on learned value function",
        "Strong theoretical foundation with Proposition 4.1"
      ],
      "weaknesses": [
        "Potential computational complexity in high-dimensional spaces",
        "Sensitivity to the choice of performance metric for regularization",
        "Limited real-world dataset diversity",
        "Absence of ablation studies on regularization"
      ],
      "questions": [
        "How does the method scale to high-dimensional state spaces?",
        "What is the impact of different regularization metrics on generalization?",
        "Could ablation studies provide more insight into the role of the regularization term?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "070DFUdNh7",
    "title": "GraphGPT: Graph Learning with Generative Pre-trained Transformers",
    "std_review": {
      "summary": "GraphGPT is a large language model specialized for graph-structured data, achieving strong results on edge- and graph-level tasks but underperforming on node-level predictions. The model leverages a transformer architecture with graph-aware attention, trained on diverse datasets like molecular graphs and protein-protein interactions. While promising, its computational demands and the need for domain-specific retraining are significant drawbacks that limit its immediate practical applicability.",
      "strengths": [
        "Versatile graph representation capable of excelling at edge-, node-, and graph-level tasks.",
        "Scalable transformer-based architecture with graph-aware attention for large datasets.",
        "Diverse dataset coverage enhances generalizability across domains."
      ],
      "weaknesses": [
        "Limited node-level performance compared to state-of-the-art benchmarks.",
        "Requires domain-specific retraining, posing practical deployment challenges.",
        "High computational intensity for pre-training large models."
      ],
      "questions": [
        "How can the model's node-level performance be improved to match edge- and graph-level results?",
        "What strategies can reduce the computational burden of retraining for different graph domains?",
        "How does the choice of context window size and subgraph sampling affect model efficiency and performance?"
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "07xuZw59uB",
    "title": "Bridging the Fairness Divide: Achieving Group and Individual Fairness in Graph Neural Networks",
    "std_review": {
      "summary": "The paper introduces FairGI, a framework that balances group fairness (Equal Opportunity and Statistical Parity) with individual fairness within groups for GNNs. It proposes a novel fairness loss function combining adversarial loss for group fairness and a similarity-matrix loss for individual fairness within groups. Empirical evaluations on several graph datasets show improved fairness metrics without significant loss in predictive performance, supported by theoretical justifications. The paper highlights its innovative metric and balanced approach, distinguishing it from prior works.",
      "strengths": [
        "Introduces a unique 'individual fairness within groups' metric that refines traditional individual fairness.",
        "Effectively balances group fairness and individual fairness, addressing a critical gap in existing literature.",
        "Provides a solid theoretical foundation for the proposed fairness loss functions.",
        "Demonstrates superior performance in maintaining fairness metrics while preserving model accuracy.",
        "Clearly distinguishes FairGI from prior works by addressing their limitations."
      ],
      "weaknesses": [
        "The introduction of a novel fairness metric and combined loss functions may increase implementation complexity.",
        "Performance is sensitive to hyperparameter tuning, which could be a barrier for practitioners.",
        "Empirical evaluation is based on a limited set of graph datasets.",
        "Lacks a thorough analysis of the framework's robustness to adversarial attacks or input variations."
      ],
      "questions": [
        "How can practitioners with limited experience in GNNs or fairness-aware machine learning effectively implement FairGI?",
        "What are the specific guidelines for hyperparameter tuning to achieve optimal fairness and accuracy trade-offs?",
        "How does FairGI perform across a broader range of graph-structured data beyond the evaluated datasets?",
        "What robustness analyses (e.g., adversarial attacks) are recommended for real-world applications of FairGI?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "09iOdaeOzp",
    "title": "Sheared LLAMA: Accelerating Language Model Pre-training via Structured Pruning",
    "std_review": {
      "summary": "Sheared-LLaMA introduces a novel structured pruning technique for LLMs that combines targeted pruning with dynamic batch loading, achieving significant performance gains while preserving accuracy. The method outperforms existing baselines like LLM-Pruner across various models and sparsity levels, and demonstrates long-term performance benefits after additional pre‑training. However, concerns about baseline comparison and lack of generalization to other models limit its acceptance.",
      "strengths": [
        "Innovative targeted structured pruning technique",
        "Integration of dynamic batch loading enhances inference speed",
        "Comprehensive experiments across multiple foundation models and sparsity levels"
      ],
      "weaknesses": [
        "Baseline comparison with LLM-Pruner may be unfair due to different training techniques",
        "Absence of dynamic batch loading in baseline limits inference speed comparison",
        "Limited generalization to other open-source foundation models",
        "Compute cost of reference losses not clearly reported",
        "No exploration of target architecture impact on performance"
      ],
      "questions": [
        "How does the method perform on other open-source foundation models like Mistral-7B or DeepSeek-Coder?",
        "What is the computational cost of computing reference losses for each domain?",
        "How does the choice of target architecture (uniform vs. non‑uniform) affect inference speed and performance?",
        "Could additional ablation studies on dynamic batch loading further strengthen the findings?",
        "What is the long‑term impact of pruning on model robustness and generalization?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "09xFexjhqE",
    "title": "AutoLoRa: An Automated Robust Fine-Tuning Framework",
    "std_review": {
      "summary": "AutoLoRa presents an innovative framework for training robust deep learning models by dynamically adjusting hyperparameters during training. The approach combines a standard LoRA branch with an auxiliary LoRA branch and employs automated scheduling for learning rate and a scalar regularization term. Evaluated on multiple image classification tasks, AutoLoRa demonstrates significant improvements in robustness against adversarial attacks while maintaining competitive standard accuracy. The paper's clear evaluation, ablation studies, and novel gradient similarity metric contribute to its strong practical utility.",
      "strengths": [
        "Innovative hyperparameter scheduling based on gradient similarity.",
        "Layer‑wise gradient aggregation for fine‑grained control over training.",
        "Substantial quantitative gains in robust accuracy across datasets.",
        "Well‑structured experiments with clear ablations and comparisons."
      ],
      "weaknesses": [
        "Increased implementation complexity and potential computational demands.",
        "Limited evaluation to image classification tasks; generalizability unclear.",
        "Lack of detailed description of the gradient similarity metric.",
        "Risk of overfitting with auxiliary LoRA branch and regularization."
      ],
      "questions": [
        "How does the framework perform on non‑image domains such as natural language processing?",
        "What is the exact formulation of the gradient similarity metric and its impact on training dynamics?",
        "Are there any theoretical guarantees on the convergence or stability of the proposed method?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0A5o6dCKeK",
    "title": "Next-Gpt: Any-to-Any Multimodal LLM",
    "std_review": {
      "summary": "The paper presents NExT‑GPT, a unified multimodal language model that can process and generate text, images, and other formats interchangeably. It introduces an alignment learning technique that balances performance across modalities by jointly optimizing a unified model on diverse tasks. The model is evaluated on standard benchmarks and outperforms existing multimodal models like InstructBLIP, LLaVA, and mPLUG‑Owl, demonstrating strong flexibility and cross‑modal understanding. The reviewer finds the approach novel, well‑evaluated, and technically sound, leading to an acceptance recommendation.",
      "strengths": [
        "Introduces a novel end‑to‑end unified multimodal language model (MM‑LLM) that seamlessly integrates multiple modalities.",
        "Proposes an alignment learning technique that effectively balances performance across different modalities.",
        "Conducts comprehensive evaluation on benchmark datasets with robust qualitative and quantitative comparisons.",
        "Demonstrates strong flexibility and cross‑modal understanding across a wide range of multimodal tasks."
      ],
      "weaknesses": [
        "The alignment learning technique may introduce additional computational complexity and require careful tuning.",
        "The dataset used is large but could benefit from further expansion to capture more real‑world variability.",
        "Qualitative comparisons, while insightful, could be more extensive with additional tasks and models.",
        "Scalability concerns suggest that performance gains may not scale linearly with model size or dataset size."
      ],
      "questions": [
        "How does the alignment learning technique scale with increasing model size or dataset diversity?",
        "What are the computational trade‑offs associated with the joint optimization across modalities?",
        "How does the model perform on edge cases or highly specialized multimodal tasks not covered in the current benchmarks?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0aEUd9UtiA",
    "title": "DiffCPS: Diffusion-based Constrained Policy Search for Offline Reinforcement Learning",
    "std_review": {
      "summary": "DiffCPS presents a novel offline RL algorithm that leverages diffusion models to address multimodal policy challenges. The approach reformulates policy search as a constrained optimization problem, using a strong duality framework for efficient gradient-based optimization. Empirical results on D4RL benchmarks show competitive performance, highlighting diffusion models' potential in offline policy optimization. While introducing significant novelty, the method's computational complexity and reliance on theoretical conditions are noted.",
      "strengths": [
        "Innovative use of diffusion models for capturing complex, multimodal policies in offline RL.",
        "Strong theoretical foundation via a strong duality framework enabling efficient gradient-based optimization.",
        "Empirical validation demonstrating competitive performance on standard benchmarks."
      ],
      "weaknesses": [
        "Higher computational costs compared to simpler policy representations.",
        "Theoretical results depend on Slater’s condition, which may not always hold.",
        "Specifically tailored to diffusion models, limiting generalization to other policy representations."
      ],
      "questions": [
        "How can the computational complexity of diffusion models be mitigated for larger-scale offline RL tasks?",
        "What are the practical implications of the reliance on Slater’s condition for the duality framework?",
        "Could the approach be extended to other policy representations, such as flow models, and what modifications would be required?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0akLDTFR9x",
    "title": "Contrastive Difference Predictive Coding",
    "std_review": {
      "summary": "The paper proposes TD InfoNCE, a method that combines temporal difference learning with contrastive information maximization to enhance sample efficiency in reinforcement learning. It introduces a novel goal distribution and a sampling strategy for the next state, leveraging geometric distributions similar to those in contrastive RL. Evaluated on several maze tasks, TD InfoNCE shows competitive performance, achieving high success rates with fewer samples. The paper's strengths lie in its innovative approach and clear experimental evaluation, though it could benefit from additional validation and clearer mathematical derivations.",
      "strengths": [
        "Introduces a novel goal distribution tailored to improve sample efficiency in RL.",
        "Proposes an innovative sampling strategy for the next state that leverages geometric distributions.",
        "Provides a thorough experimental evaluation across multiple maze tasks, demonstrating effectiveness and robustness."
      ],
      "weaknesses": [
        "The novelty of the goal distribution and sampling strategy may require further validation.",
        "The experimental setup could be expanded with a more diverse set of environments.",
        "Mathematical derivations and equations could be clearer and more detailed."
      ],
      "questions": [
        "How does the proposed goal distribution compare to other goal distributions in terms of theoretical guarantees?",
        "Could the sampling strategy be adapted to other types of environments beyond maze tasks?",
        "What are the computational costs associated with implementing the geometric distribution sampling?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0aR1s9YxoL",
    "title": "Revisiting Plasticity in Visual Reinforcement Learning: Data, Modules and Training Stages",
    "std_review": {
      "summary": "The paper introduces the Adaptive Replay Ratio (ARR) method to mitigate catastrophic plasticity loss in visual reinforcement learning (VRL) by dynamically adjusting the replay ratio based on the critic's plasticity. Experiments across DMC and Atari environments show that ARR improves VRL performance and outperforms existing techniques like Reset Deep Ensemble Agents. While the paper provides valuable insights and demonstrates the method's effectiveness, it could benefit from a deeper theoretical analysis, broader experimental scope, and a more detailed computational complexity discussion.",
      "strengths": [
        "Introduces a novel Adaptive Replay Ratio (ARR) method that dynamically adjusts the replay ratio based on the critic's plasticity, addressing catastrophic plasticity loss in VRL.",
        "Conducts comprehensive experiments across multiple environments (DMC and Atari) to evaluate the generalizability of the findings.",
        "Provides a thorough analysis of the relationship between plasticity metrics and VRL agent performance."
      ],
      "weaknesses": [
        "The paper could benefit from a more detailed discussion of the theoretical underpinnings of the proposed ARR method and its relationship to existing plasticity mitigation techniques.",
        "The experiments primarily focus on two environments (DMC and Atari), which may limit the generalizability of the findings to other domains.",
        "The paper does not provide a comprehensive analysis of the computational complexity and resource requirements of the ARR method compared to other approaches.",
        "The authors could have included more ablation studies to further validate the contribution of the ARR method and its components."
      ],
      "questions": [
        "How does the proposed ARR method compare to other adaptive replay strategies in terms of computational efficiency and scalability?",
        "What is the theoretical basis for dynamically adjusting the replay ratio based on the critic's plasticity, and how does it relate to existing plasticity mitigation techniques?",
        "Could the method be extended to other types of reinforcement learning environments beyond DMC and Atari?",
        "What are the long-term stability and generalization implications of using ARR in real-world VRL applications?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0AYosSFETw",
    "title": "Towards human-like spoken dialogue generation between AI agents from written dialogue",
    "std_review": {
      "summary": "The CHATS system introduces a novel Multi-Stream Dialogue Transformer Language Model (MS-DLM) that explicitly models backchannels, laughter, and turn-taking, significantly improving the naturalness and coherence of generated spoken dialogues. It addresses key limitations of existing models by incorporating dedicated streams for these conversational elements and a preprocessing pipeline that separates and reintroduces them. Experiments show strong performance, especially in handling complex conversational structures, though language specificity and potential overfitting are noted as areas for future work.",
      "strengths": [
        "Effectively addresses limitations of existing spoken dialogue generation models by incorporating explicit streams for backchannels, laughter, and turn-taking.",
        "Significantly improves naturalness and coherence of generated dialogues, as demonstrated by experimental results.",
        "Demonstrates robust handling of complex conversational structures, making it a strong solution for realistic dialogue generation."
      ],
      "weaknesses": [
        "Increased complexity of implementation and higher computational requirements due to additional streams and preprocessing steps.",
        "Language specificity, primarily validated for Japanese, may limit applicability to other languages without further adaptation.",
        "Potential for overfitting given the increased model complexity, especially if training data is not sufficiently diverse.",
        "Lack of extensive validation across a wider range of languages and conversational contexts could limit generalizability."
      ],
      "questions": [
        "How can the CHATS system be adapted for languages other than Japanese to address language-specific preprocessing and model training challenges?",
        "What strategies can be employed to mitigate the risk of overfitting, particularly with limited diverse training data?",
        "How does the system perform in scenarios involving highly informal or domain-specific conversations beyond the current validation set?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0b328CMwn1",
    "title": "",
    "std_review": {
      "summary": "The paper introduces Activation Prompt (AP), a novel visual prompting technique that selectively prompts specific layers of a pre-trained vision model to enhance performance. AP outperforms traditional methods and other parameter-efficient fine-tuning techniques across multiple benchmarks, offering theoretical insights and practical guidelines. However, it lacks comprehensive theoretical analysis, a thorough comparison with state-of-the-art methods, and explicit discussion of practical considerations, which are crucial for a complete evaluation.",
      "strengths": [
        "Introduces a novel and innovative approach to visual prompting.",
        "Demonstrates superior performance compared to existing methods.",
        "Provides theoretical insights into the connection with normalization tuning."
      ],
      "weaknesses": [
        "Lacks a comprehensive theoretical analysis or proofs.",
        "Benchmark datasets may not fully capture real-world diversity.",
        "Does not provide a detailed comparison with state-of-the-art methods.",
        "Practical considerations and limitations are not thoroughly explored.",
        "Reproducibility of results is not explicitly addressed."
      ],
      "questions": [
        "What is the theoretical foundation supporting the effectiveness of AP?",
        "How does AP perform on a broader set of real-world datasets?",
        "What are the practical considerations for deploying AP in industry settings?",
        "How does AP compare to the latest state-of-the-art methods in visual prompting?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "0bjIoHD45G",
    "title": "Closing the gap on tabular data with Fourier and Implicit Categorical Features",
    "std_review": {
      "summary": "The paper presents a novel method for tabular data modeling that combines implicit categorical feature identification, Fourier encoding, and a 1D convolutional ResNet. It shows strong empirical results on several datasets, outperforming traditional models like XGBoost and MLP. However, the approach lacks clear justification for many design choices, such as thresholds for low cardinality features and Fourier component selection, and does not fully address robustness or generalization. Overall, the work is promising but needs more rigorous justification and evaluation.",
      "strengths": [
        "Innovative feature identification for low-cardinality categorical features.",
        "Creative use of Fourier encoding tailored for tabular data.",
        "Adaptation of convolutional neural networks to tabular inputs via 1D convolutions."
      ],
      "weaknesses": [
        "Unclear justification for thresholds used to determine low cardinality features.",
        "Lack of detailed rationale for selecting statistical tests and interpreting p-values.",
        "No clear explanation for the choice of Fourier frequencies or periods.",
        "Model architecture details (layer numbers, kernel sizes, activation functions) are not fully specified.",
        "Hyperparameter selection (learning rate, batch size, optimizer) lacks justification.",
        "Evaluation metric 'p-range' is not standard and lacks clear justification.",
        "Baseline comparisons are limited to XGBoost and MLP.",
        "Robustness testing on unseen data or with different random seeds is insufficient.",
        "Computational resources for training and hyperparameter search are not described."
      ],
      "questions": [
        "What criteria justify the thresholds for identifying low-cardinality features?",
        "How were the Fourier frequencies or periods selected, and why were they chosen?",
        "Could you provide more details on the specific architecture of the 1D convolutional ResNet, including layer numbers and kernel sizes?",
        "What is the rationale behind the hyperparameter selection, and how was the learning rate schedule determined?",
        "How was the 'p-range' metric chosen, and what is its standardization?",
        "What additional baselines or models were compared, and how were they implemented?",
        "How was model robustness evaluated, and what were the results?",
        "What computational resources were used for training and hyperparameter search?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "0bMmZ3fkCk",
    "title": "NEFTune: Noisy Embeddings Improve Instruction Finetuning",
    "std_review": {
      "summary": "NEFTune introduces a novel regularization technique that adds noise to embedding vectors during finetuning, improving generalization across diverse instruction datasets. The method shows strong empirical results across various model sizes and datasets, outperforming baselines like FreeLB and dropout. While the paper provides valuable insights and practical improvements, it lacks detailed theoretical analysis and explores only a limited range of noise distributions and domains.",
      "strengths": [
        "Introduces a novel regularization technique that leverages noise addition to embedding vectors.",
        "Demonstrates strong empirical results across multiple instruction datasets and model sizes.",
        "Provides a clear theoretical motivation for why noise addition can act as a regularizer."
      ],
      "weaknesses": [
        "Lacks detailed theoretical analysis on the mechanism of noise as a regularizer.",
        "Limited exploration of different noise distributions and their impact.",
        "Evaluation focused primarily on instruction-following tasks, with limited domain generalization.",
        "Computational costs of applying NEFTune are not thoroughly analyzed."
      ],
      "questions": [
        "What is the theoretical basis for why adding noise to embeddings improves model generalization?",
        "How does the choice of noise distribution (e.g., Gaussian vs. Uniform) affect model performance?",
        "What are the computational costs of applying NEFTune in resource-constrained environments?",
        "How can NEFTune be adapted for other tasks beyond instruction-following, such as text classification or summarization?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0BqyZSWfzo",
    "title": "One-shot Empirical Privacy Estimation",
    "std_review": {
      "summary": "The paper introduces a method for estimating user-level differential privacy in federated learning using canary clients, which provides tighter privacy bounds compared to existing techniques. The approach is empirically validated and offers theoretical insights into parameter choices, though it has limitations in interpretability, robustness, and generalization. Overall, the method is well-suited for the Gaussian mechanism in DP-FedAvg and has potential for broader applications.",
      "strengths": [
        "Practical approach using canary clients for realistic DP estimation",
        "Strong empirical validation and theoretical analysis",
        "Clear comparison with CANIFE and insights into parameter impact"
      ],
      "weaknesses": [
        "Interpretation of privacy estimate may vary with client selection",
        "Analytical bounds may not fully capture real-world complexity",
        "Sensitivity to canary parameters can affect result variability"
      ],
      "questions": [
        "How do the privacy estimates compare when using synthetic canary examples instead of real clients?",
        "What are the theoretical guarantees for the analytical upper bound used as a reference?",
        "How can the method be adapted for other privacy mechanisms or federated settings?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0Ce3c9l7G1",
    "title": "Learning Multi-Agent Communication using Regularized Attention Messages",
    "std_review": {
      "summary": "The paper introduces ARCOMM, a communication protocol for multi-agent reinforcement learning that uses attention mechanisms and DCT compression to balance informativeness and efficiency. Empirical evaluations show ARCOMM outperforms existing methods, though comparisons with newer approaches could be strengthened. Theoretical insights motivate the design, but lack formal proofs. Implementation complexity may be a barrier.",
      "strengths": [
        "Innovative combination of attention and DCT for efficient multi-agent communication.",
        "Clear theoretical motivation for message regularisation.",
        "Strong empirical performance across various environments."
      ],
      "weaknesses": [
        "Limited comparison with recent state-of-the-art methods.",
        "Absence of detailed theoretical analysis.",
        "Potential overfitting in ablation studies.",
        "Increased implementation complexity."
      ],
      "questions": [
        "How does ARCOMM compare to the latest advancements in communication protocols?",
        "What is the impact of the DCT application to the last dimension of message vectors?",
        "How does the message regularizer affect the balance between entropy and ambiguity?",
        "What are the optimal settings for the number of observations predicted (k) and the regularisation strength?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0cJ8ERfnrM",
    "title": "Antibody DomainBed: Out-of-Distribution Generalization in Therapeutic Protein Design",
    "std_review": {
      "summary": "The paper introduces a synthetic benchmark for evaluating domain‑generalization in antibody design, presenting a dataset of synthetic ΔΔG labels and assessing several domain‑generalization methods against standard empirical risk minimization. While the benchmark is well‑structured and provides clear insights into model performance and learned invariances, it suffers from limited realism due to synthetic labels and dataset construction criteria that may not fully represent real antibody design challenges. The authors should address these concerns by validating synthetic labels against wet‑lab measurements, expanding dataset realism, and conducting more comprehensive ablation studies.",
      "strengths": [
        "Comprehensive synthetic benchmark with realistic antigen‑antibody interactions.",
        "Clear evaluation of multiple domain‑generalization methods.",
        "Use of saliency maps to enhance interpretability of model behavior."
      ],
      "weaknesses": [
        "Synthetic ΔΔG labels may not fully capture real binding affinity complexity.",
        "Dataset construction criteria may not reflect variability in actual antibody design projects.",
        "Limited testing of model size impact on performance."
      ],
      "questions": [
        "Should experiments be included to validate synthetic ΔΔG labels against wet‑lab measurements?",
        "How can the dataset be expanded to better reflect realistic changes in antigen environments?",
        "What additional ablation studies are needed to better understand model size impact?",
        "How can the benchmark be made more accessible to the community (e.g., dataset release, code sharing)?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "0d1gQI114C",
    "title": "LiDAR-PTQ: Post-Training Quantization for Point Cloud 3D Object Detection",
    "std_review": {
      "summary": "The paper presents LiDAR-PTQ, a method for post-training quantization of point cloud 3D object detection models using a sparsity-aware calibration and task-guided loss approach. It demonstrates significant performance gains over existing techniques on sparse detection tasks, though it introduces additional complexity and lacks a comprehensive comparison with other sparse training methods. Overall, the innovative technique and strong empirical results justify acceptance.",
      "strengths": [
        "Introduces a novel sparsity-aware calibration method that directly addresses challenges of sparse model training.",
        "Employs task-guided loss to enhance performance tailored to sparse detection tasks.",
        "Provides thorough empirical validation across multiple datasets and sparse configurations."
      ],
      "weaknesses": [
        "Adds complexity to the calibration process, potentially increasing computational overhead.",
        "Effectiveness is evaluated primarily on sparse object detection tasks, limiting generalizability.",
        "Lacks a comprehensive comparison with state-of-the-art sparse model training techniques."
      ],
      "questions": [
        "How does the proposed method scale to larger sparse models or different domains beyond object detection?",
        "What is the impact of the sparsity-aware calibration on inference speed and memory usage?",
        "Can the task-guided loss be adapted for other types of sparse models or tasks?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0D6mUZTWoF",
    "title": "A Topology-aware Graph Coarsening Framework for Continual Graph Learning",
    "std_review": {
      "summary": "TACO introduces a novel continual learning framework that dynamically adjusts task importance based on correlations, improving efficiency and generalization. It outperforms existing rehearsal methods on benchmark datasets, showing strong empirical results. The approach is innovative, addressing key challenges in continual learning, though some scalability and robustness concerns remain.",
      "strengths": [
        "Dynamic task importance adjustment effectively balances knowledge retention and adaptation.",
        "Reduces memory usage by focusing on relevant tasks, improving efficiency.",
        "Demonstrates superior generalization and performance over traditional methods."
      ],
      "weaknesses": [
        "Computational complexity in estimating task correlations may be high.",
        "Risk of overfitting if correlation estimation is inaccurate, especially with limited data.",
        "Potential lack of robustness to noisy or mislabeled data."
      ],
      "questions": [
        "How does TACO handle scenarios with highly noisy or mislabeled data?",
        "What is the scalability of TACO to very large and diverse datasets?",
        "Can TACO be integrated with other continual learning techniques for further improvements?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0ez68a5UqI",
    "title": "Reinforcement Learning for Node Selection in Branch-and-Bound",
    "std_review": {
      "summary": "The paper introduces a reinforcement learning framework for optimizing node selection in branch-and-bound algorithms, leveraging a graph neural network to encode the search tree structure. It demonstrates strong performance on combinatorial optimization problems like TSP, UFLP, and MILP instances, outperforming traditional heuristics. While promising, the approach is limited to specific problem types and may suffer from overfitting and increased computational complexity. Overall, the work is well‑executed and advances the state of the art in branch-and-bound optimization.",
      "strengths": [
        "Novel integration of RL with branch-and-bound for dynamic node selection.",
        "Effective use of a graph neural network to capture global search tree structure.",
        "Empirical validation across multiple benchmark datasets showing versatility."
      ],
      "weaknesses": [
        "Limited generalization to domains beyond combinatorial optimization.",
        "Potential overfitting due to training primarily on TSP problems.",
        "Additional computational overhead from using GNNs.",
        "Lack of detailed hyperparameter analysis."
      ],
      "questions": [
        "How does the method perform on non‑combinatorial optimization problems?",
        "What is the impact of hyperparameter tuning on model performance?",
        "Can the approach be extended to real‑time applications with large instances?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0fpLLsAynh",
    "title": "Sporadicity in Decentralized Federated Learning: Theory and Algorithm",
    "std_review": {
      "summary": "The paper introduces DSpodFL, a decentralized federated learning algorithm that incorporates sporadic local updates and communications to improve convergence efficiency. The authors provide rigorous theoretical analysis showing improved convergence bounds under sporadic conditions compared to standard DSGD, and extend the analysis to non-convex settings. While the theoretical contributions are significant, the paper lacks extensive empirical validation and a comprehensive comparison with existing methods, which could affect its practical applicability.",
      "strengths": [
        "Innovative approach to handling sporadic updates in decentralized federated learning",
        "Rigorous theoretical analysis demonstrating improved convergence bounds",
        "Broader applicability to non-convex settings"
      ],
      "weaknesses": [
        "Limited empirical validation of the proposed method",
        "Reliance on specific assumptions about sporadicity that may limit generalizability",
        "Lack of comprehensive comparison with existing decentralized federated learning methods"
      ],
      "questions": [
        "What are the practical implications of the theoretical benefits in real-world scenarios?",
        "How does DSpodFL perform in scenarios with highly variable network conditions?",
        "Could the algorithm be extended to handle more complex forms of device heterogeneity?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0fSNU64FV7",
    "title": "Sorting Out Quantum Monte Carlo",
    "std_review": {
      "summary": "The paper introduces the sortlet ansatz, a neural network wavefunction for quantum chemistry that uses a discrete, piecewise-linear representation of the spatial wavefunction. It aims to capture strong localization and reduce computational demands compared to full determinant methods, achieving competitive results on small molecules. However, concerns remain about the method's theoretical foundations, scalability, and ability to reach chemical accuracy. The overall assessment is borderline.",
      "strengths": [
        "Computational Efficiency: Significantly reduces trainable parameters, leading to faster training and evaluation.",
        "Expressiveness for Localization: Promotes localization through a discontinuous mixing parameter, advantageous for certain chemical phenomena.",
        "Theoretical Motivation: Grounded in a clear variational principle, ensuring well-defined kinetic energy and normalization."
      ],
      "weaknesses": [
        "Discontinuity Challenges: The discontinuous α function may complicate the well-definedness of the kinetic energy term.",
        "Limited Scalability: Performance is only demonstrated for small molecules, leaving open questions for larger systems.",
        "Comparison with Determinants: Inferior to full determinant methods, suggesting fundamental limitations.",
        "Lack of Hartree-Fock Recovery: The method's ability to efficiently recover the Hartree-Fock limit is not demonstrated."
      ],
      "questions": [
        "How does the discontinuous α function affect the well-definedness of the kinetic energy term, and what are the implications for variational optimality?",
        "What is the expected growth of the expansion parameter K with system size, and how does it impact scalability?",
        "How does the sortlet ansatz perform on larger systems beyond the small molecules tested, and what are the potential failure modes?",
        "Can the sortlet ansatz efficiently recover the Hartree-Fock limit, and if not, what are the theoretical reasons?"
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "0gDQgwjoX0",
    "title": "Stochastic Gradient Discrete Langevin Dynamics",
    "std_review": {
      "summary": "The paper introduces a novel discrete Langevin dynamics method for sampling from high-dimensional discrete spaces, leveraging a caching technique to reduce computational overhead. Theoretical guarantees for convergence are provided under certain conditions, and empirical comparisons show potential efficiency gains. However, practical scalability and implementation details remain to be fully evaluated. The reviewer concludes with an acceptance recommendation.",
      "strengths": [
        "Innovative caching technique that reduces memory usage for high-dimensional discrete spaces.",
        "Clear theoretical foundation with convergence guarantees under specific conditions.",
        "Empirical advantages demonstrated over existing techniques, particularly in efficiency and bias reduction."
      ],
      "weaknesses": [
        "Initial memory overhead for storing intermediate quantities remains significant.",
        "Limited scalability demonstrated only on small-scale problems.",
        "Unclear role of the step-size parameter N in controlling Monte Carlo error.",
        "Lack of adaptive mechanisms for step-size updates or hierarchical caching."
      ],
      "questions": [
        "How does the method scale to larger or more complex discrete domains beyond the current empirical evaluations?",
        "What are the detailed theoretical guarantees for different choices of the step-size parameter N?",
        "Could adaptive step-size updates or hierarchical caching strategies further optimize performance?",
        "What implementation details, such as neighborhood size, are necessary for practical application?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0gTW5JUFTW",
    "title": "TopoMLP: An Simple yet Strong Pipeline",
    "std_review": {
      "summary": "TopoMLP presents a simple yet effective pipeline for 3D road topology reasoning, combining YOLOv8 object detection with a Multi‑Layer Perceptron (MLP) to predict lane geometry and topology. The method achieves competitive results on the Road Topology Benchmark, especially when evaluated with an adjusted TOP metric that accounts for detection errors. While the initial detection performance is modest, the MLP's topology reasoning is strong, and the paper highlights several clear strengths and open challenges.",
      "strengths": [
        "Innovative detection‑reasoning pipeline separating object detection from topology reasoning.",
        "Adaptive evaluation metric (adjusted TOP) that better reflects topology reasoning performance.",
        "Demonstrates that a simple MLP can effectively learn lane geometry and topology, challenging the need for complex architectures."
      ],
      "weaknesses": [
        "Initial detection performance is low, leading to lower TOP_ll scores.",
        "Assumes perfect detection, which may overestimate topology reasoning capabilities.",
        "Lane geometry is represented with Bezier curves, potentially limiting handling of complex lane shapes."
      ],
      "questions": [
        "Why do the initial TOP_ll scores, especially for lane‑lane topology, appear low?",
        "How does the adjusted TOP metric differ from the original TOP metric, and what are its implications?",
        "What are the main advantages of using YOLOv8 object detection proposals over directly using YOLOv8 features?",
        "What are the limitations of using Bezier curves for lane geometry representation?",
        "What are the open challenges or next steps identified in the paper, particularly regarding feature alignment and large language model integration?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0GZ1Bq4Tfr",
    "title": "",
    "std_review": {
      "summary": "The paper introduces Real-Time Weight Decay (RWD), a modification to standard weight decay that applies the regularization term during gradient updates, addressing the 'delay defect' where weight decay is computed before updates. Empirical results on CIFAR datasets show improved convergence and robustness with RWD, and enhanced stability and performance with a combined LPWD method. Theoretical explanations and practical relevance across various models are well-documented, though some concerns about scope and statistical rigor remain.",
      "strengths": [
        "Innovative approach to weight decay addressing known issues.",
        "Comprehensive empirical validation across multiple datasets and model architectures.",
        "Solid theoretical insights into the delay defect and its impact on performance."
      ],
      "weaknesses": [
        "Limited scope to image classification tasks on CIFAR datasets.",
        "Lack of statistical rigor, with no error bars or additional runs with different seeds.",
        "Potential for overfitting, especially with larger models."
      ],
      "questions": [
        "How does RWD perform on non‑image tasks or larger model architectures beyond CIFAR?",
        "What additional experiments could address the statistical significance of the reported results?",
        "Could the authors explore regularization against overfitting in larger models?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0H6DFoZZXZ",
    "title": "Language Control Diffusion: Efficiently Scaling through Space, Time, and Tasks",
    "std_review": {
      "summary": "The paper introduces LCD, a method for text-to-video generation that combines a well-trained HULC baseline with a diffusion-based low-level policy. It leverages a large textual encoder like T5-XXXL to capture complex textual information, achieving competitive results on the CALVIN benchmark. While promising, the method's reliance on a specific HULC baseline and the computational cost of large encoders are significant concerns.",
      "strengths": [
        "Integrates a well-trained HULC baseline with a diffusion-based LLP for high-quality video generation.",
        "Uses a large textual encoder (T5-XXXL) to enhance video generation accuracy.",
        "Evaluates performance on the CALVIN benchmark, providing a controlled evaluation environment."
      ],
      "weaknesses": [
        "Performance heavily depends on a well-trained HULC baseline, which may not be easily transferable.",
        "Computational cost of using large textual encoders like T5-XXXL could be a bottleneck.",
        "The CALVIN benchmark may limit the method's generalizability to real-world scenarios."
      ],
      "questions": [
        "How does the method perform on more diverse benchmarks beyond CALVIN?",
        "What are the trade-offs between using large textual encoders and alternative encoders like CLIP?",
        "How can the reliance on a specific HULC baseline be mitigated for broader applicability?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "0i6Z9N5MLY",
    "title": "Variance Reduced Halpern Iteration",
    "std_review": {
      "summary": "The paper introduces two novel variance‑reduced algorithms for monotone operator problems, offering theoretical improvements and new convergence bounds. While the algorithms are well‑analyzed and demonstrate practical benefits, some implementation details remain unclear, and the choice of a non‑standard base estimator for convex problems is less conventional. Overall, the work is technically valuable but requires further clarification and practical validation.",
      "strengths": [
        "Innovative use of the PAGE optimizer for variance reduction.",
        "Provides new convergence bounds and analyses for monotone operator problems.",
        "Introduces an anchoring mechanism in Algorithm 2 for handling non‑monotone operators."
      ],
      "weaknesses": [
        "Unconventional choice of PAGE as the base estimator for convex problems.",
        "Lack of detailed explanation for the relationship between Lipschitz constants.",
        "Presence of logarithmic factors in convergence bounds without clear justification.",
        "Inner‑loop stopping criteria are not fully justified.",
        "Limited practical examples demonstrating the generality of the co‑monotone property."
      ],
      "questions": [
        "Clarify the rationale for selecting PAGE as the base estimator for convex problems.",
        "Provide a detailed explanation of the relationship between Lipschitz constants L and LF.",
        "Explain the source of logarithmic factors in the convergence bounds.",
        "Justify the inner‑loop stopping criteria without explicit computation of the exact solution.",
        "Include more complex examples of non‑monotone but co‑monotone operators."
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "0IaTFNJner",
    "title": "On the Embedding Collapse When Scaling up Recommendation Models",
    "std_review": {
      "summary": "The paper introduces a novel multi-embedding approach to tackle the information abundance problem in multi-embedding learning for text classification. It combines multiple embeddings into a single representation to capture diverse information, achieving state-of-the-art results on benchmark datasets. While promising, the approach relies on a heuristic method, lacks a detailed theoretical foundation, and has limited experimental validation across domains.",
      "strengths": [
        "Introduces a novel multi-embedding approach that effectively addresses the information abundance problem in ME.",
        "Provides extensive experiments on multiple benchmark datasets demonstrating superior performance.",
        "Offers a comprehensive analysis comparing the proposed method with existing ME methods."
      ],
      "weaknesses": [
        "Relies on a heuristic method to combine embeddings, which may not always yield optimal results.",
        "Limited experiments on a few benchmark datasets may restrict generalizability.",
        "Lacks a thorough analysis of computational complexity for large-scale applications.",
        "Fails to provide a detailed theoretical discussion of the approach's foundations."
      ],
      "questions": [
        "How is information abundance formally defined and quantified in the context of multi-embedding learning?",
        "What is the computational complexity of the proposed approach, especially for large-scale applications?",
        "How does the proposed method compare to existing ME methods in terms of theoretical underpinnings?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "0j9ZDzMPqr",
    "title": "UNR-Explainer: Counterfactual Explanations for Unsupervised Node Representation Learning Models",
    "std_review": {
      "summary": "UNR-Explainer introduces a Monte Carlo Tree Search (MCTS) method for generating interpretable subgraph explanations of GNN predictions. The approach is innovative and provides domain-specific insights, but its performance varies across datasets and is sensitive to parameter choices. While it shows promise, its computational cost and limited empirical comparison with other methods raise concerns about its scalability and relative effectiveness.",
      "strengths": [
        "Introduces a novel MCTS-based approach for generating interpretable subgraph explanations.",
        "Provides domain-relevant insights through graph-specific subgraph outputs.",
        "Offers flexibility in perturbation levels to tailor explanations to application needs."
      ],
      "weaknesses": [
        "High computational cost due to MCTS, especially for large graphs.",
        "Performance is sensitive to parameter choices like subgraph size and perturbation level.",
        "Lacks comprehensive comparison with state-of-the-art explanation methods."
      ],
      "questions": [
        "How can the computational efficiency of UNR-Explainer be improved for large-scale graphs?",
        "What strategies can be employed to reduce parameter sensitivity and automate tuning?",
        "How does UNR-Explainer perform in more controlled synthetic settings compared to other methods?"
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "0jHkUDyEO9",
    "title": "Magic123: One Image to High-Quality 3D Object Generation Using Both 2D and 3D Diffusion Priors",
    "std_review": {
      "summary": "The paper presents a novel approach for generating high-quality 2D images conditioned on textual descriptions using a 2D Stable Diffusion model with textual inversion. It demonstrates significant improvements in image quality and alignment with textual inputs compared to existing methods. The method also shows robustness in handling scenes without explicit object segmentation. While the paper provides a strong rationale and demonstrates superior performance, further analysis of computational efficiency and the trade-offs between textual inversion and DreamBooth is suggested.",
      "strengths": [
        "Introduces a novel integration of textual inversion with 2D Stable Diffusion, enhancing image fidelity to textual descriptions.",
        "Demonstrates superior performance in generating high-quality images with improved alignment to textual inputs.",
        "Explores robustness in handling scenes without explicit object segmentation, showcasing versatility."
      ],
      "weaknesses": [
        "Lacks detailed analysis of computational efficiency compared to existing methods.",
        "Does not thoroughly examine trade-offs between textual inversion and DreamBooth for conditioning.",
        "Performance on a broader range of complex backgrounds could be further validated."
      ],
      "questions": [
        "How does the method perform on a wider variety of complex backgrounds beyond those tested?",
        "What is the computational efficiency of the proposed approach relative to existing methods?",
        "What are the optimal trade-offs between textual inversion and DreamBooth for different conditioning scenarios?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0JnaN0Crlz",
    "title": "Enhancing Adversarial Robustness on Categorical Data via Attribution Smoothing",
    "std_review": {
      "summary": "The paper introduces IGSG, a novel method to enhance adversarial robustness on categorical data by leveraging attribution smoothing. It provides a theoretical framework and demonstrates empirical effectiveness across multiple datasets. While addressing a significant gap, the paper could improve its theoretical discussion and real-world evaluation. Overall, the contribution is strong and deserving of acceptance.",
      "strengths": [
        "Introduces a novel approach to improve adversarial robustness on categorical data, addressing a significant gap in existing literature.",
        "Provides a theoretical foundation for the proposed IGSG regularization technique, relating it to adversarial risk bounds.",
        "Demonstrates empirical effectiveness of IGSG through extensive experiments on multiple datasets.",
        "Offers a clear and concise explanation of the method, making it accessible to a broad audience."
      ],
      "weaknesses": [
        "The paper lacks a detailed discussion of the theoretical underpinnings of IGSG, which could be more convincing to readers.",
        "The evaluation section could benefit from a more comprehensive analysis of the limitations and challenges of applying IGSG to real-world scenarios.",
        "The paper does not provide a thorough comparison with state-of-the-art methods in the field of adversarial robustness for categorical data."
      ],
      "questions": [
        "Could you provide a more detailed theoretical analysis of the convergence properties of IGSG?",
        "What are the practical considerations for tuning the regularization parameters in real-world applications?",
        "How does IGSG perform when applied to high-dimensional categorical data with a large number of categories?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0jsfesDZDq",
    "title": "Sparse Spiking Neural Network: Exploiting Heterogeneity in Timescales for Pruning Recurrent SNN",
    "std_review": {
      "summary": "The paper introduces Lyapunov Noise Pruning (LNP), a task-agnostic pruning method for recurrent spiking neural networks (RSNNs) that leverages Lyapunov noise to achieve efficient pruning. The authors demonstrate its effectiveness on several datasets, showing improvements in sparsity, accuracy, and computational efficiency. While the method shows promise for neuromorphic computing, the review highlights the need for clearer explanations of the Lyapunov noise concept and more comprehensive comparisons with existing techniques.",
      "strengths": [
        "Introduces a novel task-agnostic pruning method for RSNNs, addressing the need for efficient and adaptable pruning techniques.",
        "Proposes Lyapunov Noise Pruning (LNP), a unique approach that leverages Lyapunov noise to prune RSNNs, setting it apart from conventional pruning methods.",
        "Demonstrates the effectiveness of the LNP method through experiments on various datasets and compares its performance with state-of-the-art pruning techniques."
      ],
      "weaknesses": [
        "Lacks a detailed explanation of the Lyapunov noise concept and its application in the pruning process, making it difficult for readers to fully understand the novelty and effectiveness of the LNP method.",
        "Experimental evaluation is limited to a few datasets and tasks, which may not be representative of the broader range of applications for RSNNs.",
        "Does not provide a comprehensive comparison with other existing pruning approaches for spiking neural networks.",
        "Lacks discussion on the potential limitations and challenges of implementing the LNP method in real-world scenarios."
      ],
      "questions": [
        "Can you provide a more detailed explanation of how Lyapunov noise is generated and applied in the pruning process?",
        "How does the LNP method perform on a broader range of datasets and tasks beyond those evaluated in the current study?",
        "Could you compare the LNP method with other state-of-the-art pruning approaches for spiking neural networks to better assess its relative strengths and weaknesses?",
        "What are the potential limitations and challenges of implementing the LNP method in real-world neuromorphic computing applications?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0JsRZEGZ7L",
    "title": "From Latent graph to Latent Topology Inference: Differentiable Cell Complex Module",
    "std_review": {
      "summary": "The paper introduces Directed Community Matching (DCM), a GNN architecture that enhances community detection in graphs, especially in heterophilic settings. DCM leverages directed edges and a novel similarity measure with community-based attention to improve node representation and community separation. Experimental results show strong performance over existing baselines across synthetic and real-world datasets, indicating robustness and versatility. While the theoretical foundation is solid, the paper could improve by addressing equation complexity, conducting ablation studies, and exploring directed complexes.",
      "strengths": [
        "Introduces a novel GNN architecture that effectively captures community structures using directed edges.",
        "Provides a strong theoretical foundation with clear mathematical formulations.",
        "Demonstrates superior performance over existing baselines across diverse datasets."
      ],
      "weaknesses": [
        "Complex mathematical formulations may be challenging for readers without advanced graph theory knowledge.",
        "Lacks ablation studies to evaluate the impact of key hyperparameters.",
        "Limited discussion on adapting the approach for directed complexes.",
        "Benchmarking against the latest advancements in community detection is not comprehensive."
      ],
      "questions": [
        "Could you provide a more detailed ablation study on the impact of the edge assignment threshold and parameter α?",
        "What are the specific modifications needed to adapt DCM for directed complexes?",
        "How does DCM perform when benchmarked against the most recent state-of-the-art methods in community detection?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0JTwZ30qPH",
    "title": "Task-Oriented Multi-View Representation Learning",
    "std_review": {
      "summary": "The paper introduces TOMRL, a novel few-shot learning approach that combines meta-learning with multi-view learning to generate task-specific biases and fuse them, improving performance on benchmark datasets. The method effectively addresses overfitting with limited data and demonstrates strong results compared to existing techniques. However, its generalizability could be better assessed across more diverse datasets, and the implementation complexity and hyperparameter sensitivity are areas for improvement. Overall, the paper makes a valuable contribution to few-shot learning.",
      "strengths": [
        "Introduces a novel approach to few-shot learning by combining meta-learning with multi-view learning.",
        "Effectively addresses the challenge of overfitting in limited sample scenarios.",
        "Demonstrates improved performance on benchmark datasets compared to existing methods.",
        "Provides a clear and structured methodology for task-specific bias generation and fusion."
      ],
      "weaknesses": [
        "Limited evaluation on a diverse set of datasets may not fully capture the method's generalizability.",
        "The complexity of the proposed method could make it challenging to implement and optimize in practice.",
        "Lack of detailed analysis on the impact of different hyperparameters on the model's performance.",
        "The paper could benefit from a more thorough discussion of potential limitations and future research directions."
      ],
      "questions": [
        "How does TOMRL perform on a broader range of datasets beyond the current benchmarks?",
        "What are the specific hyperparameter sensitivities of TOMRL, and how can they be optimized?",
        "Could the method be extended to handle more complex multi-task learning scenarios?",
        "What are the long-term implications of TOMRL's approach for lifelong learning frameworks?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0JWVWUlobv",
    "title": "4D Tensor Multi-task Continual Learning for Disease Dynamic Prediction",
    "std_review": {
      "summary": "The paper introduces a 4D tensor representation of MRI biomarkers for Alzheimer's disease progression, integrated into a continual learning framework. It demonstrates significant improvements over baselines on the ADNI dataset, offering valuable insights into biomarker correlations. While promising, the paper could improve by clarifying theoretical aspects and providing more comprehensive comparisons.",
      "strengths": [
        "Novel 4D tensor representation captures spatio-temporal MRI information effectively.",
        "Continual learning framework integrates and shares information across tasks, crucial for sequential AD data.",
        "Comprehensive experimental setup on ADNI dataset with clear data handling and evaluation metrics."
      ],
      "weaknesses": [
        "Lacks detailed discussion on specific biomarkers and their relevance to AD.",
        "Theoretical underpinnings of the continual learning approach are not fully explained.",
        "Experimental setup could benefit from more discussion on data preprocessing and potential biases.",
        "Evaluation results are presented qualitatively; quantitative comparison with state-of-the-art methods would strengthen the paper.",
        "Generalization to other datasets or tasks is not fully addressed."
      ],
      "questions": [
        "What is the specific rationale behind the choice of biomarkers used in the study and their relevance to AD progression?",
        "How does the proposed continual learning approach differ from other methods, and what are its theoretical foundations?",
        "Could you provide more details on the data preprocessing steps and any potential biases in the ADNI dataset?",
        "What quantitative metrics or benchmarks are used to compare the proposed approach with state-of-the-art methods?",
        "How does the model generalize to other datasets or tasks beyond the ADNI dataset, and what further validation is needed?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0KVkTDB6KZ",
    "title": "EFFL: Egalitarian Fairness in Federated Learning for Mitigating Matthew Effect",
    "std_review": {
      "summary": "The paper proposes EFFL, a framework that integrates fairness constraints directly into federated learning, balancing accuracy and fairness through a novel objective. It demonstrates strong empirical performance on both synthetic and real-world datasets, achieving equitable outcomes without significant accuracy loss. While addressing a critical gap in FL research, the paper acknowledges challenges such as parameter sensitivity and assumptions on smoothness and convexity, which may affect practical deployment.",
      "strengths": [
        "Innovative integration of fairness constraints into federated learning.",
        "Strong theoretical foundation with a rigorous mathematical formulation.",
        "Empirical validation across multiple datasets showing practical effectiveness."
      ],
      "weaknesses": [
        "Parameter sensitivity to fairness parameters may require extensive tuning.",
        "Assumes smoothness and convexity of loss functions, limiting generalizability.",
        "Communication overhead of enforcing fairness is not fully analyzed."
      ],
      "questions": [
        "How can the optimal values of fairness parameters be determined in practice?",
        "What are the scalability implications of enforcing fairness constraints in large-scale FL systems?",
        "How can the approach be extended to handle non-binary target variables?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0kvrymILfy",
    "title": "Making Predictors More Reliable with Selective Recalibration",
    "std_review": {
      "summary": "The paper presents a novel approach to enhance deep neural network robustness against out‑of‑distribution samples by combining confidence‑based rejection with a recalibration step. It introduces the R‑ECE metric to evaluate the method and demonstrates its effectiveness on ImageNet and Camelyon17 datasets. The authors argue that their method significantly improves calibration and robustness in OOD settings, though some details in the implementation and evaluation are not fully clarified.",
      "strengths": [
        "Innovative combination of confidence‑based rejection with recalibration to address learned confidence score limitations.",
        "Clear and precise definition of the R‑ECE metric, facilitating evaluation of the proposed method.",
        "Empirical results on challenging datasets under OOD conditions provide strong evidence of method effectiveness."
      ],
      "weaknesses": [
        "Ambiguity in Figure 1 regarding the interpretation of the blue and green curves.",
        "Multiple curves for non‑selected cases in Figure 1 are confusing and could be simplified.",
        "R‑ECE metric definition and computation are not fully detailed in the main text, relying on the appendix.",
        "Lack of detailed explanation in the appendix for the ECE calculations, affecting reproducibility."
      ],
      "questions": [
        "Could you clarify the exact criteria used for the selection function in Figure 1 and how it distinguishes between different groups?",
        "Why are multiple curves shown for non‑selected cases in Figure 1, and would a single baseline curve be more interpretable?",
        "Please provide a more detailed definition and computation of the R‑ECE metric, including any specific binning or notation used.",
        "Could you elaborate on the ECE calculations in the appendix, particularly the spacing and assumptions made?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0kWd8SJq8d",
    "title": "MInde: Mutual Information Neural Diffusion Estimation",
    "std_review": {
      "summary": "The paper introduces MINDE, a novel generative model that effectively estimates probability distributions using neural networks. It compares MINDE's performance to classic estimators like DoE and GM, as well as a related work, demonstrating its high-quality sample generation and competitive accuracy. While noting training and computational costs, the paper highlights its practical applicability and offers insights for future research.",
      "strengths": [
        "Introduces a novel generative model (MINDE) that effectively estimates probability distributions using neural networks.",
        "Provides a thorough comparison of MINDE's performance against classic generative estimators and a related work.",
        "Demonstrates the ability of MINDE to generate high-quality samples, showcasing its practical applicability."
      ],
      "weaknesses": [
        "Lacks a detailed explanation of the specific differences between MINDE and the work in [3].",
        "The training process for MINDE may be computationally expensive, potentially limiting its applicability in resource-constrained environments.",
        "Does not provide a comprehensive analysis of the memory requirements for training and inference."
      ],
      "questions": [
        "Can you elaborate on the specific architectural and estimation differences between MINDE and the work in [3]?",
        "What are the detailed memory and computational requirements for training and inference with MINDE?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0Lqyut1y7M",
    "title": "On the Optimality of Activations in Implicit Neural Representations",
    "std_review": {
      "summary": "The paper investigates the use of sinc activation functions in integral neural representations (INRs) and demonstrates that a 2-layer network with sinc activation can form a Riesz basis under mild conditions, which is crucial for stable and accurate signal reconstruction. It also explores the interaction between sinc activations and sinusoidal positional encodings, showing potential performance benefits. However, the theoretical analysis is limited to 2-layer networks, and the claim of sinc's optimality is not fully substantiated. The paper contributes to understanding activation functions in INRs but has several limitations regarding generalization to deeper architectures and the lack of a clear definition of optimality.",
      "strengths": [
        "Provides a rigorous theoretical analysis of sinc activation functions in INRs.",
        "Introduces a novel interaction between sinc activations and sinusoidal positional encodings.",
        "Validates theoretical claims with experiments demonstrating practical utility."
      ],
      "weaknesses": [
        "Theoretical analysis limited to 2-layer networks.",
        "Claim of sinc optimality is not fully substantiated.",
        "Does not explore potential failure modes of sinc activation.",
        "Interaction with other positional encodings is not thoroughly investigated."
      ],
      "questions": [
        "How do the theoretical guarantees of sinc activations extend to deeper INR architectures?",
        "What is the formal definition and proof of sinc activation optimality in INRs?",
        "How do sinc activations interact with other types of positional encodings?",
        "What are the potential failure modes of sinc in practical applications?"
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "0lW9cDUtf8",
    "title": "",
    "std_review": {
      "summary": "The paper introduces FairReweighing, a method that enhances fairness in regression by ensuring separation fairness (Y ⟂ A|Y) through kernel density estimation or radius-neighbor density estimation in preprocessing. It provides strong theoretical guarantees and empirical validation on real-world datasets, showing improved fairness metrics alongside competitive regression performance. While innovative, the method has complexity in parameter selection and limited baseline comparisons, and edge cases are not fully addressed.",
      "strengths": [
        "Innovative integration of KDE/RND with reweighting for direct fairness mitigation.",
        "Clear theoretical foundation ensuring separation fairness.",
        "Empirical validation on real-world datasets bridging theory and practice."
      ],
      "weaknesses": [
        "Complexity in selecting optimal bandwidth or radius for KDE/RND.",
        "Lack of detailed theoretical guarantees on convergence rate.",
        "Limited baseline comparisons may overlook other state-of-the-art methods.",
        "Edge cases like low-frequency protected groups are not exhaustively addressed."
      ],
      "questions": [
        "How does FairReweighing handle scenarios with highly imbalanced protected groups?",
        "What are the theoretical guarantees on the convergence rate of the separation metric in large datasets?",
        "How does the method perform when applied to high-dimensional data with many correlated features?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0NruoU6s5Z",
    "title": "CompoDiff: Versatile Composed",
    "std_review": {
      "summary": "CompoDiff introduces a novel approach to image retrieval by dynamically generating text prompts with CLIP to better match query images, especially in complex scenes with multiple objects. The method shows significant improvements over baselines and introduces learnable text prompts for flexible retrieval. While promising, practical implementation challenges and the need for further analysis of trade-offs are noted.",
      "strengths": [
        "Innovative use of CLIP to generate dynamic text prompts.",
        "Improved retrieval accuracy, particularly for complex scenes.",
        "Flexible learnable text prompts enhance retrieval performance."
      ],
      "weaknesses": [
        "Potential computational complexity and resource demands.",
        "Lack of detailed analysis of trade-offs between accuracy and efficiency.",
        "Limited evaluation datasets may not fully capture method's performance."
      ],
      "questions": [
        "How does the method address computational complexity in real-time applications?",
        "What is the impact of overfitting with learnable text prompts?",
        "How robust is the method across diverse datasets and scenarios?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0Nui91LBQS",
    "title": "",
    "std_review": {
      "summary": "The paper introduces SEED, a tokenizer that integrates visual information into large language models (LLMs) by converting images into discrete visual tokens. It leverages a pre-trained CLIP-ViT encoder, a Causal Q‑Former for token optimization, and a VQ codebook, trained with contrastive and causal losses. SEED shows strong performance on image-text retrieval benchmarks and scales well with larger LLMs, though it has training complexity and limited video handling. The reviewer accepts the paper, highlighting its innovative approach and strong performance.",
      "strengths": [
        "Innovative tokenization approach for seamless visual‑text integration",
        "Effective training objectives enabling robust multimodal learning",
        "Strong performance on image‑text benchmarks",
        "Scalable across different LLM sizes"
      ],
      "weaknesses": [
        "Complex training process requiring significant computational resources",
        "Evaluation using CLIP similarity may not fully capture image generation nuances",
        "Scalability concerns with discrete visual tokens compared to continuous embeddings",
        "Limited discussion on handling video data"
      ],
      "questions": [
        "How does SEED's performance compare to continuous visual embeddings in terms of expressiveness and scalability?",
        "What are the specific challenges in scaling SEED to extremely large model sizes, and how can they be addressed?",
        "How does the choice between causal and bilateral visual codes impact downstream multimodal tasks?",
        "What future work could explore SEED's application to video data and other complex multimodal scenarios?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0oIkKERYhH",
    "title": "DOG: Discriminator-only Generation",
    "std_review": {
      "summary": "The paper introduces DOG, a discriminator‑only method for generating graph data that iteratively refines structures using a discriminator network. DOG outperforms existing models like SPECTRE and diffusion approaches on several benchmarks, showing improved sample quality and faster training times. Theoretical insights and empirical evidence support DOG's effectiveness, especially in handling the discrete nature of graph data. Overall, the paper is well‑structured and makes a strong case for its approach.",
      "strengths": [
        "Simplicity and Efficiency: Uses only a discriminator, eliminating generator complexities.",
        "Improved Sample Quality: Iterative refinement yields higher quality graph samples.",
        "Faster Training: Focuses on discriminator updates, achieving significant speed gains."
      ],
      "weaknesses": [
        "Limited Generalization: May struggle with certain graph properties or structures.",
        "Training Instability: Iterative processes can be unstable if discriminator is too strong/weak.",
        "Lack of Flexibility: May require modifications for diverse graph types."
      ],
      "questions": [
        "How does DOG perform on very large or sparse graphs compared to dense ones?",
        "Can DOG be extended to handle dynamic graphs where nodes/edges change over time?",
        "What are the theoretical guarantees for convergence and sample diversity?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0Pu0H7y3gg",
    "title": "Understanding the Initial Condensation of Convolutional Neural Networks",
    "std_review": {
      "summary": "The paper introduces a novel theoretical framework explaining the initial condensation of neural network parameters along specific eigendirections of the Fisher information matrix. It derives a time estimate for when this condensation occurs and validates the findings with experiments on networks with suboptimal performance. While the theoretical insights are valuable, the practical relevance is limited by the use of low‑performing networks and the reliance on specific assumptions.",
      "strengths": [
        "Novel theoretical framework that relaxes Assumption 4 to provide a more nuanced understanding of condensation.",
        "Clear and rigorous mathematical derivation of the time estimate for when condensation occurs.",
        "Empirical validation of theoretical predictions, despite using networks with suboptimal performance."
      ],
      "weaknesses": [
        "Limited network performance in experiments may restrict the practical applicability of the findings.",
        "Theoretical results depend on specific assumptions that are not fully explored for robustness.",
        "The role of activation functions in parameter dynamics is not fully addressed.",
        "The necessity of a supremum in the theorem raises questions about the completeness of the condensation analysis."
      ],
      "questions": [
        "How robust are the theoretical results to variations in network architecture and training conditions?",
        "What is the impact of activation functions on the time derivatives of parameters during condensation?",
        "Can the framework be extended to adaptive optimizers like Adam without additional assumptions?",
        "How does the condensation phenomenon manifest in initial layer weight initialization?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0Q1mBvUgmt",
    "title": "VIPER: Vibrant Period Representation for Robust and Efficient Time Series Forecasting",
    "std_review": {
      "summary": "The paper introduces TimesNet, a novel architecture that combines convolutional and attention mechanisms to capture both intraperiod-variation and interperiod-variation in time series data. While the model shows competitive performance on benchmark datasets, the paper suffers from unclear explanations of key equations and inconsistent results compared to the original findings. The modest improvement in MSE reported may not justify the complexity of the proposed block.",
      "strengths": [
        "Introduces a novel architecture that explicitly models both intraperiod-variation and interperiod-variation in time series data.",
        "Combines convolutional and attention mechanisms to capture local and global patterns in the data.",
        "Provides a clear and interpretable framework for understanding how the model processes time series data."
      ],
      "weaknesses": [
        "The purpose of the 'Avg' in Equation (1) is not clearly explained.",
        "The representation of Equation (3) lacks clarity regarding which axis the attention operation is performed on.",
        "The paper does not provide a clear explanation of how the proposed representation block captures intraperiod-variation and interperiod-variation separately.",
        "The results presented in Table 2 are inconsistent with the original paper.",
        "The reported Avg results in Table 3 are incorrect, and the proposed block only yields a slight 2.9% improvement in MSE."
      ],
      "questions": [
        "How does the 'Avg' operation in Equation (1) contribute to the model's ability to capture intraperiod-variation and interperiod-variation?",
        "Could you clarify the axis on which the attention operation in Equation (3) is performed?",
        "What specific mechanisms does the proposed representation block use to separate intraperiod-variation and interperiod-variation?",
        "Are the inconsistencies in the reported results in Table 2 due to implementation differences or other factors?"
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "0QAzIMq32X",
    "title": "Inner Classifier-Free Guidance and Its Taylor Expansion for Diffusion Models",
    "std_review": {
      "summary": "The paper introduces a second-order inference guidance framework for diffusion models, enhancing consistency and image quality on the COCO dataset. While theoretically sound with necessary and sufficient conditions, the approach lacks comprehensive validation across multiple datasets and detailed analysis of computational efficiency compared to first-order methods. The reviewer finds the method promising but recommends further work to address these concerns.",
      "strengths": [
        "Introduces a novel second-order inference guidance method that enhances consistency and image quality.",
        "Provides a rigorous theoretical foundation with necessary and sufficient conditions.",
        "Demonstrates substantial improvements on the COCO dataset, showcasing practical benefits."
      ],
      "weaknesses": [
        "Empirical validation is limited to the COCO dataset, which may not fully demonstrate general applicability.",
        "Theoretical analysis does not fully address hyperparameter sensitivity and computational cost comparisons.",
        "Selective application of the second-order ICFG lacks detailed quantitative speedup analysis."
      ],
      "questions": [
        "Can the method be validated on additional datasets beyond COCO to demonstrate broader applicability?",
        "What is the detailed computational cost comparison between the second-order ICFG and first-order methods?",
        "How does the method perform with different hyperparameters, and what tuning strategies are recommended?"
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "0Qyxw0cCuu",
    "title": "Control: A Contrastive Learning Framework",
    "std_review": {
      "summary": "CONTROL presents a novel framework for open-world semi-supervised learning (OWSSL) by introducing three contrastive learning objectives to separate seen and unseen class features at the feature level. The approach significantly outperforms existing OWSSL methods and even improves traditional semi-supervised learning algorithms. While theoretically justified, the framework's high sensitivity to hyperparameters and lack of comprehensive theoretical guarantees are noted as areas for improvement.",
      "strengths": [
        "Introduces three distinct contrastive learning objectives to effectively separate seen and unseen class features.",
        "Optimizes at the feature level, providing a theoretically justified approach that improves performance.",
        "Demonstrates strong empirical performance across various benchmarks compared to state-of-the-art OWSSL methods."
      ],
      "weaknesses": [
        "High sensitivity to hyperparameter choices may limit practical deployment.",
        "Lacks comprehensive theoretical guarantees beyond the feature-level optimization rationale.",
        "Comparison with a broader range of baselines could strengthen the argument for generality."
      ],
      "questions": [
        "How robust is CONTROL's performance when applied to datasets with highly imbalanced class distributions?",
        "What is the impact of feature-level optimization on the interpretability of the learned representations compared to logits-level optimization?",
        "Can CONTROL's approach be extended to other learning paradigms, such as unsupervised or few-shot learning, without significant modifications?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0S0CgZEYxR",
    "title": "Examining the Achilles' Heel of CLIP Models: The Worst-Performing Categories",
    "std_review": {
      "summary": "The paper introduces a method to improve zero-shot image classification by dynamically generating enriched prompts for the worst‑performing categories using a Class‑wise Matching Margin (CMM) metric. It fine‑tunes a CLIP model with these prompts and shows significant accuracy gains on the targeted categories. While promising, the method's robustness and general applicability are limited by the lack of labeled validation data, unclear prompt application, and limited comparison to other models.",
      "strengths": [
        "Innovative prompt enrichment approach for zero‑shot classification",
        "Clear and reproducible evaluation framework using CMM",
        "Empirical results demonstrating substantial accuracy improvements"
      ],
      "weaknesses": [
        "Relies on pseudo‑labeling without labeled validation data",
        "Enriched prompts applied uniformly across categories",
        "Limited comparison to other zero‑shot/few‑shot approaches"
      ],
      "questions": [
        "How reliable are the pseudo‑labels generated without labeled validation data?",
        "Could the method be adapted to generate category‑specific prompts?",
        "What is the impact of enriched prompts on categories beyond the worst‑10?",
        "How does the approach compare to other visual‑language models?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "0sbIEkIutN",
    "title": "From Interpolation to Extrapolation: Complete Length Generalization for Arithmetic Transformers",
    "std_review": {
      "summary": "The paper introduces Attention Bias Calibration (ABC), a technique that enforces diagonal attention patterns in transformers to improve arithmetic reasoning. Experiments show strong performance on standard arithmetic benchmarks, indicating practical effectiveness. However, the method's strong inductive bias may limit its generalization to more complex tasks and natural language processing, and it could suffer from overfitting and added implementation complexity.",
      "strengths": [
        "Targeted improvement on arithmetic tasks by enforcing diagonal attention.",
        "Clear theoretical motivation for why diagonal attention benefits sequential reasoning.",
        "Empirical success on benchmark arithmetic datasets."
      ],
      "weaknesses": [
        "Limited generalization to non-linear or complex reasoning tasks.",
        "Potential overfitting due to strict diagonal attention enforcement.",
        "Increased implementation complexity and potential computational overhead."
      ],
      "questions": [
        "How does ABC perform on non-arithmetic reasoning tasks or more complex benchmarks?",
        "What is the impact of the strong inductive bias on the model's ability to generalize beyond linear sequences?",
        "Could relaxing the diagonal bias improve performance on non-monotonic tasks?"
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "0sO2euxhUQ",
    "title": "Learning Latent Structural Causal Models",
    "std_review": {
      "summary": "The paper introduces a method for learning latent structural causal models (SCMs) by inferring latent weight matrices and estimating latent Gaussian noises using interventions. Experiments on synthetic and image datasets demonstrate the method's effectiveness, showing strong performance in causal accuracy and noise estimation. While the method shows promise, its theoretical guarantees and scalability are not fully established, and practical challenges in real-world applications remain unexplored.",
      "strengths": [
        "Provides a systematic approach to learning latent SCMs, addressing key identifiability issues.",
        "Leverages interventions to infer latent structures, enhancing robustness.",
        "Demonstrates practical applicability and effectiveness through experiments on synthetic and image datasets."
      ],
      "weaknesses": [
        "Lacks comprehensive theoretical guarantees for learning latent SCMs.",
        "Scalability with respect to nodes and interventions is not thoroughly addressed.",
        "Practical challenges in applying the method to real-world scenarios are not fully explored."
      ],
      "questions": [
        "What are the theoretical guarantees for learning latent SCMs with this method?",
        "How does the method scale with the number of nodes and interventions?",
        "What are the practical challenges in applying the method to real-world scenarios?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0SOhDO7xI0",
    "title": "DeepDRK: Deep Dependency Regularized Knockoff for Feature Selection",
    "std_review": {
      "summary": "DeepDRK introduces a novel method that combines SWC dependency regularization with a perturbation technique to control false discovery rate (FDR) and boost power in high-dimensional data. The approach uses a multi‑swapper adversarial training to enforce swap consistency, which improves robustness. Empirical results show superior performance over existing methods, especially in high-dimensional contexts, though the paper lacks high-dimensional simulations and could benefit from deeper explanations of the multi‑swapper and more ablation studies on the trade‑offs between FDR and power.",
      "strengths": [
        "Innovative combination of SWC dependency regularization with perturbation techniques.",
        "Effective multi‑swapper adversarial training enforces swap consistency.",
        "Comprehensive theoretical analysis of FDR and power guarantees."
      ],
      "weaknesses": [
        "Lack of high-dimensional simulations (p > n) limits practical validation.",
        "Complexity of the multi‑swapper could be better explained.",
        "Trade‑offs between FDR control and power improvement are not fully explored."
      ],
      "questions": [
        "Could additional high-dimensional simulations demonstrate the method's effectiveness in realistic settings?",
        "What are the detailed design and validation steps of the multi‑swapper adversarial training?",
        "Would ablation studies on the DRP term clarify the balance between FDR and power?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "0t1O8ziRZp",
    "title": "Retrieval-Guided Reinforcement Learning for Boolean Circuit Minimization",
    "std_review": {
      "summary": "The paper introduces ABC-RL, a retrieval-guided RL approach for Boolean circuit minimization that uses a GCN to compute similarity between circuit graphs. It leverages cosine similarity for retrieval, weighting the learned policy by these similarities to prioritize structurally similar but functionally distinct circuits. Experiments on the ISPD benchmark show improved performance over baseline RL methods, especially for functionally diverse yet structurally similar circuits. The method is innovative and scalable, though its scalability and computational trade-offs need further exploration.",
      "strengths": [
        "Innovative retrieval mechanism using GCN for similarity-based exploration.",
        "Improved performance on circuits with structural similarities but functional differences.",
        "Scalable architecture suitable for large benchmark datasets."
      ],
      "weaknesses": [
        "Limited evaluation on larger datasets may limit generalizability.",
        "Potential computational overhead from GCN depth and retrieval process.",
        "Risk of overfitting due to reliance on cosine similarity."
      ],
      "questions": [
        "How does the method scale with larger benchmark datasets?",
        "What alternative similarity metrics could improve retrieval quality beyond cosine similarity?",
        "What empirical evidence supports the scalability of ABC-RL with very large circuits?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0tsJ7Nv5hk",
    "title": "Harnessing Orthogonality to Train Low-Rank Neural Networks",
    "std_review": {
      "summary": "The paper introduces OIALR, a novel iterative low-rank training method that enhances stability and efficiency. It combines a full-rank training phase with a low-rank optimization step, achieving better performance and resource usage compared to traditional methods. The approach is demonstrated on transformers and other models, showing scalability and broad applicability, though implementation complexity and reliance on initial training are noted.",
      "strengths": [
        "Introduces a novel stability metric specific to low-rank training.",
        "Iterative refinement provides smoother convergence and improved stability.",
        "Demonstrates empirical superiority over baseline low-rank techniques and full-rank training.",
        "Shows significant reductions in memory usage and training time."
      ],
      "weaknesses": [
        "Implementation complexity due to additional computational overhead.",
        "Dependence on the quality of the initial full-rank training phase.",
        "Limited analysis for non-transformer models."
      ],
      "questions": [
        "How does OIALR perform on models with very large parameter counts beyond transformers?",
        "What are the theoretical guarantees on the stability metric defined for OIALR?",
        "How does the method scale with different batch sizes and learning rates?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0tWTxYYPnW",
    "title": "Understanding Hidden Context in Preference Learning: Consequences for RLHF",
    "std_review": {
      "summary": "The paper introduces Distributional Preference Learning (DPL), a method that models hidden context in preference data by assuming a single underlying utility function. DPL incorporates a regularization term to ensure the uniqueness of this utility function, allowing it to uncover hidden context such as population diversity or competing objectives. The method is demonstrated through case studies on competing objectives and risk‑sensitive optimization, showing effective preference learning. While innovative, the approach relies on simplifying assumptions and lacks comprehensive comparison with existing methods, raising questions about its scalability and robustness.",
      "strengths": [
        "Clear theoretical foundation with a rigorous mathematical framework.",
        "Practical relevance demonstrated through case studies on competing objectives and risk‑sensitive optimization.",
        "Innovative approach to modeling hidden context as a single underlying utility function."
      ],
      "weaknesses": [
        "Simplistic assumption of a single underlying utility function may not capture real‑world preference complexity.",
        "Limited quantile sensitivity analysis for the risk‑sensitive optimization.",
        "Lack of comprehensive comparison with other state‑of‑the‑art methods.",
        "Scalability concerns due to experiments on small datasets."
      ],
      "questions": [
        "How does the method handle preferences influenced by multiple, competing objectives or irrational behavior?",
        "What is the sensitivity of the 0.01 quantile choice in risk‑sensitive optimization to the results?",
        "How does DPL compare to other methods like clustering or annotator identity modeling in terms of scalability and robustness?",
        "What is the impact of the assumption of a single underlying utility function on the interpretability of the model?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "0TZs6WOs16",
    "title": "Hyperbolic Embeddings in Sequential Self-Attention for Improved Next-Item Recommendations",
    "std_review": {
      "summary": "The paper introduces Hyperbolic Sequential Self-Attention (HSASRec), a model that leverages hyperbolic embeddings to enhance sequential recommendation systems. It demonstrates superior performance over existing models like SASRec and BERT4Rec on several benchmark datasets, highlighting the practical benefits of hyperbolic embeddings. While the approach is innovative and theoretically sound, it faces challenges such as implementation complexity, parameter sensitivity, and scalability issues. Overall, the paper is well-received for its novel approach and strong empirical results.",
      "strengths": [
        "Innovative use of hyperbolic geometry for sequential recommendation",
        "Demonstrated superior performance over state-of-the-art models",
        "Provides a solid theoretical foundation for hyperbolic embeddings"
      ],
      "weaknesses": [
        "Implementation complexity and optimization challenges",
        "Sensitivity to hyperbolic space parameters",
        "Potential scalability issues in large-scale systems"
      ],
      "questions": [
        "How can the model be adapted for datasets with non-hierarchical structures?",
        "What strategies can be employed to improve the scalability of hyperbolic models?",
        "How do the hyperbolic space parameters affect the model's performance in real-world scenarios?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0u9uvPdRgV",
    "title": "Semi-supervised Diffusion Solver for Travel-Ling Salesman Problem",
    "std_review": {
      "summary": "The paper presents a novel semi-supervised diffusion model for solving the Traveling Salesman Problem (TSP). It leverages a small set of labeled tours to guide the generation of high-quality tours from an unlabeled distribution, combining supervised and unsupervised losses. Empirical results demonstrate significant improvements over both unsupervised and supervised baselines on benchmark TSP instances. While the approach is theoretically motivated and empirically validated, some aspects such as clarity in the transition matrix interpretation and a more comprehensive comparison with unsupervised methods remain underexplored.",
      "strengths": [
        "Novel integration of semi-supervised learning with an unsupervised diffusion process.",
        "Clear theoretical motivation for the semi-supervised loss formulation.",
        "Empirical demonstrations showing strong performance and scalability.",
        "Use of a transition matrix to provide interpretable guidance for tour construction."
      ],
      "weaknesses": [
        "Ambiguity in the interpretation of the transition matrix.",
        "Lack of detailed comparison with other unsupervised methods.",
        "Absence of reproducibility details affecting verifiability.",
        "Unclear conditions under which the model can directly output a feasible solution."
      ],
      "questions": [
        "How can the transition matrix be interpreted more clearly to aid understanding?",
        "What is the impact of the semi-supervised approach on scalability from TSP-50 to TSP-1000?",
        "How does the proposed method compare with other state-of-the-art unsupervised TSP solvers?",
        "Under what conditions does the model output a feasible solution without a search step?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0uI5415ry7",
    "title": "Linear attention is (maybe) all you need",
    "std_review": {
      "summary": "The paper introduces a linearized Transformer as a simplified proxy for full attention Transformers, analyzing its optimization dynamics through noise distribution comparisons and theoretical insights. While it provides valuable empirical evidence and a framework for understanding similar behaviors, it lacks rigorous theoretical foundations and explores only a limited scope of non-linear tasks and data distributions. Overall, the work is promising but should address these limitations for broader impact.",
      "strengths": [
        "Introduces a linear Transformer as a useful proxy for studying full attention Transformers.",
        "Provides a detailed empirical analysis of stochastic‑gradient noise distributions using heavy‑tail indices and moments.",
        "Offers theoretical insights into why the linear model might exhibit similar optimization characteristics."
      ],
      "weaknesses": [
        "Lacks a rigorous theoretical explanation for the observed optimization behaviors.",
        "Limited exploration of non‑linear tasks and their impact on optimization dynamics.",
        "Focuses primarily on heavy‑tailed and Gaussian distributions, potentially missing broader applicability."
      ],
      "questions": [
        "What theoretical framework could rigorously explain the observed similarities between linear and full attention Transformers?",
        "How do the optimization dynamics of the linear model generalize to non‑linear tasks?",
        "What are the implications of the model's sensitivity to data distribution choices for real‑world applications?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "0upMDCx8AA",
    "title": "Post-Training Recovery from Injected Bias",
    "std_review": {
      "summary": "The paper introduces Bias-Conditioned Self-Influence (BCSI), a method that adapts self-influence to detect and mitigate spurious correlations in biased datasets. It shows strong empirical performance across various bias ratios and demonstrates robustness in post-training recovery. The approach is theoretically justified and outperforms existing methods, though its practical implementation and real-world applicability require further consideration.",
      "strengths": [
        "Innovative adaptation of self-influence to address bias.",
        "Clear theoretical foundation and justification.",
        "Comprehensive empirical validation across different bias scenarios."
      ],
      "weaknesses": [
        "Implementation complexity due to bias conditioning.",
        "Assumes availability of reliable bias scores.",
        "Limited evaluation on real-world datasets."
      ],
      "questions": [
        "How does BCSI perform on datasets with noisy or uncertain bias scores?",
        "What is the impact of BCSI on model interpretability and fairness metrics?",
        "Can BCSI be integrated with existing bias mitigation pipelines in practice?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0uUASYeXav",
    "title": "Relational Object-Centric Actor-Critic",
    "std_review": {
      "summary": "The paper presents GOCA, a multi-agent reinforcement learning framework that extends the SLATE architecture to continuous action spaces using Soft Actor-Critic with message passing. It demonstrates strong performance on the GOCA benchmark, highlighting scalability and adaptability to various object attributes. While computational cost and hyperparameter sensitivity are noted, these are addressed with clear strategies. Overall, the paper is well-received for its innovative approach and empirical results.",
      "strengths": [
        "Innovative architecture extending SLATE to continuous action spaces.",
        "Scalable message-passing mechanism that maintains performance in larger environments.",
        "State-of-the-art results on the GOCA benchmark for complex manipulation tasks."
      ],
      "weaknesses": [
        "Computational cost increases with treating slots as a complete graph.",
        "Hyperparameter sensitivity may require extensive tuning.",
        "Limited baseline comparison could strengthen the claim of superiority."
      ],
      "questions": [
        "How does GOCA perform on more diverse object attribute changes beyond the color schema?",
        "What is the impact of treating slots as a complete graph on scalability in very large environments?",
        "Could a more extensive baseline comparison further validate GOCA's superiority?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0V311Uh8q1",
    "title": "Algorithmic Stability Unleashed: Generalization Bounds with Unbounded Losses",
    "std_review": {
      "summary": "The paper presents a novel concentration inequality for sub-Weibull random variables, extending classical results to handle unbounded losses. It derives a generalization bound for learning algorithms with Lipschitz continuous losses, offering tighter error guarantees for algorithms with heavy-tailed losses. The work is technically innovative, broadly applicable, and impactful for fields like online learning and robust statistics, though it may be less accessible due to its complexity and the need for further empirical validation.",
      "strengths": [
        "Technical novelty: introduces a new concentration inequality for sub-Weibull random variables, extending classical results to unbounded losses.",
        "Generalization bound: provides tighter error guarantees for algorithms with heavy-tailed losses compared to existing bounds.",
        "Broader impact: opens avenues for analysis in online learning, streaming algorithms, and robust statistics."
      ],
      "weaknesses": [
        "Complexity of proofs: the technical innovations may obscure intuition for readers unfamiliar with sub-Weibull theory.",
        "Empirical validation: lacks empirical studies to assess practical relevance and compare with existing methods.",
        "Verification for specific algorithms: additional verification for other algorithms would strengthen the claim of broad applicability."
      ],
      "questions": [
        "Can the bound be further tightened by relaxing the assumptions on the loss function or stability parameter?",
        "What are the empirical performance characteristics of the derived bounds in real-world settings with heavy-tailed losses?",
        "How can the Lipschitz condition be verified for a wider range of algorithms beyond ridge regression?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0V5TVt9bk0",
    "title": "Q-Bench: A Benchmark for General-Purpose Foundation Models on Low-level Vision",
    "std_review": {
      "summary": "The paper presents LLVisionQA, a benchmark that evaluates large multimodal language models on perception, description, and image quality assessment tasks using GPT-4V and open-source models. It highlights the models' strengths and areas for improvement, establishing a baseline against human expertise. The review finds the benchmark comprehensive and methodologically sound, recommending acceptance.",
      "strengths": [
        "Comprehensive benchmark design covering perception, description, and image quality assessment.",
        "Incorporates both proprietary and open-source models for a broad evaluation perspective.",
        "Establishes human baselines to assess practical utility and accuracy.",
        "Uses standardized metrics to ensure reliability and reproducibility."
      ],
      "weaknesses": [
        "Relies primarily on accuracy metrics, potentially overlooking interpretability and efficiency.",
        "Human benchmarks introduce subjective bias and variability.",
        "May become outdated due to rapid advancements in LLM architectures.",
        "Requires significant computational resources, limiting accessibility."
      ],
      "questions": [
        "How can the benchmark address interpretability and efficiency in future updates?",
        "What strategies can be employed to mitigate bias in human evaluations?",
        "How will the benchmark adapt to accommodate rapid advancements in LLMs?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0VBsoluxR2",
    "title": "MoFDiff: Coarse-grained Diffusion for Metal-Organic Framework Design",
    "std_review": {
      "summary": "The paper presents MoFDiff, a novel coarse-grained diffusion model for predicting metal-organic framework (MOF) assembly from building blocks. It combines autoencoder embeddings with contrastive learning using ECFP4 fingerprints, achieving improved accuracy over baselines. While innovative, the approach has limitations such as limited orientation exploration, lack of ablation studies, and insufficient technical detail, which could affect reproducibility and generalization.",
      "strengths": [
        "Innovative integration of autoencoder embeddings and contrastive learning for MOF assembly.",
        "Comprehensive benchmarking using a diverse dataset of known MOF structures.",
        "Clear and detailed description of the MOFid algorithms and ECFP4 fingerprint approach."
      ],
      "weaknesses": [
        "Limited exploration of orientation beyond global rotation and translation.",
        "Absence of ablation studies to assess sensitivity to modeling choices.",
        "Technical detail gaps that may hinder reproducibility."
      ],
      "questions": [
        "How does incorporating orientation beyond global rotation and translation affect MOF assembly predictions?",
        "Could ablation studies or comparative analyses provide insights into the sensitivity of the method to different modeling components?",
        "What additional technical details could be provided to enhance the clarity and reproducibility of the proposed algorithms?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "0VKEJKKLvr",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a graph-based neural network (GCN) approach for stratifying cancer risk using genomic data, where nodes represent individuals and edges encode SNP similarity via Hamming distance. The GCN model learns node embeddings that capture SNP interactions and demonstrates superior accuracy compared to baseline models on simulated and real datasets. While the method shows strong performance and offers interpretability, it could benefit from a broader literature comparison, more detailed graph construction, and integration of clinical features.",
      "strengths": [
        "Innovative graph construction that captures complex SNP interactions beyond pairwise analysis.",
        "Demonstrated superior accuracy over traditional baselines, highlighting the added value of graph-based learning.",
        "Provides clear evaluation with error bars and statistical significance, enhancing credibility."
      ],
      "weaknesses": [
        "Lacks a comprehensive comparison with state-of-the-art GNN models from recent literature.",
        "Graph construction details, especially the role of Hamming distance, could be more detailed.",
        "Does not integrate clinical information, which may limit real-world applicability."
      ],
      "questions": [
        "How does the proposed GCN model compare with recent GNN approaches in the literature?",
        "Could you provide more detailed information on how nodes and edges are defined, particularly the role of Hamming distance?",
        "What are the plans for integrating clinical features in future work to enhance predictive power?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0VZP2Dr9KX",
    "title": "Baseline Defenses for Adversarial Attacks Against Aligned Language Models",
    "std_review": {
      "summary": "The paper proposes a perplexity‑based filtering defense against targeted adversarial attacks on large language models, demonstrating effectiveness on 7‑B models but raising concerns about generalizability, robustness to adaptive attacks, and evaluation on larger models. While innovative and theoretically grounded, the defense's limitations suggest it may not be broadly applicable without further validation.",
      "strengths": [
        "Introduces a novel perplexity filtering approach that reduces targeted attack success.",
        "Provides a clear, systematic evaluation framework covering static and adaptive attacks.",
        "Grounds the defense in the well‑established metric of perplexity, enhancing credibility."
      ],
      "weaknesses": [
        "Effectiveness is validated only against the Zou et al. (2023) attack, limiting generalizability.",
        "The windowed perplexity filter may not hold up against adaptive attacks with dynamic suffixes.",
        "Impact of the paraphrasing preprocessing step on attack success is not thoroughly examined.",
        "Evaluation focuses on smaller 7‑B models, leaving open questions for larger models.",
        "Adversarial training is approximated via data augmentation, potentially underestimating true robustness."
      ],
      "questions": [
        "How does the defense perform against a broader set of adversarial techniques beyond the Zou et al. (2023) attack?",
        "What is the defense's robustness in adaptive attack scenarios where suffixes can be tailored per iteration?",
        "How does the paraphrasing preprocessing step affect the overall attack success, and is it mitigated?",
        "What are the implications of the defense on larger, state‑of‑the‑art LLMs (e.g., 13‑B or 70‑B)?",
        "How does the data‑augmentation approach in adversarial training compare to true adversarial training in terms of robustness?"
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "0w42S2Gp70",
    "title": "LipSim: A Provably Robust Perceptual Similarity Metric",
    "std_review": {
      "summary": "LipSim introduces a neural‑network‑based perceptual similarity metric designed to be robust against adversarial perturbations, crucial for applications like lip‑reading and facial analysis. The metric leverages contrastive learning to align lip movements and achieves certified robustness guarantees, demonstrating strong alignment with human perception and robustness on NIGHT and BAPPS datasets. While showing promise, the paper notes higher computational costs and the need for broader evaluation across datasets.",
      "strengths": [
        "LipSim provides certified robustness guarantees, ensuring perceptual similarity scores remain stable under adversarial attacks.",
        "The metric aligns with human perception of lip movements, making it more reliable for real‑world applications.",
        "Formal verification of robustness bounds offers a stronger foundation for trust compared to empirical assessments.",
        "LipSim demonstrates generalization across different datasets, indicating its robustness and applicability."
      ],
      "weaknesses": [
        "The neural‑network architecture may introduce higher computational costs compared to non‑neural‑network metrics.",
        "Limited evaluation scope; further testing on additional datasets would strengthen the claim of general applicability.",
        "Focus on certified robustness may overlook practical computational overhead, potentially impacting adoption."
      ],
      "questions": [
        "How does LipSim perform on a broader range of datasets beyond NIGHT and BAPPS?",
        "What is the computational cost of LipSim compared to non‑neural‑network metrics, and how does it impact real‑world deployment?",
        "How does the trade‑off between perceptual similarity and robustness manifest in practical applications, and can it be optimized?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0xLWPdObG1",
    "title": "Subject-specific Deep Neural Networks",
    "std_review": {
      "summary": "The paper introduces a novel approach to integrate deep neural networks with mixed models using a Poisson DNN and Gamma random effects, leveraging the h-likelihood for efficient, globally optimal estimation. It demonstrates improved estimation accuracy and computational efficiency over traditional methods, offering a theoretically sound framework for handling complex hierarchical data. While the method shows promise, concerns about implementation complexity, assumption validity, and comprehensive empirical validation remain. Overall, the paper is well‑received for its innovative approach and strong theoretical foundation.",
      "strengths": [
        "Innovative integration of DNNs with mixed models.",
        "Theoretical foundation using the h-likelihood for global optimality.",
        "Computational efficiency by avoiding Hessian computation.",
        "Flexibility in feature design with random‑slope features."
      ],
      "weaknesses": [
        "Complexity of the adjustment process described in Theorem 1.",
        "Assumption of Gamma random effects may not be suitable for all data.",
        "Limited empirical validation and lack of sensitivity analyses.",
        "Potential identifiability issues when random‑slope features are derived from fixed effects."
      ],
      "questions": [
        "Clarify the adjustment process and its impact on model identifiability.",
        "Provide a more detailed discussion of the assumptions behind Gamma random effects.",
        "Conduct a comprehensive comparison with state‑of‑the‑art methods and include additional sensitivity analyses.",
        "Address identifiability concerns when random‑slope features are derived from fixed‑effect features."
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0xT87opqKV",
    "title": "",
    "std_review": {
      "summary": "ProteinAdapter presents a lightweight adapter architecture for fine-tuning large protein language models, achieving comparable performance to full fine-tuning while significantly reducing computational costs. The innovative pyramid architecture and adapter modules are well‑described, and experiments show strong efficiency gains. However, the paper lacks comprehensive ablation studies, detailed baseline comparisons, and quantitative efficiency analysis, which limits confidence in the reported benefits.",
      "strengths": [
        "Introduces a novel adapter design tailored for protein sequences, addressing long sequence length challenges.",
        "Demonstrates substantial speedup and reduced memory footprint compared to full model fine-tuning.",
        "Shows comparable or superior performance to existing state‑of‑the‑art methods."
      ],
      "weaknesses": [
        "Adapter architecture is heavily optimized for protein models, limiting generalizability to other domains.",
        "Lacks detailed ablation studies on integration mechanisms and adapter configurations.",
        "Does not include comparisons with other relevant baselines like ESM‑GearNet.",
        "Efficiency gains are qualitatively discussed but not quantitatively analyzed."
      ],
      "questions": [
        "Could the adapter architecture be adapted for other sequence‑based domains beyond proteins?",
        "What is the quantitative impact of the pyramid architecture on speedup and memory usage?",
        "How does the Intra‑Level Self‑Attention mechanism compare to a unified approach in preserving model capabilities?",
        "What are the baseline experiments for fine‑tuning only a few dense layers on top of the pretrained model?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "0y0yOpI4wx",
    "title": "General-Purpose In-Context Learning",
    "std_review": {
      "summary": "The paper introduces a novel framework for General-Purpose In-Context Learning (GPICL) in large language models, defining GPICL as the ability to perform a wide range of tasks without task-specific fine-tuning. It proposes a methodology that leverages in-context learning to enable the model to transition between memorization, task identification, and general learning-to-learn states. Empirical experiments on diverse datasets demonstrate significant improvements over standard baselines, highlighting the importance of state/memory size. The paper is well-structured, with clear definitions, innovative methodology, and thorough empirical validation, though it has some limitations in dataset scope and theoretical analysis.",
      "strengths": [
        "Clear definition of GPICL",
        "Innovative meta-training methodology",
        "Empirical validation on diverse datasets",
        "Insightful analysis of state/memory size",
        "Practical interventions and actionable insights"
      ],
      "weaknesses": [
        "Limited scope of datasets",
        "Complexity of methodology with many hyperparameters",
        "Lack of detailed theoretical analysis",
        "Potential for overfitting",
        "Code availability without detailed documentation"
      ],
      "questions": [
        "How does the proposed methodology scale to very large datasets or more complex tasks?",
        "What is the theoretical justification for the observed improvements in GPICL?",
        "How robust are the results to variations in tokenization and input/output sizes?",
        "Can the identified algorithmic states be generalized beyond the specific models and tasks used in the experiments?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0Y26tFG3WF",
    "title": "Inducing Precision in Lagrangian Neural Networks: Proof of concept application on Chaotic systems",
    "std_review": {
      "summary": "The paper introduces a precision‑aware modification to Lagrangian Neural Networks (LNNs) to better handle chaotic systems, where numerical precision is critical. The authors propose a regularization method that conditions the network on each significant bit of the output, addressing the challenge of precision loss in chaotic dynamics. Experiments on the double pendulum and Hénon–Heiles systems demonstrate improved performance compared to standard LNNs. The approach offers a novel way to integrate precision considerations into neural network training for dynamical systems.",
      "strengths": [
        "Innovative approach to incorporating precision into neural network training for dynamical systems.",
        "Direct applicability to real-world problems involving chaotic systems, such as physics simulations and control systems.",
        "Comprehensive experimental evaluation on well-known chaotic systems demonstrating effectiveness."
      ],
      "weaknesses": [
        "Potential increase in implementation complexity and computational resource requirements.",
        "Limited scope of evaluation to only two specific chaotic systems.",
        "Lack of detailed analysis on how the regularization interacts with the original loss function.",
        "Risk of overfitting if the regularization is too strong."
      ],
      "questions": [
        "How does the proposed precision‑aware regularization scale to more complex chaotic systems beyond the evaluated examples?",
        "What is the impact of the regularization term on the convergence behavior of the network?",
        "Could the method be extended to other types of neural networks beyond Lagrangian Neural Networks?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0ypXhS83Lh",
    "title": "Robust Reinforcement Learning with Structured Adversarial Ensemble",
    "std_review": {
      "summary": "The paper introduces a novel adversarial ensemble training method for reinforcement learning that addresses over‑optimism and over‑pessimism by training against the worst‑k adversaries and averaging their losses. Empirical results on MuJoCo environments show significant improvements in sample efficiency and disturbance robustness compared to existing baselines. Theoretical analysis provides formal bounds on approximation error, supporting the method's effectiveness. While computational cost is a concern, the approach offers strong empirical validation and practical relevance.",
      "strengths": [
        "Novel adversarial ensemble approach that combines multiple adversary samples for robust training.",
        "Theoretical backing with formal guarantees linking the ensemble to improved robustness and error bounds.",
        "Empirical validation demonstrating clear performance gains across multiple benchmark tasks.",
        "Practical relevance with minimal integration effort into existing RL pipelines."
      ],
      "weaknesses": [
        "Increased computational cost due to training against multiple adversaries.",
        "Limited scope of empirical comparisons; a broader evaluation would strengthen general applicability.",
        "Theoretical guarantees assume known adversary sets; robustness to novel attacks is not fully explored.",
        "Parameter sensitivity regarding the choice of k (number of adversaries) without systematic analysis."
      ],
      "questions": [
        "How does the method scale to very large or complex environments in terms of computational cost?",
        "What is the systematic analysis of the impact of the number of adversaries (k) on performance?",
        "How does the proposed approach perform under novel, unseen attack scenarios?",
        "Can the theoretical guarantees be extended to settings where the adversary set is not fully known or changes over time?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0Z6lN4GYrO",
    "title": "",
    "std_review": {
      "summary": "The paper introduces S4G, a graph neural network that effectively balances long-range modeling with graph inductive bias through hierarchical neighborhood aggregation. It outperforms existing models on long-range graph benchmarks while maintaining computational efficiency. The theoretical analysis provides strong support for the model's design, though some concerns about preprocessing complexity and theoretical assumptions exist.",
      "strengths": [
        "Balanced long-range modeling and inductive bias",
        "Hierarchical neighborhood representation for effective long-range dependencies",
        "Strong performance and computational efficiency on long-range graph benchmarks",
        "Clear theoretical foundation with rigorous analysis"
      ],
      "weaknesses": [
        "Additional computational overhead from preprocessing hierarchical neighborhoods",
        "Theoretical assumptions on bounded derivatives may limit generalizability",
        "Lack of detailed comparison with the latest advancements"
      ],
      "questions": [
        "How does the preprocessing step impact training efficiency on very large graphs?",
        "What are the practical implications of the bounded derivative assumption in the sensitivity analysis?",
        "How does S4G compare to recent models beyond those mentioned in the paper?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0zIKlb0prF",
    "title": "MPPN: Multi-Resolution Periodic Pattern Network For Long-Term Time Series Forecasting",
    "std_review": {
      "summary": "The paper introduces MPPN, a novel architecture for extracting multi-resolution and periodic patterns from time series data, demonstrating strong performance on noisy and irregular datasets. It is computationally efficient and interpretable, with promising scalability across domains. However, its long-term forecasting capabilities are limited, and domain adaptability may require further tuning. Overall, the model is well-suited for short-term forecasting tasks and offers valuable insights into pattern extraction.",
      "strengths": [
        "Effective pattern extraction at multiple resolutions and periodicities",
        "Adaptive channel modulation enhances performance on diverse datasets",
        "Robustness to noise and irregularities in time series data",
        "Scalable and computationally efficient design"
      ],
      "weaknesses": [
        "Performance may be sensitive to hyperparameter settings",
        "Limited long-term forecasting capabilities",
        "Potential need for domain-specific adaptations"
      ],
      "questions": [
        "How can the model's long-term forecasting capabilities be improved?",
        "What specific domain adaptations are necessary for optimal performance in specialized fields?",
        "How does the model's interpretability compare to other state-of-the-art methods?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0ZUKLCxwBo",
    "title": "",
    "std_review": {
      "summary": "The paper introduces an analytic solution for weights in a two-layer MLP trained on periodic data, linking periodic feature structures to grokking behavior. It derives trigonometric solutions that capture how periodicity leads to sudden generalization jumps and introduces phase variables to distinguish memorization from generalization phases. The authors explore data distribution impacts and discuss extending the solution to other modular arithmetic operations, highlighting both insights and limitations. Overall, the work provides novel theoretical contributions and practical implications for understanding grokking, though it is limited to simpler architectures and lacks extensive empirical validation.",
      "strengths": [
        "Provides a novel analytic solution that offers deep insights into grokking behavior.",
        "Uses trigonometric functions to intuitively model periodic feature structures and their impact on generalization.",
        "Introduces phase variables as a key factor in distinguishing memorization and generalization phases.",
        "Explores the impact of training data distributions on grokking, offering practical insights.",
        "Opens avenues for future research on extending the solution to other modular arithmetic operations."
      ],
      "weaknesses": [
        "Findings may not generalize to more complex architectures like Transformers or pure attention models.",
        "Analytic solution is derived under specific assumptions about data distribution and model architecture.",
        "Lacks empirical validation across a wide range of datasets and model configurations.",
        "Discussion on training data distribution impact is brief and could benefit from more detailed analysis.",
        "Extension to other modular arithmetic operations is discussed qualitatively."
      ],
      "questions": [
        "How can the analytic solution be extended to more complex architectures beyond two-layer MLPs?",
        "What empirical validation strategies could strengthen the credibility of the findings across diverse datasets?",
        "How do different training data distributions beyond uniform and non-uniform sampling affect grokking in more complex models?",
        "What additional mathematical or empirical evidence is needed to support the extension of the solution to other modular arithmetic operations?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "10BTKkFfhl",
    "title": "Efficient Backdoor Mitigation in Federated Learning with Contrastive Loss",
    "std_review": {
      "summary": "The paper presents a novel contrastive loss function for efficient backdoor detection in federated learning, leveraging a clean model to guide trigger image generation. It shows improved efficiency and effectiveness over existing methods, though its reliance on a clean model and limited empirical validation are concerns. Overall, the paper is well-received for its theoretical and practical contributions.",
      "strengths": [
        "Introduces a novel contrastive loss function tailored for backdoor detection in federated learning.",
        "Utilizes a clean model to enhance detection accuracy and efficiency.",
        "Demonstrates significant improvements over existing techniques.",
        "Provides a clear theoretical framework and practical implementation details."
      ],
      "weaknesses": [
        "Relies on a clean model, which may not always be available in real-world scenarios.",
        "Performance may vary depending on the federated learning setup.",
        "Lacks extensive empirical validation across diverse datasets and models."
      ],
      "questions": [
        "How does the method perform when a clean model is not available?",
        "What is the impact of the specific contrastive loss function on the detection accuracy?",
        "How robust is the method across different federated learning scenarios and datasets?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "10eQ4Cfh8p",
    "title": "Simultaneous Generation and Improvement: A Unified RL Paradigm for FJSP Optimization",
    "std_review": {
      "raw_text": "{\n  \"summary\": \"The paper proposes a novel reinforcement learning framework that simultaneously generates and improves solutions using a Dueling DQN as an improvement network. It shows improved convergence and solution quality on grid-based instances compared to baselines, but lacks scalability evaluation and detailed training comparisons. The method's choice of Dueling DQN over more advanced actor-critic methods is not fully justified, and the impact of the improvement process on the generator alone is unclear.\",\n  \"strengths\": [\n    \"Introduces a unique combination of generator and improvement networks using Dueling DQN.\",\n    \"Demonstrates significant improvements in convergence speed and solution quality.\",\n    \"Provides a clear and reproducible experimental setup.\"\n  ],\n  \"weaknesses\": [\n    \"Uses Dueling DQN without a clear justification, potentially limiting scalability.\",\n    \"Lacks experiments comparing generator performance with and without the improvement network.\",\n    \"Does not evaluate scalability to larger instances, raising questions about practical applicability.\"\n  ],\n  \"questions\": [\n    \"Why was Dueling DQN chosen over more advanced actor-critic methods like PPO?\",\n    \"How does the combined generator-improvement setup compare to training the generator alone?\",\n    \"What criteria were used to select the number of improvement iterations \\(n_t\\)?\",\n    \"How does the method perform on larger-scale instances beyond those studied?\"\n  ],\n  \"overall_score\": \"6: weak accept\",\n  \"confidence\": \"3: medium\"\n}",
      "parse_error": true
    }
  },
  {
    "paper_id": "10fsmnw6aD",
    "title": "How Out-of-Distribution Important is",
    "std_review": {
      "summary": "The paper introduces a novel Continual Learning framework that integrates Out-of-Distribution (OOD) detection to address catastrophic forgetting and data drift. It proposes a dynamic model architecture that adapts to new tasks without forgetting previous knowledge while monitoring and mitigating OOD data impact. Experiments show significant improvements over existing methods on several benchmarks, indicating strong potential for real-world applications. Despite some implementation and evaluation concerns, the method is highly innovative and effective.",
      "strengths": [
        "Innovative integration of continual learning with OOD detection",
        "Dynamic model architecture that adapts to new tasks without forgetting",
        "Robustness against data drift through explicit OOD data mitigation",
        "Empirical validation demonstrating superior performance over baselines"
      ],
      "weaknesses": [
        "Increased complexity and computational overhead due to three separate models",
        "Potential training time and resource requirements",
        "Lack of detailed analysis of trade-offs and hyperparameter impacts",
        "Limited evaluation scope that may affect general applicability claims"
      ],
      "questions": [
        "How does the method scale to very large datasets or high-dimensional data?",
        "What are the specific trade-offs between continual learning performance and OOD detection accuracy?",
        "How robust is the method to different types of OOD data beyond the examples provided?",
        "Could the integration of the OOD component be optimized to reduce computational overhead?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "11oqo92x2Z",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a novel NAS‑based approach for solar‑farm segmentation, integrating high‑performing architectures into a modified AutoDeepLab model. It evaluates the models on a newly curated solar‑farm dataset, achieving competitive mIoU results and demonstrating the benefits of NAS. While the work shows promise, concerns about dataset generalizability, potential over‑fitting, and the lack of detailed hyper‑parameter optimization remain.",
      "strengths": [
        "Innovative integration of NAS to discover high‑performing solar‑farm segmentation architectures.",
        "Customized adaptation of AutoDeepLab for solar‑farm imagery, enhancing domain relevance.",
        "Comprehensive evaluation on a held‑out test set with clear performance metrics."
      ],
      "weaknesses": [
        "Reliance on a single dataset may limit the generalizability of the findings.",
        "Potential over‑fitting is not explicitly addressed, affecting model robustness.",
        "Absence of evaluation on additional datasets or environmental conditions."
      ],
      "questions": [
        "How does the model perform on datasets with different sizes or imaging conditions?",
        "What strategies were employed to mitigate over‑fitting in the NAS search process?",
        "Could the hyper‑parameter optimization be detailed further to enhance reproducibility?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "11WAKGH8uv",
    "title": "FedAIoT: A Federated Learning Benchmark for Artificial Intelligence of Things",
    "std_review": {
      "summary": "The paper presents a novel similarity matrix method for estimating noisy labels in machine learning, particularly useful for speech recognition. It demonstrates improved performance on benchmark datasets, showing the method's effectiveness. While the approach is computationally expensive when the learning algorithm changes and may lose information by converting raw audio to the frequency domain, these issues do not undermine the paper's value. The reviewer concludes with an acceptance of the paper.",
      "strengths": [
        "Introduces a novel similarity matrix method for estimating noisy labels, applicable to various centralized learning algorithms.",
        "Provides a practical solution to a common problem in machine learning, especially in speech recognition tasks.",
        "Demonstrates improved performance on benchmark datasets, showcasing the effectiveness of the proposed approach."
      ],
      "weaknesses": [
        "The similarity matrix may need to be recalculated when the learning algorithm changes, which could be computationally expensive.",
        "The raw audio format is not used, potentially leading to loss of important information during conversion to the frequency domain.",
        "The purpose of Section 4 is unclear, as it does not explicitly state whether the benchmarks are intended to enable correct ranking of optimizers."
      ],
      "questions": [
        "How can the computational expense of recalculating the similarity matrix be mitigated when the learning algorithm changes?",
        "Could preserving the raw audio format instead of converting it to the frequency domain retain more original data?",
        "Is the primary goal of Section 4 to enable correct ranking of optimizers, and if so, are there additional aspects of model performance that should be captured?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "12Acp6ZcRa",
    "title": "Evaluating the Robustness of Text-to-image Diffusion Models against Real-world Attacks",
    "std_review": {
      "summary": "The paper investigates the robustness of text-to-image diffusion models against adversarial perturbations, revealing significant vulnerabilities when using certain attack objectives. It introduces a comprehensive evaluation framework and diverse perturbation set, highlighting real-world risks. The study is well‑structured, with clear metrics and implications, though it could benefit from broader baselines and more detailed human evaluation.",
      "strengths": [
        "Comprehensive Evaluation Framework",
        "Diverse Perturbation Set",
        "Clear Success Metrics",
        "Real-World Implications"
      ],
      "weaknesses": [
        "Limited Baseline Models",
        "Scope of Human Evaluation",
        "Potential for Further Attacks",
        "Scalability of Results"
      ],
      "questions": [
        "How do the identified vulnerabilities scale to other types of perturbations?",
        "Could the evaluation be extended to more diverse baseline models?",
        "What additional attack objectives might be relevant for future work?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "12zKEh2APn",
    "title": "PROSE: Predicting Operators and Symbolic Expressions using Multimodal Transformers",
    "std_review": {
      "summary": "PROSE introduces a dual-decoder transformer model for predicting trajectories and reconstructing symbolic expressions in dynamical systems. It shows strong performance on extrapolation and symbolic regression tasks, but lacks evaluation on out-of-distribution parameters and detailed training specifics. The model's architecture is innovative, yet several aspects of its robustness and reproducibility remain unexplored.",
      "strengths": [
        "Innovative dual-decoder architecture enabling simultaneous temporal prediction and symbolic reconstruction.",
        "Demonstrates robust extrapolation beyond training data, indicating strong generalization capabilities.",
        "Achieves high accuracy in symbolic regression, effectively reconstructing complex expressions."
      ],
      "weaknesses": [
        "Limited evaluation on out-of-distribution parameters raises concerns about model generalization.",
        "Lack of detailed training procedure details, including loss functions and hyperparameters, affecting reproducibility.",
        "Absence of ablation studies to assess the contribution of individual components.",
        "Potential overfitting due to the large transformer used for feature fusion with limited training examples."
      ],
      "questions": [
        "How does the model perform on out-of-distribution parameters, and what quantitative metrics are used for evaluation?",
        "What specific training loss functions and optimization techniques are employed, and how are they balanced?",
        "Could ablation studies be conducted to isolate the impact of individual components on overall performance?",
        "What strategies were used to prevent overfitting, especially given the limited number of training examples?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "13D1zn0mpd",
    "title": "Effective and Parameter-Efficient Reusing Fine-Tuned Models",
    "std_review": {
      "summary": "The paper introduces PERU-LoRA, a method for merging multiple task-specific fine-tuned models into a single multi-task model using singular value decomposition (SVD) to approximate the product of the transpose of the parameter matrices. It aims to reduce parameter count while maintaining performance, showing effectiveness on various tasks. While novel in its approach, the method's novelty is constrained as it primarily combines existing techniques without introducing fundamentally new concepts. The performance gain is marginal, and the comparison with LoRA is not as clear-cut. The parameter efficiency of PERU-LoRA is limited, and the method's compatibility with existing merging methods is not thoroughly explored.",
      "strengths": [
        "Introduces a novel approach to model merging using SVD, which is a well-established technique in linear algebra.",
        "Demonstrates the effectiveness of the proposed method in reducing parameter count while maintaining performance.",
        "Provides a clear comparison with existing model merging methods, highlighting the advantages of PERU-LoRA."
      ],
      "weaknesses": [
        "The novelty of the proposed method is constrained, as it primarily combines existing techniques without introducing fundamentally new concepts.",
        "The performance gain from the proposed method is marginal, with only a slight reduction in parameter count compared to existing methods.",
        "The comparison with LoRA is not as clear-cut, as LoRA is primarily a fine-tuning technique, while PERU-LoRA focuses on merging existing fine-tuned models."
      ],
      "questions": [
        "Can the authors provide insights into why singular value decomposition (SVD) was chosen over direct rank reduction of matrices At and Bt?",
        "How does the proposed PERU-LoRA method compare in parameter efficiency with existing model merging methods like Fisher-Merging, RegMean, and TIES-Merging?",
        "What are the specific advantages of PERU-LoRA over existing merging methods in terms of performance and compatibility?"
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "14rn7HpKVk",
    "title": "SALMONN: Towards Generic Hearing Abilities for Large Language Models",
    "std_review": {
      "summary": "The paper introduces Q-Former, a two-stage instruction tuning method for QA models using monotonic alignment. It shows strong performance on structured tasks like ASR and SQQA but struggles with more open-ended tasks like PR and OSR. While innovative, the method's complexity and limited analysis of performance drops raise concerns about its generalizability and reproducibility.",
      "strengths": [
        "Introduces monotonic alignment, a novel technique for ensuring consistent output generation.",
        "Demonstrates effectiveness across multiple QA domains with a clear evaluation framework.",
        "Combines teacher forcing with activation tuning to improve both instruction following and response quality."
      ],
      "weaknesses": [
        "The two-stage tuning process is computationally intensive and challenging to implement.",
        "Performance variability on tasks like PR and OSR with limited analysis.",
        "Lack of detailed data generation process for prompted QA samples.",
        "Limited generalization to more open-ended or ambiguous tasks."
      ],
      "questions": [
        "What is the detailed process for generating prompted QA samples and verifying their correctness?",
        "How can the performance drops on tasks like PR and OSR be better understood and mitigated?",
        "What additional analyses could be performed to assess the method's generalizability to more open-ended tasks?"
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "17BA0Tl2Id",
    "title": "Meta-Referential Games to Learn Compositional Learning Behaviours",
    "std_review": {
      "summary": "The paper introduces a novel benchmark and evaluation methodology for studying compositional learning behaviors (CLBs) in AI systems. The authors propose tasks that assess how AI agents compose learned concepts to solve novel problems, evaluating the benchmark across various AI models. The results highlight the importance of CLBs for developing flexible and adaptable AI systems. Overall, the paper is well-received for its significant contribution to the field, with clear methodology and practical implications.",
      "strengths": [
        "Introduces a novel benchmark focused on compositional learning behaviors, a significant contribution to AI.",
        "Provides a clear and well-defined evaluation methodology for systematic assessment of CLBs across different AI models.",
        "Uses diverse tasks that require composition of learned concepts, offering a comprehensive evaluation of CLBs.",
        "Demonstrates the practical significance of CLBs, showing their potential to develop more flexible and adaptable AI systems."
      ],
      "weaknesses": [
        "The novelty of the benchmark is limited by the specific set of tasks chosen, which may not cover all compositional learning scenarios.",
        "The evaluation methodology could benefit from more detailed examples and explanations of how CLBs are measured and assessed.",
        "The practical significance of the findings is somewhat limited by the focus on a specific type of AI model, requiring further research for generalizability."
      ],
      "questions": [
        "How can the benchmark be expanded to cover a wider range of compositional learning scenarios?",
        "What additional examples or explanations can be provided to improve the clarity of the evaluation methodology?",
        "What further research is needed to assess the generalizability of the results to other AI systems?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "17pVDnpwwl",
    "title": "Feature Learning in Infinite Depth Neural Networks",
    "std_review": {
      "summary": "The paper introduces Depth-μP, a novel parametrization that maximizes feature diversity at each depth, enabling effective hyperparameter transfer across network depths. The authors provide theoretical justification and empirical evidence supporting the approach, demonstrating its benefits for maintaining consistent training dynamics and performance. While the theoretical proofs could be strengthened and some edge cases are not fully addressed, the work makes significant contributions to understanding hyperparameter transfer in deep neural networks.",
      "strengths": [
        "Introduces a novel Depth-μP parametrization emphasizing feature diversity.",
        "Provides a clear theoretical justification for hyperparameter transfer under the proposed limit.",
        "Employs mean-centering of residual blocks to enhance gradient flow and feature diversity."
      ],
      "weaknesses": [
        "Theoretical justification for hyperparameter transfer could benefit from more rigorous proofs.",
        "Empirical validation may not fully address all edge cases or variations in network architectures.",
        "Assumes a specific form of feature diversity without exploring alternative metrics.",
        "Discussion of the infinite depth limit lacks detailed analysis on training dynamics and convergence."
      ],
      "questions": [
        "Could the theoretical justification be strengthened with additional mathematical proofs or simulations?",
        "How does the approach generalize to different network architectures and training regimes?",
        "What alternative metrics or methods could be used to quantify feature diversity beyond those explored in the paper?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "17ZbByq95E",
    "title": "Memory-Efficient Backpropagation through Large Linear Layers",
    "std_review": {
      "summary": "The paper introduces Randomized Matrix Multiplication (RMM) for compressing activations in large linear layers of GNNs and transformers, using random projections to estimate gradients. While innovative, the approach is not entirely novel and introduces computational overhead. Empirical results show competitive performance, but its applicability to other architectures like convolutional networks remains underexplored. Overall, the method offers memory savings and potential stability improvements but requires careful tuning and further validation.",
      "strengths": [
        "Innovative gradient estimation using random projections.",
        "Scalable solution for large linear layers in GNNs and transformers.",
        "Empirical validation across various benchmarks.",
        "Theoretical insights into variance reduction and convergence."
      ],
      "weaknesses": [
        "Novelty concerns compared to existing random projection techniques.",
        "Additional computational cost from averaging multiple samples.",
        "Performance may vary significantly with network depth.",
        "Limited exploration of applicability to other architectures."
      ],
      "questions": [
        "How does the choice of sample size S impact performance across different network depths?",
        "What are the theoretical guarantees for convergence when using RMM in very deep networks?",
        "How does RMM compare to activation compression methods in terms of training stability?",
        "What are the potential benefits and challenges of applying RMM to convolutional neural networks in vision tasks?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "1Akd36hG9z",
    "title": "Enhancing Offline Reinforcement Learning with an Optimal Supported Dataset",
    "std_review": {
      "summary": "The paper introduces OSD-RL, an offline RL algorithm that improves upon OptiDICE by adding a strong-convexity regularization term and a single-transition estimator. It achieves competitive performance on D4RL benchmarks, outperforming several state-of-the-art methods. While addressing bias and variance in non-deterministic environments, the approach introduces bias in complex domains and has sample complexity concerns. Overall, the paper is well-received for its theoretical contributions and practical improvements.",
      "strengths": [
        "Improved performance on D4RL benchmarks compared to several state-of-the-art offline RL methods.",
        "Strong theoretical foundation provided by the strong-convexity regularization term, addressing bias and variance.",
        "Introduces a computationally efficient single-transition estimator suitable for complex domains."
      ],
      "weaknesses": [
        "Bias introduced by the single-transition estimator in complex, non-deterministic environments.",
        "Sample complexity of O(ϵ⁻⁴) may limit scalability in practice.",
        "Lack of detailed implementation guidelines could hinder reproducibility.",
        "Comparison with a broader range of baselines would strengthen the contextualization of performance gains."
      ],
      "questions": [
        "How does the algorithm perform in highly stochastic environments beyond the D4RL benchmarks?",
        "What are the practical trade-offs between sample complexity and computational efficiency in real-world applications?",
        "Could the inclusion of more detailed implementation guidelines or code releases improve reproducibility?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1armpjgh8L",
    "title": "Adaptive Hierarchical Certification for Segmentation using Randomized Smoothing",
    "std_review": {
      "summary": "The paper presents AdaptCertify, a method that enhances semantic segmentation model certification through a hierarchical class structure and adaptive sampling. It shows significant improvements over the baseline SegCertify method on Cityscapes and ACDC datasets, particularly in certified accuracy and class-specific performance. The approach balances class granularity and certified accuracy using a custom evaluation metric (CIG). While promising, the method's evaluation is limited to two datasets and lacks visual examples and comparisons with other state-of-the-art methods.",
      "strengths": [
        "Hierarchical class structure allows nuanced and granular certification.",
        "Adaptive sampling strategy dynamically adjusts based on model confidence.",
        "Custom evaluation metric (CIG) balances class granularity and certified accuracy."
      ],
      "weaknesses": [
        "Limited dataset evaluation (Cityscapes and ACDC only).",
        "Lack of visual examples to illustrate certification results.",
        "No comparison with additional baselines.",
        "Implementation complexity due to hierarchical structure and adaptive sampling."
      ],
      "questions": [
        "How does AdaptCertify perform on a broader range of datasets beyond Cityscapes and ACDC?",
        "What are the practical implications of the certification results, and could visual examples help illustrate them?",
        "How does the adaptive sampling strategy (HSAMPLE) compare to other sampling methods in terms of efficiency and effectiveness?",
        "What is the impact of varying the hierarchical structure on the method's performance and robustness?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1AXvGjfF0V",
    "title": "Evaluating Hallucinations in Chinese Large Language Models",
    "std_review": {
      "summary": "The paper introduces HalluQA, a benchmark for evaluating hallucinations in Chinese large language models (LLMs). It categorizes hallucinations into imitative falsehoods and factual errors, addressing a gap in current evaluation methods. The benchmark shows varying hallucination rates among Chinese LLMs, with GPT-4 performing best. While valuable, the study acknowledges limitations such as reliance on GPT-4 and focus on Chinese LLMs.",
      "strengths": [
        "Comprehensive benchmark creation for Chinese LLMs",
        "Clear categorization of hallucinations",
        "Unique question patterns distinct from existing benchmarks",
        "Use of GPT-4 as a strong reference model"
      ],
      "weaknesses": [
        "Dependence on GPT-4 raises cost and bias concerns",
        "Scope limited to Chinese LLMs",
        "Potential for overfitting to the HalluQA dataset"
      ],
      "questions": [
        "How can the benchmark be extended to evaluate hallucinations in other languages?",
        "What alternative evaluation methods could mitigate reliance on GPT-4?",
        "How can the findings inform the development of more robust training data?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1bAUywYJTU",
    "title": "DreamTime: An Improved Optimization Strategy for Diffusion-Guided 3D Generation",
    "std_review": {
      "summary": "The paper introduces a Gaussian-weighted timestep annealing schedule for 3D representation learning, enhancing both geometric and textural fidelity in models like NeRF. It outperforms existing methods in perceptual quality metrics such as FID and Inception Score, and shows broad applicability to complex 3D representations. While promising, the method has limitations in terms of comprehensive prompt comparison, computational cost analysis, and theoretical depth.",
      "strengths": [
        "Introduces a novel Gaussian-weighted timestep annealing schedule that improves perceptual quality.",
        "Demonstrates consistent gains across diverse 3D representations beyond NeRF.",
        "Provides a theoretically justified approach to annealing based on prompt complexity."
      ],
      "weaknesses": [
        "Lacks a thorough quantitative comparison across a wider range of prompts and datasets.",
        "Does not quantify the computational overhead compared to baseline methods.",
        "The theoretical analysis of the Gaussian weight function is limited."
      ],
      "questions": [
        "How does the method perform on a broader set of prompts and 3D datasets beyond those tested?",
        "What is the computational cost of the proposed annealing schedule relative to baseline methods?",
        "Can the theoretical impact of the Gaussian weight function be further quantified or bounded?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1bbPQShCT2",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a novel reinforcement learning approach for robotic manipulation that integrates a learned policy with symbolic planning. It demonstrates improved sample efficiency and robustness in a 2‑D simulation environment compared to a purely learned baseline. While the results are promising, the 2‑D setting may limit real‑world applicability, and some hyper‑parameter details are not fully explored.",
      "strengths": [
        "Integrates symbolic planning with RL to leverage prior knowledge in robotic tasks.",
        "Provides a clear 2‑D simulation environment that facilitates analysis and comparison.",
        "Conducts thorough ablation studies to highlight the contribution of each component."
      ],
      "weaknesses": [
        "The 2‑D environment may not fully capture real‑world 3‑D manipulation complexities.",
        "Hyper‑parameters for the combined strategy baseline are not exhaustively tuned.",
        "Lacks detailed analysis of trade‑offs between sample efficiency and planning accuracy.",
        "Training regime (fewer than 100 k steps) raises questions about scalability."
      ],
      "questions": [
        "How does the approach generalize to more complex 3‑D manipulation tasks?",
        "What are the detailed hyper‑parameters used for the combined strategy baseline?",
        "Could a 'on‑the‑fly' GPT‑4 integration improve performance, and if so, how?",
        "What trade‑offs exist between sample efficiency and planning accuracy?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1BmveEMNbG",
    "title": "Rethinking Complex Queries on Knowledge Graphs with Neural Link Predictors",
    "std_review": {
      "summary": "The paper introduces FIT, a novel fuzzy logic-based approach for embedding complex queries in knowledge graphs, extending beyond tree structures to handle cycles, multigraphs, and existential leaves. FIT leverages fuzzy inference to provide a flexible matching mechanism, offering theoretical guarantees of completeness and soundness for EFO₁ queries. Empirical results demonstrate significant improvements in query performance and expressiveness, especially on large datasets, compared to existing methods like ConE and BetaE. The reviewer concludes that FIT advances the field by addressing limitations of deterministic query embedding techniques.",
      "strengths": [
        "Enhanced Query Expressiveness: FIT extends query embedding to non-tree structures, enabling more complex and realistic queries.",
        "Fuzzy Logic Integration: Incorporates fuzzy inference for nuanced matching, handling uncertainty and partial matches.",
        "Theoretical Guarantees: Provides strong theoretical foundations with completeness and soundness guarantees for EFO₁ queries."
      ],
      "weaknesses": [
        "Complexity of Implementation: The use of fuzzy logic and handling of complex graph structures may increase implementation complexity.",
        "Scalability Concerns: Practical scalability for extremely large knowledge graphs has not been exhaustively demonstrated.",
        "Limited Comparison: The paper could benefit from a more detailed comparison with the latest advancements beyond ConE and BetaE."
      ],
      "questions": [
        "How does FIT's performance scale with extremely large knowledge graphs, and what are the practical implications of its runtime complexity?",
        "What are the specific fuzzy rules and operators used in FIT, and how do they compare to other fuzzy inference methods?",
        "How does FIT's fuzzy inference mechanism handle uncertainty and partial matches in practice, and what are the trade-offs compared to deterministic approaches?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1BuWv9poWz",
    "title": "",
    "std_review": {
      "summary": "The paper presents Gradient Normalization and Scaling (GNS) and High Frequency Adaptation (HFA) as a novel method to generate more transferable adversarial examples for deep neural networks. By attenuating mild gradients and emphasizing high-frequency components, the authors achieve higher evasion success rates across various models. The approach is theoretically motivated, empirically validated, and practical to integrate into existing pipelines. Despite some limitations, the paper's contributions and results justify its acceptance.",
      "strengths": [
        "Innovative combination of GNS and HFA to improve adversarial example transferability.",
        "Clear theoretical motivation for attenuating mild gradients and leveraging high-frequency components.",
        "Empirical validation across multiple models and attack methods demonstrating strong performance.",
        "Practical impact with straightforward integration into adversarial training pipelines."
      ],
      "weaknesses": [
        "Lack of detailed theoretical analysis to fully support the proposed methods.",
        "Limited generalization to a broader range of architectures and tasks.",
        "Potential for overfitting due to focus on high-frequency components.",
        "Increased computational complexity from frequency-domain exploration."
      ],
      "questions": [
        "What is the theoretical basis for the effectiveness of attenuating mild gradients?",
        "How does the method generalize to other types of neural network architectures beyond those tested?",
        "What strategies can be employed to mitigate overfitting when focusing on high-frequency components?",
        "How does the computational cost of the frequency-domain adaptation compare to other adversarial generation techniques?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1CK45cqkEh",
    "title": "Unsupervised Order Learning",
    "std_review": {
      "summary": "The paper introduces an ordered k‑means algorithm that learns an order embedding to define 'previous' and 'next' clusters in high‑dimensional spaces, aiming to improve clustering for ordinal classification. It simplifies tuning with a single parameter α but relies heavily on its choice. Evaluated on MORPH II and RetinaMNIST, the method shows promise but lacks broader dataset testing and comparison with other ordinal‑aware clustering approaches.",
      "strengths": [
        "Innovative handling of high‑dimensional order by learning an order embedding.",
        "Parameter efficiency with a single tunable parameter α.",
        "Clear ablation studies demonstrating the impact of order learning."
      ],
      "weaknesses": [
        "Limited evaluation to two datasets, potentially limiting generalizability.",
        "Sensitivity to the single parameter α, raising concerns about robustness.",
        "Lack of comparative analysis with a broader range of traditional clustering algorithms."
      ],
      "questions": [
        "How does the method perform on a wider variety of datasets beyond MORPH II and RetinaMNIST?",
        "What strategies can be employed to make the algorithm more robust to the choice of α?",
        "How does the proposed method compare to other clustering algorithms specifically designed for ordinal data?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "1CPta0bfN2",
    "title": "Adaptive Retrieval and Scalable Indexing for \\(k\\)-NN Search with Cross-Encoders",
    "std_review": {
      "summary": "The paper presents AXN, an adaptive retrieval framework that dynamically adjusts the number of retrieved items per query using a dual-encoder model, aiming to improve recall efficiency. It shows competitive recall gains over traditional DE+kNN approaches while maintaining comparable inference costs. The innovative adaptive mechanism and strong theoretical motivation are highlighted, but concerns remain about clarity in performance comparisons, parameter tuning guidance, and comprehensive analysis of scaling properties.",
      "strengths": [
        "Introduces a novel adaptive retrieval mechanism that balances recall and computational efficiency.",
        "Provides strong theoretical motivation for the adaptive approach.",
        "Demonstrates empirical improvements in recall across multiple benchmarks."
      ],
      "weaknesses": [
        "Lacks clear comparison of inference times between AXN and DE+kNN.",
        "Does not thoroughly discuss the choice of dual-encoder model.",
        "Scaling behavior of AXN is only partially explored.",
        "Figure 3 omits some relevant methods, leading to potential confusion.",
        "Lacks guidance on optimal parameter tuning for CE call budget, λ, and number of rounds."
      ],
      "questions": [
        "Can you provide a detailed comparison of inference times between AXN and DE+kNN approaches?",
        "What are the specific reasons for choosing the dual-encoder model, and how does it compare to state-of-the-art encoders?",
        "Please conduct a comprehensive analysis of the scaling properties of AXN as the corpus size grows.",
        "Include all relevant methods in Figure 3 to clarify the comparative landscape.",
        "Provide clear guidelines for distributing the CE call budget, selecting λ, and determining the number of rounds R for new datasets."
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "1d2cLKeNgY",
    "title": "",
    "std_review": {
      "summary": "The paper presents a novel pipeline that integrates 3D mesh reconstruction, domain adaptation, and LiDAR simulation to bridge domain gaps in autonomous driving. It effectively reduces the domain gap, as shown by quantitative improvements in mesh fidelity and domain adaptation metrics. The method is scalable and robust to sensor variations, making it suitable for real-world applications. However, computational requirements and limited evaluation on diverse scenarios are noted as weaknesses.",
      "strengths": [
        "Integrates 3D mesh reconstruction with domain adaptation and LiDAR simulation for comprehensive domain gap bridging.",
        "Demonstrates significant improvements in mesh fidelity and domain adaptation effectiveness compared to existing methods.",
        "Scalable and robust to variations in sensor configurations, suitable for real-world applications."
      ],
      "weaknesses": [
        "High computational requirements for mesh reconstruction and LiDAR simulation may be prohibitive for resource-constrained environments.",
        "Effectiveness evaluated on a limited set of benchmark datasets, not fully capturing performance across all scenarios.",
        "Reliance on high-quality point cloud data for reconstruction could be a limitation in noisy or sparse environments.",
        "Scalability with respect to LiDAR sensors and target domain complexity is not thoroughly explored."
      ],
      "questions": [
        "How does the method perform on datasets with highly variable sensor configurations and limited labeled data for the target domain?",
        "What are the computational requirements and potential optimizations for deploying the pipeline in resource-constrained environments?",
        "How does the method handle scenarios with sparse or noisy point cloud data, and what improvements could be made?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1djnGJnaiy",
    "title": "",
    "std_review": {
      "summary": "The BrainMixer model introduces a novel graph neural network framework for jointly learning representations of voxel activity and functional connectivity in neuroimaging. It demonstrates strong performance across various datasets and tasks, outperforming existing baselines. While showing promise, the model has limitations such as potential overfitting on smaller datasets and limited interpretability. Overall, the paper makes a significant contribution to neuroimaging representation learning.",
      "strengths": [
        "Effectively combines voxel activity and functional connectivity data.",
        "Leverages graph neural networks to model complex brain connectivity patterns.",
        "Demonstrates strong performance across multiple datasets and tasks."
      ],
      "weaknesses": [
        "Performance on smaller datasets is not as strong, indicating potential overfitting.",
        "Computational complexity may pose challenges for real-time applications.",
        "Model's interpretability is limited due to non-human readable learned representations."
      ],
      "questions": [
        "How can the model's performance on smaller datasets be improved?",
        "What techniques can be explored to enhance model interpretability?",
        "How does the model perform in real-time applications or on resource-constrained devices?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1dY11GyZdp",
    "title": "Signed Binarization : Unlocking Efficiency",
    "std_review": {
      "summary": "The paper introduces Signed Binarization, a quantization technique that extends binary quantization to include signed values (±1), enhancing representational capacity while keeping computational overhead low. It demonstrates significant improvements over existing binary and ternary methods across accuracy, latency, energy consumption, throughput, and density, particularly for convolutional neural networks. The authors provide a thorough evaluation and highlight practical benefits such as reduced inference time and power consumption, making the approach highly relevant for resource-constrained environments.",
      "strengths": [
        "Introduces Signed Binarization, expanding beyond traditional binary quantization to include signed values.",
        "Leverages repetition‑sparsity trade‑off to efficiently map activations to a limited set of quantized values.",
        "Shows comprehensive performance gains across multiple metrics, including accuracy, latency, energy, throughput, and density.",
        "Demonstrates tangible benefits in real-world applications, such as reduced inference time and lower power consumption."
      ],
      "weaknesses": [
        "Adds complexity to the quantization process due to the inclusion of signed values.",
        "Potential for increased quantization error if signed values are not carefully managed.",
        "Benchmarking is somewhat limited, which may not fully capture the method's performance across all use cases.",
        "Could benefit from a more detailed comparison with the latest advancements in quantization techniques."
      ],
      "questions": [
        "How does the method handle signed values during both training and inference to minimize quantization error?",
        "What are the specific trade‑offs between the repetition‑sparsity trade‑off and the representational gain in terms of bits per activation?",
        "How does Signed Binarization perform on larger model architectures beyond the tested convolutional neural networks?",
        "Could the technique be extended to other types of neural network layers or models?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1FWDEIGm33",
    "title": "Large Language Models as Superpositions of Cultural Perspectives",
    "std_review": {
      "summary": "The paper introduces the metaphor of 'LLMs as a superposition of cultural perspectives' to explain their context‑sensitive behavior. It empirically measures shifts in responses across varied contexts using a novel metric, showing that LLMs exhibit unexpected perspective shifts beyond simple instruction following. While innovative and well‑motivated, the study has limitations in context generalizability, metric validation, and model diversity, which could affect external validity. Overall, the work is accepted for its novel contribution and empirical rigor.",
      "strengths": [
        "Innovative metaphor for understanding LLM behavior",
        "Systematic experimental design with clear metric definition",
        "Cross‑disciplinary relevance linking NLP and psychology"
      ],
      "weaknesses": [
        "Limited scope of contexts may limit generalizability",
        "Metric reliability not fully established",
        "Analysis focused on a narrow set of model architectures"
      ],
      "questions": [
        "How can the metric be validated against established psychological measures of personality/value shifts?",
        "What are the implications of the observed shifts for real‑world applications where context can vary widely?",
        "How might the identified superposition of perspectives influence future model design and evaluation benchmarks?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1gkePTsAWf",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a novel approach to recursive self‑improvement for large language models by using carefully crafted prompts. It demonstrates significant performance gains, suggesting that prompt engineering can be a powerful tool for advancing recursive self‑improvement. While the study shows promise, it lacks some depth in ablation studies and detailed evaluation metrics, and the repository is not yet publicly available.",
      "strengths": [
        "Introduces a novel methodology that integrates diverse tasks and datasets.",
        "Provides a clear and replicable framework for evaluating prompt engineering.",
        "Shows compelling empirical results with measurable improvements."
      ],
      "weaknesses": [
        "Lacks a comprehensive ablation study to isolate prompt component effects.",
        "Evaluation metrics are not fully detailed, limiting generalizability.",
        "Does not discuss potential limitations such as computational cost or overfitting.",
        "The code and data repository is not yet available."
      ],
      "questions": [
        "Could a more detailed ablation study strengthen the argument for specific prompt features?",
        "How do the results generalize to other types of tasks or models?",
        "What are the computational costs and overfitting risks of the proposed approach?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1GUTzm2a4v",
    "title": "Greedy PIG: Adaptive Integrated Gradients",
    "std_review": {
      "raw_text": "{\n  \"summary\": \"The paper introduces Greedy PIG, a gradient‑based feature attribution method that adaptively selects features to maximize a non‑submodular objective, improving attribution quality while controlling cost. Experiments show it outperforms Integrated Gradients, especially in models with correlated features. While theoretically sound and empirically superior, the method's sensitivity to the parameter \\(z\\) and the non‑strict submodularity of its objective function are noted as areas for improvement.\",\n  \"strengths\": [\n    \"Adaptive gradient utilization effectively captures feature interactions.\",\n    \"Handles feature correlations by isolating marginal gains.\",\n    \"Provides a rigorous theoretical analysis and guarantees.\"\n  ],\n  \"weaknesses\": [\n    \"Parameter \\(z\\) significantly influences performance and lacks clear guidance.\",\n    \"The objective function is not strictly submodular, affecting theoretical guarantees.\",\n    \"The sequential gradient definition is somewhat abstract.\",\n    \"Experimental details, such as the point game methodology, are not fully transparent.\"\n  ],\n  \"questions\": [\n    \"What is the optimal choice of \\(z\\) and how does it vary across different datasets?\",\n    \"How robust are the theoretical guarantees when the objective deviates from strict submodularity?\",\n    \"Could the sequential gradient be defined more concretely to aid practical implementation?\",\n    \"What are the exact network architecture and image selection criteria used in the point game experiments?\"\n  ],\n  \"overall_score\": \"7: accept\",\n  \"confidence\": \"4: high\"\n}",
      "parse_error": true
    }
  },
  {
    "paper_id": "1hhja8ZxcP",
    "title": "Turbulent Flow Simulation using Autoregressive Conditional Diffusion Models",
    "std_review": {
      "summary": "The paper introduces an Autoregressive Conditional Diffusion Model (ACDM) for simulating turbulent flows, achieving superior accuracy and stability compared to traditional methods. While computationally intensive, ACDM's innovative architecture and probabilistic sampling capabilities make it a valuable contribution to fluid dynamics. The authors highlight its potential for practical applications, though some limitations in novelty and practical utility remain.",
      "strengths": [
        "Innovative model architecture combining autoregressive modeling with conditional diffusion.",
        "Improved accuracy and stability in turbulent flow simulations.",
        "Ability to generate posterior samples for enhanced uncertainty quantification."
      ],
      "weaknesses": [
        "High computational complexity may limit real-time and resource-constrained applications.",
        "Novelty may not fully translate to practical utility due to complexity and hyperparameter tuning requirements.",
        "Performance evaluated on a limited set of datasets, potentially limiting generalizability."
      ],
      "questions": [
        "How can the computational complexity of ACDM be reduced for real-time applications?",
        "What strategies can be employed to improve the practical utility of ACDM in engineering and scientific workflows?",
        "How does ACDM perform on a broader range of turbulent flow scenarios beyond the evaluated datasets?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1hLFLNu4uy",
    "title": "Split and Merge: Aligning Position Biases in Large Language Model based Evaluators",
    "std_review": {
      "summary": "The paper proposes a method to mitigate position bias in LLM-based evaluators for open-ended questions by merging candidate answers based on semantic similarity. The approach aims to maintain high evaluation quality while reducing the influence of answer position. Experiments show improved performance in coherence and semantic relevance across merged responses. The reviewer finds the method effective and promising, with clear strengths in handling semantic similarity and generalizability, but notes potential limitations in merging dissimilar responses and the need for further empirical comparison.",
      "strengths": [
        "Effectively addresses position bias by integrating responses based on semantic content.",
        "Leverages advanced semantic similarity metrics to retain meaning and coherence.",
        "Generalizable across different types of open-ended questions."
      ],
      "weaknesses": [
        "May struggle with responses that have significantly different lengths or semantic content.",
        "Risk of over-merging dissimilar responses, potentially diluting distinctiveness.",
        "Effectiveness in maintaining coherence and meaning during merging is not fully quantified."
      ],
      "questions": [
        "How does the method handle responses with varying lengths or semantic content?",
        "What are the limitations when dealing with open-ended questions lacking clear semantic overlap?",
        "How does the merging process ensure coherence and meaning are preserved?",
        "What is the trade-off between reducing position bias and maintaining evaluation quality?",
        "How does the proposed method compare to existing approaches for mitigating position bias in LLM-based evaluators?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1hsVvgW0rU",
    "title": "Sample-Efficient Learning of POMDPs",
    "std_review": {
      "summary": "The paper introduces k-MO revealing POMDPs, extending the MO POMDP framework to allow multiple observations per episode. It provides clear definitions, rigorous theoretical analysis of learnability and sample efficiency, and highlights practical benefits of multiple retrospective observations. While addressing some accessibility and applicability concerns, the work is strong and valuable, leading to an acceptance recommendation.",
      "strengths": [
        "Novel extension of MO POMDPs to multiple observations.",
        "Clear definitions and conditions for k-MO POMDPs.",
        "Rigorous theoretical analysis of learnability and sample efficiency."
      ],
      "weaknesses": [
        "Complexity of definitions may hinder accessibility for readers unfamiliar with POMDPs.",
        "Relies on availability of multiple observations at the end of episodes, which may not be realistic.",
        "Sample efficiency discussion focuses on retrospective observations, not online learning."
      ],
      "questions": [
        "How can the framework be adapted for online learning scenarios with limited observations?",
        "What concrete examples illustrate computational or statistical separations between K=1 and K>1?",
        "How can absolute learnability be established to complement the PAC-based results?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1IaoWBqB6K",
    "title": "DiffDock-Pocket: Diffusion for Pocket-Level Docking with Sidechain Flexibility",
    "std_review": {
      "summary": "DiffDock-Pocket introduces a novel pocket-centric approach to protein-ligand docking that integrates sidechain flexibility, significantly improving docking accuracy over traditional methods like SMINA and GNINA. The model's innovative pocket definition and sidechain modeling enhance precision, especially in scenarios where sidechain movements are critical. Despite increased computational demands, the method demonstrates robust performance across diverse protein types, though its training data dependency and sidechain prediction quality remain areas for potential improvement.",
      "strengths": [
        "Innovative pocket definition enhances docking precision.",
        "Sidechain flexibility modeling captures dynamic interactions crucial for accurate binding predictions.",
        "Consistently outperforms traditional docking methods, particularly in scenarios with significant sidechain movements."
      ],
      "weaknesses": [
        "Increased computational complexity may limit applicability to large-scale or resource-constrained environments.",
        "Performance heavily relies on the quality and diversity of training datasets.",
        "Sidechain prediction quality can vary, impacting overall results in cases with significant sidechain involvement."
      ],
      "questions": [
        "How does the model handle proteins with highly atypical or poorly structured sidechains?",
        "What strategies can be employed to reduce the computational demand while maintaining performance?",
        "How does the model's performance compare to other state-of-the-art methods when the binding site is predicted rather than known?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1ii8idH4tH",
    "title": "",
    "std_review": {
      "summary": "The paper introduces Momentum Screening (MS), an algorithm designed to improve robust training in the presence of Byzantine faults and gradient heterogeneity. MS adapts its parameters based on the Byzantine fraction δ and the maximum gradient heterogeneity ζmax, achieving a minimax optimal error rate of O(δ²ζmax²). Empirical evaluations show MS outperforms existing methods across various scenarios, highlighting its practical robustness and efficiency. However, the paper could improve by addressing unknown heterogeneity, computational complexity, scalability, and providing hyperparameter tuning guidelines.",
      "strengths": [
        "Adaptive parameter tuning based on Byzantine fraction and gradient heterogeneity",
        "Theoretical guarantee of minimax optimal error rate",
        "Empirical superiority over existing methods",
        "Comprehensive theoretical analysis of convergence rates"
      ],
      "weaknesses": [
        "Unknown heterogeneity scenario not fully addressed",
        "Lack of detailed computational complexity analysis",
        "Scalability concerns not thoroughly explored",
        "No empirical guidelines for hyperparameter tuning"
      ],
      "questions": [
        "How does MS perform when true heterogeneity is unknown?",
        "What is the detailed computational complexity of MS compared to other Byzantine-robust methods?",
        "How does MS scale with an increasing number of clients or more complex models?",
        "What empirical guidelines are recommended for tuning hyperparameters like τt and the momentum coefficient?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1IIiQnLRe8",
    "title": "",
    "std_review": {
      "summary": "The paper introduces BiRDM, a bidirectional regularized diversity modulation framework for detecting semantic shifts in data streams. It effectively models feature diversity in both forward and backward directions, integrating a smoothness regularization component to balance reconstruction and suppression of out‑of‑distribution samples. Experimental evaluations across multiple datasets demonstrate BiRDM's superior performance compared to existing methods, highlighting its robustness and effectiveness. The reviewer finds the approach innovative, well‑validated, and a significant advancement in semantic shift detection.",
      "strengths": [
        "Innovative bidirectional regularized diversity modulation framework for semantic shift detection.",
        "Balanced regularization strategy that enhances robustness in dynamic environments.",
        "Comprehensive experimental validation across multiple datasets.",
        "Clear contributions to extending and improving reconstruction‑based methods."
      ],
      "weaknesses": [
        "Implementation complexity due to bidirectional architecture and dual regularization.",
        "Hyper‑parameter sensitivity may limit practical applicability without extensive tuning.",
        "Limited real‑world testing despite strong performance on synthetic and benchmark datasets."
      ],
      "questions": [
        "How can the implementation complexity be mitigated to improve practical deployment?",
        "What are the specific hyper‑parameter tuning strategies recommended for real‑world applications?",
        "Could the method be extended to handle streaming data with evolving semantics more efficiently?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1iKydVG6pL",
    "title": "Discovering Mathematical Formulas from Data via LSTM-guided Monte Carlo Tree Search",
    "std_review": {
      "summary": "The paper introduces AlphaSymbol, a method that combines LSTM networks with Monte Carlo Tree Search (MCTS) to perform symbolic regression, aiming to recover symbolic expressions from data more effectively than traditional methods. The approach shows promise with higher recovery rates and computational efficiency on benchmark datasets, but lacks detailed explanations of LSTM guidance, evaluation metrics, and specific loss function details. While the method demonstrates clear strengths, its acceptance is limited by these omissions, leading to a recommendation for weak acceptance.",
      "strengths": [
        "Innovative integration of LSTM and MCTS for symbolic regression",
        "Demonstrated higher full recovery rates compared to baselines",
        "Efficient search process with reduced computational time"
      ],
      "weaknesses": [
        "Lack of detailed explanation of how LSTM influences MCTS",
        "Ambiguity in the definition and measurement of success metrics",
        "Insufficient elaboration on the new reward and loss functions"
      ],
      "questions": [
        "How is the LSTM guidance coordinated with the MCTS search process?",
        "What are the specific details of the new reward function and loss function?",
        "How is the evaluation of the search process defined, and when is a search considered 'not recovered'?",
        "Are there comparisons of running times between the proposed method and baselines?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "1jbh2e0b2K",
    "title": "Towards Few-Shot Adaptation of Foundation Models via Multitask Finetuning",
    "std_review": {
      "summary": "The paper introduces a Consistency-Diversity Task Selection algorithm designed to enhance few-shot adaptation in multitask finetuning. It demonstrates strong empirical performance across tieredImageNet, Meta-Dataset, and ImageNet, outperforming standard multitask finetuning and meta‑learning baselines like MAML. While the theoretical framework and experimental results are compelling, the lack of visual aids, ablation studies, and publicly available code limits understanding and reproducibility.",
      "strengths": [
        "Clear theoretical framework for task diversity and consistency",
        "Innovative task selection algorithm balancing diversity and consistency",
        "Comprehensive experiments across multiple datasets and sample complexities"
      ],
      "weaknesses": [
        "Absence of visual aids makes it hard to intuit task relationships",
        "No ablation studies to assess algorithm robustness to hyperparameters",
        "Code not publicly available, hindering reproducibility"
      ],
      "questions": [
        "Could visualizations of task relationships improve understanding of the algorithm's effectiveness?",
        "What are the algorithm's robustness characteristics across different hyperparameter settings?",
        "Are there plans to release the code and experimental setup for further validation?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1JbsdayvhO",
    "title": "Denoising Diffusion via Image-Based Rendering",
    "std_review": {
      "summary": "The paper introduces IB‑planes, a novel representation for image-based rendering that integrates with diffusion models to generate high-fidelity 3D reconstructions from multi-view images. The approach conditions on multiple views during both training and inference, leveraging a diffusion model to refine 3D details while dropping self-views to encourage robustness. Experiments demonstrate improved performance over existing methods like pixelNeRF and RenderDiffusion, especially with varying numbers of views and in the presence of camera calibration errors. The method is innovative, robust, and outperforms baselines, but lacks qualitative evaluation and comprehensive baseline comparisons.",
      "strengths": [
        "Innovative representation for image-based rendering",
        "Seamless integration with diffusion models",
        "Robustness to camera calibration errors",
        "Strong performance over existing baselines"
      ],
      "weaknesses": [
        "Lack of qualitative evaluation",
        "No comparison against optimization-based pipelines or 3D-only diffusion models",
        "Limited analysis of diminishing returns with varying views"
      ],
      "questions": [
        "Could you provide qualitative comparison videos with baselines like pixelNeRF, RenderDiffusion, and Viewset-Diffusion?",
        "How does the model perform when compared to optimization-based pipelines using diffusion priors or 3D-only diffusion models?",
        "What is the detailed analysis of diminishing returns with varying numbers of conditioning views?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1JiIKjcwrr",
    "title": "Robust Self-supervised learning in Heterogeneous graph based on Feature-Topology Balancing",
    "std_review": {
      "summary": "BFTNet presents a novel framework for self-supervised learning on heterogeneous graphs by balancing graph topology and node features through a dual attention mechanism. The approach shows strong performance and robustness, especially in noisy or skewed datasets, outperforming existing methods. While introducing significant computational complexity and interpretability challenges, the theoretical justification and state-of-the-art results justify its acceptance.",
      "strengths": [
        "Balanced Integration of Topology and Features: BFTNet effectively combines graph topology and node features, enhancing representation learning.",
        "Robustness to Noisy Data: The framework includes mechanisms to handle noisy or skewed datasets, ensuring reliable performance.",
        "Theoretical Justification: The approach is grounded in theoretical insights about the importance of both structural and feature-based information in heterogeneous graphs.",
        "State-of-the-Art Performance: BFTNet demonstrates superior performance compared to existing state-of-the-art methods."
      ],
      "weaknesses": [
        "Computational Complexity: The dual attention mechanism may introduce significant computational overhead.",
        "Interpretability Challenges: The complex architecture may make it difficult to interpret the learned representations.",
        "Hyperparameter Sensitivity: The model's performance may be sensitive to hyperparameter tuning."
      ],
      "questions": [
        "How can the computational complexity of the dual attention mechanism be reduced for larger graphs?",
        "What methods can be employed to improve the interpretability of the learned representations?",
        "What are the optimal hyperparameter settings for achieving the best performance across different datasets?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1JPfHljXL4",
    "title": "When, Why and How Much?",
    "std_review": {
      "summary": "The paper presents a novel learning‑rate scheme that adapts during training, offering theoretical insights into gradient norm behavior and empirical improvements on GPT, RoBERTa, and ViT. While it provides strong evidence of effectiveness, the analysis is limited to non‑convex settings and specific model types, and some implementation details remain vague. Overall, the work is well‑received with a clear acceptance recommendation.",
      "strengths": [
        "Provides a rigorous theoretical analysis of gradient norm behavior under dynamic learning‑rate schedules.",
        "Introduces a novel, adaptive learning‑rate scheme that improves convergence and performance on state‑of‑the‑art models.",
        "Demonstrates strong empirical validation across multiple model architectures and datasets."
      ],
      "weaknesses": [
        "Theoretical analysis primarily focuses on non‑convex deep learning problems, limiting generalizability.",
        "Empirical experiments are concentrated on GPT, RoBERTa, and ViT, potentially restricting the applicability to other domains.",
        "The dynamic nature of the proposed schedule may introduce additional computational overhead.",
        "Lack of comprehensive comparison with modern adaptive optimizers like Adam or LAMB."
      ],
      "questions": [
        "How does the proposed learning‑rate scheme perform on convex optimization problems or other model types beyond GPT, RoBERTa, and ViT?",
        "What are the practical implementation details and computational costs of the dynamic learning‑rate approach?",
        "Could the method be combined with batch size adjustments or other heuristics for further performance gains?",
        "How does the proposed method compare to adaptive optimizers such as Adam or LAMB in terms of convergence speed and final performance?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1JR20YOE0H",
    "title": "On Feature Diversity in Energy-based Models",
    "std_review": {
      "summary": "The paper introduces (ϑ−τ)-diversity, a novel regularization technique for energy-based models that enhances feature diversity and improves generalization. Theoretical analysis provides new insights into feature diversity and generalization bounds, while empirical results on image classification and natural language processing tasks show significant improvements over state-of-the-art methods. Despite some limitations in generality and computational exploration, the contributions are strong and the results are compelling.",
      "strengths": [
        "Introduces a fresh perspective on feature diversity in energy-based models.",
        "Provides novel theoretical analysis and generalization bounds.",
        "Demonstrates strong empirical improvements over existing methods."
      ],
      "weaknesses": [
        "Theoretical results are limited by specific assumptions on energy functions and data distributions.",
        "Empirical evaluation is focused on a limited set of tasks and datasets.",
        "Computational implications of enforcing feature diversity are not fully explored.",
        "Comparison with existing regularization methods is cursory."
      ],
      "questions": [
        "How does the proposed regularization perform on more diverse benchmarks?",
        "What are the theoretical guarantees under broader model architectures?",
        "How does the computational cost scale with large-scale models or high-dimensional data?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1JtTPYBKqt",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a novel method for retrieving computational graphs (CGs) using a context graph that captures both structural and functional relationships. It leverages graph embeddings and a retrieval framework, evaluated on a dataset of 12k labeled CGs, showing improved performance over baseline textual and code-based systems. While demonstrating strong empirical results, the paper lacks reproducibility details, a comprehensive comparison with other retrieval techniques, and clear criteria for graded relevance, preventing full acceptance.",
      "strengths": [
        "Innovative context graph representation that captures both structural and functional relationships.",
        "Scalable retrieval system suitable for large datasets.",
        "Empirical validation on a substantial dataset with clear performance metrics."
      ],
      "weaknesses": [
        "Lack of reproducibility details regarding dataset collection and availability.",
        "Limited comparison with other state-of-the-art retrieval methods.",
        "Ambiguity in the criteria for graded relevance.",
        "Potential for overfitting due to reliance on embeddings."
      ],
      "questions": [
        "Will the 12k real-world computational graphs and their labels be made publicly available for reproducibility?",
        "How does the method compare to other state-of-the-art graph retrieval techniques?",
        "Could you clarify the specific criteria used for graded relevance versus non‑graded relevance?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "1JuMFjSkpD",
    "title": "Fair Attribute Classification via Distance Covariance",
    "std_review": {
      "summary": "The paper introduces a method for optimizing machine learning models for equal opportunity using distance covariance, a metric for measuring independence. It applies to both discrete and continuous variables, with a focus on continuous sensitive attributes. The method is compared favorably to baselines optimizing for differential privacy, showing practical advantages and potential for direct fairness optimization. Overall, the paper presents a robust and theoretically sound approach with promising practical implications.",
      "strengths": [
        "Introduces a novel metric (distance covariance) for measuring independence, particularly suited for optimization tasks.",
        "Provides a clear theoretical framework for handling both discrete and continuous variables, enhancing applicability.",
        "Demonstrates practical advantages over existing baselines that optimize for differential privacy, suggesting a more direct approach to fairness.",
        "Offers a comprehensive analysis of the method's mathematical properties, ensuring robustness and reliability."
      ],
      "weaknesses": [
        "The convergence analysis of the empirical distance covariance does not directly address the quality of the fair solution, which could limit practical applicability.",
        "Theoretical properties, while robust, do not fully address the optimization of the fairness-accuracy trade-off.",
        "The comparison with baselines optimizing for EO is not exhaustive, potentially overlooking other relevant methods or approaches."
      ],
      "questions": [
        "How does the convergence of the empirical distance covariance impact the optimization of the fairness-accuracy trade-off?",
        "Could additional analysis, such as bias-variance trade-off or sensitivity analysis, provide deeper insights into the relationship between convergence and fair solution quality?",
        "What are the specific advantages of using distance covariance over other fairness metrics in practical applications?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1k4yZbbDqX",
    "title": "InstaFlow: One Step is Enough for High-Quality Diffusion-Based Text-to-Image Generation",
    "std_review": {
      "summary": "InstaFlow presents a novel text‑conditioned rectified flow framework that accelerates diffusion‑based text‑to‑image generation to a single inference step, achieving competitive image quality with substantial computational savings. The authors demonstrate robust performance across diverse datasets, indicating general applicability. While the approach is technically innovative and efficient, concerns about training complexity, model architecture adaptability, and scalability to state‑of‑the‑art models remain. Ethical implications of rapid generation capabilities also warrant attention.",
      "strengths": [
        "Introduces a unique text‑conditioned rectified flow framework that significantly reduces inference time to a single step.",
        "Achieves comparable image quality to multiple diffusion steps with a single inference, offering substantial computational savings.",
        "Demonstrates robust performance across diverse datasets, indicating general applicability beyond specific evaluations."
      ],
      "weaknesses": [
        "Training process involves complex adjustments that may introduce hyper‑parameter sensitivity and affect reproducibility.",
        "Model architecture, particularly the Stacked U‑Net, is not fully explored for varying depth and channel dimensions, potentially limiting adaptability.",
        "Performance on advanced models like DeepFloyd IF and SDXL is not evaluated, raising questions about scalability and generalizability.",
        "Rapid generation capability could be misused for creating misleading or harmful content, necessitating careful deployment considerations."
      ],
      "questions": [
        "How does InstaFlow perform on state‑of‑the‑art diffusion models such as DeepFloyd IF and SDXL?",
        "What is the impact of varying the depth and channel dimensions of the Stacked U‑Net on model performance?",
        "What strategies can be employed to ensure the ethical deployment of one‑step text‑to‑image models like InstaFlow?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1M0qIxVKf6",
    "title": "Uncovering hidden geometry in Transformers via disentangling position and context",
    "std_review": {
      "summary": "The paper introduces a novel decomposition of Transformer hidden states into positional, contextual, and residual components, revealing low‑frequency positional embeddings and clustered contextual embeddings. It leverages Fourier analysis and operator norms to demonstrate the smooth spiral patterns of positional embeddings and their low‑rank structure. The decomposition provides interpretative insights and practical benefits for debugging and improving model design, though it has some complexity and scope limitations.",
      "strengths": [
        "Interpretability: Provides a clear framework for understanding Transformer encoding.",
        "Mathematical Rigor: Uses advanced tools like Fourier analysis and operator norms.",
        "Novel Decomposition: Separates positional, contextual, and residual components.",
        "Empirical Validation: Shows effectiveness through token randomization and arithmetic tasks."
      ],
      "weaknesses": [
        "Complexity: Requires strong linear algebra and Fourier analysis background.",
        "Scope Limitations: Focuses on hidden states, potentially overlooking other model behaviors.",
        "Scalability: Applicability to large models or specific architectures not fully addressed.",
        "Comparison with Existing Work: Lacks a comprehensive comparison of novelty and impact."
      ],
      "questions": [
        "How does the decomposition scale to very large models or specialized architectures like Vision Transformers?",
        "What are the practical implications of the low‑frequency nature of positional embeddings for model training and inference?",
        "How does the clustering of contextual embeddings relate to semantic topic modeling beyond document‑level topics?",
        "How does this decomposition compare with other analyses of positional embeddings, such as sinusoidal embeddings?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1M8yDTa0Pp",
    "title": "Cross-Model Semi-Supervised Prompt Learning for Vision-Language Models",
    "std_review": {
      "summary": "The paper presents a novel self-supervised learning approach for Vision-Language Models by adapting prompt learning techniques. It leverages the multimodal structure of VLMs to generate effective prompts, showing strong performance on benchmark datasets. While promising, the method's generalizability and robustness to out-of-distribution data are not fully explored. The authors should address these aspects in future work.",
      "strengths": [
        "Introduces a unique adaptation of prompt learning for VLMs, addressing a gap in SSL literature.",
        "Effectively leverages the multimodal nature of VLMs, potentially leading to more robust representations.",
        "Demonstrates competitive performance on benchmark datasets, validating the approach's effectiveness."
      ],
      "weaknesses": [
        "Performance is primarily evaluated on in-distribution datasets, limiting evidence of generalizability.",
        "Lacks comprehensive analysis of prompt robustness to out-of-distribution data or variations in dataset characteristics.",
        "Does not thoroughly explore trade-offs between different prompt learning strategies and their impact on VLM performance."
      ],
      "questions": [
        "How does the method perform on out-of-distribution datasets or with varying dataset characteristics?",
        "What measures can be taken to ensure the learned prompts are not overfitted to specific datasets?",
        "How does the method compare to other prompt learning strategies in terms of robustness and generalizability?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "1mjsP8RYAw",
    "title": "Unsupervised Pretraining for Fact Verification by Language Model Distillation",
    "std_review": {
      "summary": "The paper presents a method for fact verification that combines a knowledge graph (Wikidata) with a transformer-based language model. It shows strong performance on the FEVER dataset, achieving competitive accuracy. While the approach effectively integrates structured and unstructured data, it has limitations in generalizability, knowledge graph coverage, and broader benchmark evaluation. The method's scalability and interpretability for human users also warrant further consideration.",
      "strengths": [
        "Effectively combines structured knowledge with language understanding.",
        "Provides transparent evidence-based verification.",
        "Validated on a leading benchmark (FEVER) with strong results."
      ],
      "weaknesses": [
        "Relies on a fixed knowledge graph, limiting generalizability.",
        "Knowledge gaps in Wikidata may affect verification accuracy.",
        "Evaluation confined to FEVER, lacking broader benchmark comparison."
      ],
      "questions": [
        "How does the method handle claims with additional contextual information (e.g., time, location)?",
        "What is the interpretability of the evidence ranking for human users?",
        "How does the approach scale to larger models or more extensive knowledge graphs?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "1mNFsbvo2P",
    "title": "Domain constraints improve risk prediction when outcome data is missing",
    "std_review": {
      "summary": "The paper introduces a machine‑learning model that predicts disease risk for untested populations using genetic risk scores and demographic information. It leverages data from a tested cohort to inform predictions for an untested cohort, showing strong performance across age groups and clear improvements over baseline methods. Despite theoretical rigor and comprehensive evaluation, the model's reliance on a tested cohort and assumptions in baseline models limit its generalizability, and the absence of a prevalence constraint could lead to unrealistic predictions for older populations.",
      "strengths": [
        "Innovative approach to extending risk predictions to untested populations using genetic and demographic features.",
        "Theoretical justification for the negative coefficient on the genetic risk score, grounded in limited information settings.",
        "Comprehensive evaluation across age groups and clear comparisons to baseline methods."
      ],
      "weaknesses": [
        "Limited generalizability due to reliance on a tested cohort.",
        "Assumptions in baseline models may overstate the model's performance.",
        "Absence of prevalence constraint could result in unrealistic predictions for older populations."
      ],
      "questions": [
        "How does the model perform when applied to populations with different genetic testing policies?",
        "What is the impact of follow‑up data validation on the model's generalizability?",
        "How can the model be extended to incorporate additional demographic or clinical features?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1mOeklnLf4",
    "title": "FroSSL: Frobenius Norm Minimization for Self-Supervised Learning",
    "std_review": {
      "summary": "The paper introduces FroSSL, a novel loss function that enhances rotational invariance in deep learning models by combining a Frobenius norm regularizer with a logarithmic term. Experiments on image classification tasks show that FroSSL outperforms Barlow Twins and traditional softmax loss, demonstrating its effectiveness in improving model robustness and generalization. While the theoretical motivation and practical benefits are compelling, the review notes limited experimental scope and suggests additional studies to fully validate the method's broad applicability.",
      "strengths": [
        "Introduces a novel loss function that enhances rotational invariance.",
        "Demonstrates superior performance over existing methods on image classification tasks.",
        "Provides a clear theoretical justification for the use of the logarithm in the loss function."
      ],
      "weaknesses": [
        "Experiments are limited to image classification tasks.",
        "Lacks comprehensive comparison with other state-of-the-art methods.",
        "Potential overfitting risks are not thoroughly analyzed."
      ],
      "questions": [
        "How does FroSSL perform on tasks involving geometric transformations beyond image classification?",
        "What additional experiments could better demonstrate the method's advantages across diverse domains?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1MRfyGLCcU",
    "title": "Graph Representation Learning Enhanced Semi-supervised Feature Selection",
    "std_review": {
      "summary": "The paper introduces G-FS, a graph-based feature selection method that leverages graph neural networks to identify informative features in tabular data. It demonstrates superior accuracy and computational efficiency, especially on large datasets, and performs well in both semi-supervised and fully supervised settings. While innovative, the method's complexity and lack of theoretical guarantees are noted, and further benchmarking across diverse applications is suggested.",
      "strengths": [
        "Innovative integration of GNNs for feature selection.",
        "Batch-attention mechanism enhances adaptability and robustness.",
        "Demonstrates superior scalability and efficiency over traditional methods."
      ],
      "weaknesses": [
        "Implementation complexity due to advanced GNN components.",
        "Potential for overfitting with limited data.",
        "Absence of theoretical underpinnings."
      ],
      "questions": [
        "How does the method perform on highly imbalanced datasets?",
        "What regularization strategies can mitigate overfitting with limited data?",
        "How does G-FS compare to hybrid models combining graph and traditional feature selection?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1ndDmZdT4g",
    "title": "Dynamic Sparse No Training \\(\\mathbf{\\mathcal{O}}\\):",
    "std_review": {
      "summary": "The paper introduces DS⊘T, a method for creating sparse language models without extensive fine-tuning, using a dynamic threshold to prune parameters. It shows strong efficiency gains and competitive performance, but has some concerns about threshold sensitivity and scalability.",
      "strengths": [
        "Efficiently reduces computational requirements with dynamic pruning.",
        "Offers adjustable sparsity levels for flexible performance-efficiency trade-offs.",
        "Simplifies model deployment by eliminating the need for additional fine-tuning."
      ],
      "weaknesses": [
        "Threshold selection can significantly impact performance and requires careful tuning.",
        "Limited comparison with a broader range of sparse techniques.",
        "Lack of detailed hardware compatibility information.",
        "Scalability to very large models or complex tasks remains unexplored."
      ],
      "questions": [
        "How does DS⊘T perform on very large models or complex tasks?",
        "What are the specific hardware constraints and optimizations for DS⊘T?",
        "How does DS⊘T compare to other dynamic pruning methods beyond SparseGPT and Wanda?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1nfqABOIwQ",
    "title": "RIME: Robust Preference-based Reinforcement Learning with noisy human preferences",
    "std_review": {
      "summary": "The paper introduces RIME, a Preference-Based Reinforcement Learning method that improves robustness to noisy labels by actively selecting samples for labeling based on a preference discriminator. RIME integrates a discriminator into the learning pipeline to distinguish between clean and flipped labels, using these preferences to guide the training process. The method is evaluated on the Walker-2D environment, demonstrating improved performance over standard PbRL methods and robustness to varying levels of noise. The results highlight the effectiveness of RIME in maintaining high accuracy even as noise levels increase. Overall, RIME shows strong performance and robustness to noise, with a clear theoretical foundation and practical evaluation.",
      "strengths": [
        "Innovative Discriminator Integration: RIME uniquely integrates a preference discriminator directly into the learning pipeline, allowing for dynamic adjustment of label quality during training.",
        "Robustness to Noise: The method demonstrates strong performance across a range of noise levels, outperforming baseline PbRL approaches and traditional regularization methods like label smoothing and MAE.",
        "Theoretical Foundation: The paper provides a solid theoretical basis for the discriminator's role in preference discrimination, offering insights into how the method can be optimized."
      ],
      "weaknesses": [
        "Complexity of Implementation: The integration of a preference discriminator may introduce additional complexity in implementation and tuning, potentially making RIME less accessible to practitioners.",
        "Dependence on Warm-Start: The effectiveness of RIME is heavily reliant on the warm-start technique, which may limit its applicability to other domains or environments without similar pre-training strategies.",
        "Sampling Strategy: The choice of a uniform sampling schedule for query selection is not thoroughly justified compared to more sophisticated sampling methods, which could impact the method's performance in more complex scenarios."
      ],
      "questions": [
        "How can the complexity of implementing the preference discriminator be reduced to make RIME more accessible to practitioners?",
        "What are the potential impacts of RIME's dependence on warm-start techniques, and are there alternative strategies that could be explored?",
        "Could a more sophisticated sampling strategy, such as disagreement or uncertainty-based sampling, improve RIME's performance in more complex scenarios?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1NHgmKqOzZ",
    "title": "Data Distillation Can Be Like Vodka: Distilling More Times For Better Quality",
    "std_review": {
      "summary": "The paper introduces Progressive Dataset Distillation (PDD), a method that enhances dataset distillation by progressively refining distilled datasets. PDD captures training dynamics in multiple stages, leading to higher accuracy and efficiency compared to single-stage methods. The approach is evaluated against traditional techniques and various base methods, showing strong performance across different scenarios. Overall, the paper presents a novel and effective technique with clear benefits over existing methods.",
      "strengths": [
        "Improved performance over single-stage distillation methods",
        "Captures training dynamics in a multi-stage manner",
        "Enhances scalability and efficiency for large datasets",
        "Demonstrates broad applicability across different base distillation methods"
      ],
      "weaknesses": [
        "Increased implementation complexity due to multi-stage approach",
        "Potential for overfitting with smaller datasets",
        "Resource-intensive initial setup and training phases"
      ],
      "questions": [
        "How does PDD handle overfitting in scenarios with limited training data?",
        "What adaptive strategies can be employed to address challenges with datasets of varying complexity?",
        "Can PDD be integrated with other distillation techniques to further improve performance?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1OfAO2mes1",
    "title": "Backdoor Secrets Unveiled: Identifying Backdoor Data with Optimized Scaled Prediction Consistency",
    "std_review": {
      "summary": "The paper introduces MSPC, a novel method for detecting backdoors in machine learning models by incorporating a learnable mask into the Scaled Prediction Consistency approach. It proposes a bilevel optimization framework that automatically filters out backdoor samples without a predefined threshold, offering a practical solution for real-world applications. While demonstrating strong performance against various attacks, the method's computational complexity and potential false positive rates are noted as areas for improvement.",
      "strengths": [
        "Innovative learnable mask mechanism improves detection accuracy.",
        "Threshold-free detection provides a more practical solution for real-world applications.",
        "Comprehensive evaluation across multiple backdoor attacks and baselines."
      ],
      "weaknesses": [
        "Significant computational complexity may limit applicability in resource-constrained environments.",
        "Potential false positive rate could impact practical deployment.",
        "Effectiveness in high poisoning rate scenarios is not thoroughly explored."
      ],
      "questions": [
        "How does MSPC perform under extreme poisoning rates compared to other methods?",
        "What is the impact of non-normalized input values on the effectiveness of the learnable mask?",
        "How does MSPC compare to threshold-based methods like CD under similar conditions?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1oijHJBRsT",
    "title": "Self-Alignment with Instruction Backtrans-Lation",
    "std_review": {
      "summary": "The paper introduces a novel self‑alignment technique for instruction‑following language models, using multiple iterations of self‑curated instruction data from the ClueWeb dataset. The authors demonstrate significant performance gains over standard distillation methods across various benchmarks, highlighting the method's practical utility and scalability. While the study shows strong results, it also notes limitations such as limited benchmark coverage and potential quality variability in web‑derived data. Overall, the paper is well‑structured, with clear experimental setups and a promising approach.",
      "strengths": [
        "Innovative self‑alignment method using self‑curated instruction data",
        "Scalable data generation from a large web corpus",
        "Strong performance improvements over traditional distillation",
        "Clear and thorough experimental evaluation"
      ],
      "weaknesses": [
        "Limited benchmark coverage may not fully capture method's versatility",
        "Potential variability in data quality from web extraction",
        "Computational cost of generating large self‑curated datasets",
        "Lack of detailed analysis on diminishing returns of additional iterations"
      ],
      "questions": [
        "How does the method perform on a broader set of instruction benchmarks?",
        "What is the impact of different filtering criteria on data quality?",
        "Can the method be applied to resource‑constrained settings, and if so, how?",
        "Are there diminishing returns beyond a certain number of self‑curated iterations?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1OP4crhgkD",
    "title": "Semantically Aligned Task Decomposition in Multi-Agent Reinforcement Learning",
    "std_review": {
      "summary": "The SAMA framework introduces a novel approach to MARL by leveraging pre-trained language models to address sparse rewards and enable semantically aligned task decomposition. It generates task manuals and state/action translations from existing literature and code, reducing manual effort. Preliminary results on Overcooked and MiniRTS show improved sample efficiency and performance compared to traditional methods. While promising, the framework's reliance on PLMs and limited applicability to non‑language‑expressible environments are concerns.",
      "strengths": [
        "Introduces a novel framework for MARL that effectively addresses the sparse reward problem using PLMs.",
        "Enables semantically aligned task decomposition and subgoal allocation through language‑grounded interactions.",
        "Utilizes existing papers and code to generate task manuals and state/action translations, reducing manual effort."
      ],
      "weaknesses": [
        "Limited applicability to environments where human rationality is not easily expressible in language.",
        "Reliance on PLMs may introduce challenges in terms of cost and feasibility for real-world deployment.",
        "Effectiveness may depend on the quality and relevance of generated task manuals and translations.",
        "Potential limitations in handling complex or ambiguous task instructions."
      ],
      "questions": [
        "How does SAMA handle environments where human rationality is not easily expressible in language?",
        "What are the cost and feasibility implications of deploying SAMA with high‑quality PLMs in real-world scenarios?",
        "How does SAMA ensure the quality and relevance of task manuals and state/action translations generated from existing literature and code?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1op5YGZu8X",
    "title": "Theoretical Analysis of Robust Overfitting for Wide DNNs: An NTK Approach",
    "std_review": {
      "summary": "The paper introduces a novel theoretical framework using the Neural Tangent Kernel (NTK) to analyze adversarial training, deriving a regularization matrix that captures adversarial robustness. It shows improved robust test accuracy on SVHN and CIFAR-10 datasets, distinguishing between robust overfitting and adversarial training degeneration. While promising, the framework assumes large network widths and non-standard architectures, limiting its practical applicability.",
      "strengths": [
        "Introduces a novel theoretical framework using NTK to analyze adversarial training.",
        "Derives a regularization matrix Ξ(t) that effectively captures adversarial robustness.",
        "Provides a clear distinction between robust overfitting and adversarial training degeneration.",
        "Empirical results on SVHN and CIFAR-10 datasets validate theoretical findings.",
        "Discusses implications for classification settings, suggesting potential extensions."
      ],
      "weaknesses": [
        "Theoretical framework assumes large network widths, which may not be realistic in practice.",
        "Experiments use non-standard architectures without GAP layers, limiting generalizability.",
        "Lack of empirical confirmation for the phenomenon of adversarial training degeneration.",
        "Theoretical assumptions may limit applicability to real-world scenarios.",
        "Practical translation of NTK insights into adversarial training algorithms is challenging."
      ],
      "questions": [
        "Can the framework be adapted to standard architectures like ResNet?",
        "What is the impact of the absence of a global average pooling (GAP) layer on robustness?",
        "How can the phenomenon of adversarial training degeneration be empirically confirmed?",
        "What are the practical implications of the theoretical assumptions regarding network width?",
        "How can the insights from NTK be practically applied to adversarial training algorithms?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "1oqedRt6Z7",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a convolutional Deep Kernel Method (convDKM) that extends the infinite‑width Neural Network Gaussian Process (NNGP) framework to convolutional architectures. By learning a Gram matrix for each layer, the method enables representation learning through kernel functions that capture hierarchical feature interactions. Experiments on CIFAR‑10 show improved interpretability and uncertainty estimation, though the impact on larger datasets like CIFAR‑100 remains unexplored. The convDKM bridges kernel methods and deep learning, offering a principled way to learn representations and estimate uncertainty, with strengths in interpretability and theoretical insight.",
      "strengths": [
        "Extension of NNGP to Convolutional Networks",
        "Learnable Representation via Gram Matrices",
        "Interpretability and Uncertainty Estimation"
      ],
      "weaknesses": [
        "Limited Dataset Experiments",
        "Lack of Detailed Theoretical Analysis",
        "Potential Computational Complexity"
      ],
      "questions": [
        "How does the method perform on larger datasets like CIFAR‑100?",
        "What are the theoretical convergence properties and generalization bounds?",
        "How does the choice of inducing points affect scalability and accuracy?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1P1nxem1jU",
    "title": "Through the Dual-Prism: A Spectral Perspective on Graph Data Augmentation for Graph Classification",
    "std_review": {
      "summary": "The paper presents a novel spectral graph partitioning method that uses eigenvalue manipulations to create augmented graphs, aiming to improve efficiency and accuracy in large-scale graph classification tasks. Experimental results show competitive performance, but several issues remain, such as unclear computational complexity, lack of additional examples, and limited proof robustness. Overall, the work is promising yet requires further refinement.",
      "strengths": [
        "Introduces a fresh perspective on spectral graph partitioning through eigenvalue-based augmented graphs.",
        "Provides a solid theoretical foundation with clear observations and proofs.",
        "Demonstrates competitive empirical performance across multiple datasets."
      ],
      "weaknesses": [
        "Computational complexity of the eigendecomposition step is not clearly addressed.",
        "Lacks additional examples of augmented graphs to illustrate method flexibility.",
        "Marginal improvements over existing methods raise questions about limitations.",
        "Proof for Observation 4 relies heavily on a single prior work.",
        "Some figures have small font sizes, affecting readability."
      ],
      "questions": [
        "Can you clarify the computational complexity of the eigendecomposition step and its scalability with graph size?",
        "Providing additional examples of augmented graphs would help clarify the method's applicability.",
        "A more thorough analysis of the marginal improvements over existing methods would strengthen the paper.",
        "Extending the proof for Observation 4 to include independent arguments would enhance its validity.",
        "Increasing the font size in figures would improve their readability and accessibility."
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "1p4q1cXOX9",
    "title": "Attribute-Enhanced Similarity Ranking for Sparse Link Prediction",
    "std_review": {
      "summary": "The paper introduces Gelato, a GNN approach for link prediction that tackles biased testing in sparse graphs by integrating a topological heuristic, N-pair loss, and hard negative sampling via graph partitioning. Gelato's method effectively handles class imbalance and learns meaningful relationships through attribute similarity, topological weights, and learned weights in the adjacency matrix. While demonstrating superior performance on sparse datasets, the paper's applicability to non-sparse graphs and the lack of clear hyperparameter guidance are noted as areas for improvement.",
      "strengths": [
        "Gelato effectively addresses biased testing in sparse graphs by incorporating a topological heuristic and a novel N-pair loss.",
        "The use of graph partitioning for negative sampling introduces a systematic way to generate hard negatives, improving the model's ability to distinguish between true and false links.",
        "The integration of attribute similarity, topological weights, and both untrained and trained weights in the adjacency matrix allows Gelato to capture diverse relationship patterns in sparse graphs, enhancing its predictive power."
      ],
      "weaknesses": [
        "Gelato's performance on non-sparse graphs is not well-documented, limiting its broader applicability.",
        "The computational and memory overheads associated with graph partitioning and hard negative sampling could impact training efficiency, especially for very large graphs.",
        "The hyperparameters α and β require careful tuning, and their optimal values are not clearly identified, which may affect the model's generalization performance."
      ],
      "questions": [
        "How does Gelato perform on non-sparse graph datasets, and what strategies could be employed to improve its generalizability?",
        "What are the optimal values for the hyperparameters α and β, and how can they be identified?",
        "Could the computational and memory overheads be reduced while maintaining Gelato's performance on large graphs?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "1P92J25hdf",
    "title": "Going Deeper with General and Specific Inductive Bias for Real-Time Stereo Matching",
    "std_review": {
      "summary": "The paper presents a novel cost‑volume representation for 3D reconstruction that explicitly leverages a specific inductive bias to improve scale invariance and efficiency. It introduces a Dense Scale‑Aware Fusion (DSF) module that decomposes the scale problem into low‑resolution initialization and high‑resolution refinement, complemented by a Mixed Direct Long‑Range Compensation (MDLC) mechanism to capture long‑range dependencies beyond traditional Transformer architectures. The model achieves real‑time inference with competitive accuracy on standard benchmarks while demonstrating strong generalization on unseen datasets without fine‑tuning. Overall, the work is innovative, technically sound, and offers practical advantages for real‑time 3D reconstruction.",
      "strengths": [
        "Innovative inductive bias for cost‑volume representation that explicitly targets scale invariance.",
        "Dense Scale‑Aware Fusion (DSF) module effectively decomposes the scale problem into efficient low‑resolution initialization and high‑resolution refinement.",
        "Mixed Direct Long‑Range Compensation (MDLC) extends beyond Transformer methods to capture long‑range dependencies directly.",
        "Demonstrates robust generalization on unseen datasets (SCARED) without requiring fine‑tuning.",
        "Achieves real‑time inference while maintaining high accuracy, offering a practical advantage for applications."
      ],
      "weaknesses": [
        "The MDLC mechanism introduces additional complexity that may complicate implementation and require careful tuning.",
        "Limited benchmark coverage; additional evaluations could provide a more comprehensive assessment of robustness.",
        "Lack of fine‑tuning on target datasets raises questions about adaptability to highly specialized scenarios.",
        "The utility of the new statistical indicators for guiding model design or debugging remains underexplored."
      ],
      "questions": [
        "How does the MDLC mechanism compare to other direct methods in terms of computational cost and scalability?",
        "Could the statistical indicators be further refined to provide more actionable insights for debugging and model improvement?",
        "What are the specific challenges and strategies for adapting the model to highly specialized or domain‑specific 3D reconstruction tasks?",
        "How does the model perform under extreme lighting conditions or with highly textured environments that are not well represented in the current benchmark datasets?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1PPjf4wife",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a novel approach to multi-agent reinforcement learning (MARL) by leveraging multiple large language models (LLMs) to address sample inefficiency, policy generalization, and interpretability. Each agent is associated with a dedicated LLM that receives partial observations and generates policies. The authors evaluate their method on the BabyAI‑text and traffic junction environments, demonstrating improved performance over traditional RL baselines. While the approach shows promise, several concerns regarding the necessity of multiple LLMs, prompt function design, and generalizability need to be addressed.",
      "strengths": [
        "Innovative Use of LLMs: The paper creatively applies LLMs to MARL, potentially offering a solution to longstanding challenges in sample efficiency and policy generalization.",
        "Interpretability: LLM policies can be more interpretable than traditional RL policies, providing insights into decision-making processes.",
        "Communication Module: The discrete message passing module introduces a structured way for agents to share information, which could enhance coordination and performance."
      ],
      "weaknesses": [
        "Necessity of Multiple LLMs: The paper does not sufficiently justify why multiple LLMs are required, rather than a single central LLM receiving partial observations.",
        "Fixed vs. Trainable Prompt Function: The prompt function is fixed, which may limit the flexibility and performance of the policies. Making it trainable could be beneficial.",
        "Performance Gaps: The paper lacks detailed analysis on why LLM policies outperform traditional RL policies, which is crucial for understanding the method's advantages."
      ],
      "questions": [
        "Why are multiple LLMs necessary rather than a single central LLM receiving partial observations?",
        "How could the prompt function be made trainable to improve policy performance?",
        "What detailed analysis is needed to understand why LLM policies outperform traditional RL policies?",
        "What ablation studies are required to quantify the impact of the discrete message passing module?",
        "What additional training details are needed for baselines like MAPPO and MAPPO‑GLAM to ensure fair comparisons?",
        "How could the environments used be made more complex to better demonstrate the general applicability of the proposed method?",
        "How can the notation for parameters and discrete messages be standardized for clarity?",
        "How could the framework be adapted to handle heterogeneous agents beyond the current homogeneous assumption?",
        "What additional information is needed to reproduce the experimental results more reliably?"
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "1pSL2cXWoz",
    "title": "ConjNorm: Tractable Density Estimation for Out-of-Distribution Detection",
    "std_review": {
      "summary": "The paper presents ConjNorm, a method for density estimation using conjugate pairs of norms within the exponential family. It offers a flexible and theoretically grounded approach, with strong empirical results and theoretical guarantees. While implementation challenges exist, the method's potential for improved out-of-distribution detection is significant.",
      "strengths": [
        "Innovative use of conjugate pairs for tractable partition function estimation.",
        "Flexibility through tunable parameter p balances model complexity and efficiency.",
        "Provides strong theoretical backing, including consistency and tractability guarantees."
      ],
      "weaknesses": [
        "Complexity in selecting the optimal p value for practical implementation.",
        "Assumes specific data distribution forms and a uniform prior, limiting applicability.",
        "Empirical validation is limited to a few benchmark datasets."
      ],
      "questions": [
        "How can the choice of p be automated or guided in practice?",
        "What are the theoretical guarantees under more general distribution assumptions?",
        "How does the method perform on a broader range of datasets beyond the current benchmarks?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1pTlvxIfuV",
    "title": "A Reparameterized Discrete Diffusion Model for Text Generation",
    "std_review": {
      "summary": "The paper introduces a reparameterized discrete diffusion model (RDM) that enhances training and decoding efficiency through a novel non-autoregressive inference technique. It demonstrates competitive performance on conditional tasks like machine translation, question generation, and paraphrasing, and provides insights into optimizing iteration steps for quality and efficiency. However, the model's evaluation is limited to specific tasks, and its performance on open-domain generation is not thoroughly benchmarked against state-of-the-art models.",
      "strengths": [
        "Introduces a novel reparameterization technique enabling non-autoregressive inference, improving efficiency.",
        "Demonstrates competitive performance on conditional tasks such as machine translation, question generation, and paraphrasing.",
        "Provides a comprehensive analysis of the impact of iteration steps on generation quality and computational efficiency."
      ],
      "weaknesses": [
        "Limited evaluation on open-domain text generation tasks beyond specified conditional tasks.",
        "Computational cost comparison with other non-autoregressive models is not as extensive.",
        "Choice of iteration steps is not exhaustively explored, leaving room for further investigation.",
        "Model's performance on open-domain tasks is not thoroughly benchmarked against state-of-the-art models."
      ],
      "questions": [
        "How does the RDM perform on open-domain text generation tasks compared to state-of-the-art models?",
        "What is the impact of varying the number of iteration steps on generation quality in diverse applications?",
        "How does the RDM compare to other non-autoregressive diffusion models in terms of computational efficiency?"
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "1PXEY7ofFX",
    "title": "Bespoke Solvers for Generative Flow Models",
    "std_review": {
      "summary": "The paper introduces a novel solver for trajectory optimization that uses a learnable, scale‑time transformed velocity field to reduce the number of function evaluations needed, achieving significant speed improvements without sacrificing quality. The method is evaluated on several benchmarks and includes comprehensive ablation studies, demonstrating its efficiency and robustness. While the approach is innovative and shows strong empirical results, some concerns about generalization and the detailed justification of training time remain. Overall, the paper is well‑structured and makes a valuable contribution to the field.",
      "strengths": [
        "Innovative solver design using a scale‑time transformed velocity field.",
        "Significant reduction in function evaluations leading to faster training times.",
        "Comprehensive ablation studies and strong baseline comparisons."
      ],
      "weaknesses": [
        "Limited generalization to other domains due to focus on specific models and datasets.",
        "Lack of detailed information on the cost of generating ground‑truth trajectories.",
        "Absence of robustness tests under varying conditions."
      ],
      "questions": [
        "How does the solver perform when applied to a broader range of generative models beyond those tested?",
        "What is the exact computational cost of generating the ground‑truth trajectories used for training?",
        "Could you provide more details on the robustness of the solver when the number of function evaluations is increased or when faced with unseen data?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1qDRwhe379",
    "title": "Refining Corpora from a Model Calibration Perspective for Chinese Spelling Correction",
    "std_review": {
      "summary": "The paper tackles calibration issues in Chinese spelling correction models trained on OCR/ASR data, proposing a BERT-based filtering method to improve calibration. It highlights differences between random replacement and OCR/ASR data augmentation, evaluates calibration, and discusses downstream performance impacts. While innovative, the study is limited to Chinese spelling correction and BERT models, with potential generalization issues.",
      "strengths": [
        "Effectively addresses calibration challenges specific to OCR/ASR-generated datasets.",
        "Introduces a novel BERT-based filtering method to improve model calibration.",
        "Provides a thorough comparative analysis between random replacement and OCR/ASR data augmentation.",
        "Conducts empirical evaluation demonstrating the method's effectiveness."
      ],
      "weaknesses": [
        "Scope is limited to Chinese spelling correction, potentially restricting generalizability.",
        "The filtering method is specific to BERT-based models, limiting applicability to other models or datasets.",
        "Lacks extensive exploration of generalizing the approach to other data augmentation strategies or domains.",
        "Calibration metrics may not fully capture model performance nuances across all scenarios."
      ],
      "questions": [
        "How can the filtering approach be adapted for other languages or domains?",
        "What are the long-term implications of using BERT-based models for calibration in different NLP tasks?",
        "Could the method be extended to other types of data augmentation beyond OCR/ASR?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1qzUPE5QDZ",
    "title": "Rectifying Group Irregularities in Explanations for Distribution Shift",
    "std_review": {
      "summary": "The paper introduces Group‑aware Shift Explanations (GSE), a method that extends distributionally robust optimization with group constraints to improve fairness and robustness. GSE shows strong empirical improvements on several datasets and provides theoretical guarantees, but it struggles with defining groups when demographic information is ambiguous or missing, and does not fully address scalability or computational complexity.",
      "strengths": [
        "Incorporates group constraints to address fairness in distributionally robust optimization.",
        "Provides strong theoretical guarantees for feasibility and robustness.",
        "Demonstrates empirical improvements in robustness and fairness across demographic groups."
      ],
      "weaknesses": [
        "Lacks a clear methodology for defining groups when demographic information is not explicitly available.",
        "Does not explicitly address how to handle ambiguous or potentially biased group information.",
        "Theoretical guarantees are strong but their practical implications in the absence of precise group information are not fully explored.",
        "Scalability and computational complexity are not adequately addressed."
      ],
      "questions": [
        "How should groups be defined when demographic information is ambiguous or missing?",
        "What safeguards are in place to handle ambiguous or biased group information?",
        "How does the method scale to large datasets, especially when groups are automatically discovered?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "1RE0H6mU7M",
    "title": "MAMBA: an Effective World Model Approach for Meta-Reinforcement Learning",
    "std_review": {
      "summary": "MAMBA is a novel model-based meta-reinforcement learning algorithm that efficiently learns policies for tasks with decomposable structure. It introduces hierarchical task decomposition, dynamic horizon scheduling, and local reconstruction to improve sample efficiency and scalability. Empirical results show strong performance compared to existing methods, especially on decomposable tasks, but the approach is limited to tasks that can be meaningfully decomposed.",
      "strengths": [
        "Hierarchical task decomposition enables parallel learning and reduced sample complexity.",
        "Dynamic horizon scheduling balances exploration and exploitation based on task difficulty.",
        "Local reconstruction approach reduces computational burden while capturing essential task characteristics."
      ],
      "weaknesses": [
        "Relies on the assumption that tasks can be decomposed, limiting applicability to non-decomposable tasks.",
        "Local reconstruction may not capture global task dynamics as effectively as global methods.",
        "Performance is sensitive to hyperparameter choices, requiring careful tuning."
      ],
      "questions": [
        "How can MAMBA be extended to handle non-decomposable tasks?",
        "What are the theoretical guarantees for performance on non-decomposable tasks?",
        "How does MAMBA compare to global reconstruction approaches in terms of scalability and accuracy?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1rgMkDWfYV",
    "title": "",
    "std_review": {
      "summary": "The paper presents a semi-supervised learning framework that refines CLIP's loss formulation to improve zero-shot classification with noisy labels. It introduces a novel sample selection mechanism and demonstrates competitive performance on benchmarks. However, it lacks qualitative analysis, robustness evaluations, and a clear justification for the impact of label noise on the sample distribution.",
      "strengths": [
        "Introduces a novel sample selection mechanism for semi-supervised learning.",
        "Reformulates the CLIP loss to better handle noisy data, showing competitive results.",
        "Demonstrates practical utility with results on several benchmarks."
      ],
      "weaknesses": [
        "Lacks comprehensive qualitative analysis of how the method handles noisy data.",
        "Does not evaluate robustness across different model variants or vision‑language models.",
        "The justification for label noise not affecting sample distribution is unclear."
      ],
      "questions": [
        "Could you provide visual or behavioral insights into how the method handles noisy data?",
        "What is the impact of the proposed sample selection mechanism on robustness to different vision‑language models?",
        "How does the method perform under asymmetric noise scenarios?"
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "1RrOtCmuKr",
    "title": "Network Memory Footprint Compression Through Jointly Learnable Codebooks and Mappings",
    "std_review": {
      "summary": "The paper introduces a novel compression technique for large language models (LLMs) called Jointly Learnable Codebook and Mappings (JLCM). It combines codebook quantization with scaling factors to reduce memory footprint while maintaining accuracy, achieving strong empirical results across multiple models. The authors provide a clear theoretical framework and discuss practical implications, though some implementation and comparison limitations exist.",
      "strengths": [
        "Innovative combination of codebook quantization and scaling factors for LLM compression.",
        "Clear theoretical framework with a mathematical relationship between compression ratio, codebooks, and scaling factors.",
        "Empirical validation showing strong performance across multiple models and compression goals."
      ],
      "weaknesses": [
        "Increased complexity due to managing multiple codebooks and scaling factors.",
        "Lack of detailed justification for the clustering technique used.",
        "Limited comparison with recent state-of-the-art methods.",
        "Potential computational overhead during inference."
      ],
      "questions": [
        "How can the clustering technique be further justified with more empirical evidence?",
        "What is the computational overhead introduced by codebooks and mappings during inference, and how can it be mitigated?",
        "How does the proposed method compare to recent state-of-the-art techniques like SqueezeLLM and AWQ?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1SbkubNdbW",
    "title": "Be Careful What You Smooth For:",
    "std_review": {
      "summary": "The paper introduces a novel technique of negative label smoothing to enhance model robustness against adversarial attacks while maintaining competitive performance. It demonstrates significant improvements on several datasets and models, highlighting practical benefits for real-world applications. However, the study is limited to adversarial attacks and lacks broader comparative analysis with other defensive techniques.",
      "strengths": [
        "Introduces a novel method of label smoothing targeting negative labels.",
        "Provides comprehensive empirical evidence across multiple datasets and models.",
        "Clearly defines the problem, proposes a specific solution, and evaluates its effectiveness."
      ],
      "weaknesses": [
        "Focuses primarily on adversarial attacks, neglecting other types of vulnerabilities.",
        "Findings are dataset and model specific, limiting generalizability.",
        "Performance metrics are not fully defined, focusing mainly on robustness."
      ],
      "questions": [
        "Can the technique be evaluated against other types of attacks, such as backdoor attacks?",
        "How does negative label smoothing affect model generalization to unseen data?",
        "What is the impact of negative label smoothing on computational efficiency and resource usage?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "1SIBN5Xyw7",
    "title": "",
    "std_review": {
      "summary": "The paper introduces Meta‑SpikeFormer, a novel spiking neural network architecture that combines transformer principles with spike‑driven mechanisms, achieving competitive accuracy on ImageNet‑1K while significantly reducing energy consumption. The authors highlight its potential for neuromorphic hardware and energy‑efficient deep learning, though the evaluation is limited to vision tasks and it lacks detailed hardware integration discussion. Overall, the work is well‑received for its innovative design and promising results, though some concerns about generalizability and scalability remain.",
      "strengths": [
        "Innovative architecture merging transformer principles with spike‑driven learning.",
        "Demonstrates significant energy efficiency gains compared to existing SNN models.",
        "Makes valuable theoretical contributions with new SDSA operators and shortcut mechanisms.",
        "Provides comprehensive empirical validation on ImageNet‑1K with competitive accuracy and lower power consumption."
      ],
      "weaknesses": [
        "Evaluation is primarily focused on vision tasks, limiting the architecture's demonstrated versatility.",
        "Lacks detailed discussion on hardware integration with neuromorphic platforms.",
        "Higher parameter count compared to some competing SNN models.",
        "Does not provide a thorough benchmark comparison across a broader range of state‑of‑the‑art models."
      ],
      "questions": [
        "How can the proposed architecture be extended to other domains beyond vision, such as natural language processing?",
        "What are the specific steps for integrating Meta‑SpikeFormer with existing neuromorphic hardware?",
        "How does the model's performance scale with increasing parameter counts or model sizes?",
        "Could a broader benchmark comparison across different domains further validate the generalizability of the results?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1SO93f7sVf",
    "title": "Training Neural Networks from Scratch",
    "std_review": {
      "summary": "The paper introduces Low‑Rank Tensor Estimation (LTE), a method that accelerates large‑scale model training by using multi‑head LoRA for parallel low‑rank updates, reducing communication overhead and improving efficiency. Empirical results show competitive performance with significant reductions in training time and memory usage compared to standard distributed training. While LTE offers strong theoretical and practical benefits, some concerns about staleness impact, scalability, and reproducibility remain. Overall, the work is well‑received and recommended for acceptance.",
      "strengths": [
        "Innovative parallel update mechanism using multi‑head LoRA.",
        "Significant reduction in communication overhead through infrequent synchronization.",
        "Strong empirical performance with reduced training time and memory usage.",
        "Provides theoretical analysis on convergence rates and expressivity."
      ],
      "weaknesses": [
        "Does not fully quantify the trade‑offs of stale gradients on accuracy.",
        "Scalability limitations for very large models are not exhaustively explored.",
        "Limited baseline comparisons with other state‑of‑the‑art methods.",
        "Lack of detailed implementation specifics for synchronization."
      ],
      "questions": [
        "How does the choice of staleness impact the trade‑off between training speed and model accuracy?",
        "What are the practical resource requirements for scaling LTE to extremely large models?",
        "How does LTE compare to other parallel low‑rank methods and federated learning approaches?",
        "Can the synchronization mechanism be further optimized to reduce latency and bandwidth usage?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1tDoI2WBGE",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a framework for concept-based reasoning in machine learning models, leveraging human-defined 'concept words' to improve interpretability. It presents a clear evaluation strategy and a solid theoretical foundation with mathematical formulations. The experimental results show significant improvements in aligning model predictions with intended concepts over baselines. While the framework is innovative, some aspects such as the curation of concept words and the role of learnable parameters remain somewhat abstract. Overall, the paper is well‑structured and makes a strong case for its approach.",
      "strengths": [
        "Introduces a systematic way to integrate human-defined concepts into model training, addressing a key gap in current interpretability methods.",
        "Provides a clear and well‑defined evaluation protocol that assesses concept alignment with concrete metrics.",
        "Offers a solid theoretical foundation with comprehensive mathematical formulations (Equations 1‑5).",
        "Demonstrates robust empirical results across multiple benchmark datasets, outperforming standard baselines."
      ],
      "weaknesses": [
        "The process for curating concept words is not fully detailed, which may affect reproducibility and generalizability.",
        "The exact role of learnable parameters in modifying concept embeddings and influencing aggregation functions is somewhat abstract.",
        "The rationale for injecting neutral or irrelevant concept words during inference is not clearly articulated.",
        "The mathematical formulation, while comprehensive, may be challenging for readers without a strong machine learning background."
      ],
      "questions": [
        "Could you provide more details on the systematic process used to curate concept words and ensure their relevance and distinctiveness?",
        "How precisely do the learnable parameters adjust concept embeddings, and what concrete examples illustrate their impact?",
        "What is the intended benefit of injecting neutral or irrelevant concept words during inference, and how does this test the model's robustness?",
        "Are there additional examples or visualizations that could help readers without a strong ML background understand the mathematical formulation?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1tZbq88f27",
    "title": "MiniGPT-4:",
    "std_review": {
      "summary": "The paper introduces a method for enhancing vision-language models by incorporating multi-modal instruction tuning using a diverse set of Advanced Abilities tasks. While the approach shows promise and improves the model's performance on benchmark datasets, it has several weaknesses, including unclear task selection criteria, unspecified evaluation tools, and potential issues with the caption evaluation method. The authors should address these concerns and properly cite recent related work.",
      "strengths": [
        "Introduces a novel set of Advanced Abilities tasks to challenge concise and contextually relevant caption generation.",
        "Proposes a systematic multi-modal instruction tuning approach.",
        "Demonstrates effectiveness through extensive experiments on benchmark datasets."
      ],
      "weaknesses": [
        "Selection criteria for Advanced Abilities tasks are not clearly defined.",
        "Version of ChatGPT used for answer revision is unspecified.",
        "Randomly selecting a ground-truth caption for evaluation may lead to misleading results.",
        "Lacks comprehensive comparison metrics like CHAIR score.",
        "MiniGPT-4 fails to meet the 20-word instruction requirement.",
        "Does not acknowledge recent related studies on multi-modal instruction tuning."
      ],
      "questions": [
        "What are the specific criteria used to select the Advanced Abilities tasks?",
        "Which version of ChatGPT was used for answer revision in the experiments?",
        "How could reporting metrics like BLEU and Rouge scores improve the evaluation method?",
        "Why is the CHAIR score missing from Table 5?",
        "What measures can be taken to ensure MiniGPT-4 follows the 20-word instruction requirement?",
        "How should the authors acknowledge recent studies like LLaVA, InstructBLIP, M3IT, and MultiInstruct?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "1uHTIjXjkk",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a diffusion‑based motion planning framework that leverages diffusion processes to generate collision‑free paths. While offering a novel theoretical approach and producing smooth trajectories, the method's empirical validation is limited to environments with convex obstacles, and it lacks formal guarantees on optimality or completeness. The authors also need to address practical concerns such as the need for re‑training for each start‑goal pair and the uncertainty around a guaranteed 100 % success rate.",
      "strengths": [
        "Introduces a novel diffusion‑based framework for motion planning, offering a fresh perspective.",
        "Theoretically justified collision avoidance through denoising, leveraging diffusion properties.",
        "Generates smooth and aesthetically pleasing paths, beneficial for high‑quality motion applications."
      ],
      "weaknesses": [
        "Limited empirical validation on complex obstacle configurations.",
        "Absence of formal theoretical guarantees for collision‑free paths.",
        "Requires re‑training for each start‑goal pair, raising scalability concerns."
      ],
      "questions": [
        "Can the method be evaluated on environments with concave obstacles to better assess its performance?",
        "What formal analysis justifies the collision‑free nature of the generated paths?",
        "How does the algorithm handle kinodynamic planning with dynamic constraints?",
        "What is the empirical evidence or analysis regarding the 100 % success rate claim?",
        "How are sampling‑based baselines evaluated, particularly under fixed time budgets?"
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "1V1QQYARmd",
    "title": "Nearest neighbor-based out-of-distribution detection via label smoothing",
    "std_review": {
      "summary": "The paper presents a novel unsupervised out‑of‑distribution (OOD) detection method that uses intermediate embeddings from a pre‑trained network to identify OOD samples as those farthest from in‑distribution data in an embedding space. Experiments on several benchmark datasets show competitive performance, especially when only small ID datasets are available. While the method is theoretically justified and empirically validated, it lacks comprehensive theoretical guarantees and thorough comparison with label‑distribution‑based baselines.",
      "strengths": [
        "Introduces a unique unsupervised OOD detection strategy based on embedding space distance.",
        "Works well with small ID datasets, making it broadly applicable.",
        "Provides a clear theoretical justification for preferring distance‑based approaches."
      ],
      "weaknesses": [
        "Lacks quantitative theoretical guarantees for the method.",
        "Performance is sensitive to the choice of the k‑NN radius.",
        "Does not compare with label‑distribution‑based baselines when auxiliary OOD data is unavailable.",
        "Missing ablation studies on the importance of intermediate embeddings versus softmax probabilities."
      ],
      "questions": [
        "Can the theoretical results be quantified with concrete bounds or guarantees?",
        "How sensitive is the method to the choice of the k‑NN radius, and are there principled ways to tune it?",
        "How does the method compare to label‑distribution‑based baselines when no auxiliary OOD data is available?",
        "Could an ablation study demonstrate the importance of using intermediate embeddings versus softmax class probabilities?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "1VcKvdYbUM",
    "title": "",
    "std_review": {
      "summary": "The paper introduces APBench, a comprehensive benchmarking framework for evaluating data poisoning attacks on machine learning models. It defines a precise threat model and evaluates a wide range of attacks and defenses across multiple datasets and augmentations, revealing limitations of existing methods. The framework demonstrates that many defenses are vulnerable to sophisticated poisoning attacks, emphasizing the need for robust countermeasures. Overall, the paper is well‑structured, clearly presented, and makes a significant contribution to the field.",
      "strengths": [
        "Comprehensive threat model with clear definitions of adversary goals, knowledge, and capabilities.",
        "Extensive evaluation covering a wide variety of attacks, defenses, datasets, and augmentations.",
        "Extends existing benchmarks by incorporating unique aspects such as diverse attack strategies and defense mechanisms.",
        "Highlights limitations of existing attacks and defenses that were not previously identified."
      ],
      "weaknesses": [
        "Implementation effort may be non‑trivial for some users due to integration with existing workflows.",
        "Reproducibility challenges may arise from the benchmark's complexity and specific configurations required.",
        "Scope limitations may prevent coverage of all possible attack and defense strategies."
      ],
      "questions": [
        "How can the benchmark be adapted to evaluate more specialized or emerging attack strategies?",
        "What steps can be taken to improve reproducibility and ease of integration with existing machine learning pipelines?",
        "Are there plans to incorporate backdoor defenses or evaluate robustness to varying poisoning ratios?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1vCnDyQkjg",
    "title": "Unified Human-Scene Interaction via Prompted Chain-of-Contacts",
    "std_review": {
      "summary": "The paper introduces UniHSI, a framework that integrates large language model planners with human-in-the-loop feedback to generate realistic human motions. It effectively models joint interactions and object contacts, using adversarial learning to refine motion realism. While demonstrating improvements over baselines, the paper lacks comprehensive comparisons with other methods and discusses limitations in handling dynamic scenes.",
      "strengths": [
        "Integration of LLMs and Human Feedback: Enhances motion realism and complexity.",
        "Adversarial Learning for Realism: Ensures generated motions are diverse and realistic.",
        "Scalability to Complex Interactions: Suitable for advanced robotic tasks."
      ],
      "weaknesses": [
        "Limited Evaluation Metrics: Focus on local contact metrics may not fully capture global realism.",
        "Nearest-Point Contact Mapping: May not always yield meaningful contact points.",
        "Dataset Quality Concerns: Automatic generation of the ScenePlan dataset raises quality questions.",
        "Lack of Comprehensive Comparisons: Does not compare with other state-of-the-art methods."
      ],
      "questions": [
        "How do additional metrics or strategies improve the understanding of motion quality beyond local contact metrics?",
        "What post-processing steps are used to filter the ScenePlan dataset for reasonable plans?",
        "How does the method's performance vary with different LLMs or prompting strategies?",
        "What are the implications of relying on nearest-point contact mapping for complex interactions?"
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "1vDArHJ68h",
    "title": "",
    "std_review": {
      "summary": "The paper introduces R2I, a reinforcement learning approach that integrates a learned world model into the RL loop, achieving sample efficiency comparable to state-of-the-art model-based methods while being more sample-efficient. It systematically explores how different components of the world model (state, hidden state, full state) affect policy performance across various environments. The work is innovative and demonstrates strong empirical results, but concerns about generality, statistical rigor, and baseline selection limit its acceptance.",
      "strengths": [
        "Innovative integration of world model predictions with RL, offering a fresh perspective on model-based RL.",
        "Demonstrates significant sample efficiency gains over traditional RL methods, providing a compelling practical advantage.",
        "Comprehensive evaluation across multiple environments and tasks, showcasing the method's generalizability."
      ],
      "weaknesses": [
        "Policy input selection is highly environment-specific, potentially limiting broad applicability.",
        "A noticeable performance gap on standard RL benchmarks raises questions about generality compared to state-of-the-art models.",
        "Lacks standardized statistical methodology for comparing RL models, affecting performance interpretation.",
        "Omits Transformer-based world models from comparison, possibly overlooking significant alternatives.",
        "Lacks clear definitions for 'significantly worse' or 'on par' performance, complicating result assessment."
      ],
      "questions": [
        "How can the method be generalized to environments where the choice of policy input is less environment-specific?",
        "What is the impact of omitting Transformer-based world models on the perceived generality of R2I?",
        "Could a more rigorous statistical analysis, such as confidence intervals, better characterize the performance differences observed?"
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "1VeQ6VBbev",
    "title": "Beyond Stationarity:",
    "std_review": {
      "summary": "The paper presents a dynamic policy gradient algorithm for finite-horizon MDPs, extending convergence analysis from infinite to finite horizons. It leverages a dynamic programming perspective to achieve tighter convergence guarantees and focuses on unregularized softmax policies, showing competitive performance in numerical experiments. While promising, the approach has scalability and robustness limitations, and its generalization to function approximation and non‑stationary settings remains unexplored.",
      "strengths": [
        "Innovative convergence analysis for finite-horizon MDPs",
        "Dynamic programming perspective yields tighter guarantees",
        "Focus on unregularized softmax policies provides practical insights"
      ],
      "weaknesses": [
        "Limited scalability for larger MDPs",
        "Assumptions on MDP structure may not hold in all scenarios",
        "Lack of robustness analysis",
        "Empirical comparisons limited to tabular settings"
      ],
      "questions": [
        "How does the algorithm perform on large, complex MDPs?",
        "What is the impact of relaxing the MDP structure assumptions?",
        "Can robustness to parameter variations be demonstrated?",
        "How does the algorithm generalize to function approximation?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1vmSEVL19f",
    "title": "Directly Fine-Tuning Diffusion Models on Differentiable Rewards",
    "std_review": {
      "summary": "The paper introduces DRaFT, a method for fine-tuning diffusion models using differentiable rewards, which directly optimizes model parameters to improve alignment with desired criteria. Experiments show DRaFT outperforms baselines on various tasks, indicating practical utility. However, the paper lacks clear connections to prior work, limited validation of compatibility with other parameter-efficient fine-tuning methods, and a comparison with a relevant method (DPOK). The choice of model version is also unexplained, raising questions about reproducibility and generalizability.",
      "strengths": [
        "Introduces a novel approach to fine-tuning diffusion models using differentiable rewards, potentially improving output alignment.",
        "Demonstrates empirical improvements over existing methods on multiple tasks, showcasing practical utility.",
        "Provides a clear and accessible methodology, making the approach easy to follow and implement."
      ],
      "weaknesses": [
        "The relationship between DRaFT and prior work is not clearly articulated.",
        "Compatibility with other parameter-efficient fine-tuning methods is mentioned but not thoroughly explored.",
        "The paper does not compare DRaFT's performance to DPOK, a relevant method in the field.",
        "The use of the 'stop_grad' function is not adequately explained, which may hinder reproducibility.",
        "The choice of Stable-Diffusion v1.4 over newer versions is not justified."
      ],
      "questions": [
        "How does DRaFT extend or differ from prior work that also uses differentiable rewards for model fine-tuning?",
        "What is the impact of DRaFT's compatibility with other parameter-efficient fine-tuning methods like Adapters, Normalization training, and IA3?",
        "How does DRaFT compare to DPOK in terms of performance and relative strengths/weaknesses?",
        "What is the rationale behind choosing Stable-Diffusion v1.4 over newer versions like SD v1.5?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "1vqHTUTod9",
    "title": "Can Language Models be Instructed to",
    "std_review": {
      "summary": "The paper introduces PRIVQA, a benchmark for evaluating privacy risks in multimodal LLMs by assessing leakage of sensitive attributes like age, citizenship, and occupation. It provides a realistic threat model, a diverse dataset of public figures, and clear evaluation metrics. The authors demonstrate the effectiveness of their self‑moderation technique against baselines, highlighting practical privacy implications. Overall, the paper is well‑structured and makes a valuable contribution to privacy research in LLMs.",
      "strengths": [
        "Comprehensive privacy evaluation framework for multimodal LLMs",
        "Realistic threat modeling aligned with jailbreaking and model editing",
        "Diverse dataset of public figures and protected attributes",
        "Clear and interpretable privacy metrics",
        "Robust baseline comparisons demonstrating effectiveness"
      ],
      "weaknesses": [
        "Limited scope focusing on a narrow set of protected attributes and public figures",
        "Potential bias in dataset due to selection of scrutinized public figures",
        "Lack of baselines like machine unlearning or differential privacy",
        "Qualitative analysis gaps in attack scenarios",
        "Generalizability concerns to under‑represented groups"
      ],
      "questions": [
        "How can the benchmark be extended to cover less common or under‑represented protected attributes?",
        "What are the implications of using public figures for dataset curation?",
        "Could additional baselines such as machine unlearning or differential privacy provide a more comprehensive evaluation?",
        "How does the benchmark perform on models with varying sizes and architectures beyond those tested?",
        "What qualitative analyses of successful attacks could further elucidate the practical impact of privacy leaks?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1vrS1zwekw",
    "title": "Multi-Crating Multi-Faceted Instructions for Improving Instruction-Following",
    "std_review": {
      "summary": "The paper introduces MUFFIN, a method that generates facets from LLMs to enhance the BBH benchmark for evaluating language models' ability to generate coherent and contextually relevant elaborations. While the facet generation process is effective, the resulting tasks introduce challenges that affect model performance, particularly on the BBH benchmark. The authors demonstrate the method's innovative facet generation and enhanced benchmark, but the lack of trustworthiness mechanisms, limited evaluation metrics, and insufficient task analysis leave open questions about task leakage and model learning dynamics.",
      "strengths": [
        "Innovative facet generation leveraging LLMs for scalable task expansion.",
        "Enhanced benchmark with richer evaluation of language models' elaboration capabilities.",
        "Methodological rigor with detailed analyses of facet quality and performance."
      ],
      "weaknesses": [
        "Absence of explicit mechanisms to ensure facet reliability beyond human inspection.",
        "Qualitative evaluation of facet quality without clear metrics.",
        "Significant performance drop on the BBH benchmark with unclear explanations."
      ],
      "questions": [
        "What mechanisms are in place to ensure the trustworthiness of facets generated by the LLM?",
        "How is the quality of facets quantitatively measured and compared?",
        "What criteria are used to select tasks for classification expansion?",
        "Could the performance gap on the BBH benchmark be better explained by analyzing task categories?"
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "1WceuzWff5",
    "title": "Understanding the Transfer of High-Level Reinforcement Learning Skills Across Diverse Environments",
    "std_review": {
      "summary": "The paper introduces SEAL, a method that pads state dimensions to align different environments for transfer learning. It shows strong empirical results on Meta-World, improving policy adaptation across diverse tasks. While innovative, the approach has concerns about overfitting, especially in complex state spaces, and limited exploration of how source environment skill diversity affects target performance. Overall, SEAL is promising but requires further validation.",
      "strengths": [
        "Innovative padding mechanism for aligning state spaces with semantic mismatches.",
        "Empirical success on Meta-World demonstrating practical utility.",
        "Clear theoretical justification for why state padding aids transfer learning."
      ],
      "weaknesses": [
        "Potential overfitting in environments with complex state spaces.",
        "Limited analysis of how source environment skill diversity impacts target performance.",
        "Reliance on task IDs for relational structure lacks extensive validation."
      ],
      "questions": [
        "How does SEAL handle environments with very large or high-dimensional state spaces?",
        "What is the impact of the diversity of skills in the source environment on the target policy?",
        "Could additional regularization techniques mitigate overfitting in complex settings?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "1Wi0Ys33Nm",
    "title": "Beyond iid weights: sparse and low-rank deep neural networks are also Gaussian Processes",
    "std_review": {
      "summary": "The paper introduces a novel framework for analyzing deep neural network convergence by extending the pseudo‑iid assumption beyond the iid setting. It builds on prior work and provides theoretical insights into network behavior under pseudo‑iid conditions, suggesting benefits for initialization and regularization. While the theoretical contributions are significant, the paper has several weaknesses, including unclear notation, limited comparison with existing work, and insufficient experimental validation, which together result in a weak accept recommendation.",
      "strengths": [
        "Theoretical Contribution: Extends the pseudo‑iid assumption to a broader class of random variables, offering a more flexible framework for analyzing network convergence.",
        "Novel Example Distributions: Introduces low‑rank and block‑sparse distributions as concrete examples of pseudo‑iid variables, providing new insights into network behavior.",
        "Practical Implications: Links the pseudo‑iid assumption to practical initialization schemes, suggesting benefits such as improved convergence rates and stability."
      ],
      "weaknesses": [
        "Lack of Definition: The symbol 'a' is introduced without prior definition in Definition 1, which may cause confusion.",
        "Limited Comparison: The paper does not comprehensively compare the pseudo‑iid approach to existing work, missing opportunities to highlight its fundamental differences and advantages.",
        "Practical Significance: The paper does not clearly explain why the broader class of pseudo‑iid random variables is practically interesting or how it benefits practitioners.",
        "Input Space Assumption: Convergence results are stated under the assumption of a countably infinite input space, which may limit applicability to real-world scenarios with uncountably infinite input spaces.",
        "Generality of First‑Layer Initialization: Proofs assume the first layer’s weights are Gaussian IID, which may not be realistic for all network architectures and initialization schemes.",
        "Limited Experimental Validation: Experiments focus on a single orthogonal‑initialisation scheme, potentially limiting the generality of the theoretical results across different initialization strategies."
      ],
      "questions": [
        "Please provide a clear definition of the symbol 'a' used in Definition 1.",
        "How does the pseudo‑iid approach fundamentally differ from and improve upon prior work, such as Matthews et al. (2018)?",
        "What is the practical significance of considering a broader class of pseudo‑iid random variables in deep learning?",
        "How does the assumption of a countably infinite input space affect the interpretation and applicability of the convergence results?",
        "Could the generality of the results be improved by relaxing the assumption that the first layer’s weights are Gaussian IID?",
        "What additional experiments or analyses are needed to validate the generality of the theoretical results across different initialization schemes and network architectures?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "1WSd408I9M",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a conceptual framework for integrating generative AI into healthcare, addressing key desiderata such as trustworthiness, safety, and interpretability. While the proposed methodology is well‑articulated, its effectiveness is limited by a lack of empirical validation, relying primarily on illustrative case studies. The authors raise important ethical and practical concerns, but the literature review could be more focused on recent advancements. Overall, the paper is a promising contribution that merits further empirical testing and refinement.",
      "strengths": [
        "Introduces a novel framework addressing trustworthiness, safety, and interpretability in generative AI for healthcare.",
        "Provides concrete methodological steps for ensuring model reliability and safety.",
        "Offers a thorough discussion of ethical implications and potential risks in healthcare AI."
      ],
      "weaknesses": [
        "Empirical evidence is limited to illustrative case studies, lacking robust validation.",
        "Lacks detailed empirical results demonstrating the framework's impact on healthcare outcomes.",
        "Calls for more rigorous testing and validation to establish practical applicability.",
        "The literature review could benefit from a more focused discussion on recent generative AI advancements."
      ],
      "questions": [
        "What are the specific metrics and real‑world experiments planned to validate the framework's effectiveness?",
        "How will the framework be adapted to different healthcare domains and clinical workflows?",
        "What strategies will be employed to address potential model drift and ensure long‑term reliability?",
        "How will the paper incorporate feedback from domain experts to refine the proposed safeguards?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "1XarNmzbgG",
    "title": "Understanding of Server-Assisted Federated Learning with Incomplete Client Participation",
    "std_review": {
      "summary": "The paper introduces SAFARI, a server‑assisted federated learning framework that leverages an auxiliary server dataset to improve PAC‑learnability in scenarios with incomplete client participation. The authors provide a formal PAC‑learnability analysis under bounded gradient dissimilarity assumptions and derive convergence rates, showing that the auxiliary dataset size influences error bounds. Theoretical and empirical results demonstrate significant improvements over FedAvg, though practical challenges remain in obtaining suitable server data.",
      "strengths": [
        "Novel server‑assisted federated learning framework that enhances PAC‑learnability.",
        "Strong theoretical analysis providing PAC‑learnability guarantees under well‑defined assumptions.",
        "Empirical validation showing improved performance and clear impact of auxiliary dataset size."
      ],
      "weaknesses": [
        "Assumption of bounded gradient dissimilarity may be restrictive in real‑world settings.",
        "Practical challenges and privacy concerns in obtaining a large, i.i.d. auxiliary dataset.",
        "Limited guidance on optimal parameter settings despite highlighting sensitivity to q and η."
      ],
      "questions": [
        "How can the bounded gradient dissimilarity assumption be relaxed for broader applicability?",
        "What are practical strategies for obtaining a sufficiently large and privacy‑compliant auxiliary dataset?",
        "How do the theoretical convergence rates translate to real‑world deployment scenarios?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1XDG1Z5Nhk",
    "title": "",
    "std_review": {
      "raw_text": "{\n  \"summary\": \"SparseMixer presents a novel sparse mixture‑of‑experts architecture for vision transformers, introducing a top‑k routing mechanism and ω‑scaling to improve efficiency and performance. The authors demonstrate strong empirical results on ImageNet‑1K and CIFAR benchmarks, showing competitive accuracy with reduced computational overhead compared to Switch Transformers. While the approach is innovative, it introduces additional complexity and overhead, particularly with the top‑k routing and ω‑scaling components. Overall, the paper is well‑structured, with clear contributions and a convincing rationale for its design choices.\",\n  \"strengths\": [\n    \"Introduces a top‑k routing mechanism that allows multiple experts to be active per layer, potentially capturing richer representations.\",\n    \"Proposes ω‑scaling, a dynamic scaling factor that improves training stability and throughput without significant additional cost.\",\n    \"Provides strong empirical validation on standard benchmarks, showing competitive performance with reduced computational overhead.\",\n    \"Offers a detailed analysis of the trade‑offs between model efficiency and performance, providing valuable insights.\"\n  ],\n  \"weaknesses\": [\n    \"Adapting the top‑k routing mechanism introduces additional computational complexity, which may be challenging for practitioners familiar with top‑1 MoE models.\",\n    \"Lacks direct comparisons with Switch Transformers using ω‑scaling, making it difficult to fully assess the relative gains.\",\n    \"Table 3 presents identical training costs for SparseMixer and Switch Transformer, but does not account for additional overhead from ω‑scaling, potentially misleading readers.\",\n    \"Evaluation is limited to Switch Transformers, with limited exploration of SparseMixer's performance on other MoE architectures.\"\n  ],\n  \"questions\": [\n    \"Can SparseMixer be extended to k > 1 easily, and what are the computational implications?\",\n    \"How does the empirical contribution of ω‑scaling compare to Switch Transformers with ω‑scaling?\",\n    \"What is the total training time for SparseMixer, and how does it account for the overhead from ω‑scaling and \\(\\nabla_0\\) computation?\",\n    \"What is the computational cost induced by SparseMixer, particularly the top‑k routing and ω‑scaling components?\"\n  ],\n  \"overall_score\": \"6: weak accept\",\n  \"confidence\": \"4: high\"\n}",
      "parse_error": true
    }
  },
  {
    "paper_id": "1XReHUSUp9",
    "title": "Monsters in the Dark: Sanitizing Hidden Threats with Diffusion Models",
    "std_review": {
      "summary": "The paper introduces DM‑SUDS, a diffusion model-based steganography method that embeds messages in images with improved robustness. It outperforms baseline and several steganography techniques, especially under noise and JPEG compression. However, the evaluation is limited to a single dataset, lacks comparison with robust steganography methods, and does not test robustness against JPEG compression or provide detailed parameter analysis.",
      "strengths": [
        "Innovative use of diffusion models for steganography, enabling gradual and controlled embedding.",
        "Demonstrated strong robustness against noise, a critical requirement for real-world applications.",
        "Consistent performance improvements across multiple steganography techniques compared to a baseline."
      ],
      "weaknesses": [
        "Evaluation limited to the CIFAR‑10 dataset, which may not fully represent real-world scenarios.",
        "No comparison with robust steganography methods, limiting the assessment of practical robustness.",
        "Lack of testing against JPEG compression, a common image format.",
        "Absence of detailed analysis of parameter selection, affecting reproducibility."
      ],
      "questions": [
        "What is the value of the noise variance parameter (β) and how was the timestep (t) chosen for the diffusion process?",
        "How does the strength of the diffusion relate to the amount of noise in the images, allowing the method to be blind to specific steganography implementations?",
        "Could you provide a table or plot of performance metrics for the ablation studies comparing DM‑SUDS with the baseline across different steganography techniques?",
        "What is the typical length of the message hidden in the image secrets, in terms of bits or characters?",
        "How does DM‑SUDS perform on more complex image datasets beyond CIFAR‑10?",
        "What is the robustness of DM‑SUDS against JPEG compression, and how does it compare to other steganography methods?",
        "Could you provide a literature review on robust steganography methods and discuss how DM‑SUDS compares?"
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "1xyar0Ko3E",
    "title": "Efficient Quantization-aware Training with Adaptive Coreset Selection",
    "std_review": {
      "summary": "The paper introduces EVS and DS metrics for adaptive coreset selection in quantization-aware training, showing significant speedups without accuracy loss across multiple datasets. While innovative, the method introduces computational overhead and is tailored for QAT, with limited comparison to other quantization settings. Overall, it is a strong contribution with practical impact.",
      "strengths": [
        "Introduces novel EVS and DS metrics for quantization-aware training.",
        "Provides theoretical guarantees linking metrics to error bounds.",
        "Demonstrates empirical improvements in training speed and accuracy."
      ],
      "weaknesses": [
        "Adds computational overhead for EVS and DS calculations.",
        "Specifically designed for quantization-aware training, may need adaptation for other quantization types.",
        "Limited comparison scope with other methods."
      ],
      "questions": [
        "How does the method perform on very large models or datasets?",
        "What is the robustness of the method to different types of label noise?",
        "How does the method compare to state-of-the-art post-training quantization techniques?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1yll8U12GT",
    "title": "Enhancing Decision Tree Learning with Deep Networks",
    "std_review": {
      "summary": "The paper introduces ZanDT, a novel oblique decision‑tree algorithm that uses a hyperplane discontinuity score (HDS) to guide the selection of non‑axis‑aligned splits, improving accuracy over traditional greedy methods. Theoretical analysis and experiments on synthetic data show that ZanDT can exactly recover true hyperplanes, outperforming existing approaches. While computationally intensive due to neural‑network training and DBSCAN clustering, the method offers a unique deep‑learning‑based hyperplane detection network (DLGN) that enhances robustness. The paper is well‑structured, with clear contributions and thorough validation, though scalability and multi‑class extension remain open challenges.",
      "strengths": [
        "Innovative hyperplane discontinuity score (HDS) for evaluating splits.",
        "Strong theoretical justification for the limitations of greedy methods in high dimensions.",
        "Experimental validation demonstrating exact recovery of true hyperplanes.",
        "Unique deep‑learning‑based hyperplane detection network (DLGN) that improves robustness."
      ],
      "weaknesses": [
        "High computational complexity due to neural‑network training at each node and DBSCAN clustering.",
        "No clear extension to multi‑class classification problems.",
        "Theoretical assumptions about data distribution and split balance may not hold in all settings."
      ],
      "questions": [
        "How can the computational overhead be reduced for practical, large‑scale applications?",
        "What modifications are needed to extend ZanDT to multi‑class classification?",
        "How robust is the method to noisy or imbalanced data?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1YO4EE3SPB",
    "title": "A Variational Perspective on Solving Inverse Problems with Diffusion Models",
    "std_review": {
      "summary": "The paper introduces RED-diff, a diffusion-based denoiser that uses variational inference with a unimodal Gaussian to approximate the true posterior of noisy signals. It demonstrates superior reconstruction quality and lower diffusion metrics compared to existing methods, supported by theoretical justifications. While the approach offers flexibility and strong performance, it has limitations such as potential suboptimal reconstructions for multimodal posteriors and lacks direct comparisons with alternative methods.",
      "strengths": [
        "Introduces a novel variational approach using a unimodal Gaussian to approximate the true posterior.",
        "Demonstrates superior reconstruction quality and lower diffusion metrics compared to existing diffusion samplers.",
        "Provides a theoretical foundation linking the score function to the true posterior."
      ],
      "weaknesses": [
        "The unimodal Gaussian approximation may struggle with highly multimodal true posteriors.",
        "The variational step introduces a unimodal Gaussian, differing from the fixed-point iteration of the RED framework.",
        "Lacks direct comparison with plug-and-play methods.",
        "The impact of the sampling schedule on performance is not thoroughly analyzed.",
        "The stochastic and iterative nature may raise concerns about computational cost scaling."
      ],
      "questions": [
        "How does the method perform on highly multimodal true posteriors?",
        "What is the impact of the sampling schedule on the final reconstruction quality?",
        "How does the proposed method compare to recent plug-and-play approaches?",
        "What are the theoretical guarantees for convergence when the posterior is non-Gaussian?",
        "How does the method scale to larger image sizes and higher iteration counts?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1YSJW69CFQ",
    "title": "",
    "std_review": {
      "summary": "The paper presents a novel approach to uncertainty-aware ensemble boosting for medical image segmentation using V‑Net and Monte Carlo Dropout, combined with a unique test-time augmentation method. While it shows promise in improving reliability and accuracy, the work is hindered by unclear task definitions, ambiguous handling of uncertainty, and insufficient comparison with existing methods. Overall, it is a strong contribution with some areas needing clarification.",
      "strengths": [
        "Innovative integration of a segmentation backbone with uncertainty estimation techniques.",
        "Novel test-time augmentation method that enhances uncertainty estimation.",
        "Comprehensive evaluation using a range of metrics for calibration and regression."
      ],
      "weaknesses": [
        "Ambiguity in whether the task is pixel-wise segmentation or image-level classification.",
        "Unclear incorporation of entropy scores from Monte Carlo Dropout into model predictions.",
        "Lack of detailed explanation of how the proposed URF technique differs from existing methods.",
        "Insufficient comparison with baselines to justify the superiority of the TTA approach.",
        "Vague discussion of the relevance to Grand Challenge 4.",
        "Limited explanation of how the methods address batch effects in medical imaging datasets."
      ],
      "questions": [
        "How exactly are the entropy scores from Monte Carlo Dropout used in the model's predictions or loss function?",
        "What differentiates the proposed URF technique from other uncertainty-aware ensemble boosting methods?",
        "Could you provide a detailed comparison of the TTA approach with other TTA techniques to support its claimed superiority?",
        "How does the method specifically address batch effects in medical imaging datasets?",
        "Is the primary task pixel-wise segmentation or image-level classification, and which metrics (e.g., Dice score vs. accuracy) are used for evaluation?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "1zhM0XkQh0",
    "title": "",
    "std_review": {
      "summary": "The paper introduces ProFeAT, a self-supervised pre-training framework that enhances model robustness against adversarial attacks by combining a projector, an augmented teacher, and a defense loss. It demonstrates strong performance on ImageNet‑1K and adversarial benchmarks, as well as on smaller datasets like Caltech, showing benefits in low-data regimes. While the method is innovative and empirically effective, the review notes some areas for improvement in component analysis and metric consistency.",
      "strengths": [
        "Innovative combination of techniques to improve robustness",
        "Strong empirical results on both standard and adversarial benchmarks",
        "Effectiveness demonstrated on smaller datasets, highlighting scalability"
      ],
      "weaknesses": [
        "Limited isolated component analysis could provide deeper insights",
        "Inconsistent metric reporting (e.g., inconsistent use of terminology)",
        "Insufficient exploration of how different attack losses affect trade-offs",
        "Compared to a more comprehensive set of baselines"
      ],
      "questions": [
        "Could experiments varying each component independently clarify their individual contributions?",
        "How does the combination of the projector, augmented teacher, and defense loss specifically improve robustness?",
        "What is the impact of different attack loss choices on clean vs. robust accuracy?",
        "Could a more detailed discussion on the theoretical underpinnings of the method strengthen the paper?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1zt8GWZ9sc",
    "title": "Quack: Automatic Jailbreaking Large Language Models via Role-playing",
    "std_review": {
      "summary": "The paper investigates jailbreak prompts for ChatGPT using healthcare questions, employing an iterative refinement process on a knowledge graph to guide responses. It evaluates different OpenAI library versions and introduces a Materializer role for oracle answers. While highlighting the vulnerability of AI systems in sensitive domains, the study's lack of clear effectiveness criteria, detailed refinement process, comprehensive testing, and thorough safety measures for the Materializer role weakens its impact.",
      "strengths": [
        "Provides a comprehensive evaluation of jailbreak prompts against healthcare questions.",
        "Introduces a novel iterative refinement process for mitigating jailbreak attacks.",
        "Demonstrates proactive safety measures with the Materializer role."
      ],
      "weaknesses": [
        "Effectiveness criteria for jailbreak prompts are not clearly defined.",
        "Iterative refinement process lacks detailed explanation.",
        "Limited set of testing questions restricts generalizability.",
        "Safety measures for the Materializer role are not thoroughly described."
      ],
      "questions": [
        "How were the effectiveness criteria for jailbreak prompts determined?",
        "What specific details are needed for the iterative refinement process to be reproducible?",
        "Could you provide additional testing questions and their corresponding oracle answers?",
        "What safety checks and safeguards are implemented in the Materializer role?"
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "20KYsQ8Q4Z",
    "title": "High-dimensional Bayesian Optimization",
    "std_review": {
      "summary": "The paper presents GTBO, a novel Bayesian optimization method that uses group testing to reduce the number of evaluations needed for optimizing expensive black-box functions. Experiments show that GTBO significantly outperforms traditional baselines across various benchmarks, achieving faster convergence with fewer evaluations. The authors provide a solid theoretical foundation and demonstrate strong empirical results, leading to an acceptance recommendation.",
      "strengths": [
        "Innovative approach combining group testing with Bayesian optimization.",
        "Strong theoretical foundation based on Bayesian inference.",
        "Empirical performance improvements over existing methods."
      ],
      "weaknesses": [
        "Implementation complexity due to integration of group testing concepts.",
        "Sensitivity to hyperparameters such as batch size and number of groups.",
        "Limited benchmark set that may not cover all potential applications."
      ],
      "questions": [
        "How does GTBO scale to extremely high-dimensional problems?",
        "What is the impact of different acquisition functions on GTBO's performance?",
        "Can GTBO be effectively applied to non-symmetric search spaces?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "20L7txbIa8",
    "title": "UniPredict: Large Language Models are Universal Tabular Classifiers",
    "std_review": {
      "summary": "UniPredict demonstrates an innovative approach to few-shot tabular prediction by leveraging large language models without fine-tuning. The method shows competitive performance on benchmark datasets, especially in limited data scenarios. However, several concerns regarding reproducibility, statistical validation, and comprehensive evaluation prevent full acceptance.",
      "strengths": [
        "Innovative integration of LLMs with tabular data for few-shot learning.",
        "Competitive performance on benchmark datasets, particularly in limited data settings.",
        "Provides interpretable class probabilities, enhancing transparency."
      ],
      "weaknesses": [
        "Lack of detailed hyperparameter tuning for baselines.",
        "Absence of statistical testing (e.g., p-values) for performance comparisons.",
        "No exploration of few-shot performance with larger datasets.",
        "Unclear interpretation of class probabilities as true confidence measures.",
        "No ablations on handling numerical features.",
        "Potential data leakage not addressed.",
        "Code and data availability not mentioned, raising reproducibility concerns."
      ],
      "questions": [
        "How were hyperparameters for baselines selected and reported?",
        "What statistical tests were conducted to validate performance differences?",
        "Were experiments conducted to evaluate few-shot performance with larger datasets?",
        "Can the class probabilities be interpreted as true confidence measures?",
        "What ablations were performed on handling numerical features?",
        "How was potential data leakage identified and mitigated?",
        "Is the code and data used in the experiments publicly available?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "20oxNYWQl9",
    "title": "",
    "std_review": {
      "summary": "The paper presents a novel (k,z)-clustering approach for efficient model sampling, leveraging a Holder‑continuity assumption to achieve strong theoretical guarantees. Empirical experiments on neural network tasks demonstrate significant improvements in quality and efficiency over existing methods. While the Holder assumption may limit applicability, the method scales well to high-dimensional data. Overall, the work is technically novel and empirically compelling, with some areas for future improvement.",
      "strengths": [
        "Introduces a Holder‑continuity assumption for sensitivity‑sampling, providing a new theoretical framework.",
        "Offers both multiplicative and additive error bounds, enhancing robustness.",
        "Demonstrates practical benefits through targeted experiments on neural network training.",
        "Scales to high-dimensional and large datasets, making it suitable for real-world applications."
      ],
      "weaknesses": [
        "The Holder‑continuity assumption may not hold for all model classes, limiting general applicability.",
        "Lack of empirical evidence validating the Holder assumption across diverse datasets.",
        "Computational costs related to the number of model queries (k) could impact scalability.",
        "Empirical evaluation primarily focused on neural networks, with limited comparison to other model types."
      ],
      "questions": [
        "Can the Holder‑continuity assumption be validated more broadly across different model classes and loss functions?",
        "What are the practical implications of the required number of model queries (k) for very large datasets?",
        "How does the method perform when compared to other sampling techniques beyond neural networks?",
        "Are there alternative theoretical frameworks that could complement or strengthen the current approach?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "228XQpErvW",
    "title": "",
    "std_review": {
      "summary": "The paper introduces ISMAQ, a reinforcement learning framework that combines TD3's stability with the Importance Sampling-based Maximum Entropy (ISMA) approach to improve sample efficiency and robustness. Empirical results on MuJoCo and Atari benchmarks show that ISMAQ outperforms both TD3+BC and TD3 alone, especially in high‑exploration environments. While the integration of two loss functions may complicate implementation, the method's strong theoretical motivation and extensive experiments support its novelty and effectiveness.",
      "strengths": [
        "Innovative combination of TD3's stability with ISMA's exploration efficiency.",
        "Demonstrated superior performance across a range of tasks compared to baselines.",
        "Provides a solid theoretical foundation linking the ISMAQ loss to entropy maximization and variance reduction."
      ],
      "weaknesses": [
        "Increased complexity due to the integration of two distinct loss functions.",
        "Potential computational overhead from additional computations required for the ISMAQ loss.",
        "Limited real‑world validation; experiments are primarily on simulated environments."
      ],
      "questions": [
        "How can practitioners best implement the ISMAQ framework in resource‑constrained settings?",
        "What are the long‑term implications of the offline pre‑training phase using TD3 on real‑world RL applications?",
        "Could the method be extended to unsupervised or semi‑supervised learning scenarios?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "22OTbutug9",
    "title": "RA-DIT: Retrieval-Augmented Dual Instruction Tuning",
    "std_review": {
      "summary": "RA-DIT introduces a novel method that combines retriever fine-tuning with instruction tuning to enhance large language models' ability to handle complex tasks by grounding reasoning in external knowledge. The approach shows clear performance gains across multiple benchmarks, including TriviaQA and NQ, while also demonstrating robustness across different retrieval depths and retrievers. Despite some areas for improvement, such as addressing hallucination risks and clarifying baseline comparisons, the innovative design and strong results justify acceptance.",
      "strengths": [
        "Innovative dual approach combining retriever fine-tuning with instruction tuning.",
        "Flexibility in retrieval depth, showing incremental improvements with deeper retrieval.",
        "Strong baseline comparisons using a consistent dataset.",
        "Robustness across multiple benchmarks indicating broad applicability.",
        "Clear ablation studies isolating the impact of retriever fine-tuning and retrieval depth."
      ],
      "weaknesses": [
        "Limited clarity in baseline comparisons between RA-IT and RA-DIT.",
        "Potential for hallucinations due to reliance on retrieved context.",
        "Performance sensitive to dataset size, limiting applicability in resource-constrained settings.",
        "Effectiveness heavily dependent on the choice of retriever, with limited exploration.",
        "Poor zero-shot performance on NQ, raising questions about generalization."
      ],
      "questions": [
        "How can the comparison between RA-IT and RA-DIT be made clearer in the paper?",
        "What strategies can be employed to mitigate the risk of hallucinations when using retrieved context?",
        "How does the method's performance scale with smaller dataset sizes, and are there techniques to improve robustness in such scenarios?",
        "What are the specific criteria for selecting retrievers, and how can the impact of different retrievers be further explored?",
        "What ablations or experiments could be conducted to better understand the model's zero-shot performance on benchmarks like NQ?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "22pyNMuIoa",
    "title": "PromptAgent: Strategic Planning with Language Models Enables Expert-level Prompt Optimization",
    "std_review": {
      "summary": "PromptAgent introduces a novel method for optimizing prompts for large language models using Monte Carlo Tree Search (MCTS). The approach intelligently navigates the prompt space, incorporates error feedback from the base model, and balances exploration and exploitation. Experimental results show that PromptAgent outperforms existing baselines across various tasks and scales across different language models. While the method demonstrates strong empirical results and scalability, its generalizability is limited by the narrow range of evaluated tasks and its reliance on the quality of error feedback.",
      "strengths": [
        "Introduces a novel approach to prompt optimization using MCTS, which intelligently navigates the prompt space.",
        "Effectively incorporates error feedback from the base model into the optimization process.",
        "Demonstrates improved performance over existing baselines like APE and CoT on a variety of tasks.",
        "Shows scalability and generalization across different language models, including GPT-3.5, GPT-4, and PaLM 2."
      ],
      "weaknesses": [
        "Limited evaluation on a wide range of diverse tasks, which may affect the generalizability of the results.",
        "The method's performance heavily relies on the quality of the error feedback from the base model, which may not always be optimal.",
        "The scalability of the method for extremely large prompt spaces or very large language models is not thoroughly explored.",
        "The novelty and contribution of the method are somewhat limited by its reliance on existing MCTS techniques, which have been widely studied in other domains."
      ],
      "questions": [
        "How does PromptAgent perform on a broader set of diverse tasks to assess its generalizability?",
        "What strategies can be employed to improve the quality and reliability of error feedback from the base model?",
        "How does PromptAgent scale to extremely large prompt spaces or very large language models?",
        "What unique contributions does PromptAgent make beyond its reliance on existing MCTS techniques?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "23b9KSNQTX",
    "title": "RETSim: Resilient and Efficient Text Similarity",
    "std_review": {
      "summary": "RETSim introduces a novel approach to document similarity matching by combining a character-level vectorizer with a lightweight transformer block and metric learning. It leverages a typo-augmented multilingual C4 dataset to enhance adversarial robustness and introduces a custom Multi-Similarity Loss that outperforms traditional Triplet Loss. The method shows strong performance on benchmark datasets and real-world spam email clustering, though it may face deployment challenges in dynamic environments.",
      "strengths": [
        "Innovative architecture combining character-level vectorization with a lightweight transformer block.",
        "Adversarial robustness achieved through multi-level augmentation (sentence, paragraph, character).",
        "Custom Multi-Similarity Loss tailored for similarity matching tasks, outperforming traditional losses.",
        "Demonstrates superior scalability and efficiency compared to hash-based methods.",
        "Shows practical utility in real-world spam email clustering."
      ],
      "weaknesses": [
        "Potential computational overhead due to the integration of a transformer block.",
        "Performance may be sensitive to hyperparameter choices in the Multi-Similarity Loss.",
        "Effectiveness across extremely long documents or highly specialized domains is not fully explored.",
        "Deployment challenges, particularly in dynamic environments like spam detection."
      ],
      "questions": [
        "How does RETSim handle extremely long documents or highly specialized domains?",
        "What are the specific strategies for managing model updates and scalability in real-world deployments?",
        "How does the performance of RETSim degrade under more complex adversarial attacks beyond typo simulations?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "23OEmHVkpq",
    "title": "Disentanglement Learning via Topology",
    "std_review": {
      "summary": "The paper introduces Topological Disentanglement (TopDis), a novel regularization term for VAEs that improves disentanglement by focusing on the topological structure of latent spaces. It provides a theoretical link to existing disentanglement metrics and demonstrates strong empirical improvements across multiple datasets. While showing practical benefits, the paper also notes some practical concerns such as hyperparameter sensitivity and the need for more comprehensive comparisons with state-of-the-art methods.",
      "strengths": [
        "Introduces a novel perspective on disentanglement through topological properties of latent spaces.",
        "Provides a clear theoretical foundation linking the proposed loss to established disentanglement metrics.",
        "Demonstrates practical integration with existing VAE architectures with minimal computational overhead.",
        "Shows strong empirical results across multiple benchmark datasets."
      ],
      "weaknesses": [
        "Effectiveness may be sensitive to hyperparameter choices (γ₁ and γ₂).",
        "Lacks a comprehensive comparison with the latest state-of-the-art disentangled VAE methods.",
        "Gradient orthogonalization adds complexity to the optimization process.",
        "Limited theoretical guarantees such as convergence or generalization proofs."
      ],
      "questions": [
        "How robust is the TopDis loss to different hyperparameter settings across various datasets?",
        "What is the impact of gradient orthogonalization on convergence stability compared to other regularization techniques?",
        "Can the theoretical relationship between TopDis and existing disentanglement metrics be further strengthened with additional mathematical proofs?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "24CZaossxH",
    "title": "PyTorch Geometric High Order: A Unified Library for High Order Graph Neural Network",
    "std_review": {
      "summary": "The paper introduces PyGHO, a specialized library for hierarchical one-dimensional graph neural networks (HOGNNs) using 1-D tensor lists, which outperforms existing methods on standard graph datasets, particularly large, sparse molecular graphs. It highlights significant performance gains and scalability, though it lacks detailed analysis of profiling techniques and ablation studies. The innovative representation and clear design rationale are strengths, but the paper also notes limited comparison scope and sparse data handling details.",
      "strengths": [
        "Innovative representation using a list of 1-D tensors for hierarchical data.",
        "Demonstrated performance gains over existing HOGNN implementations.",
        "Strong scalability to large graphs, making it suitable for real-world applications."
      ],
      "weaknesses": [
        "Lack of detailed analysis of profiling techniques used to identify performance improvements.",
        "Limited comparison with other libraries beyond standard graph datasets.",
        "Absence of ablation studies to evaluate the impact of design choices.",
        "Sparse data structure handling lacks detailed analysis or benchmarks."
      ],
      "questions": [
        "Could you provide a more detailed analysis of the profiling techniques used to identify the efficiency gains?",
        "How does PyGHO perform on more complex or domain-specific datasets beyond the standard benchmarks?",
        "Could you include ablation studies to evaluate the impact of different design choices, such as tuple sampling and pooling techniques?",
        "What are the specific optimizations for sparse data structures, and how do they compare to existing methods?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "258EqEA05w",
    "title": "",
    "std_review": {
      "summary": "FedRDN introduces a federated learning framework that dynamically adjusts feature distributions across clients using a novel normalization technique, improving model generalization and performance across various architectures and datasets. The method mitigates feature distribution skew by aggregating client-specific statistics, aligning with privacy-preserving principles. While it shows strong empirical improvements over existing methods, concerns about communication overhead and security of shared statistics remain. Overall, the paper is well-received for its innovative approach and robust performance.",
      "strengths": [
        "Dynamic adaptation of feature distributions enhances model performance and generalization.",
        "Privacy-friendly approach by sharing aggregated statistics rather than raw data.",
        "Demonstrates significant improvements over baseline techniques across diverse datasets and architectures.",
        "Versatile applicability across various network architectures."
      ],
      "weaknesses": [
        "Potential increase in communication overhead due to shared statistics.",
        "Security risks associated with sharing aggregated statistics.",
        "Lack of extensive empirical validation across a wider range of datasets.",
        "Increased implementation complexity compared to static normalization techniques."
      ],
      "questions": [
        "How does FedRDN address communication overhead in large-scale federated learning settings?",
        "What specific security measures are proposed to mitigate risks associated with shared statistics?",
        "Could you provide more detailed results on the method's performance across a broader range of datasets and network architectures?",
        "How does FedRDN compare to other dynamic normalization methods in terms of computational efficiency?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "25VG15SnkH",
    "title": "United We Train, Divided We Fail!",
    "std_review": {
      "summary": "The paper introduces SICC, a novel loss function designed to capture semantic and intrinsic correlations in biomedical NLP, achieving strong performance on several datasets. While the results are compelling, the study is limited by a small set of datasets, lack of statistical validation, and the complexity of implementing SICC. The theoretical foundation is solid, but practical details and sample efficiency could be further elaborated.",
      "strengths": [
        "Introduces a novel loss function (SICC) that effectively captures semantic and intrinsic correlations in biomedical text.",
        "Demonstrates strong empirical results on multiple datasets, outperforming standard baselines.",
        "Provides a clear theoretical motivation and a well-documented experimental setup."
      ],
      "weaknesses": [
        "Limited to a small set of biomedical and clinical datasets, potentially limiting generalizability.",
        "Lacks statistical rigor, such as significance tests, to validate performance differences.",
        "The complexity of the SICC loss may pose challenges for practitioners unfamiliar with contrastive learning.",
        "Fails to include comprehensive comparisons with non-contrastive methods."
      ],
      "questions": [
        "How does the proposed method perform on a broader range of biomedical datasets beyond those tested?",
        "What statistical tests were used to validate the significance of the observed performance improvements?",
        "Could you provide more details on the practical implementation and tuning of the SICC loss function?",
        "How does the sample efficiency of the fine-tuning process compare to other state-of-the-art methods?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "26XphugOcS",
    "title": "Zero-Shot Continuous Prompt Transfer: Generalizing Task Semantics Across Language Models",
    "std_review": {
      "summary": "The paper presents a novel approach to improve prompt transferability across language models by leveraging a shared vocabulary of tokens. It identifies a common subset of tokens between source and target models and optimizes prompt embeddings to maximize alignment of these shared tokens, leading to significant performance gains on both classification and generation tasks. While the method shows promise, it has limitations such as reliance on shared vocabularies and computational complexity of optimization. Overall, the paper is well‑structured, empirically validated, and introduces a practical solution for prompt engineering.",
      "strengths": [
        "Innovative transferability approach leveraging a shared vocabulary of tokens.",
        "Empirical validation demonstrating consistent performance gains across tasks and models.",
        "Broad applicability to diverse model types and domains."
      ],
      "weaknesses": [
        "Reliance on a shared vocabulary may limit applicability to models with significantly different vocabularies.",
        "Optimization complexity and potential need for careful tuning.",
        "Lack of detailed implementation guidance could hinder practical adoption.",
        "Limited evaluation scope focusing on a few benchmark datasets and model types."
      ],
      "questions": [
        "How robust is the method to models with highly dissimilar vocabularies?",
        "What are the computational costs of the optimization process, and are there more efficient alternatives?",
        "Could the method be extended to handle non‑token features or embeddings for better transferability?",
        "How does the method perform on larger, more complex datasets or model architectures not covered in the current experiments?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "27YiINkhw3",
    "title": "Syntax Error-Free and Generalizable Tool Use for LLMs via Finite-State Decoding",
    "std_review": {
      "summary": "The paper introduces ToolDec, a framework that integrates finite state machines (FSMs) with large language models (LLMs) to enhance their tool use capabilities. The approach constructs FSMs for tool names and argument structures, enabling LLMs to systematically select and invoke tools based on user queries. The paper demonstrates that ToolDec improves LLMs' ability to handle complex tool interactions and generalizes to unseen tools, outperforming stronger LLMs lacking external knowledge. The evaluation includes both qualitative case studies and quantitative benchmarks, highlighting the method's effectiveness and scalability. Overall, the paper makes a significant contribution to enhancing LLMs' tool use capabilities.",
      "strengths": [
        "Innovative Integration of FSMs: The paper effectively combines FSMs with LLMs to address tool use challenges, providing a novel approach to enhancing LLMs' capabilities.",
        "Robust Generalization: Demonstrates that LLMs can generalize to unseen tools, a significant advancement over existing methods.",
        "Comprehensive Evaluation: Uses a mix of qualitative case studies and quantitative benchmarks to validate the effectiveness of ToolDec.",
        "Scalability and Efficiency: Shows how the FSM-based approach can be integrated with LLMs without significant computational overhead, maintaining efficiency."
      ],
      "weaknesses": [
        "FSM Construction Complexity: The automatic construction of FSMs for complex tools may require significant manual intervention, limiting the method's applicability.",
        "Limited Benchmark Diversity: The evaluation primarily focuses on a specific set of benchmarks, which may not fully capture the method's performance across all potential use cases.",
        "Potential for Overfitting: The reliance on FSMs for tool name and argument structure may lead to overfitting, especially if the FSMs are not sufficiently generalized.",
        "Scalability Concerns: While the paper suggests scalability, the computational implications of integrating FSMs with LLMs for a large number of tools are not fully explored."
      ],
      "questions": [
        "How can the automatic construction of FSMs be improved to reduce the need for manual intervention?",
        "What are the specific computational overheads introduced by integrating FSMs with LLMs, and how can they be mitigated?",
        "How does the proposed method perform on a broader set of benchmarks beyond those evaluated in the paper?",
        "What strategies can be employed to prevent overfitting when using FSMs for tool name and argument structure?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "28gMnEAgl9",
    "title": "Large Language Models Are Not Strong Abstract",
    "std_review": {
      "summary": "The paper introduces the ARC benchmark, a comprehensive suite of tasks designed to evaluate abstract reasoning in large language models across a wide range of sizes and fine-tuning strategies. The authors demonstrate significant performance gains with scaling and advanced fine-tuning techniques, highlighting the importance of curriculum learning and multi-task pre-training. However, the benchmark also reveals limitations, such as limited task diversity and a lack of cross-modal extensions. Overall, the paper is well-received for its innovative approach and thorough evaluation, though it could benefit from addressing some of the noted weaknesses.",
      "strengths": [
        "Novel benchmark design incorporating diverse task types and formats.",
        "Comprehensive evaluation across a wide range of model sizes and fine-tuning strategies.",
        "Demonstrates the effectiveness of advanced fine-tuning techniques like curriculum learning and multi-task pre-training."
      ],
      "weaknesses": [
        "Limited diversity of tasks compared to more comprehensive benchmarks.",
        "Lack of cross-modal extensions to capture cross-modal reasoning capabilities.",
        "Insufficient exploration of edge cases and novel blocking scenarios.",
        "Qualitative analyses may not be as in-depth as needed to fully understand model limitations.",
        "No discussion on plans for maintaining a public leaderboard or versioning the dataset."
      ],
      "questions": [
        "How can the benchmark be extended to include more cross-modal reasoning tasks?",
        "What additional edge cases or novel blocking scenarios should be explored to better assess abstraction capabilities?",
        "What strategies can be employed to ensure long-term maintenance and community engagement with the benchmark?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "28kAFnQZ5V",
    "title": "Tensorized Attention Model",
    "std_review": {
      "summary": "The paper introduces TAM, a Transformer architecture with an integrated memory module that significantly improves long-term dependency capture and computational efficiency. TAM outperforms existing methods across various NLP tasks, demonstrating strong performance gains. While the architecture is effective, its complexity may hinder implementation, and scalability to very large models remains underexplored. Overall, TAM is a valuable contribution with promising scalability.",
      "strengths": [
        "Introduces a novel memory module that effectively enhances the Transformer architecture's ability to capture long-term dependencies.",
        "Demonstrates superior performance compared to state-of-the-art methods in terms of computational efficiency and memory usage.",
        "Provides clear and comprehensive experimental results across multiple NLP tasks, showcasing the versatility of TAM.",
        "Offers a scalable architecture that can be applied to both encoder and decoder models in Transformer-based systems."
      ],
      "weaknesses": [
        "The complexity of the TAM architecture may make it more challenging to implement and maintain compared to standard Transformer models.",
        "The paper lacks detailed analysis on the impact of different memory module configurations on model performance.",
        "The scalability of TAM to extremely large parameter sizes is not thoroughly explored, leaving open questions about its performance at the extreme scale."
      ],
      "questions": [
        "How does the choice of memory module configuration impact the model's performance on different tasks?",
        "What are the potential challenges and solutions for scaling TAM to models with extremely large parameter sizes?",
        "Can TAM be integrated with other advanced Transformer techniques to further enhance its performance?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "28L2FCtMWq",
    "title": "Ground-A-Video: Zero-shot Grounded Video Editing using Text-to-image Diffusion Models",
    "std_review": {
      "summary": "The paper presents a novel video editing framework that combines depth maps and optical flow maps to enable more natural and flexible object editing. It shows improved editing quality and consistency through experiments, but its practical applicability is limited by the lack of direct comparison with existing metrics and the potential rigidity of the editing process. The method is primarily designed for adding or deleting objects, which restricts its broader utility.",
      "strengths": [
        "Introduces a novel approach to video editing by combining depth maps and optical flow maps, providing a richer representation of video content.",
        "Demonstrates improved editing quality and consistency through experimental results, showcasing practical benefits.",
        "Offers a flexible framework that can potentially be applied to various video editing tasks beyond just adding or deleting objects."
      ],
      "weaknesses": [
        "Evaluation metrics are not directly comparable to those of existing methods, limiting relative performance assessment.",
        "Integration of depth maps and optical flow maps may lead to overly consistent editing results, potentially limiting flexibility for objects with inconsistent structures.",
        "The method appears primarily designed for adding or deleting objects, restricting its applicability to other editing tasks.",
        "Flow-guided smoothing is applied only to static areas, with no mention of warping operations for more complex editing scenarios."
      ],
      "questions": [
        "Could the proposed method be extended to handle more complex editing tasks beyond adding or deleting objects?",
        "How does the method compare to existing video editing techniques in terms of performance and flexibility?",
        "What specific video datasets were used for evaluation, and how do they relate to real-world scenarios?",
        "Are there plans to incorporate warping operations to address more complex editing scenarios?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "29pGC6IYaL",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a novel low-resource Mongolian-to-Chinese machine translation framework that combines knowledge distillation with reinforcement learning, using Llama as the teacher model. It employs adversarial noise to enhance distillation and demonstrates statistically significant improvements over baselines. While the approach is promising, concerns remain about the suitability of Llama for the task, the lack of detailed reward function design, and the limited exploration of model size effects. Overall, the paper makes a valuable contribution and is recommended for acceptance.",
      "strengths": [
        "Introduces a novel combination of knowledge distillation and reinforcement learning for low-resource machine translation.",
        "Demonstrates statistically significant improvements in translation quality compared to baseline methods.",
        "Conducts comprehensive ablation studies to assess the contributions of each component of the proposed framework."
      ],
      "weaknesses": [
        "Selection of Llama as a teacher model, despite not being trained on Mongolian or Chinese languages, may raise questions about its suitability.",
        "The reward function used in the proposed framework is not explicitly detailed, making it difficult to fully understand its design and impact.",
        "Ablation studies are limited to assessing individual components but do not explore interactions between components.",
        "Performance trend with varying student model sizes is not thoroughly investigated.",
        "Statistical significance of observed improvements is not fully explored, and experiments lack additional baselines for comprehensive comparison.",
        "Specific test sets and settings used in experiments are not officially released, limiting reproducibility."
      ],
      "questions": [
        "How was the reward function designed and how does it impact the distillation process?",
        "What is the impact of varying the size of the student model on the performance of the proposed framework?",
        "How can the statistical significance of the observed improvements be more thoroughly explored?",
        "What additional baselines could be included to provide a more comprehensive comparison?",
        "Why were specific test sets and settings not released for reproducibility?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "2aebB2mf0q",
    "title": "",
    "std_review": {
      "summary": "The paper proposes a novel framework for semi-supervised learning in infrared small target detection by classifying data augmentation techniques into robust (NUC) and mild (NUP) categories. It introduces a tailored loss function, AEWLoss, and evaluates its performance using IoU, Pd, and Fa metrics, showing improved detection accuracy over baselines. While the approach is innovative, the methodology lacks clarity in certain details, and the figures are ambiguous, potentially affecting reproducibility.",
      "strengths": [
        "Proposes a novel classification of data augmentation techniques into robust and mild categories, providing a clear framework for semi-supervised learning.",
        "Introduces a tailored loss function (AEWLoss) that effectively handles both positive and negative samples, enhancing detection performance.",
        "Employs a comprehensive set of evaluation metrics (IoU, Pd, Fa) that are well-suited for assessing the performance of infrared small target detection systems."
      ],
      "weaknesses": [
        "The methodology section lacks clarity, particularly regarding the non-uniform chromaticity augmentation process and the interpolation method used.",
        "The overview figure is informal and ambiguous, making it difficult to understand the proposed framework and its components.",
        "The theoretical basis for classifying augmentations as robust or mild is not fully explained, potentially limiting the interpretability of the results."
      ],
      "questions": [
        "Could you provide a more detailed explanation of the non-uniform chromaticity augmentation process and the interpolation method used?",
        "Please revise the overview figure to clearly depict the proposed framework, including the input image, augmented images, loss function components, and evaluation metrics, with labeled arrows and annotations."
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "2bF381xEke",
    "title": "MapSelect: Sparse & Interpretable Graph Attention Networks",
    "std_review": {
      "summary": "MapSelect introduces a deterministic sparse attention mechanism for GNNs, claiming improved interpretability and parameter efficiency. While it shows promise on the BA‑Shapes dataset, the paper lacks comprehensive performance baselines, detailed experimental results, and a thorough evaluation of interpretability across graph‑level tasks. The deterministic claim and parameter efficiency are central but not fully substantiated.",
      "strengths": [
        "Introduces a deterministic sparse attention mechanism for GNNs.",
        "Demonstrates interpretability gains on the BA‑Shapes dataset.",
        "Argues convincingly that sparsity reduces computational complexity."
      ],
      "weaknesses": [
        "Lacks empirical validation of the deterministic claim.",
        "Missing performance baselines against original dense GATs.",
        "Interpretability evaluated only on a single dataset.",
        "No detailed experimental results or code availability.",
        "Parameter efficiency not consistently validated."
      ],
      "questions": [
        "Can you provide empirical validation that MapSelect is truly deterministic compared to standard GAT implementations?",
        "What are the performance baselines against original dense GATs to quantify trade-offs?",
        "How does interpretability generalize beyond the BA‑Shapes dataset?",
        "Are specific performance metrics (e.g., AUC scores) and code available for verification?",
        "Can you clarify whether the input graphs are part of the computation graph?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "2BfZMh9td4",
    "title": "Beyond One-Preference-for-All:",
    "std_review": {
      "summary": "The paper introduces MODPO, a method that separates reward modeling from preference optimization in language model fine-tuning. It demonstrates competitive performance and reduced computational cost compared to existing methods like DPO LW, handling noisy data effectively. The reviewer finds the approach promising and recommends acceptance.",
      "strengths": [
        "Decouples reward modeling from optimization, allowing more flexible and accurate reward representation.",
        "Achieves competitive performance with reduced computational overhead, beneficial for large models.",
        "Demonstrates robustness to noisy pairwise data, a common real-world issue."
      ],
      "weaknesses": [
        "Adds complexity through an additional reward model training step.",
        "Risk of overfitting due to the separate reward modeling stage.",
        "Computational cost of training the reward model, which may be significant for large models."
      ],
      "questions": [
        "How does MODPO compare to other methods that also decouple reward modeling from optimization but use different reward estimation techniques?",
        "What are the long-term implications of training a separate reward model on noisy data for downstream fine-tuning tasks?",
        "Could the method be extended to handle more complex reward structures beyond pairwise comparisons?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "2boLXjsHsB",
    "title": "Multi-Objective Reinforcement Learning for Forward-Backward Markov Decision Processes",
    "std_review": {
      "summary": "The paper introduces FB-MOAC, a reinforcement learning framework that simultaneously learns forward and backward policies in MDPs to improve learning efficiency and policy generalization. The authors provide theoretical analysis and empirical results on synthetic and real-world tasks, showing benefits over standard forward-only RL. While innovative, the approach's computational complexity and limited theoretical guarantees may limit its practical applicability.",
      "strengths": [
        "Innovative dual-direction learning framework",
        "Solid theoretical foundation with convergence guarantees",
        "Empirical validation on both synthetic and real-world tasks"
      ],
      "weaknesses": [
        "Significant computational overhead for large-scale problems",
        "Limited theoretical guarantees for general settings",
        "Assumes backward state observability, limiting real-world applicability"
      ],
      "questions": [
        "How can the computational cost be reduced for high-dimensional state spaces?",
        "What are the theoretical guarantees for convergence in more general settings?",
        "How can the framework be adapted for environments where backward state is not directly observable?"
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "2C3CWCPxNS",
    "title": "Preconditioning for Physics-Informed Neural Networks",
    "std_review": {
      "summary": "The paper presents a novel preconditioning approach for Physics-Informed Neural Networks (PINNs) that addresses training pathologies caused by ill-conditioning in complex PDEs. It introduces a method to diagnose and rectify these issues using the condition number, which links to error control and convergence. Empirical evaluations on several high-dimensional PDE problems demonstrate improved stability and convergence, with theoretical insights into the relationship between condition number and PINN performance. While promising, the method's scalability to extremely high-dimensional problems and its comparison with other advanced techniques remain areas for further exploration.",
      "strengths": [
        "Innovative diagnosis and rectification of training pathologies using the condition number.",
        "Extensive empirical validation across complex PDEs showing improved stability and convergence.",
        "Valuable theoretical insights into the relationship between condition number and PINN performance.",
        "Demonstrated enhancement in computational efficiency and scalability for high-dimensional problems."
      ],
      "weaknesses": [
        "Limited empirical scope with experiments restricted to a few specific PDE problems.",
        "Potential scalability challenges for extremely high-dimensional or very large-scale problems.",
        "Lack of detailed comparison with other advanced preconditioning methods."
      ],
      "questions": [
        "How does the proposed preconditioning method perform on a broader range of complex PDEs beyond the specific examples provided?",
        "What strategies are employed to address potential scalability issues when applying the method to extremely high-dimensional problems?",
        "How does the proposed approach compare to other advanced preconditioning techniques, such as those based on domain decomposition, in terms of performance and applicability?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "2cRzmWXK9N",
    "title": "Beyond Reverse KL: Generalizing Direct Preference Optimization with Diverse Divergence Constraints",
    "std_review": {
      "summary": "The paper introduces f-DPO, an extension of the DPO framework that generalizes the reverse KL divergence to a broader class of divergences, enhancing flexibility and effectiveness in language model fine-tuning. It provides theoretical insights and demonstrates empirical improvements over traditional methods. The reviewer finds the work novel, theoretically enriched, and practically beneficial, leading to an acceptance recommendation.",
      "strengths": [
        "Theoretical Enrichment: Introduces closed-form mappings and calibration error analysis.",
        "Flexibility and Control: Allows nuanced trade-offs between accuracy and diversity.",
        "Empirical Validation: Shows significant improvements over traditional RLHF methods."
      ],
      "weaknesses": [
        "Complexity of Divergence Selection: May complicate model selection and tuning.",
        "Computational Considerations: Increased costs for large-scale applications.",
        "Limited Comparison with State-of-the-Art: Only compares to traditional methods."
      ],
      "questions": [
        "How does f-DPO handle scenarios where the choice of divergence significantly impacts performance?",
        "What are the computational trade-offs when using multiple divergences in practice?",
        "How does f-DPO compare to the latest state-of-the-art RLHF methods?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "2CxkRDMIG4",
    "title": "Precision and Recall Reject Curves",
    "std_review": {
      "summary": "The paper introduces a novel evaluation framework for rejection‑based classifiers using precision and recall curves, tailored for class‑imbalanced datasets. It demonstrates that rejection strategies can improve model performance by selectively rejecting easy examples while retaining hard ones, with empirical results across multiple datasets supporting the benefits. The study provides comprehensive insights into the trade‑offs of rejection, though it has some limitations in scope and evaluation complexity.",
      "strengths": [
        "Relevance to Imbalanced Datasets: The focus on precision and recall as evaluation metrics is particularly suited for class‑imbalanced problems, where accuracy can be misleading.",
        "Comprehensive Evaluation: By presenting precision and recall curves for both rejected and accepted samples, the paper provides a detailed view of how rejection strategies affect classifier performance.",
        "Theoretical and Practical Insights: The analysis not only highlights the benefits of rejection but also discusses the inherent trade‑offs, offering valuable insights for practitioners."
      ],
      "weaknesses": [
        "Complexity of Evaluation: The use of multiple precision and recall curves for different rejection rates adds complexity to the evaluation process, which might be challenging for readers unfamiliar with these metrics.",
        "Limited Scope: The study focuses on binary classification tasks, which may not fully capture the applicability of rejection strategies in multi‑class or regression problems.",
        "No Comparison with Other Metrics: While the paper discusses the limitations of accuracy, it does not compare rejection‑based performance against other metrics like AUC or F1 in a balanced setting."
      ],
      "questions": [
        "How does the proposed framework perform in multi‑class or regression settings?",
        "What are the long‑term implications of using rejection thresholds on model interpretability and deployment?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "2DbVeuoa6a",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a novel neural spectral method (NSM) for solving partial differential equations (PDEs) by leveraging spectral space representations, which avoids discretization errors and aliasing artifacts. Empirical results show superior performance compared to a PINN counterpart, attributed to differences in spectral transforms and training dynamics. The theoretical advantages of spectral methods are highlighted, and the framework provides a robust approach for high-accuracy neural operator solutions. Overall, the paper is well‑structured, theoretically sound, and experimentally validated, leading to an acceptance recommendation.",
      "strengths": [
        "Theoretical Advantages: NSM leverages spectral space to compute exact residuals, eliminating discretization errors that plague grid-based PINNs.",
        "Aliasing-Free Design: By using spectral coefficients as input, the method avoids aliasing artifacts, a common issue in grid-based approaches.",
        "Improved Performance: Despite identical loss functions, NSM outperforms CNO, suggesting that spectral transforms and training dynamics play a crucial role in method efficacy.",
        "Clear Methodology: The paper provides a rigorous theoretical analysis and practical demonstrations, enhancing reproducibility and understanding.",
        "Scalability: The method's performance remains consistent across different resolutions, demonstrating its robustness and scalability."
      ],
      "weaknesses": [
        "Complexity of Spectral Transforms: The reliance on spectral transforms may introduce computational complexity, potentially limiting scalability for very large problems.",
        "Dependency on Spectral Resolution: The number of modes (spectral resolution) significantly impacts performance, requiring careful selection and validation.",
        "Potential Overfitting: The high dimensionality of spectral space might lead to overfitting, especially if the training data is limited.",
        "Lack of Comprehensive Ablation Studies: While the paper suggests ablation studies, a more extensive exploration of grid resolutions and spectral resolutions would strengthen the findings.",
        "Interpretability Challenges: The spectral formulation may obscure interpretability compared to more intuitive grid-based methods."
      ],
      "questions": [
        "How does the computational complexity of spectral transforms scale with problem size, and what strategies can be employed to mitigate this complexity?",
        "What are the optimal spectral resolutions for different types of PDEs, and how can these be systematically determined?",
        "Could a more extensive set of ablation studies on both grid and spectral resolutions further validate the method's robustness?",
        "What techniques can be used to address potential overfitting in high-dimensional spectral spaces?",
        "How can the interpretability of solutions obtained via NSM be improved to facilitate practical applications?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "2DDwxbjP9g",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a discrete Wasserstein GAN (SWAG) that uses a patch-based CNN discriminator to enforce Lipschitz continuity, providing theoretical convergence proofs and demonstrating improved stability and sample quality on CIFAR-10. While the work makes significant theoretical contributions and offers practical benefits, it relies on several assumptions and has some practical limitations, such as the need for a large number of latent vectors in the discrete setting.",
      "strengths": [
        "Introduces a novel discrete formulation of Wasserstein GANs using patch-based CNN discriminators.",
        "Provides rigorous theoretical contributions, including convergence proofs under specific conditions.",
        "Proposes a multiscale optimization approach that enhances convergence properties.",
        "Demonstrates empirical improvements in sample quality and stability on CIFAR-10."
      ],
      "weaknesses": [
        "Theoretical results depend on several assumptions that may limit their generality.",
        "Notation for Wasserstein distances is inconsistent, which can be confusing.",
        "Empirical validation is limited to CIFAR-10, with no broader dataset or architecture testing.",
        "The requirement for a large number of latent vectors in the discrete setting may be impractical for real-world applications."
      ],
      "questions": [
        "How do the convergence guarantees extend beyond the specific assumptions and regularizers used in the proofs?",
        "What is the impact of the receptive field size of the CNN discriminator on the multiscale optimization approach?",
        "How can the discrete latent space be made more practical for real-world applications with limited computational resources?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "2dHmhoWweE",
    "title": "",
    "std_review": {
      "summary": "The paper introduces Lookbehind Sharpness‑Aware Minimization (Lookbehind SAM), a variant of SAM that uses linear interpolation of gradients from multiple ascent steps to reduce variance and improve generalization, especially in robustness and lifelong learning. Experiments on CIFAR and a down‑scaled ImageNet show significant improvements over vanilla SAM and ASAM, though the method's computational cost and lack of comparison with newer SAM variants are noted as concerns.",
      "strengths": [
        "Innovative gradient combination reduces variance and improves robustness.",
        "Theoretical motivation grounded in sharpness‑aware minimization.",
        "Demonstrates strong performance gains on benchmark datasets."
      ],
      "weaknesses": [
        "Increased computational overhead due to additional backward passes.",
        "Lack of comparison with the latest SAM variants.",
        "Parameter sensitivity, particularly the adaptive α parameter."
      ],
      "questions": [
        "How does Lookbehind SAM scale to larger datasets and more complex architectures?",
        "What are the theoretical convergence guarantees for Lookbehind SAM?",
        "How robust is the method to hyperparameter variations, especially the adaptive α parameter?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "2dhxxIKhqz",
    "title": "Function-space Parameterization of",
    "std_review": {
      "summary": "The paper presents a novel sparse Gaussian Process model for continual learning, introducing a continual learning objective (Eq. 14) and a dual parameterization approach to balance expressiveness and efficiency. Experiments show improved performance over baselines in dynamic settings, supported by both theoretical insights and empirical validation. While the approach is promising, concerns about inducing point selection, objective complexity, and potential overfitting remain.",
      "strengths": [
        "Introduces a novel continual learning objective that effectively captures temporal dependencies.",
        "Dual parameterization balances model complexity and computational efficiency for dynamic environments.",
        "Provides both theoretical insights and empirical results demonstrating effectiveness."
      ],
      "weaknesses": [
        "Lacks detailed justification for inducing point selection, which could impact performance.",
        "The continual learning objective (Eq. 14) is more complex than traditional objectives, potentially complicating optimization.",
        "Comparison with functional regularization could be strengthened with more detailed analysis.",
        "Risk of overfitting due to the penalty term related to the precision matrix."
      ],
      "questions": [
        "How are the inducing points chosen for the sparse GP model, and what impact does this have on performance?",
        "What is the relationship between the continual learning objective (Eq. 14) and existing methods like VCL or online Laplace methods?",
        "How does the dual parameterization approach compare to functional regularization methods in incorporating information from all data?",
        "Could optimizing the inducing points make the method equivalent to Ortega et al., 2023?",
        "How does the objective in Eq. 14 fit into the broader framework of variational methods compared to approaches lacking precision matrix penalty terms?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "2DJUXmHZ2O",
    "title": "Generalizing Poincare Policy Representations in Multi-agent Reinforcement Learning",
    "std_review": {
      "summary": "The paper introduces a novel approach to policy representation in reinforcement learning using hyperbolic neural networks, which effectively models the hierarchical structure of trajectories. It demonstrates improved performance and generalization compared to Euclidean baselines across several benchmarks. While promising, the method has several limitations, such as unclear handling of continuous action spaces and multi-agent scenarios, and theoretical questions about convergence and representation learning.",
      "strengths": [
        "Innovative use of hyperbolic geometry to model hierarchical trajectory data.",
        "Strong theoretical foundation and clear mathematical derivations.",
        "Empirical results showing clear performance improvements over Euclidean baselines."
      ],
      "weaknesses": [
        "Limited exploration of extension to continuous action spaces.",
        "Unclear theoretical justification for applying the method to multi-agent systems.",
        "Assumptions about Euclidean properties of state, action, and observation spaces."
      ],
      "questions": [
        "How does the method extend to continuous action spaces, and what are the theoretical justifications?",
        "Can the formulation be naturally extended to multi-agent systems with history-dependent policies?",
        "What is the precise role of the trajectory sequence in the hyperbolic neural network?",
        "How are hyperbolic representations used by different agents in multi-agent learning scenarios?",
        "What are the theoretical guarantees for convergence, especially for very long or complex trajectories?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "2DldCIjAdX",
    "title": "",
    "std_review": {
      "summary": "LayerNAS introduces a novel approach to neural architecture search (NAS) by mapping candidate architectures into a transformed, polynomial-sized search space, enabling efficient exploration with reduced computational cost. The method shows competitive performance on size search tasks, achieving faster results than traditional NAS methods. However, concerns about early stopping, bucketing strategy sensitivity, limited generalization evidence, and incomplete comparison with recent state-of-the-art methods remain. Overall, the paper presents a promising direction with some technical and empirical limitations.",
      "strengths": [
        "Efficient search space transformation while preserving completeness",
        "Significantly reduced computational overhead through bucketing and limited epochs",
        "Scalable framework with potential for broader NAS applications"
      ],
      "weaknesses": [
        "Reliability of performance estimates with early stopping and limited training epochs",
        "Sensitivity of bucketing strategy to bucket size and candidate distribution",
        "Lack of empirical evidence for generalization beyond size search tasks",
        "Omission of comparisons with recent NAS methods like OFA and EfficientNet"
      ],
      "questions": [
        "How does the method perform on more general NAS tasks such as topology search?",
        "What is the impact of different bucket sizes on the discovery of high-performing architectures?",
        "Can the early stopping approach be validated with longer training runs?",
        "How does LayerNAS compare to NAS methods incorporating distillation or other acceleration techniques?"
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "2dLMPOY0HW",
    "title": "When Do MLPs Excel in Node Classification?",
    "std_review": {
      "summary": "The paper proposes InfoMLP, a model that enhances node classification by incorporating graph-augmented representations and mutual information maximization. It demonstrates significant performance gains over baselines on several benchmark datasets. While the approach is promising, it lacks a comprehensive theoretical analysis and a detailed exploration of the impact of its design choices. The experimental scope is limited, and computational complexity is not thoroughly addressed.",
      "strengths": [
        "Introduces a novel approach to incorporating graph information into machine learning models.",
        "Demonstrates significant improvements over baseline models on several benchmark datasets.",
        "Provides a clear and concise description of the model architecture and training procedure."
      ],
      "weaknesses": [
        "Lacks a thorough theoretical analysis of the proposed approach.",
        "Does not thoroughly justify the choice of graph-augmented node feature matrix and mutual information estimator.",
        "Experimental results are limited to a small number of benchmark datasets.",
        "Does not provide a detailed analysis of the computational complexity."
      ],
      "questions": [
        "What are the theoretical guarantees or bounds on the mutual information that InfoMLP aims to minimize?",
        "How does the choice of the graph-augmented node feature matrix impact the model's ability to capture complex relationships?",
        "What is the impact of the choice of the mutual information estimator on the model's performance and optimization?",
        "How can the proposed approach be extended to larger-scale applications?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "2dnO3LLiJ1",
    "title": "",
    "std_review": {
      "summary": "The paper investigates outlier tokens in Vision Transformers (ViTs) during self‑supervised pretraining, proposing that these tokens capture global image information similarly to the CLS token. It introduces 'registers' to mitigate this issue and evaluates their impact on both the CLS token and downstream tasks using models like DINOv2 and OpenCLIP. While the authors find that registers can improve performance on tasks such as unsupervised object discovery, the results are inconsistent, particularly for OpenCLIP, raising questions about the trade‑offs and generalizability of the findings.",
      "strengths": [
        "Insightful identification of outlier tokens as behaving like the CLS token.",
        "Practical solution with registers to mitigate the issue.",
        "Comprehensive evaluation of both CLS token impact and downstream tasks."
      ],
      "weaknesses": [
        "Performance discrepancy in Table 3 for OpenCLIP with registers.",
        "Lack of detailed ablations to explain the discrepancy.",
        "Limited exploration of how registers affect other downstream tasks.",
        "Potential overgeneralization of findings across model sizes and pretraining paradigms."
      ],
      "questions": [
        "Do the registers inherit the behavior of outlier tokens?",
        "Why does OpenCLIP performance slightly drop despite the authors' claim of improvement?",
        "How do image tokens behave after adding registers, and what are the exact mechanisms?",
        "How does the norm of the CLS token change after adding registers?",
        "What is the impact of registers on downstream tasks beyond unsupervised object discovery?",
        "How does dataset bias (label vs. sampling) affect the emergence of outliers?",
        "Why do outliers still appear in DINOv2 despite dense mask‑image modeling?",
        "How do model size and pretraining paradigm influence the emergence of outlier tokens?"
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "2drC319yHQ",
    "title": "RepoFusion: Training Code Models to Understand Your Repository",
    "std_review": {
      "summary": "RepoFusion presents a method for enhancing code completion in IDEs by incorporating repository context, particularly for Java projects. The approach effectively truncates code snippets while preserving essential structural elements, leading to improved performance over standard models, especially in complex scenarios. Despite its innovative approach and clear evaluation framework, the method's Java‑specific nature and limited baseline comparisons raise concerns about its broader applicability and impact.",
      "strengths": [
        "Innovative context utilization for code completion",
        "Scalable approach applicable to various completion tasks",
        "Demonstrated performance gains over baseline models"
      ],
      "weaknesses": [
        "Java‑specific implementation may limit applicability",
        "Lack of comparison with models exposed to repository contexts",
        "Insufficient analysis of how different completion types benefit"
      ],
      "questions": [
        "How could RepoFusion be adapted for other programming languages?",
        "What detailed analysis is needed for how different code completion types benefit?",
        "How does performance scale with model size or computational trade-offs?",
        "Should baselines include models exposed to repository contexts like Repocoder?",
        "What is the impact of the curated dataset's diversity on generalizability?"
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "2Ed7b52z53",
    "title": "On the Matrix Form of the Quaternion Fourier Transform and Quaternion Convolution",
    "std_review": {
      "summary": "The paper introduces significant theoretical advancements in the quaternion Fourier transform and quaternion convolution, extending classical properties to the quaternion domain. These contributions enable tighter Lipschitz constant bounds for quaternion convolutional neural networks (QCNNs), enhancing stability and generalization. The proofs are rigorous and build on established mathematical foundations, though they may be challenging for readers without a strong background in quaternion algebra. The paper demonstrates practical benefits through an application to QCNNs, though experimental validation is limited to a specific use case.",
      "strengths": [
        "Novel theoretical contributions extending Fourier transform and convolution to quaternions.",
        "Clear and rigorous mathematical proofs building on established foundations.",
        "Direct practical implications for improving QCNNs through tighter Lipschitz constant bounds.",
        "Concrete application section effectively showcasing the benefits."
      ],
      "weaknesses": [
        "Complexity of proofs may be challenging for readers without advanced knowledge of quaternion algebra.",
        "Limited scope of applications focused primarily on Lipschitz constant bounding for QCNNs.",
        "Experimental validation is limited to a specific use case, potentially underestimating broader applicability."
      ],
      "questions": [
        "Could the theoretical results be extended to higher dimensions or other types of quaternion-based models?",
        "What are the potential impacts of the Lipschitz constant bounds on training stability in large-scale QCNNs?",
        "How do the proposed bounds compare to those obtained using alternative stability measures in practice?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "2eIembMRQJ",
    "title": "Active Teacher Selection for Reinforcement Learning from Human Feedback",
    "std_review": {
      "summary": "The paper introduces the HUB framework for multi‑teacher reinforcement learning, formulating the problem as a POMCPOW and proposing an Active Teacher Selection (ATS) algorithm. It demonstrates improved efficiency and performance on recommendation and COVID‑19 vaccine testing tasks compared to single‑teacher baselines. While the approach is novel and theoretically sound, its complexity and lack of formal guarantees are significant concerns. The overall verdict leans toward weak acceptance.",
      "strengths": [
        "Novel formulation of multi‑teacher RL as a POMCPOW.",
        "Dynamic teacher selection balances exploration and guidance.",
        "Solid theoretical foundation with clear definitions of utility, regret, and teacher distribution."
      ],
      "weaknesses": [
        "High complexity of the POMCPOW formulation may hinder practical implementation.",
        "Absence of formal regret bounds or convergence proofs.",
        "Assumptions about teacher utility and feedback may limit real‑world applicability.",
        "Lack of ablation studies to assess robustness."
      ],
      "questions": [
        "What are the formal regret bounds or convergence guarantees for the ATS algorithm?",
        "How does the framework handle heterogeneous teacher utilities and delayed feedback?",
        "Could you provide more details on the simulation environment used for evaluating the POMCPOW planner?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "2FAPahXyVh",
    "title": "OptiMUS: Optimization Modeling Using MIP Solvers and Large Language Models",
    "std_review": {
      "summary": "OptiMUS is a system that uses large language models to automatically generate and refine mathematical formulations for optimization problems, significantly reducing setup time compared to manual methods. The system is evaluated on the NLP4LP benchmark, showing high accuracy and efficiency gains. While demonstrating strong potential, the review highlights concerns about solver dependency, reproducibility, and the benchmark's coverage of real-world problems.",
      "strengths": [
        "Efficiency gains through automation of the formulation process",
        "Scalability to handle a wide range of problem types and sizes",
        "User-friendly interactive debugging process"
      ],
      "weaknesses": [
        "Performance heavily reliant on the choice of solver",
        "Reproducibility issues due to variability in LLM outputs",
        "NLP4LP benchmark may not fully capture real-world problem diversity"
      ],
      "questions": [
        "How does OptiMUS handle solver dependency to improve robustness?",
        "What strategies are employed to ensure reproducibility across different runs?",
        "How can the benchmark be expanded to better represent real-world optimization challenges?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "2fSyBPBfBs",
    "title": "Bilevel Optimization without Lower-Level Strong Convexity from the Hyper-Objective Perspective",
    "std_review": {
      "summary": "The paper introduces IGFM, a zeroth-order method for bilevel optimization that does not require lower-level strong convexity. It provides non-asymptotic convergence guarantees under convexity and regularity assumptions and demonstrates competitive performance on benchmarks. While novel and theoretically sound, practical applicability may be limited by restrictive assumptions and a lack of thorough robustness analysis.",
      "strengths": [
        "Novelty of a zeroth-order bilevel optimization method without LLSC.",
        "Strong theoretical foundation with non-asymptotic convergence rates.",
        "Demonstrated practical performance on benchmark problems."
      ],
      "weaknesses": [
        "Assumptions of convexity and regularity may be too restrictive.",
        "Algorithm choice for final output lacks clear justification.",
        "Complexity analysis is provided but lacks clear practical comparison.",
        "No thorough analysis of algorithm robustness to hyper-parameters."
      ],
      "questions": [
        "How can the method be extended to non-convex lower levels?",
        "What is the impact of hyper-parameter sensitivity on practical performance?",
        "How does the total complexity compare to existing methods in practice?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "2GJm8yT2jN",
    "title": "URLOST: Unsupervised Representation Learning without Stationarity or Topology",
    "std_review": {
      "summary": "The paper presents a novel method that combines topological data analysis (TDA) with deep learning to analyze the stationarity and topology of time series data. It introduces a new metric for evaluating these properties and demonstrates its effectiveness on several benchmark datasets. While the approach is promising, its complexity and limited scalability analysis are noted as areas for improvement.",
      "strengths": [
        "Integrates TDA with deep learning to provide a unique perspective on time series data.",
        "Introduces a novel metric for assessing stationarity and topology.",
        "Demonstrates robust performance across multiple benchmark datasets."
      ],
      "weaknesses": [
        "Complexity may limit accessibility for practitioners without expertise in TDA and deep learning.",
        "Evaluation relies on a limited set of benchmark datasets.",
        "Lacks detailed discussion on scalability for large datasets."
      ],
      "questions": [
        "How does the method scale to very large datasets?",
        "What are the specific topological features extracted and how do they relate to stationarity?",
        "How does the proposed metric compare to existing benchmarks for stationarity and topology?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "2gMwe9Duc4",
    "title": "Neuroexplicit Diffusion Models",
    "std_review": {
      "summary": "The paper introduces a neuroexplicit diffusion model for optical flow inpainting, combining PDE stability with CNN learning capabilities. It demonstrates strong performance on synthetic Sintel data but lacks real-world validation, comparison with recent methods, and exploration of generalization to other vision tasks. The innovative approach is promising, though concerns about reproducibility and broader applicability remain.",
      "strengths": [
        "Innovative integration of PDE and CNN for optical flow inpainting",
        "Coarse-to-fine refinement strategy improves speed without sacrificing quality",
        "Provides inherent interpretability through the diffusion process"
      ],
      "weaknesses": [
        "Limited real-world validation on datasets like KITTI or Middlebury",
        "No comparison with recent state-of-the-art methods",
        "Absence of studies on generalization to other vision tasks"
      ],
      "questions": [
        "How does the model perform on real-world datasets beyond synthetic Sintel?",
        "What is the model's performance compared to recent state-of-the-art methods?",
        "Has the model been evaluated on other vision tasks such as depth completion or semantic scene completion?",
        "What are the specific implementation details for handling sparse masks or scaling flow values?",
        "How robust is the model to mask densities not covered in the ablation study?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "2gwo9cjOEz",
    "title": "Neural Tangent Kernels Motivate Graph Neural Networks with Cross-Covariance Graphs",
    "std_review": {
      "raw_text": "{\n  \"summary\": \"The paper introduces a novel alignment concept for Neural Tangent Kernels (NTKs) in Graph Neural Networks (GNNs), aiming to provide theoretical insights into GNN behavior during inference tasks. It presents new theorems that relate this alignment to GNN performance and demonstrates applicability on the HCP‑YA dataset. While offering valuable theoretical contributions and practical relevance, the paper lacks comprehensive experimental validation and a thorough exploration of its practical implications. Overall, it is a promising work that could benefit from additional empirical support.\",\n  \"strengths\": [\n    \"Introduces a novel alignment concept for NTKs in GNNs.\",\n    \"Provides new theoretical theorems (Theorem 2 and Theorem 3) extending NTK analyses to GNNs.\",\n    \"Focuses on practical inference tasks like node and graph classification.\"\n  ],\n  \"weaknesses\": [\n    \"Lacks detailed experimental validation of the proposed theorems.\",\n    \"Assumes the output \\(\\mathbf{y}_i\\) has the same dimensionality as the input \\(\\mathbf{x}_i\\).\",\n    \"Dataset choice may limit the generalizability of the findings.\",\n    \"Limited discussion on the impact of layer depth and extension to other tasks.\"\n  ],\n  \"questions\": [\n    \"What are the detailed experimental validations planned for Theorem 2 and Theorem 3?\",\n    \"How can the findings be generalized beyond the HCP‑YA dataset?\",\n    \"What empirical studies support the claim that maximizing the alignment measure improves GNN performance?\",\n    \"How does the proposed alignment concept perform with deeper GNN architectures?\",\n    \"Are there plans to extend the alignment concept to other inference tasks such as link prediction?\"\n  ],\n  \"overall_score\": \"5: borderline\",\n  \"confidence\": \"3: medium\"\n}",
      "parse_error": true
    }
  },
  {
    "paper_id": "2h3m61LFWL",
    "title": "",
    "std_review": {
      "summary": "The paper introduces VBMLE, a Bayesian optimization algorithm for solving a non‑concave value‑function minimization problem in linear mixture MDPs. It provides theoretical regret bounds and demonstrates empirical superiority over traditional methods like UCLK. The work is well‑structured, with clear distinctions between linear and linear mixture MDPs, and offers a novel exploration‑exploitation framework. Overall, the paper is well‑received and recommended for acceptance.",
      "strengths": [
        "Introduces Bayesian optimization to tackle a non‑concave VBMLE objective, providing a novel perspective.",
        "Provides rigorous theoretical regret analysis with a clear O(1/ϵ²) convergence rate.",
        "Demonstrates superior computational efficiency and low regret in practical experiments.",
        "Clearly distinguishes between linear MDPs and linear mixture MDPs, situating the work within relevant literature.",
        "Offers a theoretical framework for balancing exploration and exploitation through a bias term."
      ],
      "weaknesses": [
        "The comparison with UCLK does not fully quantify the computational cost of quadratic constrained optimizations.",
        "Terminology between 'linear MDP' and 'linear mixture MDP' is not always clear.",
        "Reliance on GP‑UCB may introduce additional complexity and computational overhead.",
        "Theoretical guarantee in Theorem 2 assumes specific conditions on the parameter α(t).",
        "Some notations, such as π∞MLE(s), are introduced without explicit definition."
      ],
      "questions": [
        "How does the computational cost of GP‑UCB compare to other surrogate models in large state spaces?",
        "Can the theoretical regret bounds be extended to more general MDP settings beyond linear mixture MDPs?",
        "What are the practical implications of the bias term in balancing exploration and exploitation?",
        "How does VBMLE perform when applied to non‑linear or high‑dimensional state spaces?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "2HJRwwbV3G",
    "title": "What does the Knowledge Neuron Thesis Have to do with Knowledge?",
    "std_review": {
      "summary": "The paper investigates the identification of 'knowledge neurons' in a neural network trained on linguistic data, setting an a priori limit of 2–5 neurons to study their role in representing specific linguistic knowledge. It finds that these neurons do not consistently capture knowledge, challenging the notion of a distributed knowledge representation within the model. While the study is well-structured and clearly outlines its contributions, it has limitations such as a narrow focus on a limited number of neurons and a lack of diverse linguistic examples, which could affect the comprehensiveness of its findings.",
      "strengths": [
        "Clear a priori limitation on the number of knowledge neurons",
        "Robust and reproducible findings about the non-robust representation of knowledge",
        "Concise and clearly defined contributions section"
      ],
      "weaknesses": [
        "Limitation on exploring distributed representations due to the fixed neuron limit",
        "Inconsistent messaging regarding the non-robust representation of knowledge",
        "Reliance on minimal pairs without broader linguistic examples",
        "Definitions of formal and functional competence introduced late in the paper"
      ],
      "questions": [
        "Could the findings be generalized beyond the limited set of knowledge neurons considered?",
        "How do the identified neurons compare to other methods of knowledge representation in neural networks?",
        "What additional linguistic phenomena could be explored with a more extensive set of neurons?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "2iGiSHmeAN",
    "title": "",
    "std_review": {
      "summary": "The paper introduces BROGNET, a framework that combines Brownian dynamics with machine learning to model complex systems from sparse trajectory data. It employs a graph-based approach where particles interact through a learned potential, with the dynamics captured by multi-layer perceptrals (MLPs). The framework demonstrates improved accuracy over traditional methods in handling noisy data on synthetic Brownian systems, but its real-world applicability is limited by the lack of evaluation on complex systems and sensitivity to hyperparameters.",
      "strengths": [
        "Innovative integration of Brownian dynamics and machine learning to model systems from limited data.",
        "Effective handling of noisy or incomplete trajectory data, leveraging the strengths of both stochastic and deterministic frameworks.",
        "Scalable and flexible graph-based architecture that can be adapted to various interactions and system sizes."
      ],
      "weaknesses": [
        "Limited evaluation on real-world systems, which may not fully capture complexity and variability.",
        "High sensitivity to hyperparameter choices, which were not extensively explored.",
        "Graph topology was not thoroughly investigated, potentially affecting performance in different scenarios."
      ],
      "questions": [
        "How does BROGNET perform on real-world systems with more complex dynamics and interactions?",
        "What systematic approach could be used to select optimal hyperparameters for broader applicability?",
        "How would extending the model to include directed or weighted graphs impact performance?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "2inBuwTyL2",
    "title": "Deep SE(3)-Equivariant Geometric Reasoning for Precise Placement Tasks",
    "std_review": {
      "summary": "The paper introduces a novel method for robotic manipulation that combines demonstration-based learning with a multilateration algorithm to enable precise object pose estimation from sparse visual cues. The approach shows significant improvements in task completion speed and accuracy compared to existing methods, highlighting its practical value for real-world robotics applications. While the method demonstrates strong performance, its reliance on simulated demonstrations and computational efficiency of the multilateration step could be further explored to enhance robustness and scalability.",
      "strengths": [
        "Integrates multilateration with deep learning for robust pose estimation from limited visual data.",
        "Leverages simulated demonstrations to efficiently train and transfer to new tasks, reducing real-world data collection needs.",
        "Demonstrates clear performance improvements over baseline methods, indicating practical benefits."
      ],
      "weaknesses": [
        "Dependence on simulated demonstrations may limit effectiveness in highly dynamic or unpredictable environments.",
        "Computational efficiency of the multilateration step could be a bottleneck for real-time applications.",
        "Lack of thorough analysis on robustness to varying lighting conditions and sensor noise."
      ],
      "questions": [
        "How can the method be extended to handle more complex geometric constraints, such as non-rigid objects or soft deformations, in real-world scenarios?",
        "What strategies can be employed to improve sample efficiency when the number of available demonstrations is limited?",
        "How does the computational cost of the multilateration step scale with the number of points used for pose estimation, and what optimizations can mitigate this?",
        "What preprocessing or robustness techniques are required to ensure reliable performance under varying lighting conditions or sensor noise?",
        "Can the framework be adapted to handle tasks involving multiple objects or dynamic environments, such as multi-robot coordination or interactive scenes?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "2JF8mJRJ7M",
    "title": "Lipsum-Ft: Robust Fine-Tuning of Zero-Shot Models Using Random Text Guidance",
    "std_review": {
      "summary": "The paper introduces Lipsum-FT, a method for robust fine-tuning of zero-shot models by minimizing the energy gap between pre-trained vision and language models. The energy gap is defined as the squared difference of two inner products, measuring alignment between models' representations. The method generates text tokens for regularization and evaluates its impact on computational cost and performance compared to other techniques. Overall, the paper presents a novel approach with clear motivation and practical implementation, though some aspects like the complexity of the energy gap definition and limited scope could be improved.",
      "strengths": [
        "Innovative Approach: The paper presents a novel approach to robust fine-tuning by focusing on minimizing the energy gap, which is a unique way to align pre-trained models.",
        "Clear Motivation: The motivation is well-articulated, emphasizing the importance of maintaining pre-trained connections while fine-tuning for zero-shot tasks.",
        "Practical Implementation: The method is practically implemented with a clear procedure for generating text tokens, making it accessible for replication.",
        "Comprehensive Evaluation: The paper includes a thorough evaluation comparing Lipsum-FT with other methods, providing insights into its performance and computational efficiency."
      ],
      "weaknesses": [
        "Complexity of Energy Gap Definition: The definition of the energy gap as the squared difference of two inner products in Equation (6) might be less intuitive for readers unfamiliar with inner product spaces.",
        "Limited Scope: The evaluation focuses on specific scenarios and datasets, which may limit the generalizability of the findings.",
        "Computational Cost: While the paper discusses the additional computational cost, it lacks a detailed analysis of how this cost scales with different model sizes or datasets.",
        "Lack of Extensive Baselines: The comparison with other methods is not exhaustive, potentially overlooking other state-of-the-art techniques that could provide a more comprehensive view."
      ],
      "questions": [
        "How does the energy gap definition scale with larger model sizes or more diverse datasets?",
        "Could a more intuitive explanation of the energy gap be provided for readers less familiar with inner product spaces?",
        "Are there other state-of-the-art robust fine-tuning methods that were not compared in this evaluation?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "2Kf1AIdeyt",
    "title": "",
    "std_review": {
      "summary": "The paper introduces HS‑SNE, a variant of t‑SNE that incorporates L2‑normalization to better preserve the geometry of high-dimensional data, particularly single-cell RNA‑seq datasets. It demonstrates improved clustering performance and reduced computational overhead compared to standard t‑SNE. While the method shows promise, the review suggests that further validation through additional ablation experiments and broader comparisons with other techniques would strengthen the claims.",
      "strengths": [
        "Introduces a novel L2‑normalization approach to enhance clustering in high-dimensional data.",
        "Demonstrates clear improvements in cluster separation and computational efficiency over standard t‑SNE.",
        "Provides a practical advantage for analyzing large-scale biological datasets."
      ],
      "weaknesses": [
        "Lacks comprehensive comparison with other state-of-the-art clustering methods.",
        "Does not include ablation experiments to isolate the effect of the L2‑normalization term.",
        "Potential overfitting concerns in high-dimensional settings are not thoroughly addressed."
      ],
      "questions": [
        "How does HS‑SNE perform when compared to other recent clustering techniques beyond standard t‑SNE?",
        "Could additional ablation experiments help isolate the contribution of the L2‑normalization term?",
        "What is the robustness of HS‑SNE in scenarios with varying levels of noise and dimensionality?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "2kvDzdC5rh",
    "title": "IntentGPT: Few-shot Intent Discovery with Large Language Models",
    "std_review": {
      "summary": "IntentGPT introduces a novel few-shot intent discovery method that leverages GPT-4 feedback and a Knowledge Integration Rate (KIR) to improve performance with limited data. The approach shows strong empirical gains over baselines, especially in low-data scenarios, indicating practical utility for open-world applications. While innovative, the paper could benefit from more thorough ablation studies and expanded appendices to fully support its claims.",
      "strengths": [
        "Innovative feedback loop with GPT-4 for dynamic model refinement",
        "Effective knowledge integration via KIR parameter",
        "Strong empirical results, particularly in low-data settings"
      ],
      "weaknesses": [
        "Lack of comprehensive ablation analysis for feedback component",
        "Insufficient detail in appendix regarding intent examples and statistical analysis",
        "No direct comparison with vanilla 50-shot GPT-4",
        "Ambiguous intent handling not adequately addressed",
        "Ablation study details for ICPG module are not fully described"
      ],
      "questions": [
        "How does performance change when only the feedback component is ablated?",
        "Could you provide a more detailed appendix A.7 with additional intent examples and statistical analysis?",
        "What is the performance of a 50-shot vanilla GPT-4 with KIR set to 0.75 compared to the proposed method?",
        "How does the method perform with test examples that express no intent or multiple intents?",
        "Please clarify the simple prompt description used in the ICPG module ablation study"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "2l7g7zwC4z",
    "title": "Embedding File Structure for Tabular File Preparation",
    "std_review": {
      "summary": "The paper introduces RenEMB, a method that tokenizes tabular data into a structured string using a pattern-based tokenizer before feeding it into a transformer model. This approach, combined with a structural‑masking pre‑training task, improves the model's understanding of tabular data structures and outperforms existing methods on benchmark datasets. The authors highlight its potential for multilingual and general application, though some concerns about scalability and handling of special characters remain.",
      "strengths": [
        "Innovative tokenization that captures tabular structure more effectively than raw BPE.",
        "Structural‑masking pre‑training enhances the model's awareness of tabular data hierarchies.",
        "Potential for broad applicability across languages and table formats."
      ],
      "weaknesses": [
        "Multilingual performance may be limited by the transformer's ability to generalize across linguistic structures.",
        "Pattern‑tokenization may struggle with language‑specific characters that blend with structural delimiters.",
        "Pre‑training complexity and scalability to large datasets are open questions."
      ],
      "questions": [
        "How does RenEMB perform on truly multilingual tabular datasets beyond the current benchmarks?",
        "What strategies can be employed to improve the tokenizer's handling of language‑specific characters?",
        "What are the computational and scalability implications of the structural‑masking pre‑training on very large datasets?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "2lDQLiH1W4",
    "title": "Instant3D: Fast Text-to-3D with Sparse-View Generation and Large Reconstruction Model",
    "std_review": {
      "summary": "Instant3D presents a novel approach to 3D reconstruction using DINO features and a transformer-based reconstructor. It generates four views of a scene, processes them with a transformer to predict NeRF triplanes, and shows competitive rendering quality and diversity against optimization-based methods. While promising, the method's limited resolution and potential lack of diversity compared to specialized approaches are noted.",
      "strengths": [
        "Leverages DINO features known for effectiveness in computer vision tasks.",
        "Uses a tiled representation to generate four views, potentially reducing computational complexity.",
        "Addresses the Janus problem with a transformer-based reconstructor, offering advantages over optimization-based methods.",
        "Demonstrates competitive rendering quality and diversity against established benchmarks."
      ],
      "weaknesses": [
        "Limited resolution of NeRF triplanes may impact overall rendering fidelity.",
        "Potential lack of diversity compared to optimization-based methods like DreamFusion and ProlificDreamer."
      ],
      "questions": [
        "How does the method handle scenes with highly ambiguous or ambiguous-looking features?",
        "What is the computational cost of the tiled representation compared to generating views as separate channels?",
        "Can the method be extended to higher resolutions to improve rendering quality?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "2LhCPowI6i",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a novel generative‑replay approach for class‑incremental learning that effectively mitigates catastrophic forgetting by combining a classifier‑based rejection filter with generative models to create pseudodata. Empirical results on CIFAR‑100 and Tiny ImageNet show significant improvements over existing methods, indicating strong practical utility. However, the experimental scope is limited, and the method's generalizability could be further validated through additional ablation studies, visualizations, and broader benchmarking.",
      "strengths": [
        "Novel integration of classifier‑based rejection filtering with generative replay.",
        "Generative replay provides a scalable way to maintain task performance.",
        "Theoretical justification for the rejection filter enhances method credibility.",
        "Demonstrated superior performance on standard continual learning benchmarks."
      ],
      "weaknesses": [
        "Limited experimental scope focusing on two benchmarks.",
        "Absence of ablation studies to isolate component contributions.",
        "Lack of qualitative visualizations of generated pseudodata.",
        "Potential overfitting to specific neural network architectures."
      ],
      "questions": [
        "How does the method perform on a wider range of datasets and tasks?",
        "What is the impact of the rejection filter on learning dynamics, and how can it be further optimized?",
        "Could ablation studies provide clearer insights into the contributions of the generative replay and rejection filter?",
        "What qualitative evidence supports the quality and diversity of the generated pseudodata?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "2Mo7v69otj",
    "title": "Pooling Image Datasets with Multiple Covariate Shift and Imbalance",
    "std_review": {
      "summary": "The paper introduces a category theory-based framework for handling covariate shift in image datasets, aiming to preserve invariance and equivariance during data pooling. It shows competitive performance against existing methods but has limitations in computational efficiency and robustness in scenarios with minimal covariate overlap. The authors suggest further experiments to validate generalization and explore alternative approaches.",
      "strengths": [
        "Provides a mathematically rigorous framework using category theory to address covariate shift.",
        "Introduces novel functor and morphism mappings for data pooling, potentially leading to more robust models.",
        "Demonstrates competitive empirical results against established methods."
      ],
      "weaknesses": [
        "Relies on assumptions of overlapping covariate values, which may limit effectiveness in some cases.",
        "Does not fully explore counterfactual reasoning or alternative robustness methods.",
        "Lacks comprehensive analysis of computational efficiency compared to existing techniques."
      ],
      "questions": [
        "How does the method perform under higher-dimensional or more complex covariate shifts?",
        "What are the computational efficiency trade-offs compared to existing approaches?",
        "Could alternative robustness methods, such as domain adaptation, improve the framework's applicability?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "2MpOjashKU",
    "title": "",
    "std_review": {
      "summary": "Divided Attention (DivA) introduces an unsupervised approach for multi-object segmentation using optical flow, achieving competitive performance, speed, and flexibility. The method leverages an adversarial conditional encoder-decoder architecture to segment visual fields into independently moving regions, handling varying numbers of objects without retraining. While demonstrating strengths in unsupervised learning and optical flow utilization, DivA's weaknesses include limited real-world dataset evaluation and potential challenges with complex scenes. Overall, the paper is well-received and recommended for acceptance.",
      "strengths": [
        "Unsupervised learning approach that discovers objects from scratch without pre-training.",
        "Utilizes optical flow to effectively distinguish static objects from the background.",
        "Adversarial conditional encoder-decoder architecture enhances segmentation accuracy and flexibility.",
        "Capable of handling varying numbers of objects in different datasets without requiring retraining.",
        "Demonstrates competitive performance, speed, and flexibility compared to existing methods."
      ],
      "weaknesses": [
        "Limited evaluation on diverse real-world datasets to assess robustness and generalization.",
        "Potential challenges in handling complex scenes with highly dynamic objects or occlusions.",
        "Lack of detailed analysis on the impact of different hyperparameters on segmentation quality.",
        "The unsupervised nature may lead to suboptimal segmentation in some cases compared to supervised methods."
      ],
      "questions": [
        "How does DivA perform on a broader set of real-world datasets with varying complexity?",
        "What is the impact of different hyperparameters on the segmentation quality, and how can this be optimized?",
        "Can DivA be extended to handle more complex scenarios, such as highly dynamic scenes or scenes with significant occlusions?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "2msbbX3ydD",
    "title": "",
    "std_review": {
      "summary": "The paper introduces Ferret, a model for visual grounding and referring expression comprehension that combines discrete coordinates with continuous features. It is trained on GPT-4 generated data and evaluated on the Flickr30k dataset, showing strong performance. The authors propose Ferret-Bench for benchmarking. While the model excels in referring and grounding tasks, it lacks evaluation on broader vision tasks and human validation of the generated data.",
      "strengths": [
        "Hybrid region representation enhances precision and flexibility.",
        "Training on high-quality GPT-4 generated data improves performance.",
        "Comprehensive evaluation on Flickr30k provides robust results.",
        "Proposed Ferret-Bench benchmark standardizes evaluation in visual grounding and referring tasks."
      ],
      "weaknesses": [
        "Limited evaluation on non-referencing/non-grounding tasks.",
        "Potential overfitting to GPT-4 generated data.",
        "Lack of human evaluation for the generated data.",
        "Zero-shot performance may not fully capture model capabilities."
      ],
      "questions": [
        "How does Ferret perform on non-referencing/non-grounding tasks like image captioning or VQA?",
        "What are the human evaluation results for the data generated by GPT-4?",
        "How robust is Ferret's performance under ambiguous or complex visual references?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "2nD1SvxTZc",
    "title": "One-Versus-Others Attention:",
    "std_review": {
      "summary": "The paper introduces the One‑Versus‑Others (OvO) attention mechanism for multimodal fusion, showing strong performance gains over traditional methods on several benchmark datasets. OvO scales linearly with the number of modalities and requires fewer parameters, making it both computationally efficient and effective. While the method demonstrates clear advantages, the review notes areas for improvement such as broader comparisons and more rigorous statistical analysis.",
      "strengths": [
        "Linear scalability with the number of modalities",
        "Parameter efficiency compared to self‑attention and cross‑attention",
        "Strong performance gains across diverse datasets",
        "Clear theoretical foundation with a rigorous mathematical formulation"
      ],
      "weaknesses": [
        "Limited comparison with newer techniques like hierarchical attention or contrastive learning",
        "Lack of statistical analysis to assess significance of performance improvements",
        "Insufficient testing on additional real‑world datasets for broader generalization",
        "Ambiguity in implementation details affecting reproducibility"
      ],
      "questions": [
        "How does OvO perform when compared to more recent multimodal fusion techniques?",
        "What is the impact of hyper‑parameter tuning on the model's performance?",
        "Can OvO be applied to high‑dimensional multimodal data beyond the tested datasets?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "2NpAw2QJBY",
    "title": "Neural Neighborhood Search for Multi-agent Path Finding",
    "std_review": {
      "summary": "The paper introduces a neural network architecture for subset selection in multi-agent pathfinding, leveraging transformer attention mechanisms. It compares the proposed neural approach to traditional handcrafted heuristics, showing improved solution quality with acceptable computational overhead. The authors evaluate two transformer variants, highlighting their trade-offs in speed and accuracy across various map sizes. While demonstrating strong performance, the paper could improve by addressing hyperparameter sensitivity and scalability to very large maps.",
      "strengths": [
        "Introduces a novel neural architecture tailored for multi-agent pathfinding using transformer attention.",
        "Provides a thorough comparative analysis with handcrafted heuristics, showing clear performance gains.",
        "Clearly differentiates between light‑weight and heavy‑weight transformer modules, offering insights into their trade‑offs."
      ],
      "weaknesses": [
        "Limited baseline comparison with more detailed runtime analysis of competing methods.",
        "Lacks extensive exploration of hyperparameter sensitivity, affecting reproducibility.",
        "Scalability to very large maps or high numbers of agents is not thoroughly investigated.",
        "Training details, such as the exact loss function and optimization strategy, are not fully elaborated."
      ],
      "questions": [
        "How does the model perform when scaled to very large maps or a high number of agents?",
        "What is the impact of hyperparameter choices on the model's performance and reproducibility?",
        "Could additional experiments compare the model's efficiency against other state‑of‑the‑art methods more comprehensively?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "2NwHLAffZZ",
    "title": "Weak Correlations as the Underlying Principle for Linearization of Gradient-Based Learning Systems",
    "std_review": {
      "summary": "The paper introduces a novel framework for analyzing the linearization of neural networks through the lens of 'weak correlations' among the derivatives of the network's loss function. By formalizing these correlations and establishing asymptotic conditions under which the Neural Tangent Kernel (NTK) exhibits linearity, the authors provide a rigorous mathematical foundation for understanding when gradient-based learning systems behave linearly. The work extends prior results on NTK linearization by introducing a new asymptotic framework for random tensors and proving that weak correlations imply asymptotic linearity in the NTK. The reviewer finds the mathematical rigor, theoretical contributions, and clear formalization of concepts to be significant strengths, while noting limitations in practical relevance and the need for more empirical validation.",
      "strengths": [
        "Novel mathematical framework for analyzing linearization through weak correlations.",
        "Strong theoretical contributions with rigorous definitions and characterizations.",
        "Clear formalization using Big-O notation for random tensors.",
        "Comprehensive theorem proving with well-structured derivations and bounds."
      ],
      "weaknesses": [
        "Results are primarily applicable to infinitely wide networks, limiting practical relevance.",
        "Assumptions on standard loss functions may restrict generalizability.",
        "Complex notation and definitions introduced without extensive explanation.",
        "Lack of empirical validation through numerical studies or real-world applications."
      ],
      "questions": [
        "How can the framework be extended to finite-width neural networks?",
        "What are the implications of weak correlations for non-convex or non-standard loss landscapes?",
        "Could additional numerical experiments or real-world case studies strengthen the empirical support for the theoretical predictions?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "2Oiee202rd",
    "title": "",
    "std_review": {
      "summary": "PerceptionCLIP enhances CLIP's zero-shot classification by incorporating contextual attributes inferred from images. The method improves accuracy and interpretability, showing robustness across diverse datasets. While introducing some computational overhead, the straightforward integration and clear benefits make it a valuable contribution.",
      "strengths": [
        "Enhanced interpretability through explicit mapping of contextual attributes to textual descriptions.",
        "Improved classification accuracy, especially in challenging zero-shot scenarios.",
        "Flexibility and robustness across diverse datasets with minimal additional implementation effort."
      ],
      "weaknesses": [
        "Increased computational complexity due to additional inference steps for attribute extraction.",
        "Potential struggles with ambiguous or uncertain contextual attributes.",
        "Dependence on the quality of textual descriptions generated by CLIP, which may vary."
      ],
      "questions": [
        "How does PerceptionCLIP handle cases where the inferred contextual attributes are highly ambiguous or conflicting?",
        "What is the impact of the additional computational overhead on real-time applications or resource-constrained environments?",
        "Can the method be extended to other domains beyond image classification without significant modifications?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "2ov9RiAkxE",
    "title": "Identifying and Mitigating Vulnerabilities in LLM-Integrated Applications+",
    "std_review": {
      "summary": "The paper identifies critical vulnerabilities in LLM-integrated applications and proposes a defense mechanism called Shield. Shield effectively detects and mitigates attacks while preserving application utility, as shown by experimental results. However, limitations such as reliance on LLM capabilities and unquantified cost implications are noted. Overall, the paper makes a valuable contribution and is recommended for acceptance.",
      "strengths": [
        "Identifies critical vulnerabilities in LLM-integrated applications that are not adequately addressed by current safeguards.",
        "Provides a comprehensive framework for understanding and mitigating these vulnerabilities through four key properties.",
        "Introduces a novel defense mechanism, Shield, that effectively detects and mitigates attacks across different threat models.",
        "Conducts thorough experimental evaluations demonstrating the effectiveness of Shield in preserving application utility while enhancing security.",
        "Discusses the cost implications and practical considerations of implementing Shield, providing valuable insights for real-world deployment."
      ],
      "weaknesses": [
        "The proposed Shield defense mechanism relies heavily on the LLM's capabilities for attack detection, which may limit its effectiveness in scenarios where the LLM lacks sufficient context or knowledge.",
        "The experimental results are based on a limited set of applications and attack scenarios, which may not fully generalize to other types of LLM-integrated applications.",
        "The cost implications of employing Shield are not fully quantified, making it difficult to assess its overall impact on the cost per query in real-world scenarios.",
        "The paper does not provide a comprehensive analysis of the potential real-world implications and risks associated with the identified vulnerabilities, which could limit its impact on the development and deployment of secure LLM-integrated applications."
      ],
      "questions": [
        "How can the Shield defense mechanism be adapted to scenarios where the LLM lacks sufficient context or knowledge to detect attacks?",
        "What are the long-term cost implications of deploying Shield in large-scale LLM-integrated applications?",
        "How can the identified vulnerabilities and the proposed Shield defense be generalized to a wider range of LLM-integrated applications?",
        "What are the potential real-world implications and risks of the identified vulnerabilities, and how can they be mitigated beyond the scope of this paper?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "2oWRumm67L",
    "title": "",
    "std_review": {
      "summary": "The paper introduces Light-MILPopt, a framework for efficiently solving large-scale MILP problems using graph-based methods and neural networks. It demonstrates strong performance against established solvers in benchmarks and real-world applications, though it has limitations in generalization and theoretical guarantees. Overall, the framework is well-received for its innovative approach and practical effectiveness.",
      "strengths": [
        "Innovative graph representation of MILP problems",
        "Advanced neural network model for initial solution prediction",
        "Efficient problem decomposition using FENNEL graph partitioning",
        "Strong performance in benchmarks compared to Gurobi and SCIP"
      ],
      "weaknesses": [
        "Limited generalization due to small-scale training data",
        "Potential for local optima in iterative optimization",
        "Complexity of implementation and computational resource requirements",
        "Lack of detailed theoretical analysis"
      ],
      "questions": [
        "How can the framework be extended to handle even larger problem sizes?",
        "What theoretical guarantees can be provided for the convergence of the iterative optimization process?",
        "How does the framework perform on a broader range of problem types beyond those evaluated in the case study?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "2OwSqvxjP2",
    "title": "",
    "std_review": {
      "summary": "The paper introduces VCC and INFUSE, two methods that enhance semi-supervised learning by improving pseudo-label calibration and ensuring temporal consistency. VCC uses a VAE to refine pseudo-labels, while INFUSE adds a Temporal Consistency score and a mix-up data augmentation strategy. Empirical results show significant accuracy and stability improvements over existing baselines, though implementation complexity and hyper‑parameter sensitivity are noted.",
      "strengths": [
        "Innovative calibration technique using a Variational Autoencoder (VAE) to improve pseudo‑label accuracy.",
        "Introduces a Temporal Consistency score and mix‑up data augmentation to maintain dataset stability and prevent over‑fitting.",
        "Provides comprehensive empirical validation across multiple benchmark datasets."
      ],
      "weaknesses": [
        "Increased implementation complexity, especially with the VAE component, may require significant resources.",
        "Performance may be sensitive to hyper‑parameter settings, affecting reproducibility.",
        "Ablation studies are not fully detailed, limiting understanding of individual contributions.",
        "Limited comparison with the latest state‑of‑the‑art methods."
      ],
      "questions": [
        "How robust are the methods to variations in the amount and quality of labeled data?",
        "Could the VAE component be simplified or approximated without losing performance gains?",
        "What are the computational costs of maintaining the Temporal Consistency score during training?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "2Pup7olzxj",
    "title": "Differentiable Optimization in Plane-Wave Density Functional Theory for Solid States",
    "std_review": {
      "summary": "The paper introduces a neural network-based method for interpolating electronic band structures, demonstrating its versatility on several crystal structures. While highlighting potential improvements in accuracy and efficiency, the method's quantitative accuracy is limited, lacks direct comparison with established techniques like Wannier interpolation, and its geometry optimization is tested on a single system. Overall, the method shows promise but requires further validation and broader testing.",
      "strengths": [
        "Introduces a novel neural network approach for band structure interpolation.",
        "Demonstrates versatility across multiple crystal structures.",
        "Provides a clear and detailed description of the methodology."
      ],
      "weaknesses": [
        "Limited quantitative error analysis for band structure interpolation.",
        "No comparison with Wannier interpolation for k-space path calculations.",
        "Geometry optimization tested on a single system, limiting broader conclusions.",
        "Lack of efficiency and applicability comparisons with classical SCF methods.",
        "Figure 2 and Section 3 setup are unclear and inconsistent."
      ],
      "questions": [
        "Can you provide quantitative error/discrepancy analyses for the band structure interpolation across different scenarios?",
        "Please compare the proposed method with Wannier interpolation for deriving band structures along specific k-space paths.",
        "Expand the geometry optimization testing to include additional systems to assess the method's ability to find the global minimum.",
        "Provide a detailed comparison of the method's efficiency, accuracy, and applicability across different material types (ionic, metallic, covalent network) with classical SCF methods.",
        "Clarify the setup in Figure 2 and Section 3, particularly the interpretation of the first step and any interpolation performed."
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "2pvECsmld3",
    "title": "SparseFormer: Sparse Visual Recognition via Limited Latent Tokens",
    "std_review": {
      "summary": "SparseFormer introduces a novel vision transformer that significantly reduces computational cost by dynamically adjusting regions of interest (RoIs) for attention tokens. The approach achieves comparable or better accuracy than dense transformers with far fewer parameters and FLOPs, making it suitable for resource-constrained environments. While showing promise on object detection and semantic segmentation, the model's performance on complex scenes and high-resolution images remains limited. Overall, SparseFormer is a valuable contribution to efficient vision transformer design.",
      "strengths": [
        "Efficient token pruning reduces computational cost while maintaining high accuracy.",
        "Dynamic RoI adjustment enables adaptive focus on relevant image regions.",
        "Demonstrates strong performance on dense prediction tasks beyond image classification."
      ],
      "weaknesses": [
        "Lack of explicit positional encoding may hinder precise localization in complex scenes.",
        "Performance on high-resolution images with fine details is underexplored.",
        "Additional computational overhead from the focusing transformer could be a concern for very low-power devices."
      ],
      "questions": [
        "How does SparseFormer perform on high-resolution images with intricate details?",
        "What are the trade-offs between different token generation strategies (e.g., convolutional, Swin-style)?",
        "How can explicit positional encoding be incorporated to improve localization in complex scenes?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "2qLSkTuqrb",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a novel framework that integrates a cognitive model with a biologically plausible neural network to simulate locust swarming behavior. It effectively uses Bayesian inference to estimate proximity preferences and classifies behaviors into categories such as random, hungry, and follower. While the approach is innovative, it lacks clear validation of model accuracy against real-world data and detailed explanation of how stochasticity is modeled. The neural network's implementation details are also not fully explained, making it difficult to assess its biological plausibility.",
      "strengths": [
        "Innovative integration of cognitive modeling with neural network implementation.",
        "Use of Bayesian methods for robust parameter inference.",
        "Application to real-world locust behavior dataset."
      ],
      "weaknesses": [
        "Limited validation of model accuracy against real-world data.",
        "Unclear modeling of stochasticity in agent behavior.",
        "Lack of detailed explanation of neural network implementation and its biological plausibility.",
        "Reliance on proximity and trace features may be insufficient for capturing full animal behavior complexity."
      ],
      "questions": [
        "How does the model's accuracy compare to real-world locust behavior data?",
        "What specific mechanisms are used to model the stochasticity of agent behavior?",
        "Could you provide more details on the neural network's implementation and its biological plausibility?",
        "How were the current handcrafted features (proximity and trace) validated for sufficiency in capturing animal behavior complexity?"
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "2RGQwJEcAC",
    "title": "",
    "std_review": {
      "summary": "The DCS-Transformer introduces a novel approach to model pruning by integrating the Information Bottleneck (IB) loss into channel selection, achieving significant reductions in model size and computational requirements while maintaining accuracy. The method is effective and efficient, with comprehensive experiments supporting its claims. However, the paper could benefit from a deeper analysis of computational overhead and hyperparameter trade-offs, as well as a broader comparison with state-of-the-art techniques.",
      "strengths": [
        "Introduces a novel method for model pruning using Information Bottleneck.",
        "Achieves substantial efficiency gains with minimal accuracy loss.",
        "Comprehensive ablations and experiments validate the approach."
      ],
      "weaknesses": [
        "Lacks detailed analysis of computational overhead introduced by IB loss.",
        "Ablations do not fully explore hyperparameter trade-offs.",
        "Comparison with state-of-the-art techniques is limited."
      ],
      "questions": [
        "How does the computational overhead of the IB loss affect practical applicability?",
        "Could a more extensive exploration of hyperparameter trade-offs provide deeper insights?",
        "What is the scalability of the method to larger models or more complex datasets?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "2RJAzSphy9",
    "title": "Sample Efficient Reinforcement Learning",
    "std_review": {
      "summary": "The paper presents a novel active learning algorithm for reinforcement learning fine-tuning, specifically targeting large language models. It introduces a Borda function and kernelized uncertainty estimation to guide sample selection, achieving significant performance improvements on both synthetic and real-world datasets. While the method shows promise for scalability and broader applicability, concerns remain regarding theoretical rigor, statistical validation, and practical scalability for very large models.",
      "strengths": [
        "Introduces a fresh perspective on sample selection in RL fine-tuning using innovative Borda function and kernelized uncertainty estimation.",
        "Provides novel theoretical guarantees with tighter regret bounds under specific assumptions.",
        "Demonstrates strong empirical performance on synthetic and real-world datasets, including Jeopardy and Anthropic."
      ],
      "weaknesses": [
        "Theoretical framework may be challenging for readers unfamiliar with advanced active learning and regret analysis concepts.",
        "Lack of detailed statistical significance tests could leave uncertainties about the robustness of the findings.",
        "Practical challenges in scaling the algorithm to very large models are not fully addressed.",
        "Empirical comparisons with state-of-the-art methods are limited."
      ],
      "questions": [
        "How can the theoretical guarantees be extended to more general settings beyond the specific concentration inequality assumptions?",
        "What further empirical validation is needed to assess the robustness of the method across different random seeds and dataset splits?",
        "How can the scalability challenges be addressed in practice, particularly for extremely large context and action spaces?",
        "Could additional statistical tests (e.g., bootstrapping or permutation tests) strengthen the claims about performance improvements?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "2Rwq6c3tvr",
    "title": "Time Travel in LLMs: Tracing Data Contamination in Large Language Models",
    "std_review": {
      "summary": "The paper proposes a method to detect data contamination in LLM pipelines by using GPT‑4 safeguards to guide completions from random‑length prefixes. It shows strong empirical results on synthetic and real datasets, but lacks clear contamination thresholds, limited evidence on safeguard impact, and potential human‑evaluator bias. The approach is primarily designed for decoder‑only models and lacks clear generalizability to encoder‑only models.",
      "strengths": [
        "Innovative use of LLM safeguards to detect contamination.",
        "Scalable contamination detection method for large datasets.",
        "Thorough empirical validation across multiple datasets."
      ],
      "weaknesses": [
        "Lack of clear contamination thresholds leading to potential inconsistency.",
        "Limited empirical evidence on the impact of GPT‑4 safeguards.",
        "Potential human‑evaluator bias in generating examples and labels.",
        "Applicability primarily to decoder‑only LLMs, with limited discussion for encoder‑only models."
      ],
      "questions": [
        "What specific thresholds should be used to determine contamination at the partition level?",
        "How does the impact of GPT‑4 safeguards on completions affect the overall contamination detection?",
        "What alternative approaches could be explored for encoder‑only models like BERT?",
        "How can the human‑evaluator bias be mitigated in the GPT‑4 ICL method?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "2sCcTMWPc2",
    "title": "TimelyGPT: Recurrent Convolutional Transformer for Long Time-series Representation",
    "std_review": {
      "summary": "TimelyGPT introduces a novel recurrent convolutional transformer designed for irregular time-series data, leveraging pre-training to improve ultra-long-term forecasting accuracy and efficiency. The model outperforms existing methods in evaluation, but the review highlights several gaps, including unclear dataset size calculation, lack of performance analysis without pre-training, and insufficient details on baseline models. These issues need addressing to fully validate the model's effectiveness.",
      "strengths": [
        "Introduces a novel approach to model irregular time-series data, addressing a significant challenge in real-world applications.",
        "Demonstrates strong performance in ultra-long-term forecasting tasks, outperforming existing methods.",
        "Provides a comprehensive evaluation against multiple baselines, offering a clear comparison of effectiveness."
      ],
      "weaknesses": [
        "Lacks detailed explanation of how the dataset size is calculated, which is crucial for understanding the scope of the experiments.",
        "Does not evaluate the model's performance when the pre-training step is removed, an important aspect of its overall effectiveness.",
        "Unclear details about the baselines used for comparison, including their parameter count and pre-training methods.",
        "Does not adequately address the design of experiments, which is critical for objectively situating the work within its field."
      ],
      "questions": [
        "How is the dataset size calculated, and what are the specific metrics used to determine the number of instances and their lengths?",
        "What is the impact of removing the pre-training step on TimelyGPT's performance, and how does it compare to the trained model?",
        "Could you provide detailed information on the baselines used in the ultra-long-term forecasting section, including their parameter counts and pre-training methodologies?",
        "How were the experiments designed to ensure objectivity and relevance to the field of irregular time-series modeling?"
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "2SuA42Mq1c",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a comprehensive benchmark for evaluating machine learning algorithms across five medical domains using a unified dataset. It highlights the importance of hyper‑parameter tuning and provides detailed results, though it lacks a complete matrix of hyper‑parameter settings and future expansion plans. The benchmark is valuable but could benefit from addressing hyper‑parameter exploration, dataset biases, and long‑term maintenance.",
      "strengths": [
        "Comprehensive benchmarking across multiple medical domains.",
        "Inclusion of systematic hyper‑parameter tuning.",
        "Clear reporting of results with a matrix for different settings."
      ],
      "weaknesses": [
        "Limited hyper‑parameter exploration beyond learning rate and threshold.",
        "Missing detailed matrix for each hyper‑parameter setting.",
        "Potential biases due to datasets primarily from advanced countries."
      ],
      "questions": [
        "Should the benchmark include additional hyper‑parameters beyond learning rate and threshold?",
        "What strategies can be employed to mitigate dataset biases from specific regions?",
        "How can the benchmark be updated and maintained over time to incorporate new algorithms and domains?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "2uHTuvDkLZ",
    "title": "Physics-aware Causal Graph Network for Spatiotemporal Modeling",
    "std_review": {
      "summary": "The paper introduces a physics-aware causal graph network designed for spatiotemporal modeling, combining graph neural networks with causal reasoning to enhance prediction accuracy and interpretability in climate applications. While the approach shows promise, it faces challenges such as handling ambiguous physics knowledge, noisy data, and limited extensibility beyond climate domains. The authors should address these issues and provide more comprehensive comparisons with existing methods to strengthen the case for acceptance.",
      "strengths": [
        "Integrates physics-based knowledge with machine learning to improve model performance in domains with physical constraints.",
        "Leverages graph neural networks to effectively model complex spatio-temporal relationships, particularly relevant for climate data.",
        "Incorporates causal reasoning to enhance model interpretability and trustworthiness for practical applications."
      ],
      "weaknesses": [
        "Performance under ambiguous or poorly defined physics knowledge is not thoroughly evaluated.",
        "Lack of detailed analysis on how the model handles noisy data.",
        "Limited demonstration of model extensibility to other domains.",
        "Missing comparison with state-of-the-art spatio-temporal GNN frameworks.",
        "Insufficient explanation of how causal relationships are integrated with real-world equations."
      ],
      "questions": [
        "How does the model perform when the prior physics knowledge is ambiguous or not well established?",
        "What mechanisms enable the model to handle noisy data effectively?",
        "Can you provide examples or case studies demonstrating the model's extensibility to other domains beyond climate applications?",
        "How does the proposed method compare with state-of-the-art spatio-temporal GNN frameworks?",
        "Please clarify how causal relationships are integrated with real-world equations within the proposed framework."
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "2UlfvGU6rL",
    "title": "Equivariant Graph Neural Operator",
    "std_review": {
      "summary": "The paper introduces a novel approach to modeling dynamic systems by incorporating a multiplicative state that interacts with input sequences. It proposes using a Discrete Fourier Transformation on a single time step to enable frequency domain analysis, improving accuracy in capturing periodic components. The model is evaluated on its ability to handle both single time-step inputs and sequences, and introduces an embedding of the time interval Δt to capture temporal dynamics. Overall, the paper presents an innovative method with clear strengths in flexibility and performance, though it has some limitations that could be addressed in future work.",
      "strengths": [
        "Innovative state multiplication enhances expressive power",
        "Efficient DFT implementation reduces computational complexity",
        "Flexibility with input types broadens applicability",
        "Temporal embedding of Δt improves performance in time series analysis"
      ],
      "weaknesses": [
        "Complexity of state multiplication may affect training and convergence",
        "Assumes stationarity, limiting applicability to non-stationary data",
        "Limited scalability for very large datasets",
        "Lacks robustness analysis to noise or outliers"
      ],
      "questions": [
        "How does the model handle non-stationary data?",
        "What strategies can be employed to improve robustness to noise and outliers?",
        "How does the model's performance scale with very large datasets?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "2UnCj3jeao",
    "title": "Unbalancedness in Neural Monge Maps",
    "std_review": {
      "summary": "The paper presents a novel neural approach to handle unbalancedness in Monge maps, showing improved efficiency and accuracy over existing methods. While innovative, the method introduces complexity and scalability concerns, and its broader applicability remains limited. Overall, the work is well-supported by theoretical insights and empirical evidence, leading to an acceptance recommendation.",
      "strengths": [
        "Introduces a unique method for incorporating unbalancedness into Monge maps.",
        "Provides thorough empirical evaluations demonstrating superior performance.",
        "Makes novel theoretical contributions, such as Proposition 3.1."
      ],
      "weaknesses": [
        "Focuses primarily on theoretical and empirical improvements within Monge maps.",
        "Increases model complexity with neural networks, potentially limiting accessibility.",
        "Scalability to large datasets or complex problems is not fully explored."
      ],
      "questions": [
        "How does the method perform on datasets with highly skewed distributions?",
        "What are the computational costs compared to simpler unbalancedness estimators?",
        "Can the framework be extended to other types of maps or optimization problems?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "2uwvigLUr8",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a novel approach to recommender systems by incorporating randomness into learned propensities and imputed errors, aiming to improve robustness and accuracy. The authors provide a solid theoretical framework and empirical evidence showing improved performance over deterministic models. While the theoretical proof could be more rigorous and the empirical evaluation could be more comprehensive, the proposed method demonstrates clear advantages.",
      "strengths": [
        "Introduces randomness in propensities and errors, offering a novel perspective on handling uncertainty.",
        "Provides a solid theoretical foundation for the benefits of the proposed approach.",
        "Demonstrates improved empirical performance over deterministic models."
      ],
      "weaknesses": [
        "Theoretical proof of Theorem 1 could be more rigorous and clearer.",
        "Empirical evaluation could be more comprehensive by including state-of-the-art models."
      ],
      "questions": [
        "Could the theoretical analysis be further strengthened by providing a more detailed proof of Theorem 1?",
        "How does the method perform in scenarios where the propensity and error terms are highly correlated?",
        "Would including state-of-the-art models in the empirical evaluation provide a more robust comparison?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "2V1Z0Jdmss",
    "title": "On the Over-Memorization During",
    "std_review": {
      "summary": "The paper introduces Data-Oblivious Augmentation (DOM) to improve model robustness against noise, outliers, and contamination by generating transformation-invariant augmentation patterns. DOMDA adapts the loss threshold dynamically, offering flexibility but at a potential computational cost. Experiments on CIFAR-10 show improvements, yet scalability and generalizability to larger datasets remain unproven.",
      "strengths": [
        "Introduces a novel approach to data augmentation focusing on invariance to transformations.",
        "DOMDA provides a flexible solution with dynamic threshold adaptation.",
        "Clear distinction between natural and transformed patterns aids in understanding augmentation impact."
      ],
      "weaknesses": [
        "Fixed loss threshold may limit generalizability across datasets and loss functions.",
        "Additional computational cost of DOMDA could be prohibitive for some applications.",
        "Abstract definition of patterns may lead to ambiguity in results interpretation.",
        "Limited testing on larger datasets like Tiny-ImageNet and ImageNet."
      ],
      "questions": [
        "How does the fixed loss threshold impact performance on diverse datasets?",
        "What are the computational trade-offs of DOMDA compared to traditional augmentation methods?",
        "How can the abstract definition of patterns be made more concrete for future evaluation?",
        "What larger-scale dataset experiments are needed to validate scalability and robustness?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "2VAi5F9BOJ",
    "title": "PLPP: Prompt Learning with Perplexity for Vision-Language Models",
    "std_review": {
      "summary": "The paper introduces PLPP, a method that enhances prompt readability in vision-language models by penalizing perplexity during optimization. Experiments show significant improvements in prompt interpretability without compromising model performance, as demonstrated on the CoOp benchmark. While innovative and impactful, the method's sensitivity to hyperparameters and limited scope suggest areas for further exploration.",
      "strengths": [
        "Innovative approach to optimizing prompts by penalizing perplexity.",
        "Demonstrates tangible improvements in prompt readability.",
        "Provides a clear theoretical foundation linking perplexity minimization to model performance and human comprehension.",
        "Empirical validation across multiple datasets and tasks supports the method's effectiveness."
      ],
      "weaknesses": [
        "Performance may be sensitive to hyperparameter choices, particularly the weight of the perplexity term.",
        "Evaluation is primarily focused on the CoOp benchmark, which may limit the method's generalizability.",
        "Risk of overfitting to training data could affect generalizability.",
        "Lacks direct human evaluation to assess actual readability and interpretability improvements."
      ],
      "questions": [
        "How robust is PLPP to variations in the choice of language model and embedding layer?",
        "What strategies can be employed to mitigate the risk of overfitting to specific training data?",
        "How can human evaluation be incorporated to better assess the method's impact on prompt readability?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "2wFXD2upSQ",
    "title": "A Demon at Work: Leveraging Neuron Death",
    "std_review": {
      "summary": "The paper introduces Dynamic Pruning (DemP), a method that leverages the concept of 'dead neurons' in convolutional layers to guide weight pruning during training. By modeling weight dynamics with an absorbing Brownian motion, DemP identifies and prunes unresponsive filters, achieving significant speedups without accuracy loss. The approach is evaluated on image classification tasks, showing strong performance compared to existing pruning methods. While the theoretical framework is solid and the empirical results are compelling, some aspects, such as baseline comparison and hyperparameter analysis, require further clarification.",
      "strengths": [
        "Innovative pruning approach using dead neurons",
        "Significant training speedup on large models",
        "Theoretical foundation for dynamic pruning",
        "Broad applicability to various architectures"
      ],
      "weaknesses": [
        "Unclear comparison with unstructured pruning baselines",
        "Ambiguity in distinguishing dynamic pruning from other sparse methods",
        "Lack of thorough hyperparameter sensitivity analysis",
        "Insufficient empirical validation of pruning permanence"
      ],
      "questions": [
        "Clarify the exact regularization schedule used for unstructured pruning baselines in Table 1.",
        "Provide concrete speedup results for larger models like ResNet-50.",
        "Investigate the impact of hyperparameter choices on model accuracy after pruning.",
        "Explore the effectiveness of DemP on modern architectures such as Vision Transformers.",
        "Include quantitative measures to confirm the permanence of pruned neurons."
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "2wwPG1wpsu",
    "title": "LST-Bench:A Benchmark for long sequence time-series forecasting Task",
    "std_review": {
      "summary": "The paper introduces LST-Bench, a benchmark for long sequence time-series forecasting in the electricity industry. It evaluates various model architectures and highlights the issue of model degeneracy, where low MSE predictions are achieved at the cost of meaningful patterns. While the benchmark is valuable for industry relevance and provides insightful observations, it lacks comprehensive generalization evaluation, robust hyper-parameter analysis, and deeper theoretical insights.",
      "strengths": [
        "Comprehensive benchmark setup with diverse model architectures and datasets.",
        "Clear focus on industry relevance, particularly the electricity domain.",
        "Innovative observations on model degeneracy and its implications."
      ],
      "weaknesses": [
        "Limited generalization evaluation across different domains and time series characteristics.",
        "Insufficient hyper-parameter robustness analysis.",
        "Lack of theoretical underpinnings explaining model degeneracy and convergence."
      ],
      "questions": [
        "How can the benchmark be extended to evaluate model generalization across diverse domains and time series characteristics?",
        "What systematic hyper-parameter tuning methods should be employed to ensure robustness of results?",
        "What theoretical insights can be provided to explain the causes of model degeneracy and rapid convergence?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "2XBBumBGeP",
    "title": "srgb Real Noise Modeling via Noise-Aware Sampling with Normalizing Flows",
    "std_review": {
      "summary": "The paper introduces NAFlow, a deep learning framework for non-far-field image denoising that effectively handles speckle noise and low SNR through a Noise‑Aware Sampling module and multi‑scale modeling. Extensive experiments on the SIDD dataset and additional datasets across various devices demonstrate significant performance gains over existing methods, highlighting NAFlow's strong generalizability. While noting some complexity and parameter sensitivity, the review concludes with a strong acceptance of the work.",
      "strengths": [
        "Improved noise handling through a Noise‑Aware Sampling module that learns to distinguish noise from true image features.",
        "Multi‑scale modeling captures both coarse and fine image details, enhancing overall image quality and robustness.",
        "Demonstrated effectiveness across multiple datasets and device types, indicating strong generalization capabilities."
      ],
      "weaknesses": [
        "The multi‑scale architecture may introduce computational complexity, potentially impacting real‑time performance.",
        "Performance could be sensitive to hyperparameter tuning, requiring extensive experimentation.",
        "Impact on other imaging modalities beyond non‑far‑field images may be less pronounced without further validation."
      ],
      "questions": [
        "How does NAFlow perform on real‑world non‑far‑field images captured under extreme lighting conditions?",
        "What are the computational resource requirements for deploying NAFlow in real‑time applications?",
        "Can NAFlow be adapted to improve denoising performance for other types of non‑far‑field images beyond those in the SIDD dataset?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "2XkTz7gdpc",
    "title": "Efficient and Scalable Graph Generation",
    "std_review": {
      "summary": "The paper presents a novel graph generative model that efficiently scales to large graphs by combining an iterative expansion process with spectral conditioning. It outperforms existing scalable baselines in both performance and scalability, while ensuring the validity and uniqueness of generated graphs. The model addresses key challenges in graph generation and demonstrates strong empirical results, though some interpretability and domain-specific evaluation concerns remain.",
      "strengths": [
        "Introduces a novel iterative expansion process for efficient large-scale graph generation.",
        "Leverages spectral conditioning to improve generated graph quality and control structure.",
        "Demonstrates superior performance and scalability compared to current baselines.",
        "Provides comprehensive ablations to evaluate model components.",
        "Addresses scalability challenges more effectively than one-shot generative models."
      ],
      "weaknesses": [
        "The spectral conditioning process may reduce model interpretability.",
        "Effectiveness on specific graph domains or types has not been fully explored.",
        "Ablations do not cover all possible variations, limiting understanding of model robustness."
      ],
      "questions": [
        "How can the interpretability of the spectral conditioning process be improved?",
        "What are the potential limitations of the model on specific graph domains, and how can they be addressed?",
        "Could additional ablations be performed to better assess the model's robustness across different variations?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "2XwBIcywWM",
    "title": "Learning Variational Neighbor Labels for",
    "std_review": {
      "summary": "The paper introduces a novel meta‑generalization framework for domain adaptation that does not require labeled target domain data. It leverages a meta‑learning paradigm to balance source and target domain losses, achieving strong empirical gains on Office‑Home and VisDA benchmarks compared to existing source‑free methods. While the theoretical foundation and flexibility are strong, concerns about performance on Office‑Home, hyper‑parameter complexity, and the lack of single‑source validation reduce confidence in the method.",
      "strengths": [
        "Innovative meta‑generalization framework for domain adaptation without target labels.",
        "Clear theoretical motivation for the meta‑loss formulation.",
        "Demonstrated substantial performance gains on challenging domain adaptation datasets."
      ],
      "weaknesses": [
        "Underperforms on Office‑Home compared to baseline results.",
        "Complexity of hyper‑parameter tuning may affect reproducibility.",
        "Supplementary code is non‑executable, hindering immediate validation.",
        "Lack of experiments in single‑source domain generalization settings."
      ],
      "questions": [
        "How does the method perform on other challenging domain adaptation benchmarks beyond Office‑Home and VisDA?",
        "What is the impact of the hyper‑parameter λ₁, λ₂, λ₃, and n on model stability and reproducibility?",
        "Could the method be adapted to single‑source domain generalization scenarios?",
        "What additional theoretical guarantees can be provided for the meta‑loss formulation?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "2Y5Gseybzp",
    "title": "",
    "std_review": {
      "summary": "The paper presents a novel framework for weakly supervised learning that handles three types of imprecise annotations (Precise, Semi‑Precise, and Noisy Labels) using variational inference. It derives loss functions for each scenario and integrates ground‑truth labels as latent variables, showing improved performance on image classification tasks. While innovative, the framework has some limitations in terms of mathematical complexity, novelty, and scalability.",
      "strengths": [
        "Innovative loss function derivation for three imprecise annotation scenarios",
        "Flexible integration of ground‑truth labels as latent variables",
        "Empirical performance improvements over existing methods"
      ],
      "weaknesses": [
        "Complex mathematical derivations may limit accessibility",
        "Builds on prior work with limited unique contributions",
        "No discussion on mitigating local optima in EM optimization",
        "Computational complexity not thoroughly addressed",
        "Limited exploration of applicability beyond three label types"
      ],
      "questions": [
        "Should the derivations of the loss functions be expanded for clarity?",
        "What strategies are used to mitigate local optima issues during EM optimization?",
        "How does the computational complexity scale with large datasets or complex label configurations?",
        "Can the framework be extended to more complex learning scenarios like multi‑label or multiple instance learning?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "2Y5kBPtU0o",
    "title": "Mera dEmonstrationN Distillation for Efficient and Effective In-Context Learning",
    "std_review": {
      "summary": "The paper introduces MEND, a two-stage training method for large language models that uses demonstration examples to guide distillation. It shows strong performance on benchmarks while maintaining in-context learning capabilities and introducing minimal computational overhead. The reviewer finds the method innovative, efficient, and effective, recommending acceptance.",
      "strengths": [
        "Introduces a novel two-stage training approach that enhances LLMs with demonstration data.",
        "Provides controlled distillation via a λ parameter, balancing guidance and model flexibility.",
        "Demonstrates strong performance across benchmarks while preserving in-context learning.",
        "Introduces minimal additional computational overhead compared to existing methods."
      ],
      "weaknesses": [
        "Hyperparameter sensitivity, particularly with λ and the number of demonstrations.",
        "Assumes a specific format for demonstration examples, limiting applicability.",
        "Evaluation focuses on a limited set of benchmarks, potentially overlooking broader performance."
      ],
      "questions": [
        "How robust is MEND to variations in demonstration formatting across different datasets?",
        "Can the method be extended to handle demonstration examples with diverse structures?",
        "What is the impact of MEND on the interpretability of LLMs compared to baseline methods?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "2y8XnaIiB8",
    "title": "Vision-Language Dataset Distillation",
    "std_review": {
      "summary": "The paper presents a novel vision-language dataset distillation method that creates compact datasets while preserving retrieval capabilities. It leverages bi-trajectories of image and text embeddings to align expert and student models, achieving significant performance improvements over baselines in retrieval tasks. The method is efficient, reducing computational costs, but its evaluation is limited to retrieval, and it lacks robustness analysis and detailed computational cost metrics.",
      "strengths": [
        "Innovative bi-trajectory distillation technique",
        "Demonstrated substantial performance gains in retrieval tasks",
        "Significant reductions in computational requirements"
      ],
      "weaknesses": [
        "Evaluation limited to retrieval tasks",
        "No comprehensive baseline comparison",
        "Lack of robustness analysis across model architectures",
        "Missing specific computational cost metrics"
      ],
      "questions": [
        "How does the method perform on other vision-language tasks beyond retrieval?",
        "What is the robustness of the distilled datasets across different model architectures?",
        "Could you provide specific metrics for computational savings?",
        "Are there qualitative analyses of how visual changes affect performance?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "2zoi9YI21Y",
    "title": "",
    "std_review": {
      "summary": "The paper presents a novel zero-shot purification framework for adversarial examples called Iterative Natural-Manifold Purification (INMP). It combines a coarse blur operation to project adversarial samples onto the natural image manifold with an iterative refinement step to further reduce perturbations. Experiments show significant robustness gains over existing zero-shot methods with low computational overhead, indicating practical utility. While promising, the method lacks theoretical guarantees and has some domain‑specific validation, suggesting areas for future work.",
      "strengths": [
        "Introduces a data‑agnostic zero‑shot purification method that is broadly applicable.",
        "Effectively projects adversarial samples onto the natural image manifold using a simple blur operation.",
        "Iterative refinement step systematically reduces perturbations with modest computational cost.",
        "Demonstrates strong empirical performance gains over existing zero‑shot techniques."
      ],
      "weaknesses": [
        "Lacks formal theoretical analysis or convergence guarantees for the iterative refinement.",
        "Potential trade‑off between robustness gains and clean accuracy is not fully quantified.",
        "Effectiveness is primarily validated on image data, raising questions about generalizability.",
        "Exact computational overhead relative to state‑of‑the‑art methods is not quantitatively compared."
      ],
      "questions": [
        "What are the theoretical guarantees for the convergence of the iterative refinement step?",
        "How does the method perform under strong adaptive attacks beyond the evaluated test‑time defenses?",
        "What is the impact of the blur strength and number of refinement iterations on clean accuracy?",
        "How can the method be adapted to other domains beyond image classification?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "30aSE3FB3L",
    "title": "",
    "std_review": {
      "summary": "The paper introduces SPD and Grassmann manifold neural networks using gyrovector spaces, offering a novel and potentially more interpretable and efficient approach for deep learning on non-Euclidean manifolds. It demonstrates significant performance improvements on matrix data tasks compared to Euclidean baselines, validating the method's effectiveness. While the approach is limited to gyrovector spaces and may introduce implementation complexity, its theoretical advantages and strong empirical results justify its acceptance.",
      "strengths": [
        "Introduces a novel approach to deep learning on non-Euclidean manifolds using gyrovector spaces.",
        "Demonstrates strong empirical performance improvements on matrix data tasks.",
        "Offers a more interpretable framework compared to existing manifold network methods."
      ],
      "weaknesses": [
        "Applicability is limited to SPD and Grassmann manifolds defined as gyrovector spaces.",
        "Implementation complexity may be higher due to the use of gyrovector spaces.",
        "Lacks strong theoretical guarantees for convergence or generalization."
      ],
      "questions": [
        "How can the method be extended to other types of non-Euclidean manifolds beyond gyrovector spaces?",
        "What are the theoretical guarantees for convergence and generalization of the proposed models?",
        "How does the proposed approach compare to other state-of-the-art manifold learning methods in a more comprehensive benchmark?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "30L0rr9W8A",
    "title": "LatentCBF: A Control Barrier Function in Latent Space for Safe Control",
    "std_review": {
      "summary": "The paper presents LatentCBF, a method for learning safe control policies by applying a control barrier function (CBF) in a learned latent space. It encodes a safe set from the original state space into the latent space and jointly trains an encoder and dynamics model, followed by policy learning that respects the learned CBF. The approach is evaluated on both simulated and real-world robotic tasks, showing improved safety compared to baselines. Overall, the paper is well‑structured, with clear contributions and strong empirical evidence, leading to an acceptance recommendation.",
      "strengths": [
        "Novel integration of CBFs with learned latent representations.",
        "Ability to handle high-dimensional and complex state spaces efficiently.",
        "Joint training of encoder and dynamics model ensures consistent representations.",
        "Comprehensive evaluation on simulated and real-world tasks."
      ],
      "weaknesses": [
        "Additional complexity and potential instability introduced by learning the barrier function.",
        "Assumption that the encoder accurately maps the safe set to the latent space.",
        "Reliance on learned dynamics may limit generalization.",
        "Verification process may not capture all unsafe trajectories in complex environments."
      ],
      "questions": [
        "How robust is the method to variations in the quality of the learned dynamics model?",
        "Can the approach be extended to handle systems with non‑convex safe sets?",
        "What are the computational costs of jointly training the encoder and dynamics model?",
        "How does the method perform when safety constraints are highly dynamic or time‑varying?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "30N3bNAiw3",
    "title": "Separating common from salient patterns with Contrastive Representation Learning",
    "std_review": {
      "summary": "SepCLR introduces a contrastive learning framework that effectively separates common and salient patterns in multi-modal data. The approach leverages a novel InfoMax objective and k-JEM regularization to enhance pattern separation, with strong empirical results across various datasets and tasks. While the framework shows promise, its complexity and limited analysis of hyperparameter impact and scalability are noted as areas for improvement.",
      "strengths": [
        "Proposes a novel theoretical framework for separating common and salient patterns using contrastive learning.",
        "Introduces a unique InfoMax objective that effectively estimates mutual information between common and salient factors.",
        "Demonstrates strong empirical results across multiple datasets and tasks, outperforming baselines."
      ],
      "weaknesses": [
        "The complexity of the proposed framework may make it challenging to implement and optimize.",
        "The effectiveness of SepCLR could be limited to specific types of multi-modal data or tasks.",
        "Lacks detailed analysis of the impact of hyperparameters on performance.",
        "Scalability to large-scale datasets or high-dimensional data is not thoroughly explored."
      ],
      "questions": [
        "How does SepCLR perform on more diverse datasets beyond those evaluated in the paper?",
        "What are the optimal hyperparameter settings for SepCLR, and how do they vary across different tasks?",
        "How does SepCLR scale to very large datasets or high-dimensional data?",
        "Can SepCLR be extended to other types of multi-modal data beyond images and text?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "31IOmrnoP4",
    "title": "",
    "std_review": {
      "summary": "The paper introduces Repelling Random Walks (RRW), an algorithm that prevents revisiting nodes in random walks to improve variance reduction and convergence in graph sampling and Monte Carlo methods. Theoretical analysis and empirical evaluations across tasks like PageRank estimation, graphlet detection, and kernel approximation show significant improvements over existing methods. While the approach has some limitations related to assumptions and implementation details, it demonstrates strong potential and is recommended for acceptance.",
      "strengths": [
        "Innovative mechanism to prevent node revisits in random walks",
        "Strong theoretical guarantees with formal proofs",
        "Empirical validation showing substantial performance gains across multiple graph tasks"
      ],
      "weaknesses": [
        "Theoretical analysis relies on assumptions about graph structure and distribution",
        "Potential computational overhead from ensuring node uniqueness",
        "Limited comparison with the latest graph-specific sampling techniques",
        "Lack of detailed guidance on parameter tuning and handling edge cases"
      ],
      "questions": [
        "How does the algorithm perform on disconnected or incoherently distributed graphs?",
        "What are the practical guidelines for tuning parameters in real-world applications?",
        "How does RRW compare to the most recent graph sampling methods in terms of scalability?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "324zEJCo3a",
    "title": "Local Vs. Global Interpretability:",
    "std_review": {
      "summary": "The paper presents a theoretical framework for characterizing global sufficient reasons in model interpretability, defining global subset‑minimal and cardinality‑minimal sufficient reasons and showing they coincide. It highlights the interpretability differences between linear classifiers and decision trees, and discusses the computational complexity of achieving global explanations. The work contributes a clear definition, a unified characterization, and insights into model interpretability, though some results may be seen as straightforward.",
      "strengths": [
        "Provides a clear and rigorous definition of global sufficient reasons.",
        "Offers a unified characterization of the minimal global sufficient reason.",
        "Clearly distinguishes interpretability properties of linear classifiers and decision trees."
      ],
      "weaknesses": [
        "Some propositions may be viewed as straightforward consequences of definitions.",
        "The distinction between local and global interpretability could be more explicitly motivated.",
        "Practical implications of theoretical results are not fully explored."
      ],
      "questions": [
        "Could the distinction between local and global interpretability be more explicitly motivated?",
        "How do the theoretical results inform the design and evaluation of interpretable models?",
        "What is the impact of the relaxed notion of global explainability on practical applicability?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "327tbF3S65",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a method for 3D shape representation using an occupancy function processed by a 2D CNN, aiming to generate new shapes from a 2D latent space via a VAE. While demonstrating competitive results on benchmark datasets, the approach lacks clear justification for using occupancy functions over SDFs, has a non-standard projection of sparse point clouds, and does not compare against other latent space models or thoroughly investigate the impact of latent space dimension.",
      "strengths": [
        "Introduces a novel way to represent 3D shapes using an occupancy function.",
        "Demonstrates effectiveness on benchmark datasets with competitive results.",
        "Provides a clear and well-structured methodology."
      ],
      "weaknesses": [
        "The choice of occupancy function over SDFs is not well justified.",
        "Projection of sparse point clouds onto a 2D CNN is not a standard approach.",
        "Lacks comparison with other powerful latent space models.",
        "Does not thoroughly investigate the impact of latent space dimension."
      ],
      "questions": [
        "Why use the occupancy function to represent a 3D shape instead of the SDF?",
        "How is the projection of sparse point clouds onto a 2D CNN performed?",
        "Will the code be publicly available?",
        "Did you compare the proposed method with other powerful latent space models?",
        "What is the dimension of the latent space z, and how does it affect performance?"
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "32camXjW25",
    "title": "Covariance-corrected Whitening Alleviates Network Degeneration on Imbalanced Classification",
    "std_review": {
      "summary": "The paper proposes Group‑Aware Resampling (GRBS), a heuristic‑based sampling method that dynamically adjusts sampling rates using a Bayesian Expectation‑Threshold (BET) approach to address class imbalance. While it introduces a novel way to control minority class sampling and provides a qualitative discussion on the impact of correlated features, the method lacks a rigorous theoretical foundation and its experimental results are inferior to state‑of‑the‑art baselines. The authors should focus on providing a more thorough theoretical motivation and a broader experimental evaluation.",
      "strengths": [
        "Introduces a heuristic‑based sampling method that dynamically adjusts sampling rates based on a Bayesian Expectation‑Threshold, offering a flexible alternative to fixed sampling rates.",
        "Provides a thorough qualitative discussion on the impact of highly correlated features on model performance, supported by clear visualizations.",
        "Extends existing work on class imbalance by incorporating feature covariance and normalization considerations, offering a comprehensive approach."
      ],
      "weaknesses": [
        "Lacks a detailed theoretical analysis or motivation for the sampling strategy.",
        "The qualitative discussion on why highly correlated features degrade performance is superficial.",
        "Reported results are inferior to current baselines, raising questions about practical competitiveness.",
        "Ambiguity in comparing training losses across different sampling strategies due to dataset variability."
      ],
      "questions": [
        "Can you provide a more detailed theoretical analysis or motivation for the Group‑Aware Resampling (GRBS) approach?",
        "Could you elaborate on why highly correlated features degrade model performance and clarify the SVD results in Figure 2?",
        "Would comparing the method against more recent state‑of‑the‑art baselines (e.g., ResNet‑50, EfficientNet‑B0) strengthen the experimental evaluation?",
        "Is it possible to address the ambiguity in comparing training losses by standardizing the training datasets across different sampling strategies?"
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "33XGfHLtZg",
    "title": "",
    "std_review": {
      "summary": "The paper presents a conformal risk control method using bounded loss functions, offering worst-case guarantees and theoretical analysis. While the approach is theoretically sound and addresses practical scenarios, the review highlights several areas for improvement, such as clearer exposition of the method's novelty and computational feasibility. The overall recommendation is to accept the paper.",
      "strengths": [
        "Introduces a novel conformal risk control method leveraging bounded loss functions.",
        "Provides worst-case guarantees, stronger than traditional high-probability guarantees.",
        "Offers a clear theoretical analysis and conditions for the method's validity."
      ],
      "weaknesses": [
        "The intuitive explanation in Section 1.1 is unintuitive and may hinder understanding.",
        "The computation of the optimal threshold λ^ is not explicitly detailed.",
        "The paper lacks motivating examples and clear articulation of practical differences over existing methods."
      ],
      "questions": [
        "Can you provide more intuitive examples to illustrate the use of bounded loss functions?",
        "How is the computational feasibility of λ^ justified, especially given the monotonicity of the loss?",
        "Could you clarify the differences and advantages of the proposed method over existing conformal risk control works?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "34STseLBrQ",
    "title": "Polynomial Width is Sufficient for Set Representation with High-dimensional Features",
    "std_review": {
      "summary": "The paper introduces a novel theoretical framework for permutation‑invariant DeepSets that extends to arbitrary feature dimensions, proving polynomial embedding dimensions through power mapping and exponential activation functions. It resolves the invertibility of sum‑pooling, providing a clear pathway to efficiently represent set functions. Empirical results support the theory, though the paper notes computational complexity and limited empirical scope. Overall, the work advances understanding of DeepSets and suggests future research directions.",
      "strengths": [
        "Generalizes permutation‑invariant DeepSets to higher dimensions beyond D=1.",
        "Introduces concrete constructions (power mapping, exponential activation) that achieve polynomial embedding dimensions.",
        "Proves invertibility of sum‑pooling, addressing a key challenge for representing permutation‑invariant functions.",
        "Provides geometric intuition and visual aids to clarify theoretical results."
      ],
      "weaknesses": [
        "The proposed constructions may introduce computational complexity in practice.",
        "Theoretical results rely on specific input assumptions that may not hold in all scenarios.",
        "Empirical validation is based on a limited set of experiments.",
        "Several open questions remain, particularly regarding smoothness and hierarchical extensions."
      ],
      "questions": [
        "How can the computational complexity of the proposed constructions be mitigated for practical implementations?",
        "What are the broader implications of the input assumptions on the general applicability of the results?",
        "How can the empirical validation be expanded to cover a wider range of set inputs?",
        "What further research is needed to address the open questions on smoothness and hierarchical extensions?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "36L7W3ri4U",
    "title": "Beating Price of Anarchy and Gradient Descent without Regret in Potential Games",
    "std_review": {
      "summary": "The paper introduces PRPGs and rigorously analyzes q-replicator dynamics, showing that in 2×2 PRPGs, gradient descent achieves a higher average price of anarchy than replicator dynamics under certain initial conditions. Numerical simulations support these findings in higher-dimensional games. While the results are valuable, they are limited to a specific class of games and could benefit from broader applicability and exploration of alternative initializations.",
      "strengths": [
        "Introduces a novel class of games (PRPGs) that encompass most finite potential games.",
        "Provides a clear and rigorous mathematical analysis of convergence properties.",
        "Employs numerical simulations to validate theoretical results."
      ],
      "weaknesses": [
        "Results are primarily focused on 2×2 PRPGs and higher-dimensional extensions.",
        "Does not explore alternative initialization strategies beyond random initialization.",
        "Lacks detailed discussion on practical implications for real-world applications."
      ],
      "questions": [
        "How do the results generalize to more complex game structures beyond 2×2 PRPGs?",
        "What are the implications of the findings for real-world multi-agent systems?",
        "Could alternative initialization strategies beyond random initialization provide additional insights?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "381QSrWdF2",
    "title": "Law of Balance and Stationary Distribution of Stochastic Gradient Descent",
    "std_review": {
      "summary": "The paper introduces a novel 'law of balance' to analyze SGD dynamics under symmetry, deriving a stationary distribution for diagonal linear networks and exploring phase transitions, loss of ergodicity, and fluctuation inversion. It extends findings to nonlinear networks, highlighting the role of regularization and parameter degeneracy. While theoretically significant, the results are limited to specific model assumptions. Overall, the paper is well‑received for its theoretical contributions and potential impact on understanding SGD behavior.",
      "strengths": [
        "Introduces a novel theoretical framework (law of balance) to analyze SGD dynamics under symmetry, offering a fresh perspective on parameter behavior.",
        "Derives a stationary distribution for SGD in diagonal linear networks, providing a rigorous mathematical foundation for understanding SGD's long-term behavior.",
        "Observes and explains key phenomena such as phase transitions, loss of ergodicity, and fluctuation inversion, which are crucial for understanding SGD's performance in different network depths."
      ],
      "weaknesses": [
        "The model's reliance on diagonal linear networks may limit the generalizability of the results to more complex, nonlinear architectures commonly used in practice.",
        "The theoretical analysis does not fully account for the effects of regularization beyond L2, which is a common practice in machine learning.",
        "The degeneracy of covariance matrices, while theoretically justified, may not fully capture the practical behavior of SGD in real-world scenarios with more complex loss landscapes."
      ],
      "questions": [
        "How do the findings generalize to more complex, nonlinear network architectures beyond diagonal linear networks?",
        "What is the impact of different regularization techniques (beyond L2) on the phase transitions and ergodicity observed in the analysis?",
        "How can the theoretical insights be extended to capture the effects of parameter degeneracy in practical deep learning scenarios?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "38E4yUbrgr",
    "title": "Language Model Self-improvement by Reinforcement Learning Contemplation",
    "std_review": {
      "summary": "The paper introduces Reinforcement Learning Contemplation (RLC), a method that uses language models' own generated outputs as feedback for self-improvement. RLC is evaluated on CommonGen, BigBench-Hard reasoning tasks, and CNN-Daily Mail summarization, showing significant improvements over baselines. While the approach is simple and general, its novelty is limited by the well-explored idea of self-feedback, and its scalability with larger models remains unproven. The paper is generally well-received, with strong empirical results across challenging tasks.",
      "strengths": [
        "The method is simple and general, applicable to various language model architectures.",
        "RLC improves language models without requiring external supervision, making it more efficient.",
        "Empirical results demonstrate substantial gains on challenging tasks, validating the approach's effectiveness."
      ],
      "weaknesses": [
        "The novelty of RLC may be limited due to the well-explored idea of using self-generated outputs for feedback.",
        "The effectiveness of RLC with larger models remains unproven, potentially limiting its scalability.",
        "The paper lacks a discussion on the differences between encoder-decoder and decoder-only models, which could impact the approach's applicability."
      ],
      "questions": [
        "How does RLC perform with decoder-only models?",
        "What is the impact of using non-PPO trained models in RLC?",
        "What is the statistical significance of the gains observed with RLC compared to baselines?",
        "How does RLC differ from existing approaches like RLAIF?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "39cPKijBed",
    "title": "Training Unbiased Diffusion Models From",
    "std_review": {
      "summary": "The paper presents a novel approach to improve temporal coherence in diffusion models by incorporating a time-dependent discriminator. The method shows promising results in empirical evaluations, achieving significant improvements in temporal consistency metrics. However, concerns remain regarding its generalizability, computational complexity, and lack of thorough comparison with related works.",
      "strengths": [
        "Innovative approach to enhance temporal coherence in diffusion models.",
        "Empirical validation through thorough visual and quantitative evaluations.",
        "Clear and well-defined contribution focusing on a critical aspect of diffusion model applications."
      ],
      "weaknesses": [
        "Limited generalizability to other model types or datasets.",
        "Potential increase in computational complexity.",
        "Absence of detailed analysis on overfitting concerns.",
        "Lack of benchmarking against related works like 'Fair Diffusion'."
      ],
      "questions": [
        "How does the method perform on a broader range of datasets beyond those tested?",
        "What strategies can be employed to mitigate overfitting and ensure generalization?",
        "How does the computational cost of the time-dependent discriminator compare to traditional discriminators?",
        "Could you provide a comparative analysis with 'Fair Diffusion' to better assess the method's relative advantages?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "39HaKNXpsu",
    "title": "Adapt and Diffuse: Sample-Adaptive Reconstruction via Latent Diffusion Models",
    "std_review": {
      "summary": "The paper introduces a severity encoding framework for estimating degradation severity in image restoration, specifically Gaussian blur, and integrates it into an adaptive diffusion model called Flash-Flash. The approach outperforms existing methods on Gaussian blur benchmarks, achieving higher fidelity and faster inference. While innovative, the paper has some limitations, such as limited hyper-parameter analysis and evaluation scope.",
      "strengths": [
        "Introduces a novel severity encoding framework for degradation severity estimation.",
        "Develops an adaptive diffusion model (Flash-Flash) that leverages severity estimates for efficient image restoration.",
        "Demonstrates superior empirical performance compared to state-of-the-art methods on Gaussian blur benchmarks."
      ],
      "weaknesses": [
        "Does not thoroughly investigate hyper-parameter sensitivity across datasets.",
        "Lacks a comprehensive comparison with non-diffusion restoration methods.",
        "Evaluation is primarily focused on Gaussian blur, limiting assessment of model capabilities for other degradations."
      ],
      "questions": [
        "How robust is the model to hyper-parameter sensitivity across different datasets?",
        "What is the impact of the severity encoding framework on performance for non-Gaussian degradations?",
        "How does Flash-Flash compare to traditional restoration algorithms in terms of efficiency and quality?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3a505tMjGE",
    "title": "AVOID: Alleviating VAE's Overestimation in Unsupervised OOD Detection",
    "std_review": {
      "summary": "The paper proposes PHP, a two-stage method to improve unsupervised OOD detection in VAEs by correcting posterior-prior mismatch and adjusting small OOD entropies. Experiments show significant performance gains over existing methods, but limitations include reliance on specific architectures and lack of evaluation on complex models or ablation studies.",
      "strengths": [
        "Introduces a novel two-stage PHP method to address VAE OOD detection overestimation.",
        "Effectively corrects posterior-prior mismatch and improves OOD detection.",
        "Uses a complexity measure in DEC to enhance performance on small OOD entropies.",
        "Demonstrates superior results on benchmark datasets compared to current approaches."
      ],
      "weaknesses": [
        "Effectiveness may be limited to simpler datasets and VAE architectures.",
        "Computational efficiency not evaluated, which could impact large-scale use.",
        "Lacks a thorough ablation study to isolate contributions of PHP and DEC."
      ],
      "questions": [
        "How does the method perform on more complex generative models beyond standard VAEs?",
        "What is the computational cost of the PHP and DEC components?",
        "Could the ablation study clarify the individual impact of PHP and DEC?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3ARfhjGfdF",
    "title": "Towards Control-Centric Representations in Reinforcement Learning from Images",
    "std_review": {
      "summary": "The paper introduces ReBis, a method for learning control-centric representations in reinforcement learning from images using a bisimulation metric and a transformer-based dynamics model. It effectively addresses spatiotemporal redundancies and sparse rewards, achieving strong performance improvements on Atari and DeepMind control suite tasks. While the computational complexity of the transformer model and the need for further evaluation in complex environments are noted, the overall work is well-received and recommended for acceptance.",
      "strengths": [
        "Introduces a novel approach to learning control-centric representations using a bisimulation metric.",
        "Effectively addresses spatiotemporal redundancies and sparse rewards through innovative techniques.",
        "Demonstrates strong performance improvements over existing methods on benchmark tasks.",
        "Provides a clear theoretical foundation leveraging bisimulation metrics and related theorems."
      ],
      "weaknesses": [
        "The complexity of the transformer-based dynamics model may lead to high computational costs.",
        "Effectiveness in highly complex or dynamic environments with rapidly changing states and rewards is not fully explored.",
        "Ablation studies do not comprehensively evaluate robustness across a wide range of scenarios."
      ],
      "questions": [
        "How does ReBis perform in highly complex or dynamic environments with rapidly changing states and rewards?",
        "What are the computational implications of using the transformer-based dynamics model in resource-constrained settings?",
        "How does ReBis balance model complexity with performance, especially in scenarios with limited computational resources?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3aSbJhaVDi",
    "title": "Exploiting Open-World Data for Adaptive Continual Learning",
    "std_review": {
      "summary": "The paper presents a novel approach to continual semi-supervised learning (SSCL) that effectively mitigates catastrophic forgetting by dynamically incorporating unlabeled data across tasks. It is evaluated on several benchmark datasets, showing improved performance and reduced forgetting compared to existing baselines. While the method addresses a key challenge in continual learning, its reliance on large unlabeled datasets and specific hyperparameter settings are noted as potential limitations. Overall, the paper makes a valuable contribution to the field.",
      "strengths": [
        "Innovative approach to continual learning by leveraging unlabeled data.",
        "Dynamic incorporation of unlabeled data across tasks mitigates forgetting.",
        "Robust evaluation on multiple benchmark datasets demonstrates effectiveness."
      ],
      "weaknesses": [
        "Assumes large amounts of unlabeled data are always available and unaffected by task switching.",
        "Baseline comparison with the Independent baseline may not fully capture the method's benefits.",
        "Reliance on suggested hyperparameters could introduce bias."
      ],
      "questions": [
        "How does the method handle scenarios where unlabeled data becomes unavailable or its distribution shifts significantly with task changes?",
        "Could you provide more examples or case studies illustrating the practical relevance of the Open SSCL problem definition in real-world applications?",
        "What strategies are employed to manage the dynamics of the unlabeled dataset, especially when all samples are exhausted?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3aZCPl3ZvR",
    "title": "",
    "std_review": {
      "summary": "The paper introduces SAM, a novel regularization technique that modifies SGD by adding a Jacobian-based term to the loss function, aiming to improve robustness against label noise. The authors analyze SAM's effects across varying network widths, training sample sizes, and learning rates, showing empirical improvements over standard SGD and existing robust methods. While the findings are promising, they are limited to 2-layer linear networks, raising questions about generalizability to deeper architectures and scenarios without label noise.",
      "strengths": [
        "Innovative regularization technique leveraging Jacobian matrix.",
        "Provides theoretical insights into SAM's impact on model robustness.",
        "Conducts thorough empirical validation across different regimes."
      ],
      "weaknesses": [
        "Analysis limited to 2-layer linear networks, potentially limiting generalizability.",
        "Robustness gains are evaluated under the assumption of label noise.",
        "Risk of overfitting in over-parameterized models.",
        "Lacks detailed implementation guidance."
      ],
      "questions": [
        "How does SAM perform in deeper, nonlinear architectures beyond 2-layer linear networks?",
        "What is the impact of SAM on models trained without label noise?",
        "Can SAM be combined with other robust training methods additively?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3b8CgMO5ix",
    "title": "Model guidance via explanations turns image classifiers into segmentation models",
    "std_review": {
      "summary": "The paper introduces a novel approach to weakly-supervised semantic segmentation by establishing a formal equivalence between differentiable heatmap architectures and encoder-decoder segmentation networks. It proposes an unrolled layer-wise relevance propagation (LRP) mechanism to train heatmap layers, integrated with a combined classification and segmentation loss function. The method is evaluated for robustness under class imbalance and diverse object classes, showing competitive performance on Pascal VOC and CityScapes benchmarks, with ablation studies highlighting key contributions.",
      "strengths": [
        "Formal equivalence between heatmap and encoder-decoder architectures provides a strong theoretical foundation.",
        "Innovative unrolled LRP mechanism offers a novel way to train heatmap layers, potentially improving interpretability and performance.",
        "Comprehensive evaluation across multiple datasets and scenarios demonstrates robustness.",
        "Strong baselines and ablation studies effectively isolate and demonstrate the impact of various components."
      ],
      "weaknesses": [
        "Complexity of formal equivalence and mathematical derivations may be challenging for readers without a strong ML background.",
        "Unrolled LRP mechanism could introduce significant computational overhead, limiting applicability in resource-constrained environments.",
        "Limited dataset evaluation; additional experiments could further validate generalizability.",
        "Interpretability trade-offs due to the complexity of the unrolled LRP.",
        "Code and reproducibility guidelines are not explicitly mentioned, which could hinder further research."
      ],
      "questions": [
        "How can the computational cost of the unrolled LRP mechanism be reduced for practical deployment?",
        "What are the specific interpretability benefits of the proposed approach compared to existing methods?",
        "Could the method be extended to other domains beyond image segmentation, such as video or 3D data?",
        "Are there any theoretical guarantees on the convergence of the unrolled LRP training process?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3bmjHYX42n",
    "title": "Leveraging Human Revisions for Improving Text-to-Layout Models",
    "std_review": {
      "summary": "The paper introduces a novel dataset of 10,000 images across 50 categories and studies the impact of human-designed edits on machine learning model performance. The authors' systematic analysis reveals significant improvements in model accuracy when incorporating these edits, suggesting potential benefits for model robustness and interpretability. While the dataset is substantial, it may still be limited in capturing real-world scenarios, and the study does not fully explore ethical considerations or the impact of different edit types. Overall, the findings are promising and warrant further investigation.",
      "strengths": [
        "Introduces a novel dataset of 10,000 images across 50 categories.",
        "Provides a systematic approach to analyzing human-designed edits.",
        "Demonstrates significant improvements in model performance with human edits.",
        "Contributes to the field by exploring human interventions in machine learning."
      ],
      "weaknesses": [
        "Dataset size may limit generalizability to real-world scenarios.",
        "Focus on specific categories and images may limit scope.",
        "Lacks detailed analysis of specific edit types.",
        "Does not address ethical considerations or IRB approval."
      ],
      "questions": [
        "How do the results generalize to a broader range of scenarios and categories?",
        "What is the impact of different types of human-designed edits on model performance?",
        "What ethical considerations should be addressed in future research?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3bq3jsvcQ1",
    "title": "Step-Back Prompting Enables Reasoning Via Abstraction in Large Language Models",
    "std_review": {
      "summary": "The paper introduces a novel prompting technique called 'Step-Back' that improves large language models' ability to retrieve high-level facts and perform structured reasoning. Empirical evaluations across several benchmarks show clear improvements on multi-step reasoning tasks, though the method also introduces challenges such as potential loss of relevant facts and increased complexity in question design. Overall, the study provides valuable insights into prompting strategies for LLMs, highlighting both benefits and trade-offs.",
      "strengths": [
        "Introduces a structured prompting approach that encourages LLMs to break down complex questions into intermediate steps.",
        "Provides comprehensive empirical evaluations across multiple benchmarks, demonstrating clear improvements.",
        "Grounded in a solid theoretical motivation for decomposing questions to maintain context and retrieve relevant facts.",
        "Offers practical insights through concrete examples and error analysis."
      ],
      "weaknesses": [
        "Limited benchmark coverage may not fully capture the versatility of the Step-Back method.",
        "Evaluation focuses on proprietary models (GPT-3) rather than more recent or diverse open-source LLMs.",
        "Potential for over-decomposition leading to loss of high-level facts.",
        "Complexity in designing effective Step-Back questions could be challenging for non-expert users."
      ],
      "questions": [
        "How does the Step-Back method perform on a broader set of reasoning benchmarks, including more recent open-source LLMs?",
        "What are the specific criteria for designing effective Step-Back questions to minimize over-decomposition?",
        "Can the method be adapted to work with less powerful or less capable LLMs without sacrificing performance?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3bqesUzZPH",
    "title": "FTA: Stealthy and Adaptive Backdoor Attack with Flexible Triggers on Federated Learning",
    "std_review": {
      "summary": "The paper introduces Feature Trigger Attack (FTA), a novel backdoor insertion method that embeds triggers directly into the global model's parameter space, offering high stealthiness and flexibility. Experiments show strong resistance to common defenses and high backdoor hit rates across datasets and models. While innovative, scalability and federated learning validation remain open questions.",
      "strengths": [
        "Innovative stealth mechanism by embedding triggers in the parameter space.",
        "High flexibility and personalization through per-example trigger learning.",
        "Strong resistance to post-training defenses like clustering-based filtering and Neuron Clipping.",
        "Clear theoretical foundation with an optimization formulation balancing stealth and effectiveness."
      ],
      "weaknesses": [
        "Implementation complexity due to alternating optimization between classifier and triggers.",
        "Potential scalability issues for very large datasets or complex models.",
        "Limited evaluation in federated learning settings.",
        "Risk of overfitting with highly personalized triggers."
      ],
      "questions": [
        "How does the method scale to very large datasets or complex models?",
        "What are the implications of per-example trigger learning for overfitting?",
        "How does FTA perform under non-IID and federated learning scenarios?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3cE6NKYy8x",
    "title": "Towards Fair Graph Anomaly Detection:",
    "std_review": {
      "summary": "The paper introduces a fairness-aware approach to graph anomaly detection, evaluating nine existing methods on Twitter and Reddit datasets. It highlights the need for fairness-aware techniques, as traditional methods often fail to detect anomalies fairly across different sensitive groups. While the approach is novel and well‑evaluated, the datasets and edge definitions may limit generalizability, and the paper could benefit from exploring semi‑supervised methods, dynamic graphs, and a broader range of fairness concerns.",
      "strengths": [
        "Introduces a novel fairness‑aware approach to graph anomaly detection.",
        "Provides a comprehensive evaluation of nine existing GAD methods.",
        "Uses real‑world datasets to demonstrate practical relevance.",
        "Offers a clear methodology for identifying and mitigating bias."
      ],
      "weaknesses": [
        "Datasets may not be fully representative of all graph structures and sensitive attributes.",
        "Political leaning as the sensitive attribute may not capture broader fairness concerns.",
        "Edge definition in Reddit may not capture meaningful graph structures.",
        "Lacks evaluation of semi‑supervised GAD methods.",
        "Does not explore impact of edge definition or dynamic graphs."
      ],
      "questions": [
        "How do the findings generalize to other graph structures and sensitive attributes?",
        "What impact does the choice of sensitive attribute have on fairness analysis?",
        "How does the edge definition in the Reddit dataset affect GAD performance?",
        "Could semi‑supervised GAD methods improve robustness and applicability?",
        "What is the impact of removing sensitive attributes on fairness concerns?",
        "How can the interpretability and explainability of the proposed approach be enhanced?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3cuJwmPxXj",
    "title": "Identifying Representations for Intervention Extrapolation",
    "std_review": {
      "summary": "The paper introduces a method for identifying parameters in a linear model with noise, addressing identifiability issues. It derives conditions for parameter ℓ and λ to be identifiable, showing they are identifiable only up to an additive constant without extra assumptions. The method is applied to intervention extrapolation, comparing favorably with existing approaches like iVAE. While theoretically rigorous and providing clear identification conditions, the paper lacks empirical validation and clarity on handling assumption violations.",
      "strengths": [
        "Clear identification conditions for parameters ℓ and λ.",
        "Mathematically rigorous derivations providing a solid theoretical foundation.",
        "Application of the method to intervention extrapolation, demonstrating practical utility.",
        "Effective comparison with related work, highlighting unique advantages and limitations."
      ],
      "weaknesses": [
        "Complexity of assumptions required for identifiability may limit applicability.",
        "Lack of empirical validation showing method performance when assumptions are violated.",
        "Notation clarity issues, such as the domain of ℓ(z) not being explicitly confirmed.",
        "Absence of discussion on robustness when assumptions about linear relationships or injective mappings are not strictly held."
      ],
      "questions": [
        "How robust is the method when the assumptions about the linear relationship between A and Z or the injective mapping from X to Z are not strictly held?",
        "What empirical results demonstrate the method's performance under assumption violations?",
        "Could additional experiments clarify the impact of differentiability and convex interior of supp(A) assumptions on identifiability?"
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "3d0OmYTNui",
    "title": "Privately Aligning Language Models with Reinforcement Learning",
    "std_review": {
      "summary": "The paper introduces a method for training reward models in reinforcement learning with differential privacy guarantees, comparing private and non-private models. It highlights the impact of DP on model utility and alignment, offering practical insights and a comprehensive analysis of hyperparameter trade-offs. While innovative, the study has limitations in scope and lacks detailed confidence interval information, affecting its overall impact.",
      "strengths": [
        "Innovative approach to integrating differential privacy into reward model training.",
        "Clear methodology for comparing non-private and private reward models.",
        "Practical implications for model utility and alignment in reinforcement learning."
      ],
      "weaknesses": [
        "Limited scope focusing primarily on reward model alignment in RL.",
        "Complexity of integrating DP mechanisms into the alignment process.",
        "Lack of confidence interval details for reported results.",
        "Unclear significance of trade-offs in setting $T_{\text{PPO}}$."
      ],
      "questions": [
        "How can the fine-tuning method be generalized to other domains beyond the current examples?",
        "What are the detailed steps for calculating confidence intervals in the experiments?",
        "How does the choice of $T_{\text{PPO}}$ affect model utility, and what are the trade-offs involved?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "3edHHvu5GX",
    "title": "Adaptive Visual Scene Understanding:",
    "std_review": {
      "summary": "The paper introduces a novel dynamic graph structure for continual learning in scene graph generation, showing improved performance on a benchmark dataset. While promising, the work lacks detailed methodology, clear evaluation metrics, and a comprehensive comparison with existing methods, leading to a weak accept recommendation.",
      "strengths": [
        "Introduces a novel dynamic graph structure for continual learning in scene graph generation.",
        "Demonstrates improved performance on a benchmark dataset compared to existing approaches.",
        "Addresses a significant gap in the literature by focusing on continual learning for scene graph generation."
      ],
      "weaknesses": [
        "Lacks detailed discussion of potential limitations of the dynamic graph structure.",
        "Evaluation metrics used to assess performance are not explicitly defined.",
        "Does not provide a comprehensive comparison with state-of-the-art continual learning methods.",
        "Experimental setup and dataset details are not fully described."
      ],
      "questions": [
        "Could you provide a more detailed description of the dynamic graph structure and its implementation?",
        "What are the specific continual learning methods employed in the evaluation?",
        "Please clarify the evaluation metrics used to assess the performance of the proposed methods.",
        "How does the proposed approach compare with state-of-the-art methods in related domains?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "3eFMnZ3N4J",
    "title": "Efficient-3Dim: Learning a Generalizable Single-image Novel-view Synthesizer in One Day",
    "std_review": {
      "summary": "The paper Efficient-3Dim presents a novel framework for single-image novel view synthesis that significantly speeds up the process while maintaining high quality. It introduces a crafted timestep sampling strategy, uses DINO-v2 for 3D feature extraction, and incorporates mixed-precision training and extra layer normalization to enhance efficiency. The approach is demonstrated on the Planet dataset and shows strong results, indicating good generalizability to other 3D vision tasks. Despite some noted weaknesses, the overall contribution is substantial and aligns well with current research goals.",
      "strengths": [
        "The crafted timestep sampling strategy intelligently reduces the number of timesteps needed for efficient novel view synthesis, leading to substantial computational savings compared to uniform sampling.",
        "The choice of DINO-v2 over CLIP for 3D feature extraction is well justified, as DINO-v2 is better suited for capturing high-level 3D semantics, which is crucial for generating realistic novel views.",
        "The introduction of mixed-precision training and extra layer normalization in the training scheme significantly enhances the speedup without compromising the quality of the synthesized images.",
        "The framework's design allows for easy adaptation to other 3D vision tasks, such as 3D object creation and scene reconstruction, indicating its broad applicability and generalizability."
      ],
      "weaknesses": [
        "The paper could benefit from a more detailed analysis of the trade-offs between the crafted timestep sampling strategy and uniform sampling, particularly in terms of synthesis quality and computational cost.",
        "While the choice of DINO-v2 over CLIP is justified, the paper does not provide a comprehensive comparison with other 3D vision models, which could strengthen the argument for its superiority.",
        "The training paradigm enhancements, while clearly described, lack quantitative benchmarks comparing their impact on speedup versus quality, which would be valuable for readers.",
        "The scalability of the proposed techniques in distributed or large-scale training setups is not thoroughly explored, leaving open questions about how the speedup benefits scale with increased computational resources."
      ],
      "questions": [
        "How do the trade-offs between the crafted timestep sampling strategy and uniform sampling manifest in terms of synthesis quality and computational cost?",
        "Could a more comprehensive comparison with other 3D vision models further support the choice of DINO-v2 over CLIP?",
        "What quantitative benchmarks are available to compare the impact of mixed-precision training and extra layer normalization on speedup versus quality?",
        "How do the proposed techniques scale in distributed or large-scale training setups, and what are the expected gains in such environments?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3EWTEy9MTM",
    "title": "Chain of Thought Empowers Transformers to Solve Inherently Serial Problems",
    "std_review": {
      "summary": "The paper investigates the expressive power of transformers equipped with Constant‑Time (CoT) reasoning, deriving theoretical upper bounds (AC0 class) and demonstrating that CoT enhances performance on arithmetic tasks. While the theoretical contributions are novel and the empirical evidence is compelling, the results are limited to non‑uniform embeddings and arithmetic tasks, raising questions about practical generalizability and comparison with recent work.",
      "strengths": [
        "Clear theoretical contributions: novel AC0 upper bounds for transformers with CoT.",
        "Empirical validation: experiments show CoT improves performance over hint strategies on arithmetic tasks.",
        "Insightful analysis: theorems on embedding size and rounding mechanisms provide nuanced understanding."
      ],
      "weaknesses": [
        "Practicality of non‑uniform embeddings may limit real‑world applicability.",
        "Empirical validation is restricted to arithmetic tasks, not covering all domains.",
        "Lacks extensive comparison with recent related work, such as Merrill & Sabharwal (2023).",
        "Some theoretical results (e.g., embedding size) do not perfectly align with empirical observations."
      ],
      "questions": [
        "How do the theoretical results translate to models with uniform embeddings?",
        "Can the findings be extended to non‑arithmetic tasks or other domains?",
        "How do the results compare with recent advancements like Merrill & Sabharwal (2023)?",
        "What are the theoretical limits of expressiveness when embedding size is fixed?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3f5PALef5B",
    "title": "LEGO-Prover: Neural Theorem Proving with Growing Libraries",
    "std_review": {
      "summary": "LEGO-Prover presents a novel approach to neural theorem proving by combining large language models with a growing lemma library and a directional evolution component. The system decomposes problems, generates informal proofs, and formalizes lemmas that are added to a skill library, which is expanded by the directional evolution component. Evaluation on the miniF2F benchmark shows significant improvements over prior methods, though the system has limitations such as potential inconsistencies in generated proofs and challenges in managing a large lemma library.",
      "strengths": [
        "Utilizes LLMs to automate theorem proving, reducing manual intervention.",
        "Employs a growing lemma library that learns and expands over time, enhancing capabilities.",
        "Directional Evolution component effectively refines and generates new lemmas, improving the theorem proving process.",
        "Demonstrates significant improvements over prior state-of-the-art methods on the miniF2F benchmark dataset."
      ],
      "weaknesses": [
        "Reliance on LLMs may lead to inconsistencies and errors in generated proofs.",
        "Growing lemma library may become unwieldy and difficult to manage.",
        "Evaluation is limited to a single benchmark dataset, potentially overlooking broader performance.",
        "Performance could be further improved with additional techniques or optimizations."
      ],
      "questions": [
        "How does the system handle inconsistencies or errors in proofs generated by LLMs?",
        "What strategies are employed to manage the growth and manageability of the lemma library?",
        "How does the performance on the miniF2F dataset translate to other benchmark datasets or real-world problems?",
        "What additional techniques or optimizations could be incorporated to further enhance the system's performance?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3fEKavFsnv",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a method for synthetic text detection that leverages diverse LLM-generated text, treating entire paragraphs as single units. It demonstrates that a more diverse set of LLMs improves detection accuracy compared to using a single LLM or none. The approach is practical and innovative, though it lacks detailed analysis on LLM characteristics and potential overfitting, and does not fully explore computational costs.",
      "strengths": [
        "Introduces a novel approach to leveraging diverse LLM-generated text for synthetic text detection.",
        "Considers a wide range of LLMs, from less capable to advanced models, providing a comprehensive evaluation.",
        "Treats entire paragraphs as single units, offering a practical and innovative way to handle longer text.",
        "Experimental setup is well-structured with clear comparisons between different training scenarios."
      ],
      "weaknesses": [
        "Lacks detailed analysis on how specific LLM characteristics affect detection performance.",
        "Does not discuss potential overfitting issues when training on diverse LLM-generated texts.",
        "Evaluation metrics (accuracy, precision, recall) do not capture all performance aspects, such as false positives/negatives in different contexts.",
        "Does not explore the computational cost of training on a larger, more diverse dataset."
      ],
      "questions": [
        "How do the specific characteristics of each LLM (e.g., output length, style) influence detection performance?",
        "What measures are taken to address potential overfitting when training on a diverse set of LLM-generated texts?",
        "Could the evaluation metrics be expanded to capture a broader range of performance aspects beyond accuracy, precision, and recall?",
        "What is the computational cost of training on a larger, more diverse dataset, and how does it compare to traditional methods?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3FJOKjooIj",
    "title": "Self-supervised Heterogeneous Graph Learning: a Homophily and Heterogeneity Perspective",
    "std_review": {
      "summary": "The paper introduces HERO, a self-supervised learning framework that simultaneously leverages homophilous and heterophilous graph representations to improve downstream tasks. HERO's novel concatenation fusion strategy outperforms existing baselines on node classification and similarity search, supported by a theoretical guarantee (Theorem 2.3). While strong empirically, the review notes limited baseline comparisons and a lack of exploration of alternative fusion methods, suggesting further investigation.",
      "strengths": [
        "Innovative fusion strategy that concatenates homophilous and heterophilous representations.",
        "Strong theoretical foundation with a theoretical guarantee (Theorem 2.3).",
        "Empirical success across multiple node classification and similarity search tasks."
      ],
      "weaknesses": [
        "Limited comparison with baselines that handle both homophilous and heterophilous information.",
        "No exploration of alternative fusion techniques like average pooling or max pooling.",
        "Theoretical guarantees are not fully explored in terms of practical performance."
      ],
      "questions": [
        "How does HERO perform on a broader set of downstream tasks beyond node classification and similarity search?",
        "What impact does the choice of fusion method (concatenation vs. alternative pooling techniques) have on performance?",
        "Can the theoretical guarantees be extended to other types of graph data or tasks?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3fRbP8g2LT",
    "title": "Efficient Redundancy-Free Graph Networks:",
    "std_review": {
      "summary": "The paper introduces DLGN and ERFGN, models that address the over‑squashing problem in message passing neural networks through a redundancy‑free design. Theoretical analyses provide guarantees on sensitivity and effective resistance, and empirical results show significant efficiency gains across various baselines and datasets. The authors demonstrate that their models can capture non‑isomorphic subgraphs more effectively than k‑WL tests and achieve substantial improvements in training time and parameter efficiency. Overall, the paper is well‑received for its innovative approach and strong empirical support.",
      "strengths": [
        "Redundancy‑free design effectively eliminates over‑squashing in MPNNs.",
        "Provides concrete theoretical guarantees on sensitivity and expressiveness.",
        "Demonstrates substantial empirical efficiency gains across diverse datasets.",
        "Offers a novel way to model cycles through path trees, enhancing expressiveness."
      ],
      "weaknesses": [
        "Implementation complexity may introduce additional computational overhead.",
        "Empirical validation is limited to specific baselines and datasets.",
        "Theoretical expressiveness claims require further demonstration in practical applications."
      ],
      "questions": [
        "How does the model scale to extremely large graphs with billions of nodes?",
        "What is the impact of varying the tree-height L on model performance in real‑world scenarios?",
        "Can the expressiveness gains be quantified in terms of downstream task performance?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3GDKJSQnW2",
    "title": "",
    "std_review": {
      "summary": "PDEdit introduces a novel diffusion‑based approach for editing video motion using textual prompts, leveraging a dynamic motion prior and a spatial‑temporal focusing module to ensure temporal consistency. The method shows high‑quality results and scalability across video lengths and resolutions, though it faces computational demands and sensitivity to prompt relevance. Overall, the paper is well‑received for its innovative technique and strong visual results.",
      "strengths": [
        "Dynamic motion prior captures physical constraints for plausible edits.",
        "Spatial‑temporal focusing module enhances temporal coherence.",
        "Scalable and flexible across video sizes and content types.",
        "Produces high‑quality, context‑preserving edits."
      ],
      "weaknesses": [
        "High computational cost, limiting deployment on resource‑constrained devices.",
        "Edit quality heavily depends on prompt relevance to the video content.",
        "Potential artifacts like color drift and object misalignment remain.",
        "Does not utilize the original video caption, which could improve robustness."
      ],
      "questions": [
        "How can the method be optimized for real‑time applications on low‑power devices?",
        "What strategies can improve prompt robustness for less relevant textual inputs?",
        "Are there techniques to further reduce color drift and object misalignment artifacts?",
        "How could incorporating the original video caption enhance the method's adaptability?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3GunDQNKFJ",
    "title": "Reformulating Domain Adaptation of Large Language Models as Adapt-Retrieve-Revise",
    "std_review": {
      "summary": "The paper introduces the adapt-retrieve-revise framework for efficient domain adaptation of large language models in legal document analysis. It leverages a small LM for initial drafts and GPT-4 for revisions, achieving significant gains in precision and recall over baselines. While computationally demanding, the method offers interpretability, scalability, and improved handling of ambiguous queries. Overall, it is a valuable contribution with strong potential for broader applications.",
      "strengths": [
        "Efficient domain adaptation by using a small LM for initial drafts and GPT-4 for revisions.",
        "Improved answer quality with higher precision and more contextually accurate responses.",
        "Scalable and adaptable to various domains with minimal changes.",
        "Enhanced interpretability through a clear lineage of answer evolution."
      ],
      "weaknesses": [
        "Significant computational overhead, especially for the GPT-4 revision step.",
        "Reliance on retrieval module quality, which can vary across domains.",
        "Potential struggles with open-ended or ambiguous legal questions.",
        "Evaluation metrics may not fully capture legal reasoning quality."
      ],
      "questions": [
        "How can the retrieval module's performance be further improved for less well‑documented legal domains?",
        "What are the trade‑offs between query‑based and answer‑based retrieval in terms of precision and context relevance?",
        "How can the framework be extended to handle multi‑modal legal evidence (e.g., images, tables) more effectively?",
        "What are the long‑term computational costs associated with deploying this method at scale?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3GurO0kRue",
    "title": "On Harmonizing Implicit Subpopulations",
    "std_review": {
      "summary": "The paper introduces SHE, a method for handling class imbalance by balancing subpopulations in a latent space using a mixture of experts. It shows strong empirical improvements over baselines, especially in scenarios with large subpopulation shifts, and provides a theoretical argument supporting its effectiveness. However, the evaluation is limited to out-of-domain settings, and the method's performance in the critical in-domain scenario is not demonstrated. The approach also has implementation complexity and relies on assumptions about label distribution that may limit its applicability.",
      "strengths": [
        "Novel approach to class imbalance by focusing on subpopulation balance in a latent space.",
        "Strong theoretical foundation with a proposition suggesting non‑underperformance of SHE relative to ERM in the limit.",
        "Empirical success across synthetic and real-world datasets, particularly in challenging subpopulation shift scenarios."
      ],
      "weaknesses": [
        "Limited evaluation to out-of-domain settings; in-domain imbalance is not adequately assessed.",
        "Implementation complexity due to reliance on a mixture of experts and operations in the latent space.",
        "Assumes balanced label distributions within subpopulations, which may not hold in all cases.",
        "Potential for overfitting with the mixture of experts component."
      ],
      "questions": [
        "How does SHE perform when both training and testing data are imbalanced (in-domain scenario)?",
        "What is the method's behavior under other notions of subpopulation shift where label distributions are not balanced?",
        "Can SHE be extended to handle arbitrary target distributions over the latent subpopulation?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "3husFxdHI1",
    "title": "Duality of Information Flow: Insights in Graphical Models and Neural Networks",
    "std_review": {
      "summary": "The paper establishes a duality between information flow in graphical models and neural networks, particularly Bayesian neural networks, showing that backpropagation and belief propagation are equivalent. It proposes a belief propagation-based training algorithm for Bayesian neural networks, demonstrating its advantages through numerical experiments. While the theoretical contributions are rigorous, some practical concerns such as scalability and lack of comparison with state-of-the-art methods remain.",
      "strengths": [
        "Novel duality insight between graphical models and neural networks.",
        "Unified framework linking backpropagation and belief propagation.",
        "Algorithmic contribution with a belief propagation-based training method.",
        "Strong theoretical foundation with mathematical proofs and connections to Langevin dynamics."
      ],
      "weaknesses": [
        "Complexity of theoretical contributions may limit accessibility.",
        "Numerical experiments are limited in scope.",
        "Potential scalability issues for large networks.",
        "Lack of extensive comparison with other state-of-the-art methods."
      ],
      "questions": [
        "How does the proposed algorithm perform on very large network architectures?",
        "What are the convergence properties in more complex or realistic scenarios?",
        "How does the algorithm compare to other state-of-the-art Bayesian neural network training methods?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3i7iNGxw6r",
    "title": "Where does In-context Machine Translation Happen in Large Language Models?",
    "std_review": {
      "summary": "The paper investigates how large language models transition from input‑aware to task‑aware representations across layers, using attention and embedding analysis on few‑shot translation tasks. It identifies specific layers where the model shifts focus to the translation task, offering insights into model design and optimization. While the findings are strong and theoretically grounded, they are specific to translation and larger models, and the robustness to different prompts or model sizes remains unexplored.",
      "strengths": [
        "Clear and reproducible methodology for identifying task‑aware layers.",
        "Insightful findings on systematic layer behavior in LLMs.",
        "Broad applicability across multiple language directions.",
        "Theoretical contribution framing the transition as encoder‑like compression and decoder‑like refinement."
      ],
      "weaknesses": [
        "Limited scope to the translation task.",
        "Dependence on specific few‑shot examples.",
        "Potential overfitting to 3‑B model size.",
        "Lack of robustness analysis."
      ],
      "questions": [
        "Can similar layer transitions be observed in other tasks like summarization or question answering?",
        "How robust are the identified task‑aware layers to variations in input or prompt phrasing?",
        "Do the same layer transition points emerge in larger models (e.g., 7B or 13B)?",
        "How would different few‑shot examples affect the layer transition patterns?",
        "What is the impact of input usage across all layers, not just the identified task‑aware layers?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3ijmMNaSJk",
    "title": "Towards Understanding Masked Distillation",
    "std_review": {
      "summary": "The paper introduces masked distillation as a novel self-supervised learning technique that refines teacher-student learning through masked predictions. It demonstrates improved ImageNet-1k performance and model stability, offering theoretical insights and visual analyses. However, the definition of masked distillation is vague, lacks direct comparisons with other methods, and some key results are only in the appendix.",
      "strengths": [
        "Introduces masked distillation as a refined SSL technique.",
        "Provides comprehensive comparisons with multiple SSL methods.",
        "Offers novel metrics to analyze model behavior."
      ],
      "weaknesses": [
        "Lacks a precise definition of masked distillation.",
        "Omits direct comparison with MIM.",
        "Experimental coverage may not fully represent all variants.",
        "Performance metrics are not prominently featured.",
        "Uses entropy for attention metrics, which may be less appropriate."
      ],
      "questions": [
        "Should a direct comparison with MIM be included to highlight novelty?",
        "How representative is the experimental implementation of all masked distillation variants?",
        "Should ImageNet-1k performance scores be included in the main text?",
        "How should the relevance of frequency analysis be clarified?",
        "What is the rationale for excluding SL from the loss‑landscape analysis?"
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "3IyC5lQTSi",
    "title": "Fairness Through Matching",
    "std_review": {
      "summary": "The paper introduces Matched Demographic Parity (MDP) and Fairness Through Matching (FTM) as a method to align predictions across demographic groups using optimal transport. It demonstrates effectiveness on both synthetic and real-world datasets while addressing flexibility and fairness concerns. The review highlights the method's strengths in providing a novel fairness perspective and leveraging optimal transport theory, but also notes concerns about distance metric choice, preprocessing sensitivity, visualization clarity, and computational complexity.",
      "strengths": [
        "Introduces a novel fairness measure (MDP) focusing on matching demographic distributions.",
        "Leverages optimal transport theory for a mathematically grounded approach to fairness.",
        "Demonstrates effectiveness on both synthetic and real-world datasets.",
        "Provides flexibility in specifying target distributions for various fairness scenarios."
      ],
      "weaknesses": [
        "Relies on squared Euclidean distance which may not always capture relevant similarities.",
        "Standardization preprocessing could be sensitive to distance metric choice.",
        "Small visualizations in the paper reduce clarity of fairness metric results.",
        "Lacks detailed analysis of computational complexity for large-scale applications."
      ],
      "questions": [
        "How does the choice of distance metric affect the alignment of predictions across demographic groups?",
        "What are the computational implications of the proposed method for large-scale datasets?",
        "How does the preprocessing step impact the fairness outcomes, and are there alternative methods that could be more robust?",
        "Could the visualization of fairness metrics be improved to enhance clarity and interpretation?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3j5bsiwRv6",
    "title": "Sparse Refinement for Efficient",
    "std_review": {
      "summary": "The paper presents a novel entropy-based refinement module for semantic segmentation models, achieving significant speedups without substantial loss in accuracy across multiple benchmark datasets. While innovative, the method introduces parameter overhead and requires careful tuning of entropy thresholds, which could limit its deployment on resource-constrained devices. The comprehensive evaluation across several datasets supports its effectiveness and general applicability, though additional testing on other benchmarks could further validate its broad utility.",
      "strengths": [
        "Innovative entropy-based refinement targets areas of uncertainty for more accurate segmentations.",
        "Achieves notable speedups while maintaining competitive accuracy, beneficial for real-time applications.",
        "Designed to be applicable to various segmentation architectures, enhancing versatility.",
        "Includes extensive experiments across multiple datasets, providing robust evidence of effectiveness."
      ],
      "weaknesses": [
        "Adds a significant number of parameters, potentially impacting model size and computational efficiency.",
        "Threshold selection for entropy is critical and not well-documented, raising concerns about robustness.",
        "Limited testing on other benchmarks like COCO or ADE20K could strengthen claims of general applicability.",
        "Comparison with token pruning is limited, suggesting a need for a more thorough analysis."
      ],
      "questions": [
        "How can the parameter overhead be mitigated to improve deployment on resource-constrained devices?",
        "What strategies can be employed to make the entropy threshold selection more robust across diverse datasets?",
        "Would additional testing on benchmarks like COCO or ADE20K provide further validation of the method's general applicability?",
        "How does the method compare to other state-of-the-art techniques in terms of parameter efficiency and computational cost?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3J7foqnJkA",
    "title": "Understanding Parameter Saliency",
    "std_review": {
      "summary": "The paper introduces the Probability of Overfitting (POT) algorithm, which estimates the probability of overfitting based on model complexity and training data. While demonstrating improved generalization performance in experiments, the review notes limited experimental validation and insufficient exploration of POT's parameters and limitations. The assumption of a normal distribution for the algorithm may not be representative for all problems. Overall, the paper presents a novel approach but requires more thorough analysis and validation.",
      "strengths": [
        "Introduces a novel approach to prevent overfitting by estimating the probability of overfitting.",
        "Provides a theoretical foundation for the POT algorithm based on model complexity and training data.",
        "Demonstrates improved generalization performance in experiments compared to existing methods.",
        "Offers a practical solution to a common problem in machine learning."
      ],
      "weaknesses": [
        "The experimental work is limited and lacks sufficient comparison experiments to validate the effectiveness of POT.",
        "The impact of POT's parameters on system performance is not thoroughly investigated.",
        "The assumption of normal distribution in the proposed POT system may not be representative enough for all problems.",
        "The paper lacks detailed discussion on the limitations of the previous solution (Levin) and how POT addresses those limitations."
      ],
      "questions": [
        "How will the parameters in the proposed POT system affect the system performance?",
        "What's the limitation in the previous solution (Levin) and how this solution can solve that?",
        "Why is a simple normal distribution used in proposition 1 and appendix B, and can it be representative enough for all problems?"
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "3JjJezzVkT",
    "title": "The Marginal Value of Momentum",
    "std_review": {
      "summary": "The paper provides a novel theoretical analysis showing that under small learning rates, stochastic gradient descent (SGD) and stochastic gradient descent with momentum (SGDM) exhibit nearly identical trajectories, challenging the conventional belief that momentum is only beneficial for large learning rates. It introduces Theorem 3.5 and explores its implications for convergence rates and regularization effects. While the analysis is technically rigorous and offers practical insights for optimization, it has some methodological limitations, particularly in scope and experimental design, which affect the generality and validity of the results.",
      "strengths": [
        "Novel theoretical insights into the behavior of SGD and SGDM under small learning rates.",
        "Clear delineation of momentum's role across different regimes.",
        "Strong theoretical rigor with well‑structured proofs and lemmas."
      ],
      "weaknesses": [
        "Scope limitations regarding full‑batch gradient descent when momentum is zero.",
        "Assumptions on noise scaling (σ ≤ η^(–1/2)) may restrict generality.",
        "Unclear explanation of behavior for α > 1 when η → 0.",
        "CIFAR‑10 experiments lack proper rescaling of the learning rate for SGDM."
      ],
      "questions": [
        "How does the theoretical framework extend to scenarios where noise scaling exceeds the assumed threshold?",
        "What are the practical implications of the theorem's prediction that no limiting dynamics exist for α > 1?",
        "How can the experimental methodology be improved to better compare SGD and SGDM under fair conditions?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "3Jl0sjmZx9",
    "title": "Large Multimodal Model for Real-World Radiology Report Generation",
    "std_review": {
      "summary": "The paper introduces DeMMo, a model that combines ChatGPT-generated context with a medical vision encoder to generate clinical radiology reports. It evaluates DeMMo on the MIMIC‑R3G benchmark, showing strong linguistic quality and clinical accuracy compared to baselines. While innovative, the model's reliance on ChatGPT introduces variability, and the computational impact of the medical vision encoder is not fully detailed. Overall, the work is a valuable contribution to clinical report generation.",
      "strengths": [
        "Innovative integration of large language models with domain-specific medical vision encoders.",
        "Comprehensive evaluation using multiple linguistic and clinical metrics.",
        "Demonstrates competitive performance against established baselines."
      ],
      "weaknesses": [
        "Dependence on ChatGPT for context generation may introduce variability and inaccuracies.",
        "Lack of detailed computational analysis of the medical vision encoder's impact.",
        "Limited clinical validation beyond linguistic metrics."
      ],
      "questions": [
        "How does the model handle cases where ChatGPT-generated context is inconsistent or inaccurate?",
        "What strategies are employed to mitigate potential biases introduced by the general language model?",
        "How does the computational complexity of DeMMo scale with larger datasets or more complex medical images?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3JoQqW35GQ",
    "title": "Training-free linear image inversion via flows",
    "std_review": {
      "raw_text": "{\n  \"summary\": \"The paper introduces VP‑ODE, an ODE sampler that replaces the stochastic DDIM sampler in diffusion models, achieving improved performance on ImageNet‑64/128 and AFHQ‑256 datasets compared to the baseline $\\Pi$GDM. While the approach is innovative and the class‑conditional training is relevant, the limited benchmark comparison and the impact of conditional modeling raise questions about the method's broader applicability. Overall, the work is promising but requires further justification of its strengths.\",\n  \"strengths\": [\n    \"Innovative sampling approach using an ODE sampler (VP‑ODE) for more stable and efficient diffusion.\",\n    \"Diverse dataset evaluation on ImageNet‑64/128 and AFHQ‑256, providing insights into model performance across scales.\",\n    \"Relevance of class‑conditional model training for practical applications.\"\n  ],\n  \"weaknesses\": [\n    \"Evaluation on less common datasets may not fully justify the method's strength compared to more standard benchmarks.\",\n    \"Conditional modeling introduces additional complexity and potential bias, affecting relevance to typical applications.\",\n    \"Performance gains over OT‑ODE are marginal and lack detailed theoretical justification.\"\n  ],\n  \"questions\": [\n    \"How do the results generalize to more widely used benchmarks like FFHQ and ImageNet?\",\n    \"What are the theoretical reasons for the marginal superiority of VP‑ODE over OT‑ODE?\",\n    \"How does the choice of class‑conditional models impact the model's applicability to unconditional tasks?\"\n  ],\n  \"overall_score\": \"6: weak accept\",\n  \"confidence\": \"3: medium\"\n}",
      "parse_error": true
    }
  },
  {
    "paper_id": "3jXCF5dNpC",
    "title": "Re-Reading Improves Reasoning in Language Models",
    "std_review": {
      "summary": "The paper introduces RE2, a two‑pass prompting technique that enhances reasoning in language models. It shows strong empirical improvements across multiple reasoning benchmarks, with larger models benefiting more. While the technique is theoretically compelling and scalable, it lacks detailed mechanistic explanation and statistical robustness, leading to some concerns about its generalization and potential overfitting.",
      "strengths": [
        "Clear and reproducible methodology with detailed prompts and procedures.",
        "Comprehensive evaluation across reasoning datasets and model sizes.",
        "Empirical evidence supported by quantitative improvements and qualitative analyses."
      ],
      "weaknesses": [
        "Lack of detailed explanation of the mechanism enabling bidirectional understanding.",
        "Limited evidence on performance outside reasoning tasks.",
        "Absence of statistical measures like standard deviations or confidence intervals.",
        "Potential for overfitting to specific benchmarks."
      ],
      "questions": [
        "What is the precise mechanism by which the second pass enables bidirectional understanding?",
        "How does RE2 perform on non‑reasoning tasks such as classification or generation?",
        "What are the statistical robustness of the reported gains (e.g., standard deviations, confidence intervals)?",
        "How does RE2 scale beyond reasoning tasks, and are there any negative impacts on generation quality?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "3klVRLhK7w",
    "title": "Budgeted Online Continual Learning by Adaptive Layer Freezing and Frequency-based Sampling",
    "std_review": {
      "summary": "The paper proposes an adaptive layer freezing mechanism for online continual learning, aiming to balance computational efficiency and model accuracy. It demonstrates effectiveness across CNNs and Transformers, showing significant improvements. While innovative, the method lacks detailed criteria for layer selection and robustness analysis, and computational gains are not quantified. Overall, the work is promising but requires further refinement.",
      "strengths": [
        "Introduces a novel adaptive layer freezing mechanism for online continual learning.",
        "Demonstrates broad applicability across CNNs and Transformers.",
        "Shows significant improvements in computational efficiency and model performance."
      ],
      "weaknesses": [
        "Lacks detailed explanations of criteria for layer freezing/unfreezing.",
        "Limited discussion on method robustness across data distribution shifts.",
        "Computational efficiency improvements are not quantified.",
        "No comprehensive comparison with state-of-the-art methods."
      ],
      "questions": [
        "Could you provide more details on the specific criteria used for layer selection?",
        "What is the robustness of the method under different types of data distribution shifts?",
        "How do the computational efficiency gains compare to baseline methods?",
        "Could you compare the proposed method with recent state-of-the-art approaches in continual learning?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3LFy3dUS86",
    "title": "P2RBox: A Single Point is All You Need for Oriented Object Detection",
    "std_review": {
      "summary": "P2RBox introduces a novel approach to oriented object detection by leveraging a Symmetry Axis Estimation (SAE) module to enhance performance, particularly for symmetric objects. The method integrates single point annotations with a segmentation mask approach using Self-Attention Mask (SAM) to generate oriented bounding boxes. The paper evaluates P2RBox on the DOTA dataset and compares its performance against state-of-the-art fully supervised oriented object detectors, highlighting improvements in accuracy and efficiency. Overall, the paper presents an innovative method with strong performance gains, though it has some limitations in robustness and generalization.",
      "strengths": [
        "Innovative Symmetry Utilization: The SAE module effectively leverages object symmetry to improve detection accuracy, especially for symmetric objects like vehicles and animals.",
        "Efficient Mask Generation: By using SAM for mask generation, P2RBox reduces the computational burden associated with traditional bounding box regression.",
        "Robustness to Single Point Annotations: The method's reliance on single point annotations simplifies data collection and processing, making it more practical for real-world applications."
      ],
      "weaknesses": [
        "Limited Generalization: The method's performance may not generalize well to datasets with different object densities and occlusion rates, such as aerial imagery or urban scenes.",
        "Sensitivity to Point Quality: The effectiveness of P2RBox is highly dependent on the quality of single point annotations, which can be challenging to obtain accurately.",
        "Computational Cost of SAE Module: The SAE module introduces additional computational overhead, which may impact real-time applications."
      ],
      "questions": [
        "How does P2RBox perform on datasets with varying object densities and occlusion rates, such as aerial imagery or urban scenes?",
        "What strategies can be employed to improve the robustness of P2RBox to noisy or low-quality single point annotations?",
        "How can the computational cost of the SAE module be further reduced to make P2RBox more suitable for real-time applications?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3LLkES6nNs",
    "title": "Infinitely Deep Residual Networks: Unveiling Wide Neural ODEs as Gaussian Processes",
    "std_review": {
      "summary": "The paper presents a novel theoretical framework that links Residual Networks (ResNets) and Neural Ordinary Differential Equations (Neural ODEs) by interpreting ResNet depth as a time parameter. It provides rigorous convergence analysis and empirical evidence on image classification tasks, demonstrating practical benefits. While the work is innovative, it relies on certain assumptions about matrix A and activation functions that may limit its generality.",
      "strengths": [
        "Clear theoretical framework linking ResNets and Neural ODEs",
        "Thorough convergence analysis under specific conditions",
        "Empirical validation on image classification tasks",
        "Interdisciplinary contribution bridging two deep learning paradigms"
      ],
      "weaknesses": [
        "Unclear assumptions for Equation (4) regarding matrix A",
        "Convergence analysis assumes a fixed time T, which may not be practical",
        "Reliance on controllable activation functions in Theorem 3.2",
        "Minor formatting issues with inconsistent equation references"
      ],
      "questions": [
        "What are the precise assumptions on matrix A for Equation (4) to hold?",
        "How does the fixed time T (β = T/L) affect the practical applicability of the convergence results?",
        "Can the convergence results be extended to activation functions without the controllability assumption?",
        "Should Lemma C.2 reference the equation it uses for clarity?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3M0GXoUEzP",
    "title": "CriBo : Self-Supervised Learning via Cross-Image Object-Level Bootstrapping",
    "std_review": {
      "summary": "The paper introduces CrIBo, a self-supervised learning framework that leverages cross-image object-level consistency to enhance scene-centric visual representation learning. CrIBo uses a memory bank to store object representations and mask-based pooling to cluster these representations, achieving competitive performance on dense downstream tasks. While the method shows promise, its higher computational cost and dependency on clustering algorithm choice are notable concerns.",
      "strengths": [
        "Innovative approach focusing on cross-image object-level consistency.",
        "Effective representation learning through a memory bank and mask-based pooling.",
        "Competitive performance on benchmark datasets."
      ],
      "weaknesses": [
        "Higher computational cost due to large memory bank and mask-based pooling.",
        "Performance heavily dependent on the choice of clustering algorithm.",
        "Limited evaluation across diverse datasets and tasks."
      ],
      "questions": [
        "How can the computational cost be reduced while maintaining performance?",
        "What alternative clustering algorithms could improve robustness?",
        "How does CrIBo generalize to other types of visual tasks beyond dense prediction?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3mdCet7vVv",
    "title": "Maestro: Uncovering Low-Rank Structures via Trainable Decomposition",
    "std_review": {
      "summary": "The paper introduces a novel approach to structured pruning of neural networks that avoids SVD by using an initial factorized mapping, refining sparsity with Lasso regularization. It demonstrates effectiveness on ResNets and Vision Transformers, showing competitive performance with reduced model sizes and highlighting scalability. While innovative, the method lacks detailed theoretical foundations, comprehensive comparisons, and clear guidance on hyperparameter selection, which are critical for practical adoption.",
      "strengths": [
        "Novel factorization technique that bypasses traditional SVD, potentially reducing computational overhead.",
        "Achieves structured sparsity through low-rank factorization and Lasso regularization, leading to efficient inference.",
        "Demonstrates scalability to large models like ViTs on ImageNet, indicating practical applicability."
      ],
      "weaknesses": [
        "Lacks a detailed methodology for choosing the initial maximal rank r.",
        "Limited comparison with other structured pruning methods.",
        "Insufficient analysis of hyperparameter sensitivity, particularly the Lasso coefficient.",
        "Ambiguous reporting of training cost, making it unclear whether reported values reflect training or inference."
      ],
      "questions": [
        "Could you provide a detailed methodology for selecting the initial maximal rank r?",
        "How does the proposed method compare quantitatively with established structured pruning techniques like channel-based pruning?",
        "What is the impact of different Lasso coefficients λ on performance, and is there a theoretical guideline for optimal selection?",
        "Could you clarify whether the reported GMACs values represent training or inference costs, and provide a breakdown of computational resources used?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "3NmO9lY4Jn",
    "title": "Don't Play Favorites:",
    "std_review": {
      "summary": "The paper introduces a novel approach to generative modeling that focuses on generating samples from low-likelihood regions of the data distribution, termed 'minority data.' By integrating a minority score into the guidance mechanism of a diffusion model, the authors demonstrate improved diversity and authenticity of generated samples, especially in underrepresented areas. The method is theoretically justified and empirically validated, showing strong performance compared to baseline models. Overall, the paper presents a valuable contribution to the field of generative modeling.",
      "strengths": [
        "Innovative guidance mechanism that integrates minority score with existing techniques.",
        "Enhanced diversity and authenticity of generated samples, particularly in underrepresented regions.",
        "Theoretical motivation for using minority score to address data scarcity in low-likelihood regions.",
        "Empirical validation with improved performance metrics over baseline models."
      ],
      "weaknesses": [
        "Complexity introduced by the minority score computation and tuning requirements.",
        "Potential risk of over-fitting due to limited examples in minority data.",
        "Lack of quantitative analysis on the interaction between minority guidance and other guidance forms.",
        "Threshold selection for minority score not clearly justified, affecting results and generalizability."
      ],
      "questions": [
        "How robust is the minority score to variations in dataset characteristics?",
        "Could the integration of minority guidance with other guidance forms be further explored?",
        "What quantitative metrics would best capture the impact of minority guidance on generated sample quality?",
        "How does the choice of minority score thresholds influence the trade-off between diversity and authenticity?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3NMYMLL92j",
    "title": "Brain encoding models based on binding multiple modalities across audio, language, and vision",
    "std_review": {
      "summary": "The paper introduces ImageBind, a multimodal alignment framework that integrates text, audio, and video into a unified representation space to predict brain activity. It demonstrates superior performance over strong unimodal baselines across the whole brain and specific regions of interest. While innovative and insightful, the study has limitations in generalization, orthogonal modality experiments, and audio synthesis impact, leading to a weak accept recommendation.",
      "strengths": [
        "Innovative multimodal alignment framework that integrates text, audio, and video into a unified representation space.",
        "Comprehensive brain prediction analyses across different modalities, showing superior performance compared to unimodal baselines.",
        "Robust experimental design with thorough ablation studies and cross-modal retrieval analyses."
      ],
      "weaknesses": [
        "Limited generalization due to reliance on specific neural network architectures.",
        "Lack of controlled experiments with orthogonal modalities.",
        "Insufficient exploration of the impact of audio synthesis on brain prediction.",
        "Computational requirements and scalability of the ImageBind framework for real-world applications are not thoroughly addressed."
      ],
      "questions": [
        "How do the findings generalize to other neural network architectures beyond BERT, AST, and ViT?",
        "What are the implications of the study's results for orthogonal modalities, such as combining visual and linguistic information?",
        "How does the use of synthesized audio versus original text captions affect brain prediction accuracy, and what are the underlying mechanisms?",
        "What are the computational and scalability challenges of applying ImageBind to real-world multimodal alignment tasks?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "3NnfJnbJT2",
    "title": "Gio: Gradient Information Optimization for Training Dataset Selection",
    "std_review": {
      "summary": "The paper introduces a two-stage greedy algorithm for selecting dataset instances that minimize the KL divergence from a target set. It is evaluated on FashionMNIST, showing improvements over baselines, and discusses theoretical aspects of approximation. While innovative and theoretically sound, the method lacks comprehensive empirical validation and real-world guidance, leading to a weak accept recommendation.",
      "strengths": [
        "Clear theoretical foundation linking KL minimization to instance selection.",
        "Novel two-stage greedy approach for maximizing and then minimizing KL divergence.",
        "Empirical evidence on FashionMNIST supporting effectiveness compared to baselines."
      ],
      "weaknesses": [
        "Complexity in defining the target set X as a mix of high- and low-quality data.",
        "Absence of baselines in experiments limiting interpretability.",
        "Lack of detailed guidance on defining target and initial sets for new domains.",
        "Theoretical analysis of approximation gap could benefit from more empirical validation."
      ],
      "questions": [
        "How should the target set X be defined in practice to align with the goal of KL minimization?",
        "What baselines should be included in future experiments to better assess the method's performance?",
        "How can the method be adapted for real-world applications with diverse data quality?",
        "What is the empirical approximation ratio of the greedy algorithm compared to the optimal solution?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "3nPFco1EKt",
    "title": "Evolving Deep Neural Network's Weights at ImageNet Scale",
    "std_review": {
      "summary": "The paper introduces SA‑SHADE‑tri‑ensin, an innovative ensemble method that iteratively recombines network weights using a novel operator (S₍Trig₎) to enhance performance. It combines Weight Averaging and Sparse Mutation Decomposition, showing significant accuracy and robustness gains over traditional ensembles, especially on complex datasets. While promising, the method's computational complexity and sensitivity to parameters are noted as potential drawbacks.",
      "strengths": [
        "Introduces a novel ensemble approach that innovatively combines WA and SMD with a unique recombination operator.",
        "Demonstrates significant improvements in accuracy and robustness over existing ensemble methods.",
        "Provides a solid theoretical foundation with clear definitions and operations."
      ],
      "weaknesses": [
        "The iterative recombination may increase computational complexity, limiting practicality for very large datasets.",
        "Performance may be sensitive to parameter choices, requiring extensive tuning.",
        "Lacks a comprehensive comparison across a wider range of datasets and models."
      ],
      "questions": [
        "How does the method scale to very large datasets or real-time applications?",
        "What are the optimal parameter settings for different types of models and datasets?",
        "Could a more extensive baseline comparison strengthen the claim of superiority?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3Ok7ccvtf3",
    "title": "Unlearning the Unwanted Data from a Personalized Recommendation Model",
    "std_review": {
      "summary": "The paper presents a novel convolution fusion-based method for unlearning specific data points from a trained recommendation model without full retraining. It introduces the 'fading effect' theorem, providing a theoretical foundation for targeted data removal. Experimental results on synthetic and real datasets demonstrate the method's effectiveness and efficiency compared to baselines. While innovative, the paper has limitations in theoretical accessibility and scalability, and it only addresses unwanted data in the training set.",
      "strengths": [
        "Introduces a novel unlearning method without full retraining.",
        "Provides a solid theoretical framework with the 'fading effect' theorem.",
        "Demonstrates strong empirical performance through comprehensive experiments."
      ],
      "weaknesses": [
        "Theoretical contributions may be challenging for readers without a strong ML background.",
        "Focuses on unwanted data in the training set, not the test set.",
        "Lacks comprehensive evaluation metrics for unlearning effectiveness.",
        "Scalability concerns are not thoroughly addressed."
      ],
      "questions": [
        "How can the theoretical framework be made more accessible to a broader audience?",
        "What is the impact of unwanted data present in the test set on the model's predictions?",
        "How does the method perform in large-scale models or with very large datasets?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3oTPsORaDH",
    "title": "Improving Generalization in Equivariant Graph Neural Networks with Physical Inductive Biases",
    "std_review": {
      "summary": "The SEGNO framework introduces a continuous-time GNN that preserves equivariance while offering precise temporal dynamics, outperforming existing baselines in force field and trajectory prediction tasks across diverse benchmarks. Its theoretical guarantees on bounded errors and comprehensive evaluation metrics highlight its robustness and accuracy, though computational complexity and hyperparameter sensitivity are noted as areas for improvement.",
      "strengths": [
        "Preserves equivariance with continuous-time updates.",
        "Provides strong theoretical guarantees on error bounds.",
        "Demonstrates superior performance across a wide range of benchmarks."
      ],
      "weaknesses": [
        "Introduces computational complexity compared to discrete-time models.",
        "Performance may be sensitive to hyperparameter choices.",
        "Limited extensive baseline comparisons could further validate results."
      ],
      "questions": [
        "How does SEGNO scale to real-time applications with large graphs?",
        "What are the optimal hyperparameter settings for different datasets?",
        "How does SEGNO compare to emerging continuous-time GNN models?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3OzQhhPLyW",
    "title": "Meta-Value Learning: a General Framework for Learning with Learning Awareness",
    "std_review": {
      "summary": "The paper introduces MeVa, a meta‑value function approach for two‑player games that aims to improve upon existing methods like LOLA, HOLA, and COLA. MeVa defines a meta‑value function using a correction‑based formulation to address high variance of policy‑gradient gradients and employs Gaussian noise for exploration. Empirical results on Atari games show competitive performance, but the impact of variance reduction and exploration choices is not fully quantified. Overall, MeVa presents a promising direction with some methodological gaps.",
      "strengths": [
        "Introduces a correction‑based formulation to mitigate high variance in policy‑gradient methods.",
        "Uses Gaussian noise for meta‑level exploration, potentially offering smoother convergence.",
        "Demonstrates strong empirical performance on Atari benchmarks.",
        "Provides a clear theoretical distinction between naive and corrected meta‑value formulations."
      ],
      "weaknesses": [
        "Lacks quantitative variance metrics (e.g., standard deviations, confidence intervals).",
        "Does not compare Gaussian noise exploration with conventional methods.",
        "Limited discussion on scalability beyond two‑player games.",
        "Missing ablation experiments comparing the surrogate formulation directly with the naive one."
      ],
      "questions": [
        "Could you provide standard deviations or confidence intervals for the results to better assess variance reduction?",
        "How does the Gaussian noise strategy compare to ϵ‑greedy or action noise in terms of exploration efficiency?",
        "What are the scalability plans for extending MeVa to multi‑agent settings?",
        "Could ablation experiments directly compare the surrogate formulation (Eq. 6) with the naive formulation (Eq. 5) and standard exploration schedules?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "3P87ptzvTm",
    "title": "Optimal Multiple Transport with Applications to Visual Matching, Model Fusion and Beyond",
    "std_review": {
      "summary": "The paper introduces Optimal Multiple Transport (OMT), extending optimal transport to multiple measures with a cycle-consistency constraint. It proposes an efficient alternating optimization scheme using the Sinkhorn algorithm, demonstrating strong empirical performance on synthetic and real-world datasets. While the theoretical analysis provides conditions for solution existence, convergence guarantees are not fully addressed. The method shows promise but requires clearer guidance on cycle construction and broader empirical validation.",
      "strengths": [
        "Introduces a novel cycle-consistency constraint for multiple measures.",
        "Proposes an efficient alternating optimization scheme leveraging the Sinkhorn algorithm.",
        "Provides a solid theoretical foundation for solution existence under certain conditions.",
        "Demonstrates strong empirical performance on both synthetic and real-world datasets."
      ],
      "weaknesses": [
        "Lacks clear guidelines for optimal ordering of measures in the cycle construction.",
        "Empirical validation is limited to synthetic and a few real-world datasets.",
        "Parameter sensitivity analysis is thorough but lacks a comprehensive ablation study.",
        "Theoretical analysis does not fully address convergence guarantees of the optimization algorithm."
      ],
      "questions": [
        "What are the best practices for selecting the ordering of measures in the cycle construction for $K > 2$?",
        "How can the empirical validation be expanded to cover a wider range of datasets and scenarios?",
        "Could a more comprehensive ablation study on parameter values be conducted to better understand their impact?",
        "What are the convergence guarantees for the proposed optimization algorithm, and how do they compare to existing methods?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3pf2hEdu8B",
    "title": "Rethinking The Uniformity Metric in Self-Supervised Learning",
    "std_review": {
      "raw_text": "{\n  \"summary\": \"The paper introduces a novel $\\mathcal{W}_2$ metric for evaluating the uniformity of self-supervised learning representations, addressing limitations of existing metrics. It demonstrates strong empirical improvements across multiple datasets and frameworks, though it lacks comprehensive theoretical proofs and comparisons. The metric effectively detects dimensional collapse and generally enhances performance when combined with popular frameworks, though results vary by architecture.\",\n  \"strengths\": [\n    \"Introduces a novel $\\mathcal{W}_2$ metric with a solid theoretical foundation.\",\n    \"Demonstrates strong empirical improvements over existing methods on CIFAR-10/100 and other datasets.\",\n    \"Effectively detects and penalizes dimensional collapse across varied dimensions.\"\n  ],\n  \"weaknesses\": [\n    \"Lacks sufficient theoretical proof that the identified criteria are sufficient for an ideal metric.\",\n    \"Does not provide a comprehensive comparison across additional datasets and tasks.\",\n    \"Impact of the $\\mathcal{W}_2$ loss relative to existing $\\mathcal{L}_U$ losses is not fully explored.\"\n  ],\n  \"questions\": [\n    \"Could a more extensive theoretical analysis be provided to prove the sufficiency of the criteria?\",\n    \"What is the relative impact of the $\\mathcal{W}_2$ loss compared to existing $\\mathcal{L}_U$ losses in various frameworks?\",\n    \"How does the metric perform on a broader range of datasets and tasks beyond CIFAR-10/100?\"\n  ],\n  \"overall_score\": \"7: accept\",\n  \"confidence\": \"4: high\"\n}",
      "parse_error": true
    }
  },
  {
    "paper_id": "3pgJNIx3gc",
    "title": "AlphaFold Distillation for Protein Design",
    "std_review": {
      "summary": "The paper introduces AF-Distill, a distilled version of AlphaFold used for protein inverse folding, aiming to improve sequence recovery and diversity. It integrates a structure-consistency loss (SC loss) into baseline models, showing significant gains in sequence recovery and diversity while reducing computational costs. The method is cost-effective and integrates well with existing models, though the marginal gains in other metrics and the choice of regularization coefficient warrant further exploration.",
      "strengths": [
        "Innovative use of a distilled model for protein inverse folding.",
        "Significant improvements in sequence recovery and diversity.",
        "Cost-effective training with reduced computational overhead."
      ],
      "weaknesses": [
        "Marginal gains in metrics like perplexity.",
        "Trade-offs in training cost due to dataset choice.",
        "Discretized 50-bin output for pTM/pLDDT scores may limit precision.",
        "Optimal regularization coefficient (α) not fully explored."
      ],
      "questions": [
        "How does the choice of training datasets affect the generalizability of AF-Distill?",
        "What is the optimal value of the regularization coefficient (α) for the SC loss?",
        "How do the discretized pTM/pLDDT scores compare to direct regression approaches in terms of interpretability and precision?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3pWSL8My6B",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a novel method for analyzing the sensitivity of deep neural networks (DNNs) to input perturbations through the concept of 'Sensitivity Sets' (S). It provides a practical approach to identify and quantify the impact of input variables on model predictions, offering insights into model robustness and interpretability. While the method is demonstrated across various DNN architectures and datasets, its applicability is limited to DNNs. The paper is well-explained but lacks error analysis and clear guidelines for forming Sensitivity Sets, which could affect its reliability and generalizability.",
      "strengths": [
        "Introduces a novel concept of Sensitivity Sets (S) to analyze DNNs, providing a new perspective on model interpretability.",
        "Proposes a practical method for identifying and quantifying the impact of input variables on model predictions.",
        "Demonstrates the method's effectiveness across a range of DNN architectures and datasets, highlighting its versatility."
      ],
      "weaknesses": [
        "The method is primarily applicable to DNNs, limiting its generalizability to other AI models.",
        "The process of forming Sensitivity Sets is not clearly defined, potentially leading to subjective interpretations.",
        "Lacks error bars and analysis of results across multiple random seeds, impacting the reliability of findings."
      ],
      "questions": [
        "Should the title be revised to reflect the method's specificity to DNNs?",
        "What criteria or guidelines can be provided for forming Sensitivity Sets to improve reproducibility?",
        "Could including error bars and analyzing results across multiple random seeds strengthen the robustness of the findings?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "3PWYAlAQxv",
    "title": "Neural Networks Trained by Weight Permutation are Universal Approximators",
    "std_review": {
      "summary": "The paper proposes a novel training method for neural networks that uses weight permutations to enhance generalization. The approach is theoretically grounded in the approximation of step functions by permutations and empirically shown to improve performance on unseen data. While the method demonstrates significant benefits, several aspects, such as the selection of the permutation period and the generalizability to other activation functions, remain underexplored.",
      "strengths": [
        "Introduces a unique training paradigm leveraging permutations to improve model generalization.",
        "Provides a clear theoretical justification linking permutations to step function approximation.",
        "Demonstrates substantial empirical improvements across various datasets."
      ],
      "weaknesses": [
        "Lacks justification for the choice of permutation period k.",
        "Insufficient exploration of training dynamics, particularly in Fig. 1.",
        "Does not thoroughly investigate the impact of sparse training.",
        "Theoretical analysis is limited to ReLU activation functions."
      ],
      "questions": [
        "What criteria were used to select the permutation period k, and how does it affect flexibility and robustness?",
        "Could you provide a deeper analysis of the training dynamics illustrated in Fig. 1, especially the thread-like patterns observed?",
        "How does the method perform with sparse training, where a subset of weights is initialized to zero?",
        "What is the generalizability of the findings to other activation functions beyond ReLU?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "3QkzYBSWqL",
    "title": "Universal Backdoor Attacks",
    "std_review": {
      "summary": "The paper introduces a novel universal backdoor attack that can be transferred across different target classes in deep neural networks, even when those classes are far apart in the latent space. The attack leverages a surrogate classifier to extract latent features, which are then manipulated to embed a backdoor trigger. While demonstrating effectiveness on several models and comparing against defenses, the paper acknowledges limitations such as trigger visibility and high sample efficiency. Overall, the work advances the field but requires addressing these practical concerns for broader deployment.",
      "strengths": [
        "Novelty of Universal Transferability: Demonstrates that a single backdoor trigger can be transferred across multiple target classes.",
        "Robust Surrogate Classifier Design: Uses a surrogate classifier with distinct latent representations for each target class to facilitate backdoor injection.",
        "Empirical Validation: Provides extensive experiments across multiple datasets and model architectures, showing consistent performance."
      ],
      "weaknesses": [
        "Trigger Visibility: Generated triggers may be detectable by human observers or advanced input-space defenses.",
        "Sample Efficiency: Requires a high number of poisoned samples (e.g., 0.39% of the dataset), which may limit feasibility in real-world scenarios.",
        "Defensive Robustness: Defense parameters were optimized against a specific baseline, and their robustness against the proposed universal attack is not fully explored.",
        "Latent Space Complexity: Requires a surrogate classifier with a distinct latent representation for each target class, which may be restrictive."
      ],
      "questions": [
        "How can the attack be made more stealthy to avoid detection by human observers or advanced input-space defenses?",
        "What is the impact of using a surrogate classifier with a more general latent space on the attack's effectiveness?",
        "How does the proposed method compare to other universal backdoor attacks in terms of sample efficiency and robustness?",
        "Can the attack be extended to more complex or diverse model architectures beyond those with distinct latent spaces?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "3QLkwU40EE",
    "title": "",
    "std_review": {
      "summary": "The paper introduces Spatial Prompt Tuning (SPT), a method that learns spatial prompts to guide object detection models. The approach shows improved performance on standard benchmarks and enhances model interpretability. While innovative, the paper lacks quantitative validation of prompt sparsity and clarity in some methodological details, leading to a weak accept recommendation.",
      "strengths": [
        "Novelty of Spatial Prompts: Learning discriminative spatial prompts is a fresh approach to improving object detection interpretability.",
        "Integration with Existing Frameworks: SPT can be seamlessly integrated with current object detection models without major modifications.",
        "Empirical Performance: Experiments demonstrate clear gains in detection accuracy and interpretability."
      ],
      "weaknesses": [
        "Interpretability of Learned Prompts: The paper does not quantitatively validate the sparsity or localization of the learned prompts.",
        "Ablation Experiment Design: Ablation experiments could be more comprehensive, including a baseline where model parameters are trained to convergence before SPT parameters.",
        "Training Design Clarification: The training procedure for different values of k is not fully justified, and results for combined training are not detailed.",
        "Comparison with Global Prompts: The paper does not fully explore how increasing the number of global prompts affects performance.",
        "Clarity in Methodology: The distinction between SPTNet and SPTNet-P is not clearly explained in the main text.",
        "Use of Prompts as Augmentations: The paper assumes network invariance to learned prompts without fully investigating the implications."
      ],
      "questions": [
        "Can you provide quantitative validation of the sparsity and localization of the learned SPT parameters?",
        "Could you include an ablation experiment where model parameters are trained to convergence before training SPT parameters?",
        "How does increasing the number of global prompts (as in Bahng et al.) affect performance compared to SPT?",
        "Please clarify the distinction between SPTNet and SPTNet-P in the main text.",
        "Could you explore the implications of assuming network invariance to learned prompts on performance?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "3qo1pJHabg",
    "title": "Lrr: Language-Driven Resample Continuous Representation against Adversarial Tracking Attacks",
    "std_review": {
      "summary": "The paper introduces LRR, a lightweight defense method that enhances the robustness of template-based trackers against adversarial attacks. Experiments show significant improvements in precision and IoU over baselines like SiamRPN++, while maintaining low computational overhead. The defense is evaluated on multiple benchmarks, demonstrating robustness across diverse scenarios. Overall, the paper is well‑structured and technically sound, though it could benefit from additional comparisons and evaluations.",
      "strengths": [
        "Effectiveness Against Adversarial Attacks: LRR significantly improves precision and IoU against RTAA, IoUAttack, and CSA.",
        "Lightweight and Efficient: The method introduces minimal computational overhead, suitable for real-time tracking.",
        "Broad Applicability: Evaluated on multiple benchmarks, showcasing robustness across diverse scenarios."
      ],
      "weaknesses": [
        "Limited Comparison with Advanced Defenses: LRR is primarily compared to baseline methods without extensive comparison to more advanced adversarial defenses.",
        "No Evaluation on Transformer-Based Trackers: The paper lacks experiments on state-of-the-art transformer-based trackers.",
        "Potential Overfitting: There is a lack of detailed analysis on potential overfitting issues.",
        "No Discussion on Natural Language-Based Trackers: The defense is not adapted or evaluated for natural language-based trackers."
      ],
      "questions": [
        "Implementing Diffusion for Tracking Defense: Effectiveness and computational trade-offs compared to DiffPure.",
        "More Visualization Results: Include high-resolution visualizations of clean images, adversarial examples, and defense examples.",
        "Effectiveness of the Proposed Method on the Entire Search Image: Clarify how the entire search image is reconstructed.",
        "Comparison with Basic Defense Methods: Compare LRR with resizing, compression, and adversarial training techniques.",
        "Clarification of Attack Implementation in Experiments: Provide detailed implementation details for each attack.",
        "Evaluation on More Challenging Benchmarks: Assess robustness on TrackingNet and TNL2K.",
        "Experiments with Transformer-Based Trackers: Evaluate LRR on state-of-the-art transformer-based trackers.",
        "Incorporation of Natural Language-Based Trackers: Discuss challenges and approaches for adapting LRR to natural language-based trackers."
      ],
      "overall_score": "6: weak accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3QR230r11w",
    "title": "Multi-Fidelity Active Learning",
    "std_review": {
      "summary": "The paper presents a novel multi-fidelity active learning algorithm that leverages GFlowNets to efficiently query expensive black-box objective functions in scientific discovery. It balances exploration and exploitation while improving sample efficiency and diversity of discovered candidates compared to baselines. The authors demonstrate practical implications across domains but note limitations in scalability and robustness to noise.",
      "strengths": [
        "Addresses a critical challenge in scientific discovery by efficiently querying expensive high-fidelity functions.",
        "Integrates GFlowNets with multi-fidelity active learning to balance exploration and exploitation.",
        "Demonstrates improved sample efficiency and diversity of discovered candidates over existing methods."
      ],
      "weaknesses": [
        "Complexity of GFlowNets may limit applicability to smaller-scale problems.",
        "Relies on a well-defined acquisition function that may be hard to define in practice.",
        "Performance sensitive to oracle costs, acquisition function, and batch size, requiring careful tuning.",
        "Lacks detailed analysis of scalability in high-dimensional input spaces.",
        "No robustness analysis to noise and outliers in high-fidelity data."
      ],
      "questions": [
        "How scalable is the proposed approach to high-dimensional input spaces?",
        "What is the robustness of the algorithm to noise and outliers in the high-fidelity data?",
        "Can the diversity-promoting term in the acquisition function be generalized to other domains?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3rBu7dR7rm",
    "title": "Unified Long-Term Time-Series Forecasting Benchmark",
    "std_review": {
      "summary": "The paper introduces a comprehensive LTSF benchmark that evaluates both synthetic and real-life datasets, highlighting the effectiveness of newer models like N-HITS and PatchTST. While the benchmark is innovative, it has limitations such as a limited number of real-life datasets and lack of detailed hyperparameter tuning information. Overall, the paper is well-structured and provides valuable insights into LTSF research.",
      "strengths": [
        "Innovative benchmark design that includes both synthetic and real-life datasets.",
        "Diverse synthetic datasets designed to introduce long-term dependencies and complex patterns.",
        "Comprehensive comparison of classical and newer forecasting models."
      ],
      "weaknesses": [
        "Limited number and diversity of real-life datasets.",
        "Lack of detailed information on hyperparameter tuning.",
        "Potential bias in model selection."
      ],
      "questions": [
        "Could the benchmark be extended to include more diverse real-life datasets?",
        "What are the specific hyperparameter tuning strategies used for each model?",
        "How can the benchmark address potential biases in model selection?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3RfGSbXUt8",
    "title": "",
    "std_review": {
      "summary": "The paper introduces Option Boosting, a hierarchical reinforcement learning method that learns a set of options to solve complex tasks more efficiently. It demonstrates improved performance on gridworld scenarios and addresses the issue of redundant option-policies. However, the paper lacks a comprehensive comparison with existing methods and a detailed analysis of redundant options, and the experiments are limited to controlled gridworld settings.",
      "strengths": [
        "Introduces a novel hierarchical reinforcement learning approach that can potentially improve efficiency and performance.",
        "Evaluates the method on gridworld scenarios, providing a clear environment to demonstrate effectiveness.",
        "Addresses the issue of redundant option-policies, an important consideration in hierarchical reinforcement learning."
      ],
      "weaknesses": [
        "Does not provide a comprehensive comparison with other existing hierarchical reinforcement learning methods.",
        "Experiments are limited to gridworld scenarios, which may not fully capture the complexity of real-world environments.",
        "Lacks a detailed analysis of how redundant option-policies are effectively addressed in the proposed framework.",
        "Experiments use only 4 seeds, which may not provide a reliable estimate of the method's performance."
      ],
      "questions": [
        "How does Option Boosting compare to other state-of-the-art hierarchical reinforcement learning methods in terms of efficiency and performance?",
        "What is the impact of redundant option-policies on the performance of Option Boosting, and how is this addressed?",
        "How does the method perform in more complex environments beyond gridworld scenarios?",
        "What is the variance of the results reported in the experiments, and how does this affect the reliability of the findings?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "3rmpixOjPS",
    "title": "Boosting Vanilla Lightweight Vision Transformers via Re-parameterization",
    "std_review": {
      "summary": "The paper introduces TDRL, a Transformer-based architecture that enhances lightweight Vision Transformers for image classification, achieving superior performance over existing models like VanillaNet, especially with limited data. It employs a pyramid multi-branch structure and batch normalization in linear layers to improve efficiency and stability. While demonstrating strong results, the increased model complexity and potential for overfitting are noted as areas for future work.",
      "strengths": [
        "TDRL achieves superior performance over existing lightweight ViT models, particularly in data-scarce scenarios.",
        "The pyramid multi-branch structure and batch normalization in linear layers contribute to a more efficient and stable model.",
        "The re-parameterization technique shows promise for broader applicability beyond Vision Transformers."
      ],
      "weaknesses": [
        "Increased model complexity may lead to higher computational costs during inference.",
        "Risk of overfitting, especially with limited training data, could limit generalization.",
        "Empirical validation of TDRL's effectiveness in diverse tasks or datasets is needed."
      ],
      "questions": [
        "How does TDRL perform on larger datasets compared to VanillaNet?",
        "What strategies can be employed to mitigate overfitting in scenarios with limited data?",
        "How can the re-parameterization technique be adapted for other neural network architectures?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3ROGsTX3IR",
    "title": "",
    "std_review": {
      "summary": "The paper investigates the scaling behavior of a neural network model in the infinite-width limit, identifying a phase transition related to feature learning. It employs a mean‑field parameterization and saddle‑point approximation to derive an action governing the model’s dynamics, revealing a critical regime where the likelihood term vanishes. While the analysis offers new insights into the limits of feature learning, it has methodological weaknesses such as unclear scaling of noise variance and limited discussion of finite‑width behavior.",
      "strengths": [
        "Clear formulation of the scaling limits",
        "Mean‑field parameterization simplifies analysis and highlights feature learning",
        "Identification of a phase transition in model dynamics",
        "Connection to existing work on phase transitions in neural networks"
      ],
      "weaknesses": [
        "Likelihood term vanishes in the infinite‑width limit, potentially obscuring complex feature capture",
        "Unclear justification for scaling noise variance with respect to model parameters",
        "Analysis primarily focused on infinite‑width limit, with limited discussion of finite‑width behavior",
        "Lack of detailed comparison with alternative methods"
      ],
      "questions": [
        "How does the vanishing likelihood term in the infinite‑width limit affect the model's ability to capture complex features?",
        "What is the precise justification for the scaling of noise variance with respect to model width, depth, and data size?",
        "How do the observed phase transitions translate to finite‑width networks, and what are the practical implications?",
        "Could a more detailed comparison with sampling‑based approaches provide additional insights into the strengths and limitations of the saddle‑point approximation?"
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "3SJE1WLB4M",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a spectral profile Λ for Gaussian kernel matrices, aiming to bound the generalization error of kernel ridge regression. It connects the continuous kernel to its discretized version used in practice, providing a novel learning measure ρ. While the theoretical framework is promising, ambiguities in parameter definitions and limited formalization of some conjectures reduce confidence in the results.",
      "strengths": [
        "Introduces a novel spectral profile Λ that offers a fresh perspective on bounding generalization error in kernel ridge regression.",
        "Provides a rigorous framework linking the continuous kernel to its discretized counterpart, bridging theory and practice.",
        "Defines a learning measure ρ that serves as a meaningful proxy for excess risk, directly relating to the spectral profile Λ."
      ],
      "weaknesses": [
        "The role of the parameter P in defining Λ is not fully clarified, leaving ambiguity about whether it represents the exact or numerical rank of the kernel.",
        "The conjecture on discretization errors lacks formalization, making it difficult to assess its validity without additional assumptions.",
        "The analysis primarily covers gradient flow, with limited discussion on its application to gradient descent, potentially limiting practical applicability.",
        "Assumptions on the discrete kernel may not hold for all data models, posing challenges for generalization."
      ],
      "questions": [
        "Can the parameter P be formally distinguished between exact and numerical rank to clarify its role in controlling generalization error?",
        "How can the conjecture on discretization errors be formally stated and proven to address convergence rates under appropriate conditions?",
        "What additional assumptions or conditions are required to extend the analysis from gradient flow to gradient descent, ensuring similar convergence properties?",
        "How can the theory be generalized to other kernels or data models beyond the current assumptions?"
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "3sOE3MFepx",
    "title": "PDE-Diffusion: Physics guided diffusion model for solving partial differential equations",
    "std_review": {
      "summary": "The PDE-Diffusion model introduces a novel approach to solving PDEs by integrating physics-based priors into a diffusion process. It defines two noise terms for initial and boundary physics, enhancing temporal coherence and accuracy. While promising, the model's computational cost and limited dataset evaluation are notable concerns.",
      "strengths": [
        "Incorporation of physics-based priors ensures generated solutions respect physical constraints.",
        "Probabilistic framework naturally handles uncertainty and captures a wider range of physical behaviors.",
        "Improved temporal coherence through multiple diffusion steps allows for more accurate intermediate and future state predictions."
      ],
      "weaknesses": [
        "High computational cost may limit applicability in real-time or resource-constrained environments.",
        "Limited comparison with existing methods could strengthen claims about superiority.",
        "Evaluation based on only two new datasets may not fully capture model performance across various PDEs.",
        "Complexity of implementing physics-based priors could make the model challenging to use."
      ],
      "questions": [
        "How does the model perform on high-dimensional or complex PDEs beyond the evaluated datasets?",
        "What is the impact of the computational cost on real-world applications, and are there strategies to mitigate it?",
        "Could the model be extended to handle PDEs with unknown or complex physical interactions?"
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "3TAhlGaMKD",
    "title": "",
    "std_review": {
      "summary": "The paper investigates the security of Instruction Tuned (IT) models against membership inference and backdoor attacks, demonstrating vulnerabilities that can be exploited by subtly altering training data. It compares the robustness of IT models with standard fine-tuning, Sparse Prompt Tuning (SPT), and Low-Rank Adaptation (LoRA) across various datasets, finding LoRA to be most secure against membership inference attacks. While the study provides valuable insights into real-world risks, it has limitations such as limited granularity in membership inference attacks and variability in backdoor attack results.",
      "strengths": [
        "Comprehensive analysis of model vulnerabilities through membership inference and backdoor attacks.",
        "Methodological rigor with diverse datasets and multiple model adaptation techniques.",
        "Clear and well-documented experimental setup facilitating replication."
      ],
      "weaknesses": [
        "Limited scope of membership inference focusing on the entire prompt rather than individual examples.",
        "Lack of diversity in backdoor labels tested, only using label 0.",
        "Potential for overfitting in backdoor implementation due to concatenating clean and backdoored samples.",
        "High variability in backdoor attack success rates, possibly due to insufficient sample size or model initialization variability."
      ],
      "questions": [
        "How does the paper address the potential for more granular membership inference attacks beyond the entire prompt?",
        "What are the implications of the variability in backdoor attack results on the generalizability of the findings?",
        "Could the use of different backdoor labels provide a more comprehensive understanding of model susceptibility?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "3tjTJeXyA7",
    "title": "Revitalizing Channel-dimension Fourier Transform for Image Enhancement",
    "std_review": {
      "summary": "The paper presents a novel approach to image enhancement using a channel-dimension Fourier Transform (CFTL) and its variants. It demonstrates significant improvements over existing methods on exposure correction tasks and shows strong generalization across diverse datasets. While innovative and empirically effective, the method's complexity and computational cost are notable concerns, and its broader applicability beyond exposure correction remains unproven.",
      "strengths": [
        "Innovative modeling of channel discrepancy using Fourier transforms.",
        "Versatility across multiple variants tailored for different enhancement aspects.",
        "Strong empirical performance on exposure correction tasks."
      ],
      "weaknesses": [
        "Increased implementation complexity due to multiple variants and Fourier transforms.",
        "Potential high computational cost, especially in global pooling spaces.",
        "Limited demonstrated effectiveness on tasks beyond exposure correction."
      ],
      "questions": [
        "How can the computational overhead of Fourier transforms be mitigated for resource-constrained environments?",
        "What is the impact of the proposed method on other image enhancement tasks such as denoising or super-resolution?",
        "Could the method be extended to handle non-image data with similar channel discrepancy issues?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3tM1l5tSbv",
    "title": "Generative Learning for Solving Non-Convex Problem with Multi-Valued Input-Solution Mapping",
    "std_review": {
      "summary": "The paper presents a novel generative framework for solving non-convex optimization problems by learning the probability distribution of optimal solutions. It demonstrates improved performance over existing methods on benchmark problems, highlighting the potential of generative models in optimization. However, the lack of a detailed theoretical analysis and limited experimental scope are noted as areas for improvement.",
      "strengths": [
        "Introduces a unique generative framework for optimization.",
        "Effectively learns the probability distribution of optimal solutions.",
        "Demonstrates superior performance compared to existing methods."
      ],
      "weaknesses": [
        "Lacks a detailed theoretical analysis.",
        "Experimental setup is limited to a few benchmark problems.",
        "Does not provide probabilities for samples in Figure 3."
      ],
      "questions": [
        "Could a more detailed theoretical analysis strengthen the credibility of the proposed method?",
        "How can the experimental scope be expanded to better generalize the results?",
        "What are the specific limitations of the proposed method, and how can they be addressed?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3UWuFoksGb",
    "title": "Learning Planning Abstractions",
    "std_review": {
      "summary": "The paper presents a novel planning abstraction method for robots that converts natural language instructions into detailed execution plans using an abstract transition model and a feasibility function. It demonstrates improved efficiency and adaptability over baselines, especially in handling complex tasks. However, it lacks thorough handling of ambiguous language inputs and comprehensive evaluation across diverse scenarios, leading to a weak accept recommendation.",
      "strengths": [
        "Efficient planning through an abstract transition model that reduces state space complexity.",
        "Robustness via a feasibility function ensuring valid actions.",
        "Natural language interaction enabling new human-robot communication possibilities."
      ],
      "weaknesses": [
        "Limited handling of ambiguous or incomplete language inputs.",
        "Training on demonstrations may restrict generalizability.",
        "Unclear feasibility function training process.",
        "Evaluation focused on specific tasks, not covering a broad range of scenarios."
      ],
      "questions": [
        "How does the system resolve ambiguities or incomplete language inputs?",
        "What is the dataset and size used for training the feasibility function?",
        "How does the system perform when evaluated on a wider variety of tasks beyond the specific experiments?"
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "3VD4PNEt5q",
    "title": "Fusion is Not Enough: Single Modal Attacks on Fusion Models for 3D Object Detection",
    "std_review": {
      "summary": "The paper introduces a novel adversarial attack on 3D object detection models, specifically targeting camera-LiDAR fusion systems. It demonstrates high success rates in both simulation and real-world scenarios, effectively deceiving the system into classifying pedestrians as vehicles under various lighting conditions. While innovative, the attack's limited scope to pedestrian detection and the complexity of patch placement in real-world conditions are noted as weaknesses. Overall, the paper is technically strong and warrants acceptance.",
      "strengths": [
        "Innovative adversarial patch attack targeting camera-LiDAR fusion systems",
        "Demonstrates high effectiveness in both simulated and real-world scenarios",
        "Shows robustness across varying lighting conditions"
      ],
      "weaknesses": [
        "Focused only on pedestrian detection, limiting broader applicability",
        "Patch placement in real-world conditions is complex and challenging",
        "Ethical implications of deploying such attacks are not fully addressed"
      ],
      "questions": [
        "How can the attack be extended to other object types beyond pedestrians?",
        "What strategies can be employed to simplify patch placement in diverse real-world environments?",
        "What ethical guidelines should be considered when deploying adversarial attacks on autonomous systems?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3Vw7DQqq7U",
    "title": "LEMON: Lossless model expansion",
    "std_review": {
      "summary": "LEMON presents a method for expanding model capacity by adding layers to existing models like Vision Transformers and BERT without retraining, showing improved performance on larger models. While the approach is versatile and offers insights into learning rate impacts, its generalizability to other architectures and the theoretical basis for learning rate effects are underexplored. The incremental expansion strategy is briefly mentioned but lacks detailed analysis.",
      "strengths": [
        "Provides a novel, efficient way to scale model capacity without retraining.",
        "Demonstrates effectiveness across multiple model architectures, showcasing versatility.",
        "Offers valuable insights into optimizing training with learning rate schedules."
      ],
      "weaknesses": [
        "Limited evaluation on diverse architectures reduces generalizability.",
        "Lacks thorough theoretical analysis of learning rate impacts.",
        "Incremental expansion strategy is not extensively explored.",
        "Potential challenges for adapting LEMON to different architectures are not fully addressed."
      ],
      "questions": [
        "How does LEMON perform on non-Transformer architectures like CNNs?",
        "What is the theoretical justification for the observed effects of learning rate schedules?",
        "How does the incremental expansion strategy compare to single-step expansion in terms of stability and performance?",
        "What variant-specific considerations are needed for applying LEMON to pre-LayerNorm Transformer models?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "3WB5hT27zf",
    "title": "Partial Optimal Transport for Open-set Semi-supervised Learning",
    "std_review": {
      "summary": "The paper introduces a novel approach to Open-Set Semi-Supervised Learning (OSSL) by leveraging Partial Optimal Transport (POT) for detecting out-of-distribution (OOD) samples. The proposed Mass Score Function (MSF) uses the optimal transport plan to score unlabeled samples, distinguishing between in-distribution (ID) and OOD data. Experimental results show superior performance and robustness compared to existing OOD detection techniques in OSSL settings. The method is innovative, providing a clear and interpretable metric for OOD detection, and demonstrates strong effectiveness through comprehensive experiments.",
      "strengths": [
        "Innovative Use of POT: The paper effectively applies POT to the OSSL problem, providing a novel framework for OOD detection.",
        "Mass Score Function (MSF): The MSF offers a clear and interpretable metric for assessing the likelihood of samples being outliers, enhancing the method's practical applicability.",
        "Robustness and Performance: The method outperforms traditional approaches like MTCF, T2T, and OpenMatch, particularly in challenging scenarios with high OOD presence.",
        "Comprehensive Experiments: The paper includes thorough ablation studies and comparative experiments, demonstrating the method's effectiveness and reliability."
      ],
      "weaknesses": [
        "Computational Complexity: The POT approach may introduce significant computational overhead, potentially limiting its applicability to large-scale datasets.",
        "Assumption of Known OOD Distribution: The method assumes a known distribution of OOD data, which may not always be feasible in real-world scenarios.",
        "Limited Generalization: The effectiveness of the MSF may vary across different domains and data types, requiring careful validation in diverse settings."
      ],
      "questions": [
        "How can the computational complexity of the POT approach be mitigated for large-scale datasets?",
        "What strategies can be employed to handle scenarios where the distribution of OOD data is unknown?",
        "How can the proposed method be generalized to work across different domains and data types?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3wL1tj3kqE",
    "title": "Fair Domain Generalization with Arbitrary Sensitive Attributes",
    "std_review": {
      "raw_text": "{\n  \"summary\": \"The paper introduces SISA, a framework that mitigates bias in machine learning models by selectively sampling sensitive attributes during training. It uses a fairness encoder to conditionally concatenate sampled attributes with input data, followed by a latent representation enforcing equalized odds. Experiments show improved fairness without significant performance loss, especially with multiple attributes. The method is evaluated on several datasets and compared to baselines, demonstrating its effectiveness. While innovative, the paper has some theoretical and practical gaps that need addressing.\",\n  \"strengths\": [\n    \"Innovative sampling strategy for incorporating fairness directly into training.\",\n    \"Latent representation approach for enforcing equalized odds.\",\n    \"Strong empirical validation across multiple datasets and configurations.\"\n  ],\n  \"weaknesses\": [\n    \"Lack of detailed ablation studies on the sampling strategy.\",\n    \"Unclear handling of different input and attribute dimensions.\",\n    \"Complex formulation of the equalized odds loss with limited theoretical justification.\",\n    \"No thorough examination of hyperparameter sensitivity.\",\n    \"Limited guidance on balancing generalization and fairness with multiple attributes.\"\n  ],\n  \"questions\": [\n    \"Could the sampling strategy be made more robust with ablation studies?\",\n    \"How does the method handle input and attribute dimension mismatches?\",\n    \"What is the theoretical basis for the equalized odds loss formulation?\",\n    \"How do hyperparameters \\(\\epsilon\\) and \\(\\gamma\\) affect robustness?\",\n    \"What trade-off analysis is provided for increasing numbers of sensitive attributes?\"\n  ],\n  \"overall_score\": \"6: weak accept\",\n  \"confidence\": \"4: high\"\n}",
      "parse_error": true
    }
  },
  {
    "paper_id": "3xDaj4pRna",
    "title": "Sharpness-Aware Minimization Promotes Diverse Feature Learning",
    "std_review": {
      "summary": "The paper introduces a theoretical framework linking feature diversity to model generalization, deriving a mathematical expression and demonstrating empirical benefits of encouraging diverse features via a specific loss term. While offering novel insights and practical guidance, the findings are based on a simplified toy dataset and rely on assumptions about feature disentanglement that may not hold in real-world scenarios. The work is valuable for advancing understanding of feature diversity but has limited immediate impact due to its scope and assumptions.",
      "strengths": [
        "Clear theoretical contribution linking feature diversity to generalization.",
        "Empirical validation on a controlled toy dataset showing improved generalization.",
        "Insightful discussion on feature entanglement and its implications.",
        "Practical guidance for promoting feature diversity in model design."
      ],
      "weaknesses": [
        "Limited scope to toy settings that may not generalize to complex real-world data.",
        "Assumes features can be cleanly separated into easy-to-fit and hard-to-fit categories.",
        "Focuses on second-order terms, potentially overlooking higher-order effects.",
        "Defines diversity narrowly in terms of easy-to-fit and hard-to-fit features."
      ],
      "questions": [
        "How can the theoretical framework be extended to high-dimensional, real-world datasets like ImageNet?",
        "What methods can be used to detect and quantify feature entanglement in real data?",
        "What are the practical implications of ignoring higher-order terms in the theoretical derivation?",
        "How does the concept of feature diversity defined in this paper relate to other notions of robustness and generalization beyond in-distribution settings?"
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "3xHbRLymyZ",
    "title": "DeeDiff: Dynamic Uncertainty-Aware Early Exiting for Accelerating Diffusion Model Generation",
    "std_review": {
      "summary": "DeeDiff introduces an innovative early‑exiting framework for diffusion models that uses an uncertainty estimation module to dynamically decide when to stop sampling. The approach integrates a layer‑wise loss that combines standard diffusion loss with uncertainty‑aware terms, leading to significant improvements in sample efficiency across multiple datasets. While the method shows strong empirical results and a solid theoretical foundation, implementation complexity and scalability concerns are noted. Overall, the paper is well‑received and recommended for acceptance.",
      "strengths": [
        "Introduces a novel early‑exiting mechanism that leverages uncertainty estimation.",
        "Provides a principled layer‑wise loss function that guides early termination.",
        "Demonstrates clear empirical improvements in sample efficiency across diverse datasets."
      ],
      "weaknesses": [
        "The integration of the uncertainty estimation module may add implementation complexity.",
        "Scalability concerns exist for very large models or different architectures.",
        "Empirical comparisons could be more extensive, including state‑of‑the‑art methods."
      ],
      "questions": [
        "How can the implementation complexity of the uncertainty estimation module be reduced for broader adoption?",
        "What further experiments are needed to assess the scalability of DeeDiff to very large diffusion models?",
        "Could the method be extended to other types of generative models beyond diffusion models?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3xHDeA8Noi",
    "title": "Sophia: A Scalable Stochastic Second-order Optimizer for Language Model Pre-training",
    "std_review": {
      "summary": "Sophia is a second-order optimizer that accelerates pre‑training of large language models by stabilizing updates with a clipping mechanism. It shows a 2× speed‑up on benchmark models while maintaining comparable performance, with theoretical guarantees under non‑convex settings. However, scalability to very large models and downstream generalization are not fully demonstrated, and a broader comparison with state‑of‑the‑art methods is limited.",
      "strengths": [
        "Introduces a novel clipping mechanism to stabilize second-order updates in non‑convex landscapes.",
        "Provides theoretical convergence guarantees for non‑convex functions with rapidly changing Hessians.",
        "Demonstrates empirical speed‑up across a range of model sizes with clear ablation studies."
      ],
      "weaknesses": [
        "Limited scalability testing on models with billions of parameters.",
        "No evaluation of downstream task performance beyond pre‑training.",
        "Theoretical guarantees are limited to specific classes of non‑convex problems.",
        "Lacks detailed guidance on hyper‑parameter tuning for the clipping mechanism.",
        "Comparison with state‑of‑the‑art methods is limited to a few competitors."
      ],
      "questions": [
        "How does Sophia scale to models with billions of parameters, such as GPT‑3 or LLaMA?",
        "What are the downstream task performance results on fine‑tuning or few‑shot learning?",
        "Can you provide more detailed guidance on hyper‑parameter tuning for the clipping mechanism?",
        "How does Sophia compare to a broader range of state‑of‑the‑art optimizers in terms of computational cost and implementation effort?"
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "3y1K6buO8c",
    "title": "Brain decoding: Toward real-time reconstruction of visual perception",
    "std_review": {
      "summary": "The paper presents a novel two-stage method for decoding visual information from MEG signals and generating corresponding images. It combines a CNN for feature extraction with a supervised image model (VGG/ResNet) to generate coherent images. While the approach is innovative and empirically validated, several methodological concerns, such as the hyperparameter search for λ and the discussion of temporal resolution, need clarification. Overall, the work is promising with a clear scientific contribution, but these issues should be addressed to strengthen the paper.",
      "strengths": [
        "Innovative integration of MEG decoding with image generation.",
        "Clear methodological framework with transparent evaluation strategy.",
        "Empirical validation showing generated images are coherent with original stimuli."
      ],
      "weaknesses": [
        "Ambiguity in hyperparameter search for λ and its evaluation.",
        "Limited discussion on the temporal resolution of MEG and its impact on low-level detail recovery.",
        "Unclear time windows used for decoding and retrieval analyses.",
        "Potential overemphasis on the scientific insight without a concise statement."
      ],
      "questions": [
        "How was the hyperparameter λ selected for the retrieval task, and was it evaluated on the small test set used for image generation?",
        "How does the temporal resolution of MEG limit the recovery of low-level details, and how does this relate to existing literature?",
        "What specific layers of the supervised image models (e.g., VGG, ResNet) were used, and how does this affect model performance?",
        "Was the retrieval metric (e.g., relative median rank or top-5 accuracy) consistently applied across different window sizes and configurations?",
        "What is the size of the retrieval set used for evaluating top-5 accuracy, and how was it determined?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "3y2TfP966N",
    "title": "T-Rep: Representation Learning for Time Series using Time-Embeddings",
    "std_review": {
      "summary": "The paper introduces T-Rep, a self-supervised framework for time series that learns robust temporal representations using two pretext tasks. It outperforms both supervised and existing self-supervised methods across multiple datasets, demonstrating strong performance and versatility. The theoretical motivation is solid, and the comprehensive evaluation supports its effectiveness, leading to an acceptance recommendation.",
      "strengths": [
        "Innovative dual pretext tasks enhance generalizability of learned representations.",
        "Consistently achieves state-of-the-art results across diverse datasets and tasks.",
        "Provides a clear theoretical foundation linking pretext tasks to capturing temporal dynamics."
      ],
      "weaknesses": [
        "Implementation complexity may limit accessibility for practitioners.",
        "Lacks formal theoretical guarantees for convergence or optimality.",
        "Evaluation could be strengthened by comparing against a broader range of state-of-the-art methods."
      ],
      "questions": [
        "How does T-Rep compare to recent self-supervised approaches beyond those mentioned in the evaluation?",
        "What are the long-term stability and robustness guarantees of the learned representations?",
        "Could the framework be adapted to handle non-stationary or multi-modal time series data more effectively?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3Y7r6xueJJ",
    "title": "Continual Learning in the Presence of Spurious Correlations: Analyses and a Simple Baseline",
    "std_review": {
      "summary": "The paper introduces Bias‑Aware Gradient Stacking (BGS) for contrastive learning, aiming to reduce bias in learned representations. It demonstrates that BGS outperforms existing methods GDumb and DFR in bias reduction across three scenarios, though the benefit diminishes with larger datasets. While the paper is well‑structured and provides clear metrics, it lacks a thorough analysis of scalability, robustness across bias types, and potential overfitting issues. Overall, the innovative approach and strong empirical results justify acceptance.",
      "strengths": [
        "Clear problem definition and a concrete bias metric enhance reproducibility.",
        "Introduces a novel bias‑mitigation method by stacking gradients with bias awareness.",
        "Comprehensive comparison with GDumb and DFR highlights BGS's advantages.",
        "Empirical evidence in Table 1 shows significant bias reduction."
      ],
      "weaknesses": [
        "Limited scalability insights; reasons for reduced improvement with larger datasets are not explored.",
        "Lack of robustness analysis across different bias types or data distributions.",
        "Potential overfitting in scenarios with limited data is not addressed.",
        "Evaluation relies solely on a single bias metric, possibly overlooking other performance aspects."
      ],
      "questions": [
        "Could additional metrics (e.g., accuracy, representation diversity) provide a fuller picture of BGS's impact compared to GDumb and DFR?",
        "What are the underlying reasons for the observed limited scalability of BGS with larger datasets?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3yyGlNHnlj",
    "title": "GraphECL: Towards Efficient Contrastive Learning for Graphs",
    "std_review": {
      "summary": "GraphECL introduces a novel approach to learning on quantum circuits using complementary negative pairs, aiming to improve learning efficiency and accuracy, especially for large or complex circuits. The method shows promise but lacks detailed experimental results, scalability analysis, and thorough theoretical explanation, making it difficult to fully assess its performance and applicability.",
      "strengths": [
        "Introduces a novel approach to learning on quantum circuits using complementary negative pairs, which can potentially enhance learning efficiency and accuracy.",
        "Demonstrates the method's effectiveness on very large or complex quantum circuits, addressing a significant challenge in quantum machine learning.",
        "Provides a clear and structured methodology that can be easily understood and implemented by researchers in the field."
      ],
      "weaknesses": [
        "Lacks detailed experimental results and comparisons with existing methods, making it difficult to fully assess the method's performance and advantages.",
        "Scalability of GraphECL for extremely large quantum circuits is not thoroughly explored, leaving open questions about its practical applicability.",
        "Theoretical underpinnings of the method are not fully explained, which could hinder its adoption by the broader research community.",
        "Does not discuss potential limitations or challenges in implementing GraphECL, such as computational requirements or data availability."
      ],
      "questions": [
        "Could you provide more detailed experimental results and comparisons with existing methods to better assess the method's performance and advantages?",
        "What are the scalability limits of GraphECL for extremely large quantum circuits, and how does it handle increased computational complexity?",
        "Please elaborate on the theoretical foundations of the method to facilitate broader adoption by the research community.",
        "What are the potential limitations or challenges in implementing GraphECL, such as computational requirements or data availability?"
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "3Z1gxuAQrA",
    "title": "PoSE: Efficient Context Window Extension of LLMs via Positional Skip-wise Training",
    "std_review": {
      "summary": "The paper introduces PoSE, a method for efficiently fine-tuning large language models on long-context tasks using prompts. It demonstrates competitive performance on perplexity and downstream tasks, reducing computational costs compared to full-length fine-tuning. While showing promise, the method has limitations in scope, baseline comparison, scalability, and interpretability that warrant further exploration.",
      "strengths": [
        "Efficiently reduces computational resources for long-context fine-tuning.",
        "Achieves comparable or superior performance on standard benchmarks.",
        "Demonstrates versatility across various tasks and datasets.",
        "Grounded in a solid theoretical framework leveraging prompt engineering."
      ],
      "weaknesses": [
        "Evaluation is limited to perplexity and a few downstream tasks.",
        "Lacks comprehensive baseline comparison for robust assessment.",
        "Scalability to larger models remains an open question.",
        "Interpretability of prompt influence on reasoning is underexplored."
      ],
      "questions": [
        "How does PoSE perform on a broader range of long-context tasks beyond those evaluated?",
        "What is the method's scalability to larger model sizes?",
        "Can additional baselines, such as few-shot learning or chain-of-thought prompting, be compared to PoSE?",
        "How do the prompts specifically guide the model's reasoning, and what are the implications for interpretability?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3z60EWfh1p",
    "title": "Geometrically Aligned Transfer Encoder",
    "std_review": {
      "summary": "The paper introduces GATE, a transformer that uses differential geometry to learn cycle-consistent and metric-preserving mappings between heterogeneous data modalities. It outperforms conventional multi-task learning approaches across single-task, multi-task, and knowledge distillation tasks, demonstrating strong theoretical foundations and practical robustness. Despite its innovative approach, the method's complexity and scalability issues limit its accessibility and broad applicability.",
      "strengths": [
        "Innovative use of differential geometry to learn cycle-consistent and metric-preserving mappings.",
        "Robust performance across a variety of tasks, including single-task learning, multi-task learning, and knowledge distillation.",
        "Clear theoretical foundation with rigorous mathematical derivations."
      ],
      "weaknesses": [
        "Complexity of implementation due to reliance on advanced differential geometry concepts.",
        "Potential scalability issues with very large datasets or high-dimensional spaces.",
        "Lack of extensive hyperparameter tuning, which may affect reproducibility and generalization."
      ],
      "questions": [
        "How can the method be made more accessible to practitioners without a strong mathematical background?",
        "What strategies can be employed to improve scalability for very large datasets or high-dimensional spaces?",
        "Could additional hyperparameter tuning improve reproducibility and generalization across different datasets?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3ZDEwhAlCO",
    "title": "ILPO-NET: convolution network for the recognition of arbitrary volumetric patterns",
    "std_review": {
      "summary": "ILPO-Net introduces a novel 3D equivariant convolution method using spherical harmonics combined with orientational pooling. The approach addresses limitations of existing spherical-harmonic and group-convolution techniques by providing a more efficient and flexible framework for handling arbitrary volumetric patterns while maintaining parameter efficiency. Experimental results demonstrate competitive performance on synthetic and real-world datasets, highlighting the method's ability to capture complex spatial and orientational features. The paper is well-structured, with clear contributions, thorough experiments, and a promising direction for future research.",
      "strengths": [
        "Novel integration of spherical harmonics and pooling for 3D equivariant processing.",
        "Parameter-efficient design that reduces computational overhead.",
        "Flexibility to handle a wide range of arbitrary volumetric patterns.",
        "Comprehensive experimental validation with state-of-the-art comparisons."
      ],
      "weaknesses": [
        "Potential complexity in implementation due to the integration of advanced mathematical techniques.",
        "Limited scope of real-world datasets used for evaluation.",
        "Lack of detailed theoretical analysis for the pooling mechanism."
      ],
      "questions": [
        "How does the method scale to very large or highly complex volumetric datasets?",
        "What are the theoretical guarantees regarding the preservation of orientational information?",
        "Could the pooling mechanism be adapted for other types of spatial data beyond 3D volumes?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3zKtaqxLhW",
    "title": "Generalized Knowledge Distillation for Auto-regressive Language Models",
    "std_review": {
      "summary": "The paper introduces Generative Knowledge Distillation (GKD), a method that uses a student model to generate synthetic training data for a teacher model, improving knowledge transfer across summarization, translation, and reasoning tasks. Empirical results show GKD consistently outperforms self-distillation, especially on tasks requiring high diversity, while maintaining competitive accuracy. Despite its innovative approach and strong performance, the method introduces implementation complexity, hyperparameter sensitivity, and potential computational overhead, which could limit its practical adoption.",
      "strengths": [
        "Introduces a generative mechanism to enhance knowledge distillation, offering a fresh perspective.",
        "Promotes a richer set of examples by allowing the student to generate data, potentially improving the teacher's ability to capture diverse knowledge.",
        "Demonstrates significant improvements over self-distillation across multiple tasks and model sizes, highlighting practical benefits.",
        "Provides a clear theoretical rationale for why generating diverse student outputs can lead to better knowledge transfer."
      ],
      "weaknesses": [
        "Adds complexity in both implementation and training, which could be a barrier for some practitioners.",
        "Performance is sensitive to the choice of divergence and teacher temperature, requiring careful tuning.",
        "Increases computational costs due to sampling from the student distribution, potentially limiting scalability for large models.",
        "Lacks a robustness analysis, which could be critical for real-world applications."
      ],
      "questions": [
        "How can the computational overhead of GKD be mitigated for training large models?",
        "What are the long-term stability and robustness of distilled models using GKD, especially under adversarial conditions?",
        "Could the method be adapted to other model architectures beyond auto-regressive language models?",
        "How does GKD perform when applied to tasks with highly structured output formats?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3ZqKxMHcAg",
    "title": "Evaluating Language Model Agency through Negotiations",
    "std_review": {
      "summary": "The paper introduces a novel approach to evaluate Theory of Mind (ToM) in large language models (LLMs) through a structured negotiation framework and a unique faithfulness metric. It compares models initialized as 'average,' 'expert,' and 'novice' across various negotiation games, revealing distinct behavioral patterns linked to their initial skill levels. The study's innovative metric and comprehensive experimental setup make it a valuable contribution to assessing LLM social intelligence, though it has some methodological limitations.",
      "strengths": [
        "Clear definition of ToM in the context of negotiation.",
        "Innovative faithfulness metric for measuring ToM in LLMs.",
        "Diverse model comparisons across different skill levels.",
        "Robust experimental setup with well-defined rules and termination conditions."
      ],
      "weaknesses": [
        "Limited utility function may oversimplify negotiation scenarios.",
        "Fixed prompt design could limit exploration of diverse negotiation styles.",
        "Ambiguity in cross-play scoring computation.",
        "Lack of comparative analysis with prior work."
      ],
      "questions": [
        "How does the choice of utility function impact the evaluation of ToM in LLMs?",
        "Could varying prompts across negotiations reveal more nuanced negotiation behaviors?",
        "How do cross-play scores in Tables 5 and 6 capture the full range of strategic interactions?",
        "What are the implications of the observed strategic structures, such as rock-paper-scissors cycles, for LLM evaluation?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3zQo5oUvia",
    "title": "Retrieval-Based Reconstruction For",
    "std_review": {
      "summary": "The paper introduces REBAR, a method for motif comparison in time series using a convolutional cross-attention mechanism with an intermittent mask during evaluation. It shows strong performance on several datasets, outperforming existing methods in noisy data. However, it lacks comprehensive ablation studies, detailed hyperparameter tuning, and visualizations, and the rationale for mask usage is not fully explored.",
      "strengths": [
        "Introduces a unique intermittent mask strategy for motif comparison.",
        "Leverages convolutional cross-attention to efficiently compare motifs.",
        "Demonstrates strong performance across diverse datasets."
      ],
      "weaknesses": [
        "Lacks comprehensive ablation studies to assess component contributions.",
        "Does not thoroughly discuss hyperparameter tuning.",
        "Few visualizations provided to illustrate learned embeddings.",
        "Rationale for using different masks for training and evaluation is unclear.",
        "Performance evaluated on specific datasets, not diverse characteristics."
      ],
      "questions": [
        "Could you provide more detailed ablation studies to isolate the impact of each component?",
        "What are the detailed hyperparameter tuning procedures and their impact?",
        "Could you include more visualizations to illustrate learned embeddings and identified pairs?",
        "Please clarify the rationale behind using different masks for training and evaluation.",
        "How does REBAR perform on time series with varying lengths, noise levels, or other characteristics?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "3zvB14IF6D",
    "title": "DORSal: Diffusion for Object-centric Representations of Scenes _et al._",
    "std_review": {
      "summary": "DORSal presents a novel framework for 3D scene generation and editing using object slot representations. It leverages an Object Slot Representation Transformer (OSRT) encoder to extract object slots from images, which are then used by a multi-view diffusion decoder to produce high-quality 3D reconstructions. The approach maintains 3D consistency across views and supports practical editing tasks like object removal and transfer with minimal supervision. While demonstrating strong results, the framework's reliance on pre-trained encoders and training complexity are noted limitations.",
      "strengths": [
        "Introduces a novel object slot representation approach for structured 3D scene generation.",
        "Supports efficient scene editing with minimal supervision, making it highly practical.",
        "Ensures 3D consistency across multiple views, crucial for realistic reconstructions.",
        "Designed to be scalable, allowing extension to more complex editing operations."
      ],
      "weaknesses": [
        "Dependence on the quality of the pre-trained OSRT encoder may limit applicability.",
        "Joint training of encoder and decoder introduces additional complexity and computational cost.",
        "Current editing capabilities are limited to object removal and transfer.",
        "Diffusion-based generation may introduce artifacts, especially in complex scenes."
      ],
      "questions": [
        "How can the framework be extended to support more diverse editing operations like translation, rotation, and scaling without additional supervision?",
        "What impact does fine-tuning the pre-trained OSRT encoder during decoder training have on the quality of object representations?",
        "Could ablation studies quantify the contribution of the multi-view diffusion decoder to 3D consistency across views?",
        "What strategies could mitigate the potential for artifacts introduced by the diffusion process in complex scenes?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3ZWdgOvmAA",
    "title": "LumiNet: The Bright Side of Perceptual Knowledge Distillation",
    "std_review": {
      "summary": "LumiNet introduces a perception matrix to enhance knowledge distillation by capturing inter-instance relationships more effectively than traditional methods. The approach recalibrates instance-level logits, leading to significant improvements in tasks requiring precise inter-class and inter-instance modeling. While demonstrating strong performance across heterogeneous architectures, the method introduces additional complexity and may benefit from broader benchmark diversity.",
      "strengths": [
        "Introduces a perception matrix that explicitly models inter-instance relationships, advancing knowledge distillation.",
        "Improves logit calibration, addressing limitations of existing KD techniques that fail to capture complex instance interactions.",
        "Shows robust performance gains across diverse architectures, outperforming both feature-based and traditional logit-based KD methods."
      ],
      "weaknesses": [
        "Adds implementation complexity and computational overhead due to the perception matrix.",
        "Limited benchmark diversity could affect the generalizability of the approach.",
        "Potential for overfitting with additional parameters, though mitigated by regularization."
      ],
      "questions": [
        "How does the perception matrix scale with very large datasets or models?",
        "Can the method be adapted for real-time applications with limited computational resources?",
        "What are the long-term maintenance implications of integrating the perception matrix into existing distillation pipelines?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "41CYtxM2jQ",
    "title": "Boosting Fast and High-Quality Speech Synthesis with Linear Diffusion",
    "std_review": {
      "summary": "The paper presents a waveform generation framework that combines a Transformer-based architecture with a diffusion model for high-quality speech synthesis, achieving competitive results on LibriTTS while balancing synthesis quality and computational efficiency. It shows promise for generalization beyond vocoder tasks but lacks thorough analysis of continuous time step training, the necessity of the Transformer backbone, and detailed ablations on patch size and generalization, which are critical for fully evaluating its impact and broader applicability.",
      "strengths": [
        "Innovative integration of Transformers with diffusion models for improved synthesis quality.",
        "Efficient inference using a single diffusion step, balancing quality and speed.",
        "Strong performance on objective metrics like MCD and F0 CORR compared to state-of-the-art methods."
      ],
      "weaknesses": [
        "Limited analysis of training with continuous time steps and their impact.",
        "No thorough comparison of the necessity and impact of the Transformer backbone.",
        "Single diffusion step performance evaluated only on a few metrics and methods.",
        "Generalization to other tasks not extensively tested.",
        "Missing detailed ablations on patch size and its trade-offs."
      ],
      "questions": [
        "How do continuous time step training effects compare to discrete steps in terms of performance and speed?",
        "What is the necessity and impact of the Transformer backbone compared to alternative architectures like CNNs?",
        "How does the single diffusion step perform subjectively (e.g., MOS) and how does it compare to more comprehensive evaluations?",
        "What are the broader generalization capabilities of the framework beyond vocoder tasks?",
        "What trade-offs exist between patch size, inference speed, and synthesis quality, especially for larger datasets?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "42lcaojZug",
    "title": "Neural Rate Control for Learned Video Compression",
    "std_review": {
      "summary": "The paper presents a novel two-stage learned video compression framework that decouples rate allocation and implementation, using a hyperbolic R-λ model for allocation and a learned transformation for implementation. Experiments show significant RD improvements over existing learned methods and competitive results against traditional coders across multiple datasets. While innovative, the approach introduces additional complexity and lacks thorough ablation studies and out-of-domain validation. Overall, the work is technically sound and makes a strong contribution to learned video compression.",
      "strengths": [
        "Innovative two-stage training process for rate control",
        "Effective use of a hyperbolic R-λ model to capture non-linear RD trade-offs",
        "End-to-end learned pipeline achieving state-of-the-art RD performance",
        "Strong empirical results across diverse datasets"
      ],
      "weaknesses": [
        "Increased training complexity and computational overhead",
        "Potential lack of generalization to all content types and resolutions without further validation",
        "Absence of detailed ablation studies to isolate component contributions",
        "Limited out-of-domain evaluation"
      ],
      "questions": [
        "How does the method perform on very high-resolution or high-frame-rate content?",
        "What are the computational costs of the two-stage training process compared to single-stage alternatives?",
        "Could the hyperbolic model be further optimized or replaced with other non-linear models?",
        "What additional ablation studies would help clarify the impact of each component?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "43cYe4oogi",
    "title": "Understanding Expressivity of Neural KG Reasoning from Rule Structure Learning",
    "std_review": {
      "summary": "The paper presents a novel rule-based formalism for knowledge graphs that integrates structural rules with graph neural networks, aiming to enhance expressivity while maintaining scalability. It introduces two models, QL‑GNN and EL‑GNN, and demonstrates their effectiveness on benchmark datasets, showing improved performance over existing methods. While theoretically rigorous, the paper could improve clarity in defining expressivity and connecting the formalism to real-world data, and provide more detailed explanations of theoretical results.",
      "strengths": [
        "Innovative rule-based formalism that bridges expressivity and scalability.",
        "Strong theoretical foundation with Theorem 4.4 explaining learnability limitations.",
        "Empirical validation on real-world datasets showing clear performance gains."
      ],
      "weaknesses": [
        "Definition of expressivity introduced late, potentially confusing readers.",
        "Lacks clear examples of how the formalism translates to real-world datasets.",
        "Theoretical explanation of Theorem 4.4 is somewhat opaque.",
        "Does not fully address computational constraints for large-scale graphs."
      ],
      "questions": [
        "How should expressivity be defined earlier in the paper to improve clarity?",
        "Can more concrete examples from real datasets better illustrate the practical relevance of the rule structures?",
        "What additional details can be provided in the explanation of Theorem 4.4 to clarify why certain rules cannot be learned?",
        "What strategies can be discussed to mitigate computational challenges when applying the models to very large graphs?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "43flsheS4s",
    "title": "Improving Robustness and Accuracy with Retrospective Online Adversarial Distillation",
    "std_review": {
      "summary": "The paper presents Retrospective Online Adversarial Distillation (ROAD), a method that enhances adversarial robustness and natural accuracy of deep neural networks using soft labels and asymmetric knowledge transfer during online distillation. ROAD shows significant improvements over baselines, with strong ablation studies supporting its components. However, it has higher computational costs and lacks thorough evaluation of stability and generalization. The novelty of ROAD is not fully established compared to existing methods.",
      "strengths": [
        "Introduces a novel approach to adversarial distillation using soft labels and asymmetric knowledge transfer.",
        "Demonstrates significant improvements in both adversarial robustness and natural accuracy.",
        "Provides comprehensive ablation studies and experiments to validate the impact of individual components.",
        "Compares ROAD to multiple state-of-the-art methods, showcasing its competitive performance."
      ],
      "weaknesses": [
        "Higher computational costs and memory requirements compared to other methods.",
        "Stability and generalization across different random seeds and training runs are not thoroughly evaluated.",
        "Novelty of ROAD compared to other adversarial distillation methods is not clearly established."
      ],
      "questions": [
        "How does ROAD's performance compare across different random seeds and training runs?",
        "What is the practical impact of the increased computational costs and memory requirements?",
        "How does ROAD's novelty compare to other adversarial distillation methods in real-world applications?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "43WKxTuJxu",
    "title": "Orthogonal Function Representations for Continuous Armed Bandits",
    "std_review": {
      "summary": "The paper introduces a novel algorithm for handling high-dimensional state spaces in reinforcement learning by leveraging a smoothness assumption on the reward function. It proposes a parameter N to control state space discretization, improving exploration and learning efficiency. Empirical results show improved performance over existing methods, but the algorithm's theoretical guarantees depend on empirical tuning of N, raising concerns about robustness.",
      "strengths": [
        "Novel algorithm leveraging a smoothness assumption for high-dimensional state spaces.",
        "Parameter N provides a clear mechanism for balancing exploration and computational efficiency.",
        "Empirical validation demonstrates practical utility in high-dimensional environments."
      ],
      "weaknesses": [
        "Reliance on an unknown smoothness parameter s introduces complexity.",
        "Empirical tuning of N may limit accessibility and reproducibility.",
        "Theoretical regret guarantee is contingent on the empirical choice of N."
      ],
      "questions": [
        "How can the algorithm be generalized to handle unknown smoothness parameters s without empirical tuning?",
        "What are the theoretical guarantees when N is chosen based on empirical data?",
        "Can the algorithm be extended to scenarios with limited data or computational resources?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "468KWV14ll",
    "title": "Exploration and Anti-Exploration with Distributional Random Network Distillation",
    "std_review": {
      "summary": "The paper introduces SAC‑RND, a method that combines Random Network Distillation (RND) with Soft Actor-Critic (SAC) to improve offline reinforcement learning. It proposes using RND to generate intrinsic rewards that encourage exploration in offline settings, demonstrating competitive performance on MuJoCo tasks compared to online baselines. While the approach is innovative and shows promise, it faces challenges such as unclear intrinsic reward design, limited backpropagation from the reward, and sensitivity to hyperparameters.",
      "strengths": [
        "Innovative integration of RND with SAC to enhance offline RL performance.",
        "Demonstrates that RND can effectively guide SAC in offline settings.",
        "Provides strong empirical evidence on MuJoCo tasks, showing practical utility."
      ],
      "weaknesses": [
        "Poor performance in some experiments compared to online baselines.",
        "Lack of clear definition of the desired distribution influenced by intrinsic rewards.",
        "Absence of backpropagation from the intrinsic reward complicates policy optimization."
      ],
      "questions": [
        "How can the intrinsic reward design be improved to better guide exploration in offline settings?",
        "What is the impact of λ parameters on SAC‑RND performance across different offline datasets?",
        "Could additional ablation studies clarify the contribution of each component to the final results?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "47hDbAMLbc",
    "title": "",
    "std_review": {
      "summary": "The paper advances the theoretical understanding of robust memorization in ReLU networks by proving NP-hardness results and introducing a novel network construction that achieves robust memorization. It extends prior work and offers insights into designing neural networks that balance memorization and adversarial robustness. While the theoretical contributions are strong, practical implementation challenges and generalization limitations are noted.",
      "strengths": [
        "Provides rigorous theoretical analysis of robust memorization complexity, establishing NP-hardness results.",
        "Introduces a concrete construction of ReLU networks that achieve robust memorization, offering a new perspective on network design.",
        "Delivers clear and detailed proofs addressing the challenges of proving NP-hardness in this context.",
        "Highlights significant implications for neural network architecture design, particularly in adversarial robustness."
      ],
      "weaknesses": [
        "Does not extensively address practical optimization challenges for implementing such networks.",
        "Results are limited to specific conditions, with limited exploration of generalization to unseen data.",
        "The defined robust budget may restrict applicability to real-world scenarios requiring more flexible robustness."
      ],
      "questions": [
        "How can the theoretical results be extended to more practical optimization scenarios?",
        "What are the generalization properties of the constructed networks on unseen data?",
        "How can the robust budget be adapted to accommodate broader robustness requirements in real-world applications?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "488A64eOf6",
    "title": "Language Model Decoding as Direct Metrics Optimization",
    "std_review": {
      "summary": "The paper presents a novel decoding framework that simultaneously optimizes multiple human‑evaluated quality aspects (coherence, diversity, and repetition) using a multi‑objective loss function. Empirical experiments show significant improvements over traditional methods across several benchmarks, demonstrating the framework's effectiveness. While the approach is theoretically grounded and flexible for various NLP tasks, it introduces computational complexity and requires careful hyperparameter tuning. Overall, the paper is well‑received with strong empirical evidence and theoretical foundations, though some practical and theoretical concerns remain.",
      "strengths": [
        "Unified Multi‑Objective Optimization: Effectively integrates multiple quality metrics into a single decoding objective.",
        "Theoretical Foundation: Provides a solid theoretical basis for the proposed approach.",
        "Empirical Validation: Demonstrates clear improvements over baseline methods across various benchmarks."
      ],
      "weaknesses": [
        "Computational Complexity: Introduces significant computational overhead due to candidate sampling.",
        "Parameter Sensitivity: Performance is highly sensitive to hyperparameter choices.",
        "Limited Theoretical Guarantees: Lacks rigorous theoretical guarantees for convergence and optimality."
      ],
      "questions": [
        "How can the computational cost be reduced while maintaining the quality gains?",
        "What are the theoretical conditions under which the proposed multi‑objective loss is guaranteed to converge?",
        "How can the framework be adapted for other NLP tasks beyond open‑ended text generation?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "48CXLrx7K3",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a novel method for reconstructing face images from embeddings while preserving privacy, using different face attribute encoders and embedding techniques. It evaluates reconstruction quality and privacy leakage, but lacks detailed explanations of privacy leakage mechanisms and comprehensive comparisons of method components. The reviewer finds the method promising but with some gaps, leading to a weak accept recommendation.",
      "strengths": [
        "Proposes a novel approach to reconstruct face images from embeddings while ensuring privacy.",
        "Improves reconstruction quality by using different face attribute encoders and embedding techniques.",
        "Provides quantitative evaluation of reconstruction quality using similarity scores."
      ],
      "weaknesses": [
        "Does not provide a detailed explanation of how private information is leaked in the reconstructed images.",
        "Lacks a thorough comparison of different face attribute encoder methods and face embedding methods.",
        "The ablation study on loss functions is not fully detailed, and the trade-off between image quality and privacy is not extensively analyzed."
      ],
      "questions": [
        "Can you provide a detailed explanation of the specific mechanisms by which private information is leaked in the reconstructed face images?",
        "How do the different face attribute encoder methods (e.g., FaceNet, ArcFace, SphereFace) compare in terms of performance?",
        "Could you expand the ablation study to provide more detailed insights into the choice of loss functions for each block in StyleGAN?",
        "What is the trade-off between the quality of the reconstructed image and the level of privacy preserved?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "49Tn5mfTy5",
    "title": "Uncertainty Quantification",
    "std_review": {
      "summary": "The paper introduces UA-IB, a method that integrates uncertainty estimation directly into deep learning models, improving robustness and performance. It is theoretically grounded in information theory and demonstrates strong empirical results across various datasets. While computationally efficient, the method's hyperparameter sensitivity and lack of detailed high-dimensional experiments are noted. Overall, the paper is well-received for its innovative approach and practical advantages.",
      "strengths": [
        "Integrates uncertainty estimation directly into the learning process.",
        "Strong theoretical foundation based on information theory.",
        "Demonstrates superior empirical performance across multiple datasets.",
        "Computational efficiency makes it suitable for large-scale applications."
      ],
      "weaknesses": [
        "Hyperparameter selection, especially codebook size, could be more clearly guided.",
        "Lack of detailed experimental results on high-dimensional tasks.",
        "Integration with existing frameworks is not fully explored."
      ],
      "questions": [
        "Can UA-IB be integrated with existing machine learning frameworks without significant modifications?",
        "What are the long-term reproducibility and validation challenges due to the lack of shared code?",
        "How does UA-IB perform on high-dimensional data such as images or language models?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "49z97Y9lMq",
    "title": "LCOT: Linear circular optimal transport",
    "std_review": {
      "summary": "The paper introduces LCOT, a novel extension of Optimal Transport to circular data, providing a solid theoretical foundation and clear mathematical definitions. While it demonstrates effectiveness on synthetic data, it lacks detailed algorithms, real-world experiments, and a comprehensive related work section. The proposed method shows promise for applications in domains dealing with circular data, but the current manuscript does not fully validate its practical utility.",
      "strengths": [
        "Innovative generalization of Optimal Transport to circular data.",
        "Strong theoretical foundation with clear definitions and equivalence to classical Optimal Transport under certain conditions.",
        "Potential for real-world applications in fields like image retrieval and color interpolation."
      ],
      "weaknesses": [
        "Missing detailed algorithm for computing the LCOT barycenter.",
        "Unclear experimental units in presented results.",
        "Absence of real-world benchmarks weakens practical applicability.",
        "Incomplete related work section lacking key references."
      ],
      "questions": [
        "Could the authors provide a more intuitive explanation of the LCOT definition and its extension from classical OT?",
        "Should the equivalence between LCOT and COT barycenters be formally proven, especially in the special case where LCOT recovers COT?",
        "A detailed algorithm or step-by-step description for computing the LCOT barycenter is needed for reproducibility.",
        "The unit of computation time in Figure 4 should be clarified for better interpretation.",
        "Potential real-world applications of LCOT should be discussed, along with suggested experimental setups.",
        "The manuscript should include the reference to 'The Statistics of Circular Optimal Transport' by Hundrieser et al., 2022, to provide a more comprehensive context."
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "49ZYkhEGmv",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a doubly‑efficient debate model for large language models, imposing polynomial‑time constraints on the prover to enhance scalability and efficiency. While it offers strong theoretical guarantees and addresses key limitations of existing debate frameworks, practical implementation challenges and assumptions about oracle reliability remain. Overall, the model is promising but requires further refinement.",
      "strengths": [
        "Efficiency and scalability through polynomial‑time proving constraints.",
        "Constant human‑oracle queries reduce overhead and maintain consistency.",
        "Formal soundness and completeness guarantees ensure reliable outcomes."
      ],
      "weaknesses": [
        "Assumption of polynomial efficiency may be too restrictive for some LLMs.",
        "Reliance on a single unbiased human oracle introduces practical challenges.",
        "Complex implementation of a robust reinforcement‑learning loop between models and human raters."
      ],
      "questions": [
        "How can the model be adapted for scenarios where human feedback is noisy or delayed?",
        "What strategies can mitigate oracle bias without compromising scalability?",
        "How does the model perform when scaled to extremely large or complex problem domains?"
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "4A5D1nsdtj",
    "title": "An Effective Universal Polynomial Basis for Spectral Graph Neural Networks",
    "std_review": {
      "summary": "The paper introduces UniBasis, a polynomial basis aligned with a graph's homophily ratio, and proposes UniFilter to handle both homophilous and heterophilous graphs. Theoretical contributions include spectral frequency alignment and analysis of the basis and filter. Empirical results show strong performance across diverse datasets, though the evaluation could be more comprehensive. Overall, the work is promising with some areas for improvement.",
      "strengths": [
        "Introduces a novel polynomial basis (UniBasis) that aligns with the graph's homophily ratio, addressing limitations of existing polynomial filters.",
        "Proposes a UniFilter that effectively handles diverse graph structures, including both homophilous and heterophilous graphs.",
        "Provides theoretical contributions on the spectral frequency of signal basis vectors and their alignment with homophily ratios.",
        "Demonstrates the effectiveness and adaptability of the proposed method across various datasets and graph structures.",
        "Discusses practical implications and limitations of using estimated homophily ratios for designing the UniBasis and UniFilter."
      ],
      "weaknesses": [
        "Lacks a comprehensive comparison with other state-of-the-art models on a wide range of datasets.",
        "The evaluation section could benefit from more detailed analysis and ablation studies.",
        "Practical implications and limitations of using estimated homophily ratios are not fully explored, especially for real-world large-scale graph datasets with incomplete node labels."
      ],
      "questions": [
        "How does the proposed method perform on real-world large-scale graph datasets with incomplete or noisy node labels?",
        "What is the impact of noisy or missing label information on the performance of the UniFilter?",
        "Could the evaluation be strengthened by comparing the UniFilter with a broader range of state-of-the-art models?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "4aJg9e4nvF",
    "title": "",
    "std_review": {
      "summary": "The paper introduces an optimization‑based feature visualization method for Vision Transformers (ViTs), demonstrating that ViTs preserve spatial information and that the CLS token significantly influences performance. While the method offers deeper insights than existing techniques, it has limitations in visualizing internal operations and could benefit from more detailed discussions and broader comparisons. Overall, the work is well‑executed and highlights key advantages of ViTs over CNNs.",
      "strengths": [
        "Introduces a novel optimization‑based feature visualization technique that provides deeper insights into ViT internals.",
        "Demonstrates that ViTs preserve spatial information better than CNNs through both theoretical and empirical evidence.",
        "Shows the critical role of the CLS token in aggregating information in the final layers of ViTs."
      ],
      "weaknesses": [
        "Visualization of keys, queries, and values is limited, restricting understanding of transformer internals.",
        "Lacks a detailed discussion of the method's limitations compared to other visualization techniques.",
        "Comparison with CNNs is somewhat superficial, lacking in‑depth analysis of architectural differences.",
        "Experimental setup could be expanded to include more ViT architectures and datasets."
      ],
      "questions": [
        "How can the visualization of keys, queries, and values be improved to better understand transformer internals?",
        "What are the specific limitations of the optimization‑based method compared to other visualization approaches?",
        "Could the analysis be extended to more ViT architectures and datasets to strengthen the generalizability of the findings?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "4Ay23yeuz0",
    "title": "Mixed-Type Tabular Data Synthesis with Score-based Diffusion in Latent Space",
    "std_review": {
      "summary": "The paper presents a novel latent diffusion model for generating synthetic tabular data, addressing mixed-type data challenges through a VAE-diffusion hybrid. It demonstrates superior performance in quality metrics and privacy preservation compared to existing methods, though implementation complexity and limited dataset evaluation are noted. Overall, the work is innovative, well-evaluated, and makes a valuable contribution to synthetic data generation.",
      "strengths": [
        "Innovative combination of VAE and diffusion models for mixed-type tabular data synthesis.",
        "Comprehensive evaluation using multiple quality metrics and privacy scores.",
        "Competitive performance against state-of-the-art methods in both quality and efficiency."
      ],
      "weaknesses": [
        "Implementation complexity and potential high computational resource requirements.",
        "Sensitivity to hyperparameter choices, which may complicate optimization.",
        "Limited evaluation on diverse datasets, raising questions about generalizability."
      ],
      "questions": [
        "How can the model's performance be further validated on a broader range of tabular datasets?",
        "What strategies can be employed to reduce the model's sensitivity to hyperparameter selection?",
        "Could the reproducibility of the model be improved with additional documentation or guidelines?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "4aywmeb97I",
    "title": "Tackling the Data Heterogeneity in Asynchronous Federated Learning with Cached Update Calibration",
    "std_review": {
      "summary": "The paper introduces CA2FL, a caching-assisted asynchronous federated learning method that improves efficiency and scalability across diverse architectures. It demonstrates significant gains in convergence speed and resource utilization on CIFAR-10/100 and ResNet-18, with a memory-efficient variant using 4/8-bit quantization. While promising, the method's scalability, handling of practical constraints, and long-term adaptation are not fully explored.",
      "strengths": [
        "Innovative two-stage caching mechanism that dynamically selects model parameters based on their impact on global performance.",
        "Demonstrated broad applicability across various neural network architectures and datasets.",
        "Memory-efficient quantization reduces computational demands on resource-constrained devices."
      ],
      "weaknesses": [
        "Limited scalability testing on complex models like Vision Transformers and larger datasets like ImageNet.",
        "Insufficient discussion on handling practical constraints such as varying data quality and computational overhead.",
        "Lack of analysis on adapting to long-term data shifts or concept drift.",
        "Potential trade-offs between memory overhead reduction and computational complexity."
      ],
      "questions": [
        "How does CA2FL perform on more complex models and larger datasets beyond CIFAR-10/100 and ResNet-18?",
        "What mechanisms does CA2FL employ to address varying data quality and computational overhead compared to traditional FL frameworks?",
        "How does the method adapt to long-term data shifts or concept drift in dynamic environments?",
        "What is the detailed impact of 4/8-bit quantization on convergence rate and model accuracy, especially on resource-constrained devices?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "4bat0pSQBq",
    "title": "Flood Simulation with Physics-Informed Message Passing",
    "std_review": {
      "summary": "The paper presents a physics‑informed graph neural network (GNN) for simulating flood dynamics, using a two‑stage message‑passing framework to capture water retention and dispersion. It shows improved accuracy over traditional ML baselines and competitive results against a state‑of‑the‑art physics solver, with clear theoretical foundations and promising scalability. The reviewer finds the approach strong and viable, recommending acceptance.",
      "strengths": [
        "Physics‑Guided Design: Directly encodes conservation laws into the model.",
        "Two‑Stage Architecture: Separates water retention and dispersion for better accuracy and interpretability.",
        "Theoretical Foundation: Provides a clear mathematical formulation linking GNN layers to shallow‑water equations."
      ],
      "weaknesses": [
        "Static Graph Representation: Assumes a fixed graph derived from DEM, limiting handling of dynamic topographies.",
        "Limited Baselines: Comparison with other models is narrow, potentially missing stronger benchmarks.",
        "Absence of Dynamic Graphs: Relies on static graphs, which may overlook important dynamic edge changes.",
        "Computational Cost: Training and inference are computationally expensive, though competitive in accuracy."
      ],
      "questions": [
        "How can the model be extended to handle dynamic topographies with evolving flood scenarios?",
        "What are the most effective dynamic baselines to compare against in future studies?",
        "How can the computational cost be further reduced while maintaining accuracy?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "4bLXfRd0CX",
    "title": "EMO: Earth Mover Distance Optimization for Auto-regressive Language Modeling",
    "std_review": {
      "summary": "The paper proposes Earth Mover's Diversity Optimization (EMO), a novel approach to training language models that simultaneously maximizes diversity and quality. EMO modifies the standard maximum-likelihood estimation objective by incorporating an Earth Mover's Distance term to measure divergence between model outputs and a diversity prototype. Empirical evaluations on several benchmarks show significant improvements in diversity without sacrificing quality, though some theoretical and practical limitations are noted.",
      "strengths": [
        "Introduces a novel objective that explicitly encourages diversity alongside quality.",
        "Provides a clear theoretical motivation by framing diversity as a minimization problem involving the Earth Mover's Distance.",
        "Demonstrates significant improvements in diversity metrics on standard benchmarks."
      ],
      "weaknesses": [
        "Empirical evidence for convergence properties and robustness is limited.",
        "Computational cost may be high due to Earth Mover's Distance calculations.",
        "Reliance on cosine similarity as the transport cost may not be optimal for all data distributions."
      ],
      "questions": [
        "What are the convergence properties of EMO in practice, especially for very large models or datasets?",
        "How does EMO perform on real-world applications beyond synthetic benchmarks?",
        "Are there alternative similarity metrics that could improve the effectiveness of EMO in certain contexts?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "4bSQ3lsfEV",
    "title": "",
    "std_review": {
      "raw_text": "{\n  \"summary\": \"The paper proposes an Iterative Feature Magnitude (IFM) pruning method for neural networks, aiming to improve model compression by iteratively pruning features based on magnitude. While it demonstrates competitive performance on benchmark datasets and discusses hyperparameter sensitivity, the method lacks detailed ablation studies and a thorough exploration of feature complexity's impact on generalization. The comparison with other pruning techniques is superficial, and the paper does not comprehensively evaluate compression ratios and performance trade-offs.\",\n  \"strengths\": [\n    \"Introduces a novel iterative pruning approach based on feature magnitude.\",\n    \"Evaluates performance on multiple benchmark datasets.\",\n    \"Discusses the importance of hyperparameter sensitivity.\"\n  ],\n  \"weaknesses\": [\n    \"Lacks detailed ablation studies on hyperparameter \\(\\beta\\).\",\n    \"Insufficient exploration of feature complexity's impact on generalization.\",\n    \"Superficial comparison with other pruning techniques.\",\n    \"Does not comprehensively evaluate compression ratios and performance trade-offs.\"\n  ],\n  \"questions\": [\n    \"Should provide ablation studies to illustrate the impact of different \\(\\beta\\) values on performance.\",\n    \"Explore the relationship between feature complexity and generalization performance with more concrete evidence.\",\n    \"Conduct a detailed comparison of the proposed method with other pruning techniques regarding compression ratio and performance trade-offs.\",\n    \"Provide a comprehensive evaluation of the compression ratio and performance trade-offs.\"\n  ],\n  \"overall_score\": \"5: borderline\",\n  \"confidence\": \"3: medium\"\n}",
      "parse_error": true
    }
  },
  {
    "paper_id": "4DoSULcfG6",
    "title": "Chameleon: Increasing Label-Only Membership Leakage with Adaptive Poisoning",
    "std_review": {
      "summary": "The Chameleon attack introduces a dynamic shadow model approach to membership inference, achieving strong empirical performance on CIFAR-100 and VGG-16. While it outperforms existing methods, concerns about empirical validation, overfitting, theoretical assumptions, and lack of robustness evaluation prevent full acceptance.",
      "strengths": [
        "Innovative dynamic shadow model approach that adapts based on real-time feedback.",
        "Strong empirical performance with high true positive rates and low false positives.",
        "Clear theoretical framework and evaluation on benchmark datasets."
      ],
      "weaknesses": [
        "Empirical validation of false positives is limited to observed results.",
        "Concerns about overfitting when increasing training epochs for larger models.",
        "Theoretical analysis relies on assumptions about posterior distributions and poisoning impacts.",
        "Lack of evaluation against simpler defenses like regularization.",
        "Absence of reproducibility details for reported improvements."
      ],
      "questions": [
        "How robust is the Chameleon attack against simpler defenses such as regularization or per-example gradient clipping?",
        "What is the impact of overfitting when increasing training epochs for larger models like VGG-16?",
        "Can the theoretical assumptions about the posterior distribution and poisoning be validated in practice?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "4e0ItHjNo9",
    "title": "Rethinking Counterfactual Fairness:",
    "std_review": {
      "summary": "The paper introduces Protected Class Fairness (PCF), an extension of conventional fairness that incorporates protected attributes into fairness definitions. It provides a theoretical framework and a case study on university admissions with athletic scholarships to illustrate its application. While the paper offers a clear extension of fairness definitions and strong theoretical foundations, it lacks clarity on handling causal effects of protected attributes and justifying attribute selection, and the motivating example is confusing.",
      "strengths": [
        "Clear extension of fairness definitions",
        "Solid theoretical foundation with well-grounded assumptions",
        "Practical motivation through a relevant case study"
      ],
      "weaknesses": [
        "Unclear handling of situations where protected attributes causally affect outcomes",
        "Assumes CF defines protected attributes without sufficient justification",
        "Confusing motivating example that does not clearly demonstrate PCF's superiority"
      ],
      "questions": [
        "How should the method address cases where protected attributes causally affect outcomes?",
        "Why should CF define which attributes are protected, and what justification supports this view?",
        "Could a clearer real-life example better illustrate the benefits of PCF over CF?",
        "How realistic are the assumptions like ignorability in typical fairness applications?",
        "Could structural, graphical models clarify the definitions and examples?"
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "4eJDMjYZZG",
    "title": "Language Model Detectors Are Easily Optimized Against",
    "std_review": {
      "summary": "The paper introduces a fine-tuning method that significantly improves the ability of language models to evade detection by existing content filters, while maintaining text quality. It demonstrates scalability across model sizes and includes extensive evaluations across multiple detectors. However, concerns remain about the technique's generalizability, potential overfitting, and the lack of detailed data or countermeasures.",
      "strengths": [
        "Effective evasion technique with strong scalability.",
        "Minimal impact on text quality, preserving model performance.",
        "Comprehensive evaluation across multiple detectors and model sizes."
      ],
      "weaknesses": [
        "Limited generalization to other detection systems.",
        "Risk of overfitting due to close similarity between training and test data.",
        "Absence of detailed information on training and evaluation datasets.",
        "No exploration of countermeasures or defense strategies."
      ],
      "questions": [
        "How does the evasion technique generalize to detectors beyond those evaluated?",
        "What are the detailed characteristics of the training and evaluation datasets?",
        "Are there any countermeasures or defense strategies proposed to mitigate the described evasion?",
        "How does the technique perform with larger, more complex models?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "4fbFKO4a2W",
    "title": "Guided Sketch-Based Program Induction",
    "std_review": {
      "summary": "The paper introduces a novel approach to program synthesis using Natural Evolution Strategies (NES) to fill in program sketches, demonstrating efficiency in terms of the number of programs explored and wall-clock time. While the method shows promise, particularly in reducing search space and time compared to baseline approaches, its evaluation is limited to toy examples and lacks comprehensive comparison with other state-of-the-art methods. The extension to neural-guided search strategies is discussed but not extensively explored, and the theoretical underpinnings could be further elaborated. Overall, the paper presents a promising direction with some limitations that warrant further investigation.",
      "strengths": [
        "Introduces NES for program synthesis, offering a novel and efficient optimization strategy.",
        "Demonstrates significant efficiency gains over baseline approaches in terms of explored programs and search time.",
        "Explores the potential of extending the algorithm to neural-guided search strategies, opening new research avenues."
      ],
      "weaknesses": [
        "Evaluation is limited to two toy examples, which may not fully capture performance on more complex tasks.",
        "Lacks a comprehensive comparison with other state-of-the-art methods, limiting generalizability.",
        "The extension to neural-guided search strategies is discussed but not extensively explored.",
        "Theoretical underpinnings of the NES approach could be further elaborated."
      ],
      "questions": [
        "How does the method perform on larger, more realistic program synthesis tasks beyond the provided toy examples?",
        "What are the practical benefits and feasibility of integrating neural-guided search strategies into the algorithm?",
        "How does the NES approach compare to other gradient-based optimization techniques in terms of robustness and flexibility?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "4FUa5dxiiA",
    "title": "Risk-Sensitive Variational Model-Based Policy Optimization",
    "std_review": {
      "summary": "The paper introduces β‑VMBPO, a risk‑sensitive reinforcement learning algorithm that extends VMBPO by incorporating a risk parameter β into the variational lower bound. This allows explicit control over risk‑seeking behavior and improves robustness through probabilistic Gaussian ensembles for dynamics modeling. Experimental results show clear advantages over standard MBPO and other baselines across various environments, supporting the method's effectiveness and robustness.",
      "strengths": [
        "Innovative risk control via a risk parameter β in the variational lower bound.",
        "Probabilistic modeling using Gaussian ensembles introduces robustness by capturing uncertainty.",
        "Strong theoretical foundation linking β to risk‑sensitive utility functions.",
        "Empirical validation demonstrates improved risk‑sensitive performance."
      ],
      "weaknesses": [
        "Increased implementation complexity due to learning two models (q and p).",
        "Higher computational overhead from learning models and computing KL divergence.",
        "Tuning of β and KL divergence constraint may be challenging.",
        "Limited evaluation scope could be expanded with more detailed statistics."
      ],
      "questions": [
        "How can practitioners with limited experience in variational inference best implement β‑VMBPO?",
        "What are the recommended strategies for tuning β and the KL divergence constraint in practice?",
        "Could additional experiments on more diverse environments further substantiate the method's robustness?",
        "How does β‑VMBPO perform under extreme risk conditions or in highly uncertain environments?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "4fVuBf5HE9",
    "title": "Towards analyzing self-attention via linear neural networks",
    "std_review": {
      "summary": "The paper introduces a theoretical framework for analyzing a simplified linear‑attention Transformer model, proving linear convergence under certain conditions. While offering valuable insights into training dynamics and the role of linear attention, the results are limited to this specific model and may not directly apply to more complex Transformers. The study highlights potential benefits for understanding poor initialization but lacks comprehensive analysis and comparison to full models.",
      "strengths": [
        "Introduces a novel theoretical framework for a simplified linear‑attention Transformer model.",
        "Provides clear insights into training dynamics and convergence properties.",
        "Makes the analysis accessible and results interpretable due to the simplicity of the model."
      ],
      "weaknesses": [
        "Results are specific to the simplified linear‑attention model and may not extend to more complex architectures.",
        "Theoretical guarantees rely on specific assumptions about initialization and loss functions.",
        "Lacks a comprehensive analysis of loss behavior under poor initialization.",
        "Does not fully compare the simplified model to full Transformers in terms of capturing self‑attention mechanisms."
      ],
      "questions": [
        "How do the theoretical guarantees extend to more complex Transformer architectures?",
        "What is the comprehensive analysis of loss behavior under poor initialization?",
        "How does the simplified model compare to full Transformers in practical applications?",
        "What are the practical implications of the findings for training real-world Transformers?"
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "4g02l2N2Nx",
    "title": "The Hedgehog & the Porcupine: Expressive Linear Attentions with Softmax Mimicry",
    "std_review": {
      "summary": "The paper introduces Hedgehog, a linear attention mechanism that captures the beneficial properties of softmax attention while achieving linear computational complexity. It evaluates Hedgehog across three settings and demonstrates competitive performance on NLP and vision benchmarks, indicating its potential for generalization. However, scalability and cross-modal applicability are noted as limitations. Overall, the paper is well‑structured, clearly presented, and makes a significant contribution to the field.",
      "strengths": [
        "Preserves softmax attention properties like low entropy and dot‑product monotonicity.",
        "Achieves linear computational complexity, improving efficiency over traditional quadratic attention.",
        "Provides comprehensive evaluation across multiple settings, showing robust performance.",
        "Shows promise for cross‑modal generalization beyond NLP."
      ],
      "weaknesses": [
        "Scalability concerns for very large models (e.g., 1 B+ parameters).",
        "Limited empirical evidence for cross‑modal generalization.",
        "Implementation details for MLP initialization and training are not fully detailed.",
        "Lack of extensive ablation studies to isolate the contribution of each component."
      ],
      "questions": [
        "How does Hedgehog scale to extremely large models (e.g., 1 B+ parameters)?",
        "What further ablation studies are needed to better understand the contribution of each component?",
        "How does Hedgehog perform on out‑of‑distribution data for vision tasks?",
        "What initialization strategies could improve reproducibility and performance?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "4GfEOQlBoc",
    "title": "",
    "std_review": {
      "raw_text": "{\n  \"summary\": \"The paper introduces a theoretical framework to quantify perceptual sensitivity using a probabilistic model, deriving parametric predictions for perceptual metrics and validating them with additive uniform noise experiments. It aims to bridge algorithmic and human perception, offering actionable insights but with some methodological and interpretational limitations.\",\n  \"strengths\": [\n    \"Clear theoretical foundation with rigorous mathematical formulation.\",\n    \"Novel parametric predictions for perceptual metrics.\",\n    \"Empirical validation using straightforward computational experiments.\"\n  ],\n  \"weaknesses\": [\n    \"Definition of perceptual sensitivity may oversimplify human perception.\",\n    \"Ambiguity in treating the probability factor \\(p(x)\\) as either PDF or PMF.\",\n    \"Choice of additive uniform noise may not capture all real-world distortions.\",\n    \"Interpretation of parametric predictions can become trivial under extreme conditions.\",\n    \"Lack of explicit connection between computational results and human perception.\"\n  ],\n  \"questions\": [\n    \"How does the directionality of perceptual changes align with the direction‑agnostic definition in Eq. (1)?\",\n    \"Could clarifying whether \\(p(x)\\) is a PDF or PMF improve the clarity of probabilistic analyses?\",\n    \"What alternative perturbation strategies could better capture real-world image distortions?\",\n    \"How can the parametric predictions be refined to avoid triviality under extreme conditions?\",\n    \"What additional metrics or analyses would explicitly connect computational findings with human perception?\"\n  ],\n  \"overall_score\": \"6: weak accept\",\n  \"confidence\": \"3: medium\"\n}",
      "parse_error": true
    }
  },
  {
    "paper_id": "4h1apFjO99",
    "title": "Diffusion-TS: Interpretable Diffusion for",
    "std_review": {
      "summary": "The paper presents Diffusion-TS, a novel diffusion-based approach for time series imputation and forecasting that incorporates trend and seasonality decomposition. It demonstrates strong performance on long-term generation tasks, outperforming existing methods, and provides a flexible framework adaptable for both imputation and forecasting. While the ablation studies and evaluation metrics could be more comprehensive, the overall findings are significant and warrant acceptance.",
      "strengths": [
        "Introduces a novel approach to time series imputation and forecasting using diffusion models and trend/seasonality decomposition.",
        "Demonstrates strong performance on long-term generation tasks, outperforming existing methods in many cases.",
        "Provides a flexible framework that can be adapted for both imputation and forecasting tasks.",
        "Includes thorough ablation studies to highlight the importance of the trend and seasonality synthesis blocks and Fourier regularization."
      ],
      "weaknesses": [
        "The ablation studies could be more comprehensive, including additional experiments to further validate the contributions of the trend and seasonality synthesis blocks and Fourier regularization.",
        "The evaluation metrics used in the experiments are inconsistent, making it difficult to fully assess the performance of Diffusion-TS across different tasks.",
        "The model's performance on conditional generation tasks is not as thoroughly evaluated as the long-term generation tasks, leaving some uncertainty about its effectiveness in real-world scenarios."
      ],
      "questions": [
        "Could additional ablation studies further validate the contributions of the trend and seasonality synthesis blocks and Fourier regularization?",
        "Would reporting consistent evaluation metrics across all tasks provide a clearer assessment of Diffusion-TS's performance?",
        "How does the model perform on conditional generation tasks in real-world scenarios, and what additional evaluations could be conducted?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "4Hf5pbk74h",
    "title": "Improving classifier decision boundaries using nearest neighbors",
    "std_review": {
      "summary": "The paper proposes a method to improve adversarial robustness by constructing an optimal decision boundary in a latent space derived from a pre-trained classifier. While it introduces a novel approach and provides a clear theoretical foundation, the empirical gains are modest, and the method's interpretability as explainable AI is limited. The reviewer finds the method interesting but questions its practical significance due to limited performance improvements and lack of robust empirical support for key claims.",
      "strengths": [
        "Novel Latent Space Utilization: The approach creatively repurposes a pre-trained classifier's latent space to define an optimal decision boundary, offering a fresh perspective on adversarial robustness.",
        "Theoretical Foundation: The paper provides a clear mathematical formulation linking the optimal decision boundary to classifier performance, grounding the method in solid theoretical principles.",
        "Empirical Validation: The results on standard benchmarks show consistent improvements, suggesting practical utility despite modest magnitude."
      ],
      "weaknesses": [
        "Performance Gaps: The improvements over existing methods are minor, raising questions about the method's competitive edge in the broader landscape.",
        "Implementation Complexity: The approach may require additional computational resources or expertise to implement effectively, potentially limiting accessibility.",
        "Interpretability: While described as providing interpretability, the interpretation as 'local' may not align with expectations for explainable AI applications.",
        "Sparse Latent Space Assumption: The claim of a sparse latent space lacks empirical support, and the method's robustness may not be solely attributable to this property."
      ],
      "questions": [
        "How can the method's performance gains be made more substantial compared to existing baselines?",
        "What empirical evidence supports the claim of a sparse latent space?",
        "How does the method address cases where one class completely encloses another in the latent space?",
        "Can you provide a more rigorous statistical analysis to demonstrate the significance of the reported improvements?",
        "What concrete examples or experiments demonstrate the method's interpretability as 'local'?"
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "4i4fgCOBDE",
    "title": "Networked Inequality: Preferential Attachment Bias in Graph Neural Network Link Prediction",
    "std_review": {
      "summary": "The paper introduces a fairness metric and regularization approach to mitigate preferential attachment bias in GNN link prediction, extending analysis to more expressive models. While it addresses a critical gap, theoretical assumptions and relevance to current GNN practices are concerns. The proposed methods are innovative but require further validation and exploration of fairness beyond the used metric.",
      "strengths": [
        "Introduces a novel fairness metric tailored for GNN link prediction.",
        "Proposes a practical regularization approach with clear theoretical foundations.",
        "Extends analysis to more expressive link prediction methods, broadening applicability."
      ],
      "weaknesses": [
        "Relies on an independence assumption that may not hold in many real-world networks.",
        "Empirical validation on rarely used canonical GNNs may limit relevance to current practices.",
        "Does not fully explore the impact of group size and homophily on within-group bias.",
        "Evaluation focuses primarily on fairness as a regularization term without other metrics."
      ],
      "questions": [
        "How robust are the theoretical results under more realistic network dependency assumptions?",
        "What is the impact of using more expressive link prediction models beyond the evaluated ones?",
        "How do group size and homophily affect within-group fairness, and what experiments could clarify this?",
        "What other fairness metrics or baselines should be considered to comprehensively assess the approach?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "4iPw1klFWa",
    "title": "",
    "std_review": {
      "summary": "The paper introduces SNNK, a method that integrates spiking neural networks with kernelized kernels to improve the efficiency of deep learning models. It demonstrates empirical evidence that SNNK can reduce training time and memory usage in models like Transformers, but the scope of replacement is limited to specific layers rather than full model overhauls. While promising, the paper lacks comprehensive comparative analysis, detailed exploration of performance trade-offs, and thorough scalability evaluation.",
      "strengths": [
        "Innovative integration of spiking neural networks with kernelized methods.",
        "Empirical evidence showing reduced training time and memory usage.",
        "Broad applicability demonstrated across various models, including Transformers."
      ],
      "weaknesses": [
        "Limited scope of replacement, focusing on specific layers rather than full model replacement.",
        "Lack of detailed exploration of performance trade-offs, especially in inference.",
        "Absence of comparative analysis with other dimensionality reduction techniques.",
        "Unclear scalability of SNNK to larger or more complex models."
      ],
      "questions": [
        "Could you provide more detailed empirical validation of efficiency gains, including specific metrics for memory reduction and inference speed improvements?",
        "What are the performance trade-offs when considering comprehensive replacement of feedforward layers in models?",
        "How does the scalability of SNNK impact model performance and training efficiency in larger architectures?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "4iQuByhNie",
    "title": "Context-NER: Contextual Phrase Generation at Scale",
    "std_review": {
      "summary": "The paper introduces Context-NER, a novel approach for extracting contextual information from financial reports using the EDGAR10-Q dataset. It proposes a baseline method that combines rule-based and machine learning techniques, achieving significant accuracy improvements over existing methods. The comprehensive dataset provides valuable resources for financial data analysis, though the paper could benefit from more detailed dataset validation and evaluation metrics. Overall, the work demonstrates strong potential for enhancing context-ner tasks in finance.",
      "strengths": [
        "Introduces a novel context-ner task tailored for financial data analysis.",
        "Constructs a comprehensive dataset (EDGAR10-Q) from public company financial reports.",
        "Proposes a baseline approach that effectively addresses the specific challenges of the context-ner task in financial data.",
        "Demonstrates significant improvements in model performance compared to existing methods."
      ],
      "weaknesses": [
        "The dataset construction process could benefit from further elaboration and validation.",
        "The baseline approach may not be as effective for other types of financial data or context-ner tasks.",
        "The evaluation metrics used could be more comprehensive, considering additional aspects.",
        "The paper lacks a detailed discussion on potential limitations and future directions."
      ],
      "questions": [
        "How was the EDGAR10-Q dataset validated for representativeness and reliability?",
        "Could the baseline approach be generalized to other financial data types or context-ner tasks?",
        "What additional evaluation metrics could be used to assess computational efficiency and scalability?",
        "What are the potential limitations of the proposed approach in other domains?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "4IT2pgc9v6",
    "title": "One for All: Towards Training One Graph Model for All Classification Tasks",
    "std_review": {
      "summary": "The paper presents a novel graph prompting framework that integrates large language models (LLMs) with graph structures, showing improved performance across several domains. While innovative, the approach has limitations such as limited domain coverage, lack of visualizations, and insufficient ablation studies on GNN architectures. Overall, the work is promising but requires further refinement.",
      "strengths": [
        "Innovative integration of LLMs and graph prompting.",
        "Comprehensive ablation studies comparing different LLMs and prompting structures.",
        "Clear and well-structured presentation of methodology and results."
      ],
      "weaknesses": [
        "Limited domain coverage in experimental results.",
        "Absence of visualizations to illustrate node feature unification.",
        "Lack of detailed ablation studies on GNN architectures."
      ],
      "questions": [
        "How can the framework be extended to cover a broader range of domains?",
        "What visualizations or qualitative analyses could better demonstrate the unification of node features?",
        "Could further optimization of the interaction between LLMs and GNNs yield additional performance gains?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "4IxtmklIym",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a synthetic dataset for fruit bin picking, addressing the gap between simulated environments and real-world robotic applications. The dataset is generated using a custom simulation environment that captures natural variation in fruit size and shape, with plans to integrate real-world data for future evaluation. While the dataset is a significant contribution, concerns remain about the reliance on outdated benchmarking methods and the lack of detailed plans for handling symmetric objects and real-world data integration.",
      "strengths": [
        "Comprehensive dataset capturing natural variation in fruit size and shape.",
        "Realistic simulation environment with advanced rendering techniques.",
        "Robust evaluation framework planning to assess sim2real gap with real-world data."
      ],
      "weaknesses": [
        "Limited real-world data integration demonstrated in the current paper.",
        "Use of outdated benchmarking methods may not fully capture recent advancements.",
        "No explicit handling of symmetric objects in benchmarking."
      ],
      "questions": [
        "How will the real-world data be collected and integrated into the evaluation process?",
        "What specific recent benchmarking methods will be incorporated to address outdated ones?",
        "How will symmetric objects be handled in future benchmarking to ensure accurate evaluation?"
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "4jBL79L5QS",
    "title": "Beyond Shortest-Paths: A Benchmark for Reinforcement Learning on Traffic Engineering",
    "std_review": {
      "summary": "The paper introduces eleganTE, a reinforcement learning framework for traffic engineering in software-defined networks using a novel SwarMDP formulation. It integrates custom ns‑3 modules for realistic simulation and demonstrates competitive performance in delay and drop metrics compared to traditional and other RL methods. While the evaluation focuses on limited objectives and the novelty of the SwarMDP approach is not fully justified, the framework shows promise for advancing TE in SDNs.",
      "strengths": [
        "Introduces a novel SwarMDP formulation combining MDP with swarm intelligence for RL in TE.",
        "Provides a comprehensive simulation environment with realistic topology, traffic, and protocol simulation.",
        "Demonstrates competitive performance in terms of packet delay and drop ratio compared to existing methods."
      ],
      "weaknesses": [
        "Evaluation primarily focuses on limited objectives (delay and drop), potentially overlooking other important TE metrics.",
        "Lack of extensive comparative analysis with a broader range of state-of-the-art techniques.",
        "Experiments are largely exploratory with limited ablation studies, limiting insights into robustness."
      ],
      "questions": [
        "How does the framework perform on additional TE objectives such as energy consumption, fairness, and resilience to failures?",
        "What is the computational efficiency and scalability of eleganTE compared to traditional TE methods?",
        "How does the framework adapt to dynamic network conditions and unexpected events?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "4JbrdrHxYy",
    "title": "",
    "std_review": {
      "summary": "ZIP introduces an annotation-free instance segmentation method that combines CLIP and SAM, leveraging their complementary strengths to improve segmentation accuracy without manual annotations. The method uses a semantic-aware initialization and a classification-first-then-discovery pipeline, achieving competitive results on COCO and Pascal VOC datasets. While promising, ZIP faces challenges in handling complex scenes, ambiguous object representations, and high computational demands, limiting its broad applicability.",
      "strengths": [
        "Combines CLIP and SAM to leverage complementary strengths, addressing individual limitations.",
        "Introduces a semantic-aware initialization technique that improves initial segmentation quality.",
        "Proposes a classification-first-then-discovery pipeline, enhancing segmentation robustness.",
        "Demonstrates competitive performance on benchmark datasets, outperforming some annotation-based methods."
      ],
      "weaknesses": [
        "Limited evaluation on complex scenes with multiple overlapping objects or challenging lighting conditions.",
        "Performance may be affected by ambiguous object representations or rare object classes.",
        "High computational requirements for training and inference could limit applicability to resource-constrained environments.",
        "Novelty is not fully established as it builds upon existing techniques rather than introducing a fundamentally new approach."
      ],
      "questions": [
        "How does ZIP perform in scenarios with complex scenes involving multiple overlapping objects or challenging lighting conditions?",
        "What strategies can be employed to improve ZIP's performance on ambiguous object representations or rare object classes?",
        "What are the computational trade-offs and potential optimizations for resource-constrained environments?"
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "4JtwtT4nYC",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a novel reinforcement learning approach that parameterizes policies using shared parameters and task-specific embeddings, aiming to improve generalization across multiple tasks. Experiments demonstrate improved performance, suggesting the method effectively balances expressiveness and generalization. While the approach shows promise, concerns about increased model complexity and overfitting need addressing. Overall, the innovative design and empirical results justify acceptance.",
      "strengths": [
        "Innovative parameterization using shared parameters and task-specific embeddings.",
        "Enhanced policy capacity by expanding the parameter space with task-specific nuances.",
        "Empirical validation showing improved performance across various tasks."
      ],
      "weaknesses": [
        "Increased model complexity may lead to higher computational costs and training time.",
        "Risk of overfitting due to a larger parameter space.",
        "Lack of detailed analysis on how embeddings influence learning dynamics.",
        "Potential hyperparameter sensitivity not thoroughly explored."
      ],
      "questions": [
        "How does the method handle scenarios where task-specific embeddings conflict or provide redundant information?",
        "What are the long-term implications of increased model complexity on scalability and deployment?",
        "Could a more systematic approach to hyperparameter tuning improve generalization across unseen tasks?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "4kJfWZChJI",
    "title": "",
    "std_review": {
      "summary": "The paper introduces SMEE, a novel domain generalization method that combines a mixture-of-experts (MoE) paradigm with spectral ensemble learning. SMEE demonstrates competitive performance against traditional single-model approaches while maintaining computational efficiency. The authors highlight scalability and inference speed advantages for real-world applications, though the novelty could be further emphasized by comparing it to other MoE-based methods. Overall, the paper is well-received with strong technical contributions and practical implications.",
      "strengths": [
        "Introduces a novel SMEE approach that effectively combines MoE and spectral ensemble learning for domain generalization.",
        "Demonstrates competitive performance compared to traditional single-model domain generalization methods.",
        "Addresses computational complexity of spectral ensemble learning, particularly in online incremental settings without re-training or iterative optimization."
      ],
      "weaknesses": [
        "Limited empirical comparison with state-of-the-art domain generalization methods beyond traditional single-model approaches.",
        "Could provide more detailed analysis on the scalability and inference speed benefits of SMEE in large-scale real-world applications.",
        "Novelty of the SMEE approach could be further emphasized by comparing it to other MoE-based domain generalization methods."
      ],
      "questions": [
        "How does SMEE compare to other state-of-the-art domain generalization methods beyond traditional single-model approaches?",
        "Can you provide more detailed analysis on the scalability and inference speed benefits of SMEE in large-scale real-world applications?",
        "How does SMEE's novelty compare to other MoE-based domain generalization methods?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "4kLVvIh8cp",
    "title": "Pessimistic Nonlinear Least-Squares Value Iteration for Offline Reinforcement Learning",
    "std_review": {
      "summary": "The paper introduces PNLSVI, an offline RL algorithm with a novel instance‑dependent regret bound expressed via weighted D2‑divergence. The theoretical analysis is strong, covering a wide range of function classes, but lacks empirical validation and practical comparisons. The restrictive uniform coverage assumption may limit applicability, and the absence of state‑of‑the‑art comparisons hinders clear assessment of its benefits.",
      "strengths": [
        "Novel instance‑dependent regret bound for offline RL.",
        "Thorough theoretical analysis with clear assumptions.",
        "Generality across various function classes, including non‑linear ones."
      ],
      "weaknesses": [
        "No empirical evaluations to demonstrate practical performance.",
        "Uniform coverage assumption may be overly restrictive.",
        "Lack of comparison with other state‑of‑the‑art offline RL algorithms."
      ],
      "questions": [
        "What empirical results would best demonstrate PNLSVI's practical benefits and limitations?",
        "How can the uniform coverage assumption be relaxed for more realistic scenarios?",
        "What benchmarks should be used to compare PNLSVI against other offline RL methods?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "4KqkizXgXU",
    "title": "Curiosity-driven Red-teaming for Large Language Models",
    "std_review": {
      "summary": "The paper presents an RL+Curiosity method for red‑teaming large language models, dynamically generating diverse prompts to improve the detection of toxic outputs. It shows strong empirical results across multiple models and datasets, with promising scalability and generalization. However, concerns about computational cost, classifier dependency, and the lack of robust ethical safeguards remain. Overall, the method is promising and should be accepted for publication.",
      "strengths": [
        "Innovative integration of RL and curiosity-driven exploration.",
        "Demonstrated effectiveness in improving success rates and prompt diversity.",
        "Provides valuable scalability insights and comprehensive evaluation across datasets."
      ],
      "weaknesses": [
        "High computational cost may limit accessibility.",
        "Reliance on a specific toxicity classifier raises robustness concerns.",
        "Lack of concrete ethical safeguards for potential misuse."
      ],
      "questions": [
        "How can the method be made more computationally efficient for broader use?",
        "What strategies can be employed to improve robustness to different toxicity classifiers?",
        "What concrete safeguards can be proposed to mitigate the risk of misuse?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "4KZpDGD4Nh",
    "title": "Neurosymbolic Grounding for Compositional World Models",
    "std_review": {
      "summary": "The paper introduces COSMOS, a neuro‑symbolic framework that integrates a frozen CLIP model with a symbolic grounding module to enable compositional reasoning in reinforcement learning. COSMOS uses a novel key‑query attention mechanism to dynamically select the most relevant rule‑slot pair for each state‑action transition, improving performance on tasks requiring explicit rule‑based reasoning. The symbolic embeddings learned by COSMOS can be partially interpreted, providing insights into the learned compositional rules. The model also generalizes to unseen attribute combinations through a predefined symbolic vocabulary, and the use of a frozen CLIP model offers a scalable solution. Overall, COSMOS demonstrates strong empirical results and offers interpretability and scalability benefits, leading to an acceptance recommendation.",
      "strengths": [
        "Hybrid neuro‑symbolic approach combining neural and symbolic reasoning",
        "Dynamic rule selection via key‑query attention mechanism",
        "Interpretability of symbolic embeddings",
        "Scalability through use of a frozen foundation model",
        "Competitive and superior empirical performance"
      ],
      "weaknesses": [
        "Interpretability of symbolic embeddings may vary for complex attribute combinations",
        "Reliance on a predefined symbolic vocabulary limits generalization to unseen attribute combinations",
        "Initial training of the frozen foundation model can be resource-intensive"
      ],
      "questions": [
        "How robust are the symbolic embeddings' interpretations when dealing with ambiguous or complex attribute combinations?",
        "What is the impact of the size and representativeness of the predefined symbolic vocabulary on the model's generalization ability?",
        "Could the key‑query attention mechanism be further optimized to reduce computational overhead during inference?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "4L0xnS4GQM",
    "title": "Chain-of-Table: Evolving Tables in the Reasoning Chain for Table Understanding",
    "std_review": {
      "summary": "The Chain-of-Table (CoT) method introduces a novel approach for reasoning over tabular data by decomposing complex queries into a sequence of atomic operations, leveraging large language models to generate arguments for each operation. Experimental results show that CoT achieves competitive performance with fewer queries compared to baselines like Chain-of-Thought and Binder, especially with self-consistency. The method offers efficient query processing, a flexible operation set, and improved performance, though it has limitations such as a fixed set of operations and reliance on LLM quality.",
      "strengths": [
        "Efficient query processing with fewer queries",
        "Flexible operation set covering comprehensive table manipulations",
        "Improved performance with self-consistency",
        "Structured argument generation enhancing interpretability"
      ],
      "weaknesses": [
        "Limited by a fixed set of predefined atomic operations",
        "Potential computational overhead from LLM argument generation",
        "High dependency on LLM performance",
        "Risk of overfitting on specialized datasets"
      ],
      "questions": [
        "How can the method be extended to handle more complex or nested table structures?",
        "What strategies can be employed to reduce the computational overhead of LLM argument generation?",
        "How does the method perform on datasets with noisy or incomplete data?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "4lOWCkhr4g",
    "title": "Unsupervised ASR",
    "std_review": {
      "summary": "The paper presents a cross‑lingual unsupervised speech recognition framework that uses a language model to iteratively refine pronunciation models without parallel data. It achieves state‑of‑the‑art word error rates across multiple language pairs, demonstrating strong potential for low‑resource and zero‑resource scenarios. While showing clear advantages, the method also faces challenges such as high computational demand, reliance on high‑quality language models, and limited evaluation of robustness to noisy data.",
      "strengths": [
        "Effective pseudo‑labeling loop that significantly improves pronunciation model quality in low‑resource settings.",
        "Scalable language model architecture that generalizes across diverse linguistic structures.",
        "Competitive performance compared to recent unsupervised baselines, highlighting practical viability."
      ],
      "weaknesses": [
        "High computational requirements may limit scalability for very large datasets.",
        "Dependence on the quality of the language model can impact overall results.",
        "Limited exploration of alternative acoustic models beyond Transformer.",
        "Performance in noisy conditions and with speaker variability is not thoroughly evaluated."
      ],
      "questions": [
        "How does the method perform when applied to languages with highly divergent phonotactic rules?",
        "What is the impact of using a CTC‑based acoustic model instead of a Transformer model?",
        "How robust is the framework to background noise and speaker variability in real‑world deployments?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "4lqA5EuieJ",
    "title": "Prediction Tasks in Graphs: a Framework to Control the Interpretability-Performance Trade-off",
    "std_review": {
      "summary": "The paper introduces a bi-level optimization framework for Graph Neural Networks (GNNs) that simultaneously optimizes performance and interpretability by sparsifying graph representations. It demonstrates that the proposed approach achieves competitive accuracy while significantly improving interpretability through sparsity. The method is innovative, scalable, and provides a clear quantitative control over the interpretability-performance trade-off. Despite its strengths, the framework's complexity and hyperparameter sensitivity are noted as potential drawbacks. Overall, the paper is well-received for its empirical validation and practical implications.",
      "strengths": [
        "Innovative bi-level optimization framework for balancing interpretability and performance in GNNs.",
        "Scalable to large graph datasets, making it applicable to real-world scenarios.",
        "Provides a clear and quantitative way to control the trade-off between sparsity (interpretability) and accuracy.",
        "Empirical results show superior interpretability quality and computational efficiency compared to traditional methods."
      ],
      "weaknesses": [
        "Complexity of the bi-level optimization framework may hinder implementation and require significant computational resources.",
        "High sensitivity to hyperparameters, particularly those controlling sparsity, which could complicate practical application.",
        "Lack of direct human evaluation to assess the practical interpretability of the generated sparse graphs.",
        "Comparison with state-of-the-art interpretability methods is limited to traditional techniques."
      ],
      "questions": [
        "How does the proposed method perform when applied to extremely large graphs with millions of nodes?",
        "What is the impact of different edge removal policies on the trade-off between interpretability and performance?",
        "Could the method be extended to other types of neural networks beyond GNNs?",
        "How does the interpretability metric (concept relevance) align with human understanding of model decisions?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "4lqo5Jwfnq",
    "title": "Class-Incremental Learning with Parameter-Efficient Cross-Task Prompts",
    "std_review": {
      "summary": "The paper presents a novel continual learning (CIL) method that limits prompt updates to mitigate catastrophic forgetting, operating on prompt parameters rather than all model parameters. It introduces a feature fusion module to integrate task-specific knowledge, achieving improved performance on standard CIL benchmarks. While innovative and empirically successful, the method's reliance on a fixed prompt set and limited exploration could hinder performance on complex tasks, and lacks a robustness analysis.",
      "strengths": [
        "Introduces a unique constraint on prompt updates to prevent catastrophic forgetting.",
        "Focuses on prompt parameters, potentially reducing computational overhead.",
        "Features a novel feature fusion module that effectively combines task-specific information.",
        "Demonstrates empirical success on standard CIL benchmarks."
      ],
      "weaknesses": [
        "Limiting prompt updates may restrict the model's ability to explore new solutions.",
        "Using a fixed set of prompts could be insufficient for tasks with large domain gaps.",
        "The complexity of the feature fusion module may pose tuning challenges.",
        "Lacks a thorough analysis of robustness to different task distributions or noise."
      ],
      "questions": [
        "How does the method perform on benchmarks with larger domain gaps between tasks?",
        "What is the impact of the feature fusion module's complexity on training time and convergence?",
        "Could extending the prompt set improve performance on complex tasks?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "4MsfQ2H0lP",
    "title": "Generative Adversarial Policy Network for Modelling Protein Complexes",
    "std_review": {
      "summary": "The paper introduces GAPN, a method for predicting protein-protein interactions (PPIs) by leveraging pre-computed dimer structures. Experimental results show improved performance on benchmark datasets compared to existing methods, highlighting the potential of using pre-computed dimer information in PPI prediction. However, concerns about data source bias, lack of dimer structure optimization, and scalability to larger complexes need addressing.",
      "strengths": [
        "Innovative integration of pre-computed dimer structures.",
        "Improved performance on benchmark datasets.",
        "Scalability and efficiency gains by using pre-computed structures."
      ],
      "weaknesses": [
        "Potential bias from using ground-truth dimer structures.",
        "Lack of optimization of dimer structures.",
        "Unclear impact of pre-computed vs. ground-truth dimer structures.",
        "Scalability concerns for larger protein complexes."
      ],
      "questions": [
        "What is the source of the dimer structures used by GAPN?",
        "How are the dimer structures pre-computed or fetched, and what are the associated computational costs?",
        "How does GAPN handle errors in pre-computed dimer structures compared to ground-truth structures?",
        "What is the impact of using pre-computed dimer structures from AFM or ESMFold versus ground-truth structures on GAPN's performance and efficiency?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "4MvHiijJL3",
    "title": "Model Explanation Disparities as a Fairness Diagnostic",
    "std_review": {
      "summary": "The paper introduces Feature Importance Disparity (FID) as a novel metric to assess fairness in machine learning models, particularly in the context of model interpretability. It proposes an algorithm that identifies subgroups with significant FID using cost-sensitive learning and Lagrangian relaxation. The method is evaluated on multiple datasets and feature importance techniques, demonstrating its effectiveness and providing clear guidelines for practitioners. While the metric focuses on feature importance and has some computational complexity concerns, it offers valuable insights and actionable guidelines for addressing fairness issues.",
      "strengths": [
        "Introduces a novel and interpretable fairness metric (FID) that quantifies feature importance disparities across subgroups.",
        "Proposes an algorithm leveraging cost-sensitive learning and Lagrangian relaxation to identify subgroups with significant FID.",
        "Conducts comprehensive experiments on multiple datasets and feature importance methods, demonstrating robustness and applicability.",
        "Provides clear guidelines for practitioners on interpreting and acting upon the results, enhancing practical utility."
      ],
      "weaknesses": [
        "The metric and algorithm are specific to feature importance, which may not capture all aspects of fairness.",
        "Computational complexity could be a concern for large-scale datasets, limiting practical applicability.",
        "Does not fully address the relationship between FID and other established fairness metrics.",
        "Evaluation is limited to a few datasets and feature importance methods, which may not generalize well."
      ],
      "questions": [
        "How does FID compare to other fairness metrics in terms of capturing different aspects of fairness?",
        "What are the computational efficiency improvements that could be made for large-scale datasets?",
        "How can FID be integrated with existing fairness evaluation frameworks?",
        "Are there specific model types or feature importance methods where FID might be particularly effective or ineffective?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "4N7v4w2r3b",
    "title": "",
    "std_review": {
      "summary": "ProxyBench introduces a standardized benchmark for evaluating the robustness of proxy reward models, which are increasingly used in reinforcement learning. The benchmark assesses how easily these models can be exploited through adversarial attacks, providing a comprehensive evaluation framework. The authors demonstrate that existing proxy models often fail under such attacks, highlighting the need for robustness. They propose several methods to mitigate proxy gaming and evaluate their effectiveness using ProxyBench. The paper is well‑structured, clearly defines the problem, and provides actionable insights and methods.",
      "strengths": [
        "Standardized Evaluation Framework: ProxyBench provides a unified benchmark for assessing proxy model robustness, addressing the lack of standardized metrics in prior work.",
        "Comprehensive Evaluation: The benchmark evaluates proxy models across various domains and architectures, offering a broad assessment of their vulnerability to adversarial attacks.",
        "Practical Insights: The paper provides actionable insights into improving proxy robustness, including specific mitigation strategies and their trade-offs.",
        "Empirical Validation: The authors conduct extensive experiments to validate the effectiveness of their proposed methods, using real-world proxy models as case studies."
      ],
      "weaknesses": [
        "Scope Limitations: The benchmark primarily focuses on adversarial robustness, potentially overlooking other critical aspects of proxy model evaluation, such as alignment with true objectives or computational efficiency.",
        "Assumptions in Attack Simulations: The evaluation assumes specific attack scenarios that may not fully capture the complexity of real-world adversarial environments.",
        "Limited Generalizability: The findings may not be easily transferable to all domains or model architectures, as the benchmark is tailored to the specific attack methods and environments used in the study.",
        "Resource Intensity: The proposed methods for improving robustness may require significant computational resources, limiting their applicability in resource-constrained settings."
      ],
      "questions": [
        "How can the benchmark be extended to evaluate other aspects of proxy model performance, such as alignment with true objectives or computational efficiency?",
        "Are the attack scenarios used in the benchmark representative of real-world adversarial environments, and how can the benchmark be adapted to better capture these complexities?",
        "What are the trade-offs between robustness improvements and the computational resources required to implement the proposed mitigation methods?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "4N97bz1sP6",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a novel method for audio separation that incorporates textual descriptions, using a consistency reconstruction loss to align generated audio with the textual input. This approach aims to improve robustness against background noise and unmentioned sources, showing competitive performance against state-of-the-art methods. While the method shows promise, concerns remain about its handling of background noise not described in the text and the model's ability to generalize when the prompt and recording differ. Overall, the paper is well-received for its innovative approach and practical potential.",
      "strengths": [
        "Introduces a unique approach to audio separation by incorporating textual descriptions, enhancing interpretability and generalizability.",
        "Utilizes a consistency reconstruction loss (CRL) to enforce alignment between generated audio and textual input, potentially improving separation accuracy.",
        "Demonstrates competitive performance against state-of-the-art methods, suggesting practical applicability."
      ],
      "weaknesses": [
        "Performance may be impacted by background noises not mentioned in the textual input.",
        "Challenges in handling discrepancies between specified sources in the prompt and those present in the recording.",
        "Model's performance may vary with background noise levels and the presence of extraneous source components.",
        "Effectiveness of the CRL component when textual captions do not fully capture all components of the mixture is unclear."
      ],
      "questions": [
        "How does the model handle background noises not mentioned in the textual input?",
        "What strategies can be employed to improve the model's performance when the prompt mentions specific sources but the recording includes unexpected background noise?",
        "How robust is the model to varying levels of background noise and extraneous source components in the training data?",
        "What are the specific conditions under which the consistency reconstruction loss (CRL) effectively enforces alignment between audio and text?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "4NhMhElWqP",
    "title": "DAM: Towards A Foundation Model for Time Series Forecasting",
    "std_review": {
      "summary": "The paper introduces DAM, a novel time series forecasting model that dynamically adapts its context size and basis functions to improve accuracy and interpretability. Empirical results show strong performance, especially in long-term forecasts, but the model's complexity and lack of ablation studies are noted as areas for improvement. Overall, the innovative approach and empirical gains justify acceptance.",
      "strengths": [
        "Adaptive context and basis function selection enhances flexibility and performance.",
        "Provides interpretable insights into temporal dynamics, improving over black-box models.",
        "Demonstrates superior long-term forecasting capabilities compared to traditional methods."
      ],
      "weaknesses": [
        "Computational cost may be high due to adaptive mechanisms.",
        "Lack of ablation studies to quantify component contributions.",
        "Complexity could complicate interpretation for non-experts."
      ],
      "questions": [
        "How does the adaptive nature of DAM impact interpretability for users without a strong time series background?",
        "What strategies could be employed to balance performance and inference speed in resource-constrained environments?",
        "How does DAM's performance scale with multivariate inputs?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "4nyTlyTtfX",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a theoretical framework analyzing the performance gap between fully autonomous and mixed-autonomy systems with human agents. It derives regret bounds showing that human participation can significantly reduce regret compared to an autonomous-only system, supported by empirical results on simulated scenarios. While the work offers valuable insights and a realistic model of human behavior, it has limitations such as oversimplified assumptions and a lack of comparative experiments with other multi-agent frameworks.",
      "strengths": [
        "Clear theoretical contributions with novel regret bounds quantifying the performance gap.",
        "Realistic modeling of human agents with bounded rationality and limited planning horizons.",
        "Empirical validation on simulated mixed-autonomy scenarios supporting theoretical findings."
      ],
      "weaknesses": [
        "Assumptions about bounded rationality and planning horizons may oversimplify human behavior.",
        "Derived regret bounds may not be tight, not fully capturing all interactions.",
        "Empirical validation limited to a two-agent setting, potentially limiting broader applicability.",
        "Lack of comparative experiments with other multi-agent frameworks."
      ],
      "questions": [
        "How can the regret bounds be tightened to better reflect the potential benefits of human involvement?",
        "What further empirical studies are needed to validate the framework in more complex mixed-autonomy systems?",
        "How do the assumptions about human bounded rationality and planning horizons impact the generalizability of the results?",
        "Could comparative experiments with other multi-agent frameworks like Dec-POMDPs provide additional insights?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "4olqbTBt1Y",
    "title": "DREAM: Dual Structured Exploration with Mixup for Open-set Graph Domain Adaption",
    "std_review": {
      "summary": "DREAM introduces a novel method for open-set graph domain adaptation, leveraging attention mechanisms, a graph-of-graph design, and a tailored loss function. The approach shows promise in adapting to new graph structures while maintaining performance on known ones, as demonstrated by empirical results. However, the paper lacks clear comparisons with existing methods and comprehensive ablation studies, which limits the assessment of its relative strengths and the contributions of its components.",
      "strengths": [
        "Innovative approach combining attention mechanisms and a graph-of-graph design for open-set graph domain adaptation.",
        "Demonstrated robust performance in adapting to new domains with minimal degradation on known domains.",
        "Scalable design suitable for real-world applications with increasing complexity."
      ],
      "weaknesses": [
        "Absence of clear comparative analysis with existing graph domain adaptation and open-set graph classification methods.",
        "Limited ablation studies prevent thorough evaluation of individual contributions.",
        "Potential resource intensity of the 'dream' mechanism in complex scenarios."
      ],
      "questions": [
        "How does DREAM compare to state-of-the-art methods like DEAL, CoCo, RIGNN, OpenWGL, and OpenWRF in terms of performance and scalability?",
        "What are the individual impacts of the attention mechanism, graph-of-graph design, and Mixup component on the model's performance?",
        "Could additional ablation studies or a broader set of baselines provide clearer insights into DREAM's contributions?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "4pnhzuRtJ2",
    "title": "Optimized Tradeoffs for Private Majority Ensembling",
    "std_review": {
      "raw_text": "{\n  \"summary\": \"The paper introduces DaRRM, a framework that combines randomized response with differential privacy for multi-class aggregation, offering strong theoretical privacy guarantees and flexibility with non-uniform priors. While empirical results show benefits over naive baselines, the optimization problem's complexity and some notational ambiguities limit its practical applicability. Overall, the work is innovative but requires addressing computational and interpretative challenges.\",\n  \"strengths\": [\n    \"Introduces a novel framework that combines randomized response with differential privacy to improve privacy in multi-class aggregation.\",\n    \"Provides strong theoretical privacy amplification guarantees under \\((\\epsilon, \\delta)\\)-DP mechanisms.\",\n    \"Allows for the use of non-uniform priors, which can be tailored to specific application contexts to optimize utility.\"\n  ],\n  \"weaknesses\": [\n    \"The optimization problem for designing \\(\\gamma\\) involves a high number of constraints (\\(O(K^7)\\)), which may make it computationally intractable for large \\(K\\).\",\n    \"The notation \\(\\gamma\\) is used ambiguously across different contexts, which can lead to confusion.\",\n    \"Empirical results do not always directly support theoretical privacy guarantees, especially when non-uniform priors are used.\",\n    \"The paper discusses extending the framework to multi-class settings but does not provide a detailed analysis of the challenges and necessary adaptations.\"\n  ],\n  \"questions\": [\n    \"How can the computational intractability of the optimization problem be addressed in practice?\",\n    \"What are the specific challenges and adaptations required when extending DaRRM to multi-class settings?\",\n    \"Can the framework be made more interpretable by clarifying the definition and usage of \\(\\gamma\\)?\",\n    \"How does the choice of prior distribution \\(p_i\\) impact the utility in scenarios with non-uniform priors?\"\n  ],\n  \"overall_score\": \"5: borderline\",\n  \"confidence\": \"3: medium\"\n}",
      "parse_error": true
    }
  },
  {
    "paper_id": "4pW8NL1UwH",
    "title": "LIRE: listwise reward enhancement for preference alignment",
    "std_review": {
      "summary": "The paper introduces LIRE, a listwise distribution designed to improve candidate response quality in open-domain question answering. It modifies the pointwise approach by constructing a listwise dataset and using softmax over sampled generations to guide sampling. Evaluated on the HH dataset, LIRE achieves competitive results against strong baselines like Alpaca‑7B, with a clear theoretical foundation and effective offline dataset generation. Despite some implementation complexities and limited ablation studies, the method shows significant promise and is recommended for acceptance.",
      "strengths": [
        "Introduces a novel listwise distribution that leverages offline dataset generation to improve candidate response quality.",
        "Effectively utilizes Equation 4 to create a listwise dataset, enhancing the diversity and quality of generated responses.",
        "Provides a clear theoretical framework for understanding the listwise sampling process and its impact on model behavior.",
        "Achieves competitive performance on the HH dataset, outperforming baselines such as Alpaca‑7B.",
        "Demonstrates strong empirical results with a well-defined listwise approach."
      ],
      "weaknesses": [
        "The listwise approach introduces additional complexity in dataset generation and model training, which may require more computational resources.",
        "The PPO model achieves a lower reward compared to the Alpaca‑7B baseline, which may be surprising given the training objectives and dataset characteristics.",
        "Lacks detailed evaluation metrics on the divergence between the LIRE‑tuned policy and the anchor policy.",
        "Limited comparison with other listwise methods could provide a more comprehensive analysis of LIRE's performance.",
        "Insufficient ablation studies or hyperparameter sensitivity analyses, which could provide deeper insights into the method's robustness and limitations."
      ],
      "questions": [
        "How does the listwise distribution compare to other listwise methods in terms of performance and computational efficiency?",
        "What are the specific ablation studies or hyperparameter sensitivity analyses that could further validate the robustness of LIRE?",
        "Could the method be extended to handle larger datasets or more complex question answering tasks?",
        "What are the theoretical guarantees or bounds on the performance improvement provided by LIRE compared to traditional pointwise approaches?",
        "How does the choice of temperature parameter T in the softmax function affect the trade‑off between diversity and quality of generated responses?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "4PzxLPEGRn",
    "title": "OCAtari: Object-Centric Atari 2600 Reinforcement Learning Environments",
    "std_review": {
      "summary": "The paper introduces OCAtari, an object‑centric Atari representation that transforms raw pixel observations into a structured object grid using two complementary methods. It demonstrates improved performance and sample efficiency on classic Atari games compared to pixel‑based baselines and addresses non‑determinism through deterministic variants. While the approach shows strong promise, some limitations in object detection and benchmark scope should be considered.",
      "strengths": [
        "Improved abstraction: Converts raw pixels into a structured object grid, enhancing representational power for deep RL.",
        "Dual detection methods: Combines Vision‑Enhanced Model and RAM Extraction Method for robust object detection.",
        "Benchmark robustness: Introduces deterministic Atari variants for more reliable performance metrics."
      ],
      "weaknesses": [
        "Object‑centricity requirement: Effectiveness depends on accurate object modeling, which may not be necessary for all Atari tasks.",
        "REM limitations: May struggle with blinking, partially occluded, or non‑gameplay objects.",
        "Benchmark scope: Focuses on classic Atari games, potentially limiting generalizability."
      ],
      "questions": [
        "How does OCAtari's object‑centric representation impact performance on more complex or modern game environments?",
        "What are the trade‑offs between object modeling and simpler pixel‑based approaches for specific Atari tasks?",
        "How does the benchmark address the stochastic nature of RL algorithms beyond non‑determinism?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "4QaKdsh15T",
    "title": "",
    "std_review": {
      "summary": "The paper introduces LEO, an embodied AI framework that integrates CLIP with a learned motion policy to enable robots to follow natural language instructions in complex indoor environments. It demonstrates strong performance on tasks like object retrieval, navigation, and manipulation, showing competitive results on the Embodied AI benchmark. While innovative, the paper lacks comprehensive evaluation, particularly in 3D task coverage and navigation baselines, and some reported metrics are not fully supported. Overall, the work is promising but requires additional evaluation to fully validate its impact.",
      "strengths": [
        "Innovative integration of CLIP for combining language understanding with visual perception.",
        "Scalable policy learning enabling generalization across diverse tasks.",
        "Demonstrated robustness across multiple benchmark tasks, indicating strong generalization capabilities."
      ],
      "weaknesses": [
        "Limited 3D task coverage, evaluating only 3 out of 10 original 3D tasks.",
        "Absence of baselines for embodied navigation, hindering performance assessment.",
        "Ambiguity regarding the impact of human demonstrations versus shortest path training on task success.",
        "Potential reporting error regarding the claim of presenting soft‑SPL metrics.",
        "Insufficient comparison of navigation results against recent state‑of‑the‑art methods."
      ],
      "questions": [
        "Should the full results of the remaining 7 3D tasks from the original CLIPort experiment be provided and included in the supplementary material?",
        "What baselines should be presented for the embodied navigation task, such as comparisons to Habitat‑Web and other recent benchmarks?",
        "How does training on human demonstrations compare quantitatively to using shortest path trajectories, despite the higher success rate on navigation tasks?",
        "Is the claim of presenting soft‑SPL in Section 4.3 a typo, and if so, what are the missing soft‑SPL results?",
        "What additional baselines, such as recent imitation learning approaches, should be included to better contextualize LEO's navigation performance?"
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "4qFIkOhq24",
    "title": "Fundamental limitations of alignment",
    "std_review": {
      "summary": "The paper introduces a theoretical framework for analyzing alignment in large language models (LLMs) by modeling their output distribution as a mixture of positive and negative components. It derives conditions under which the negative component can dominate, leading to misaligned behavior, and demonstrates these concepts through experiments on a synthetic LLM. While the framework provides valuable insights and actionable insights for detecting and mitigating misalignment, its reliance on simplifying assumptions and the granularity of treating LLMs as generating single sentences limit its generality and practical applicability. The paper is recommended for its theoretical contributions but with reservations.",
      "strengths": [
        "Clear theoretical framework capturing misalignment in LLMs",
        "Provides actionable insights for detecting and mitigating misalignment",
        "Empirical validation through well-designed experiments"
      ],
      "weaknesses": [
        "Simplifying assumptions about the LLM model may limit generality",
        "Granularity limitations in treating LLMs as single-sentence generators",
        "Challenges in constructing a negative behavior sub-component"
      ],
      "questions": [
        "How can the framework be extended to capture the nuances of longer, more contextually rich outputs?",
        "What are the practical implications of the β‑distinguishability condition in real-world applications?",
        "How can the granularity of sentence definition be refined to better align with natural discourse boundaries?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "4QtywskEyY",
    "title": "",
    "std_review": {
      "summary": "The paper presents Multi-Stage Distillation (MDR), a novel knowledge distillation framework that uses a Relational Decouple Module (RDM) to break the teacher's output into multiple stages and an Adaptive Distillation Selection (ADSS) module to dynamically select the most informative stages for the student model. Experiments on ImageNet show that MDR often outperforms state-of-the-art KD methods, including the teacher network itself, demonstrating significant empirical improvements. Theoretical justifications and innovative approach justify the acceptance of the work.",
      "strengths": [
        "Introduces a novel RDM that enables more nuanced and selective knowledge transfer.",
        "Adaptive stage selection via ADSS improves distillation quality by focusing on informative stages.",
        "Demonstrates superior performance on ImageNet, often surpassing both the teacher and other KD methods."
      ],
      "weaknesses": [
        "The multi-stage approach adds complexity to the distillation process.",
        "Computational overhead may be a concern for resource-constrained environments.",
        "Limited validation across diverse datasets and tasks could strengthen the robustness claim."
      ],
      "questions": [
        "How does MDR perform on other benchmark datasets beyond ImageNet?",
        "What is the impact of the number of stages on the distillation quality and computational cost?",
        "Can the proposed approach be extended to other domains, such as natural language processing?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "4Qz9BT4mpM",
    "title": "Predicting the Performance of Foundation Models via Agreement-on-the-Line",
    "std_review": {
      "summary": "The paper proposes a method to improve neural network training stability by introducing diversity through differently initialized random heads. Empirical evaluations across multiple datasets show reduced variance in model performance, leading to more consistent test accuracy. While the method is innovative and promising, its effectiveness is modest and depends on the degree of diversity introduced. The paper lacks absolute performance metrics, making it difficult to fully assess the magnitude of improvements.",
      "strengths": [
        "Clear motivation for addressing training stability, a well‑documented issue.",
        "Introduces a novel diversity mechanism via differently initialized random heads, offering a promising direction for improving model robustness.",
        "Conducts thorough empirical evaluations across multiple datasets and models, providing robust evidence of effectiveness."
      ],
      "weaknesses": [
        "Does not report absolute test accuracy values, hindering assessment of performance gains.",
        "Lacks clear quantification of the significance of observed deviations in test accuracy.",
        "Relies on random initializations, which may limit the exploration of diversity compared to other initialization strategies.",
        "Potential for overfitting if diversity is not carefully controlled."
      ],
      "questions": [
        "How do the observed performance improvements compare to absolute test accuracy values?",
        "What is the significance of deviations in test accuracy (e.g., 5% difference) without baseline accuracy context?",
        "How does the method's performance scale with increased diversity beyond the explored range?",
        "Are there systematic ways to quantify and control overfitting introduced by the diversity mechanism?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "4r2ybzJnmN",
    "title": "Learning Delays in Spiking Neural Networks using Dilated Convolutions with Learnable Spacings",
    "std_review": {
      "summary": "The paper introduces DCLS, a method for learning delays in spiking neural networks using dilated convolutions with learnable spacings. It shows promise in improving delay learning efficiency and has practical benefits for neuromorphic hardware. While the method is strong, it could benefit from broader comparisons and more detailed robustness analysis.",
      "strengths": [
        "Introduces a novel approach to learning delays in SNNs using dilated convolutions with learnable spacings.",
        "Demonstrates improved performance and computational efficiency compared to existing methods.",
        "Provides a thorough evaluation of the LIF neuron model and highlights practical implications for neuromorphic hardware."
      ],
      "weaknesses": [
        "Lacks a comprehensive comparison with a broader range of existing methods.",
        "Evaluation on neuromorphic hardware is limited.",
        "Robustness analysis could be more detailed across different network architectures.",
        "Theoretical underpinnings of the DCLS method are not as thoroughly explored."
      ],
      "questions": [
        "How does the proposed method compare to a wider range of existing delay learning approaches?",
        "What are the detailed robustness results across various network architectures?",
        "Could the theoretical foundations of DCLS be further investigated to address long-term viability concerns?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "4rBEgZCubP",
    "title": "Learning 3D Particle-based Simulators",
    "std_review": {
      "summary": "The paper introduces Visual Particle Dynamics (VPD), a method for long-term video prediction that uses a UNet variant to generate per-pixel latent features, which condition a particle simulation in a defined work space. Experiments show that VPD outperforms baselines in handling long-term dynamics and reducing blurring, as quantified by PSNR metrics. The innovative use of per-pixel latent features and detailed experimental validation strongly support its acceptance.",
      "strengths": [
        "Innovative latent feature map for detailed conditioning of particle simulations.",
        "Effective conditioning mechanism linking visual observations to particle dynamics.",
        "Quantitative performance gains with superior PSNR scores over baselines."
      ],
      "weaknesses": [
        "Increased implementation complexity due to novel latent feature map and conditioning mechanism.",
        "Potential for overfitting with detailed latent features.",
        "Scalability concerns not thoroughly tested for large or high-resolution inputs."
      ],
      "questions": [
        "How does the model handle scenarios with limited or non-representative training data to mitigate overfitting?",
        "What is the impact of latent feature granularity on the model's ability to generalize to unseen scenarios?",
        "How can the conditioning set be dynamically adjusted for varying input sizes and resolutions?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "4sGoA7Eih8",
    "title": "Unmasking Transformers: A Theoretical Approach to Data Recovery via Attention Weights",
    "std_review": {
      "summary": "The paper presents a novel inversion attack on transformer models using attention weights and outputs, leveraging a constrained optimization approach to iteratively refine input samples. While theoretically sound and empirically validated across multiple models, the method's computational intensity and reliance on model outputs limit its practical scalability and generalizability. The paper highlights potential privacy risks but does not extensively explore broader implications or mitigation strategies.",
      "strengths": [
        "Innovative approach targeting transformer attention mechanisms",
        "Strong theoretical foundation with clear convergence guarantees",
        "Empirical validation across various transformer architectures"
      ],
      "weaknesses": [
        "High computational complexity, especially for large models",
        "Dependence on availability of model outputs",
        "Limited generalization across different architectures and training regimes",
        "Privacy implications not fully explored"
      ],
      "questions": [
        "How can the optimization process be made more scalable for large-scale models?",
        "What are the practical mechanisms for obtaining model outputs in real-world scenarios?",
        "How does the method's effectiveness vary across different transformer architectures and training conditions?",
        "What are the broader privacy and security implications of this attack, and what mitigation strategies can be proposed?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "4SmhpF1nO4",
    "title": "Tabular Deep-SMOTE:",
    "std_review": {
      "summary": "Tabular Deep-SMOTE extends SMOTE with a deep auto‑encoder to generate synthetic samples in a learned latent space, using a metric‑learning loss to separate minority and majority classes and an importance‑sampling step to weight synthetic samples. Experiments on several tabular datasets show significant improvements over baseline methods, especially in F1‑score and AUC. While promising, the method lacks ablation studies, statistical significance testing, and theoretical justification, which reduce confidence in its robustness and generalizability.",
      "strengths": [
        "Integrates deep learning to project tabular data into a latent space where SMOTE can be more effective.",
        "Introduces a metric‑learning loss that adaptively emphasizes minority class separation.",
        "Applies importance‑sampling tailored to the latent space to generate more relevant synthetic samples."
      ],
      "weaknesses": [
        "Does not perform ablation studies to isolate the impact of individual components.",
        "Lacks statistical significance testing for reported improvements.",
        "Excludes conceptually similar baselines (DAEGO, TAEI) from comparison.",
        "Focuses only on binary datasets, limiting assessment of multi‑class performance.",
        "Fails to provide theoretical justification for why the approach improves minority class representation."
      ],
      "questions": [
        "Could ablation studies clarify the individual contributions of the auto‑encoder, metric‑learning loss, and importance‑sampling?",
        "What statistical tests (e.g., paired t‑tests) could be added to verify the significance of the reported improvements?",
        "How does the method perform on multi‑class imbalanced datasets?",
        "What theoretical analysis explains the effectiveness of the learned latent space for minority class representation?"
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "4SrzKsJocx",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a generative linear model to compare intrinsic dimensionality (IDR) and supervised dimensionality reduction (SDR) methods, finding that SDR methods like rCCA outperform IDR methods like PCA on synthetic data. While the study provides valuable insights into the strengths and limitations of these methods, its findings are limited by strong independence assumptions and reliance on synthetic data, which may not generalize to real-world scenarios. The lack of theoretical underpinnings and practical recommendations for practitioners are also noted.",
      "strengths": [
        "Introduces a novel generative linear model providing a theoretical framework for comparing IDR and SDR methods.",
        "Uses synthetic data to allow controlled exploration of parameter effects on dimensionality reduction performance.",
        "Offers clear insights into the strengths and limitations of IDR and SDR methods, particularly in supervised learning contexts."
      ],
      "weaknesses": [
        "Strong independence assumptions in the generative model may not hold in real-world scenarios, limiting generalizability.",
        "Conclusions are based on synthetic data, which may not accurately reflect performance on real-world datasets.",
        "Theoretical underpinnings of the model are limited, with no guarantees provided for observed differences between IDR and SDR methods."
      ],
      "questions": [
        "How do the findings generalize to real-world datasets with complex, nonlinear relationships?",
        "What theoretical guarantees or results can explain the observed differences between IDR and SDR methods in this model?",
        "How do the parameter settings affect the model's performance in more realistic data structures?",
        "What practical recommendations can be provided for practitioners based on these findings?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "4stB7DFLp6",
    "title": "InstructRetro: Instruction Tuning post Retrieval-Augmented Pretraining",
    "std_review": {
      "summary": "InstructRetro presents a novel retrieval‑augmented pretraining approach for instruction following, where the transformer encoder is removed and retrieval is optimized through instruction‑tuning. The method leverages a Faiss index with carefully selected hyper‑parameters, achieving competitive performance on various tasks while being more efficient than full encoder models. The paper is well‑structured, with clear experiments and ablations, though it leaves some open questions about robustness and completeness.",
      "strengths": [
        "Innovative retrieval mechanism that simplifies model architecture without sacrificing performance.",
        "Efficient indexing using Faiss with well‑chosen hyper‑parameters, making the approach scalable.",
        "Strong empirical results that outperform standard RAG baselines on multiple downstream tasks."
      ],
      "weaknesses": [
        "Lack of detailed analysis on why removing the encoder does not significantly degrade performance.",
        "Limited baseline comparison; more comprehensive benchmarks could further validate novelty.",
        "Potential data leakage between training and testing phases is not thoroughly addressed.",
        "No exploration of alternative encoder architectures beyond the one used."
      ],
      "questions": [
        "How robust is the encoder removal strategy, and what are the implications for different instruction‑following tasks?",
        "Could exploring more recent encoder models improve retrieval quality or efficiency?",
        "What additional ablations or qualitative analyses could further demonstrate the model's generalizability?",
        "How does the method handle long‑form QA tasks, and what are the trade‑offs in answer quality?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "4u0ruVk749",
    "title": "Dfite: Estimation of Individual Treatment Effect Using Diffusion Model",
    "std_review": {
      "summary": "The paper proposes a diffusion‑based generative model for imputing unobserved confounders in causal inference, aiming to improve treatment effect estimation. It leverages a reverse diffusion process to generate plausible values for missing variables from observed covariates, showing superior ITE performance on ACIC 2016 and IHDP datasets. While theoretically sound and empirically effective, the method lacks clear interpretation of how observed variables guide the generation of unobserved confounders, and it does not fully justify its theoretical assumptions or compare comprehensively with other state‑of‑the‑art methods.",
      "strengths": [
        "Flexibility in modeling complex relationships without strong structural assumptions.",
        "Provides a principled theoretical foundation linking the reverse diffusion process to the true data distribution.",
        "Demonstrates superior empirical performance on real‑world datasets, especially in the presence of unmeasured confounding."
      ],
      "weaknesses": [
        "Lacks clear explanation of how observed covariates are used to infer unobserved confounders.",
        "Theoretical contribution is not fully substantiated by well‑defined conditions for accurate latent recovery.",
        "Hyperparameter choices for the diffusion process are not well justified, potentially affecting model performance.",
        "Lacks comprehensive comparison with other state‑of‑the‑art methods."
      ],
      "questions": [
        "How exactly are observed covariates used to guide the generation of unobserved confounders in the diffusion process?",
        "What specific conditions or assumptions ensure the diffusion model accurately recovers true latent confounders?",
        "How does the choice of distance metric and hyperparameters impact the model’s performance, and how could they be better justified?",
        "How does the proposed method compare to other state‑of‑the‑art methods like VAE, TARnet, and CFR_MMD in terms of ITE estimation, especially under varying levels of unmeasured confounding?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "4Ua4hKiAJX",
    "title": "Locality-Aware Graph Rewiring in GNNs",
    "std_review": {
      "summary": "The paper introduces a novel graph rewiring technique that enhances GNN representational power by iteratively adding local edges, aiming to mitigate over‑squashing. Empirical results on benchmark datasets show significant performance gains, but the method's novelty and generalizability are limited by limited baseline comparisons and unclear parameter tuning. Overall, the work is promising yet requires further validation.",
      "strengths": [
        "Innovative sequential rewiring strategy that respects local structure.",
        "Clear theoretical motivation linking local edges to practical GNN needs.",
        "Empirical validation across multiple datasets demonstrates strong performance gains."
      ],
      "weaknesses": [
        "Limited comparison with other rewiring techniques undermines perceived novelty.",
        "Parameter sensitivity (ρ) is not thoroughly explored.",
        "Computational complexity may be a concern for very large graphs.",
        "Generalizability across diverse graph types and tasks is not fully demonstrated."
      ],
      "questions": [
        "Why must we respect locality in the rewiring process?",
        "How does the choice of the number of walks as a connectivity measure affect the rewiring balance between locality and sparsity?",
        "What are the implications of computing connectivity and locality measures only once versus at each rewiring step?",
        "How does the proposed method compare to other recent rewiring techniques like GTR or BOFR?",
        "What is the impact of the ρ parameter on the trade‑off between preserving the original graph structure and improving connectivity?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "4uaogMQgNL",
    "title": "",
    "std_review": {
      "summary": "The paper introduces UpFusion, a method for generating novel views of objects from unposed images using a 3D NeRF framework. It addresses pose ambiguity by aligning views per frame and employs neural mode distillation to transfer 3D information from a reference view. The method is evaluated on ShapeNetCore, achieving competitive metrics but has several limitations, such as unclear evaluation, lack of justification for using the DINOv2 backbone, and limited comparison with pose‑optimization baselines.",
      "strengths": [
        "Innovative use of 3D NeRF for capturing and synthesizing novel views.",
        "Alignment strategy mitigates pose ambiguity effectively.",
        "Neural mode distillation enhances realism and coherence of synthesized images."
      ],
      "weaknesses": [
        "Per‑frame alignment may not fully resolve global consistency issues.",
        "Lack of detailed justification for choosing the DINOv2 backbone.",
        "Reliance on the first input image as an anchor introduces scale ambiguity.",
        "Insufficient comparison with pose‑optimization and single‑image‑to‑3D baselines.",
        "Potential trade‑off between geometric consistency and visual detail."
      ],
      "questions": [
        "How does the per‑frame alignment approach compare to global alignment in terms of overall view consistency?",
        "Why was the DINOv2 backbone specifically chosen over other feature extraction methods?",
        "How does the method handle scale ambiguity when using the first input image as an anchor?",
        "How does the performance of UpFusion compare to pose‑optimization baselines and single‑image‑to‑3D methods?",
        "What are the trade‑offs between geometric consistency and visual detail in the generated views?"
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "4UIBysXjVq",
    "title": "Rayleigh Quotient Graph Neural Networks for Graph-level Anomaly Detection",
    "std_review": {
      "summary": "The paper introduces Rayleigh Quotient Graph Neural Networks (RQGNN) for graph-level anomaly detection, leveraging spectral properties to outperform existing methods on chemical and other datasets. While innovative and theoretically sound, the method's generalization to other domains and deeper theoretical exploration of detectable perturbations remain areas for improvement. Overall, the approach is robust and demonstrates strong performance.",
      "strengths": [
        "Innovative use of Rayleigh Quotient to capture spectral characteristics of graphs.",
        "Strong theoretical foundation supporting the method's effectiveness.",
        "Demonstrated superior performance across various datasets, including chemical graphs."
      ],
      "weaknesses": [
        "Limited validation on datasets from other domains, such as social networks.",
        "Insufficient exploration of the detectable range of perturbations using the Rayleigh Quotient.",
        "Comparison with a broader range of state-of-the-art methods could further establish novelty."
      ],
      "questions": [
        "How does RQGNN perform on datasets from domains other than chemistry?",
        "What is the theoretical limit of perturbations that can be detected using the Rayleigh Quotient?",
        "How does RQGNN compare to other recent methods in terms of computational efficiency?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "4UiLqimGm5",
    "title": "",
    "std_review": {
      "summary": "The paper introduces Continuous Activation Mapping (CAM) for neural fields, enhancing expressiveness and training stability while improving rendering efficiency. Experimental results show significant improvements over baselines, demonstrating CAM's potential for various computer graphics and vision applications. The reviewers highlight strong performance and future research directions, leading to an acceptance recommendation.",
      "strengths": [
        "CAM introduces a continuous activation mapping function that significantly enhances the expressiveness of neural fields.",
        "The method improves training stability by stabilizing the optimization process, addressing a common challenge in neural radiance fields.",
        "CAM achieves faster rendering times while maintaining high-quality results, making it suitable for real-time applications."
      ],
      "weaknesses": [
        "The introduction of the continuous activation mapping function adds complexity to the model, potentially requiring more computational resources and careful tuning.",
        "Scalability to very large datasets remains an open question.",
        "The experimental evaluation primarily compares CAM against a few selected baselines, which may not fully capture its relative performance across all aspects.",
        "The continuous activation mapping function may be less interpretable compared to traditional activation functions, potentially hindering its adoption in certain applications."
      ],
      "questions": [
        "How does CAM scale to very large datasets, and what strategies can be employed to maintain performance?",
        "What are the interpretability implications of the continuous activation mapping function, and how can they be addressed?",
        "How does CAM compare to other state-of-the-art methods in terms of generalization across diverse datasets and applications?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "4UP387Adir",
    "title": "",
    "std_review": {
      "summary": "The paper introduces WSNet, a weakly supervised graph neural network that uses community information to improve performance on graphs with noisy labels. It proposes a novel labeling function framework and a community-aware contrastive learning objective, achieving higher accuracy than existing methods, especially under high label noise. The work highlights the importance of incorporating community structure when training GNNs with weak supervision, demonstrating strong scalability and real-world applicability through large-scale experiments.",
      "strengths": [
        "Innovative LF Framework: The paper introduces a systematic way to generate weak labels using multiple labeling functions, which is a practical approach for real-world scenarios where ground-truth labels are scarce.",
        "Community-Aware Contrastive Learning: By integrating community information into the contrastive learning objective, WSNet effectively captures structural dependencies within graph communities, leading to improved performance.",
        "Robustness to High Label Noise: The experiments convincingly show that WSNet maintains high accuracy even when the label noise is substantial (53 % accuracy), demonstrating its robustness.",
        "Scalability: Evaluation on large-scale datasets (OGB, Aminer‑CS) provides strong evidence of WSNet's scalability and its potential for real-world applications."
      ],
      "weaknesses": [
        "Limited Comparison with State-of-the-Art: While the paper compares WSNet to several existing methods, it would benefit from a more comprehensive comparison with recent state-of-the-art graph contrastive learning methods that also handle weak supervision.",
        "Lack of Detailed Reproducibility Guidelines: The methodology section is thorough but lacks explicit reproducibility guidelines, which could hinder efforts to replicate the experiments.",
        "Insufficient Analysis of Label Noise Impact: Although the paper discusses label noise qualitatively, a more detailed analysis of how different levels of noise affect WSNet's performance would strengthen the findings.",
        "Potential Overfitting on Community Structure: The heavy reliance on community information might lead to overfitting, especially on graphs with less pronounced community structures. The paper should discuss this trade-off more explicitly."
      ],
      "questions": [
        "How does WSNet compare to recent state-of-the-art graph contrastive learning methods that also handle weak supervision?",
        "What are the specific reproducibility guidelines that could be provided to facilitate replication of the experiments?",
        "Could a more detailed analysis of how different levels of label noise impact WSNet's performance be included?",
        "How does the method handle graphs with less pronounced community structures to avoid overfitting?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "4VgBjsOC8k",
    "title": "Unveiling the Unseen: Identifiable Clusters in Trained Depthwise Convolutional Kernels",
    "std_review": {
      "summary": "The paper provides a novel analysis of kernel structures in EfficientNet‑B4 and B6 models, identifying distinct DoG filter clusters that offer insights into model interpretability and efficiency. While the methodology is clear and reproducible, the findings are limited to the specific architectures studied and lack quantitative metrics. The authors' comparative insights suggest practical implications for designing more interpretable and efficient depthwise separable convolutional networks, but the analysis could be further strengthened by exploring broader architectures and incorporating quantitative performance measures.",
      "strengths": [
        "Innovative analysis of kernel structures in depthwise separable convolutional networks.",
        "Clear and reproducible methodology for classifying and visualizing DoG filter patterns.",
        "Valuable comparative insights into the representational capabilities of depthwise separable networks versus traditional CNNs."
      ],
      "weaknesses": [
        "Limited scope to EfficientNet‑B4 and B6, which may not generalize to other architectures.",
        "Lack of quantitative metrics to assess the impact of identified filter patterns on model performance.",
        "Potential for misinterpretation of the distinction between 'on-center' and 'off-center' clusters."
      ],
      "questions": [
        "How do the identified filter patterns generalize to other architectures beyond EfficientNet‑B4 and B6?",
        "What quantitative metrics could be used to evaluate the impact of these filter patterns on model performance?",
        "How might the training dynamics influence the emergence of these specific filter clusters?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "4VGEeER6W9",
    "title": "Towards Non-Asymptotic Convergence for Diffusion-Based Generative Models",
    "std_review": {
      "summary": "The paper introduces a deterministic sampler for diffusion models based on solving a probability-flow ODE, establishing convergence rates under certain assumptions. It highlights the impact of score-estimation and Jacobian errors, providing a detailed analysis of convergence behavior with a d‑dependence. While the theoretical contributions are novel and rigorous, practical verification of the assumptions remains a concern.",
      "strengths": [
        "Introduces a novel deterministic sampler for diffusion models.",
        "Provides a comprehensive convergence analysis with clear assumptions.",
        "Offers insights into the impact of score-estimation and Jacobian errors."
      ],
      "weaknesses": [
        "Assumptions, especially the Jacobian-error assumption, may be hard to verify practically.",
        "Analysis focuses only on the first step of the diffusion process.",
        "Relies on theoretical metrics like TV and KL divergence that may not always reflect practical sample quality."
      ],
      "questions": [
        "How can the Jacobian-error assumption be practically verified in real-world applications?",
        "What are the convergence properties of the sampler over longer diffusion chains?",
        "Could alternative performance metrics, such as the Wasserstein distance, provide more favorable convergence guarantees?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "4VIgNuQ1pY",
    "title": "Stable Neural Stochastic Differential Equations in Analyzing Irregular Time Series Data",
    "std_review": {
      "summary": "The paper introduces Neural Stochastic Differential Equations (Neural SDEs) for modeling irregular time series with noise and drift, proposing three classes tailored to different stochastic processes. Experiments show improved performance over traditional models, especially in handling missing data and distribution shifts. While theoretically robust, practical concerns such as hyper‑parameter tuning, solver choice, computational efficiency, and reproducibility remain unaddressed.",
      "strengths": [
        "Introduces versatile Neural SDE classes for complex stochastic processes.",
        "Provides theoretical bounds on model robustness.",
        "Demonstrates significant empirical improvements over baseline models."
      ],
      "weaknesses": [
        "Lacks detailed hyper‑parameter tuning information.",
        "Missing ablation studies on numerical solvers.",
        "Does not detail computational efficiency or training time.",
        "Implementation code and reproducibility details are absent."
      ],
      "questions": [
        "Should be clarified: Which hyper‑parameters were tuned for training the Neural SDE models?",
        "Should be explored: What are the computational time and complexity of training Neural SDEs?",
        "Should be addressed: Are there reproducibility concerns due to the lack of publicly available code?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "4vPVBh3fhz",
    "title": "",
    "std_review": {
      "summary": "The paper presents a novel algorithm to mitigate label shift in machine learning models by adjusting importance weights through Gaussian elimination. It demonstrates improved accuracy in dynamic settings but has limitations in robustness to extreme shifts and computational efficiency. The overall recommendation is borderline.",
      "strengths": [
        "Effectively addresses label shift with importance weights.",
        "Provides a systematic refinement of weight estimates.",
        "Shows practical benefits in maintaining model accuracy."
      ],
      "weaknesses": [
        "Sensitivity to estimation errors in importance weights.",
        "Lack of mitigation strategies for weight estimation inaccuracies.",
        "Computational overhead from Gaussian elimination may limit scalability."
      ],
      "questions": [
        "How robust is the algorithm under extreme label shift conditions?",
        "What mechanisms can be introduced to mitigate estimation errors in importance weights?",
        "How does the algorithm perform on large datasets in terms of computational efficiency?"
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "4w4PDIT3h4",
    "title": "",
    "std_review": {
      "summary": "The paper introduces Diverse Data Augmentation (DDA) and Differential Diverse Data Augmentation (D3A) methods that leverage a lightweight Segnet to generate diverse masks for reinforcement learning agents in the Domain Randomization (DMC) environment. These methods significantly improve the agent's performance and robustness compared to existing approaches. The reviewer finds the contribution innovative and practical, though additional experiments are needed to fully assess generalizability.",
      "strengths": [
        "Introduces innovative data augmentation techniques (DDA and D3A) that leverage segmentation to generate diverse masks, enhancing the agent's ability to generalize across varied visual conditions.",
        "Utilizes a lightweight segmentation network (Segnet), which is computationally efficient compared to more complex segmentation methods, making the approach practical for real-world applications.",
        "Demonstrates superior performance and robustness of the proposed methods over existing object-centric approaches and traditional domain randomization techniques."
      ],
      "weaknesses": [
        "The paper could benefit from more detailed ablation studies to comprehensively evaluate the impact of different hyperparameters on the performance of DDA and D3A.",
        "Additional experiments or benchmarks are needed to thoroughly evaluate the generalizability of the proposed methods beyond the DMC environment.",
        "The potential overfitting of the pre-trained encoder to the DMC environment is mentioned but not extensively addressed, which could limit the practical applicability of the methods."
      ],
      "questions": [
        "How do the proposed methods perform when applied to other reinforcement learning environments beyond the DMC environment?",
        "What specific ablation studies are planned to further evaluate the impact of different hyperparameters on the performance of DDA and D3A?",
        "How can the potential overfitting of the pre-trained encoder to the DMC environment be mitigated to improve the practical applicability of the methods?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "4WKDwIaF7y",
    "title": "",
    "std_review": {
      "summary": "The paper introduces EG‑SAM, an extension of SAM that uses an extra‑gradient step to escape saddle points more effectively. Theoretical analysis supports the approach, and empirical experiments show significant performance gains, especially in deep neural networks with many saddle points. While the theoretical guarantees are limited to certain conditions and the method incurs some computational overhead, the paper makes a strong case for its practical benefits. Overall, the work is well‑motivated, theoretically grounded, and empirically validated, leading to an acceptance.",
      "strengths": [
        "Clear motivation for using extra‑gradient steps to improve SAM's saddle‑point escape.",
        "Solid theoretical foundation based on infinitesimal step sizes and quadratic loss.",
        "Empirical validation demonstrates substantial performance improvements, particularly in complex models.",
        "Novel contribution that builds on existing SAM techniques with a practical and theoretically sound approach."
      ],
      "weaknesses": [
        "Theoretical guarantees are limited to infinitesimal step sizes and quadratic loss, which may not fully capture practical scenarios.",
        "The introduction of extra‑gradient steps increases computational time, potentially affecting scalability.",
        "Empirical validation is primarily theoretical and lacks extensive real‑world training experiments.",
        "The paper could benefit from more comprehensive comparisons with other state‑of‑the‑art methods."
      ],
      "questions": [
        "How do the theoretical guarantees extend to larger step sizes and non‑quadratic loss functions?",
        "What is the computational overhead of EG‑SAM in large‑scale training scenarios compared to standard SAM?",
        "Can you provide more extensive real‑world validation of EG‑SAM using standard SGD?",
        "How does EG‑SAM compare to other state‑of‑the‑art methods in terms of convergence speed and final performance?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "4WM0OogPTx",
    "title": "Learning from Sparse Offline Datasets via Conservative Density Estimation",
    "std_review": {
      "summary": "The paper introduces Conservative Density Estimation (CDE), an offline RL method that balances exploration and exploitation through an OOD constraint and density estimation. It outperforms existing methods on MuJoCo tasks, especially with sparse or limited data, and provides strong theoretical guarantees. While practical challenges and scalability concerns exist, the method's robustness and empirical superiority justify its acceptance.",
      "strengths": [
        "Balanced exploration and exploitation via OOD constraint and density estimation.",
        "Robustness to out-of-distribution actions with strong theoretical guarantees.",
        "Empirical superiority across multiple MuJoCo tasks, particularly with limited data."
      ],
      "weaknesses": [
        "Complexity of hyperparameters, especially ε and μ, may require careful tuning.",
        "Potential scalability issues to high-dimensional or continuous control problems.",
        "Theoretical bounds may be overly conservative in some scenarios."
      ],
      "questions": [
        "How can the method be extended to high-dimensional or continuous control tasks?",
        "What are the theoretical conditions under which the OOD constraint is optimal?",
        "How does CDE perform in real-world offline RL settings with diverse and complex environments?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "4WnqRR915j",
    "title": "Lemma: an open language model for mathematics",
    "std_review": {
      "summary": "The paper introduces Llemma, an open-source language model trained on diverse mathematical datasets, achieving strong performance on benchmarks like MATH and GSM8k. It highlights the benefits of open‑source release and a well‑designed data mixture. However, it lacks detailed training specifics and reproducibility, and does not fully compare with state‑of‑the‑art models.",
      "strengths": [
        "Diverse Data Mixture: Combines multiple mathematical datasets to enhance model performance.",
        "Open‑Source Release: Encourages community participation and accelerates research.",
        "Strong Performance: Outperforms other open‑source models on standard benchmarks."
      ],
      "weaknesses": [
        "Lack of Detailed Training Details: Missing specifics on training objectives, loss functions, and hyper‑parameters.",
        "Limited Comparison with State‑of‑the‑Art Models: Does not include a comprehensive evaluation against proprietary models.",
        "Absence of Reproducibility Package: Training process and data release details are insufficient for reproducibility.",
        "Potential Overfitting: Fine‑tuning may limit the model's generalizability to unseen problems."
      ],
      "questions": [
        "Can you provide detailed training objectives, loss functions, and hyper‑parameters used?",
        "How does Llemma perform on newer, proprietary mathematical benchmarks?",
        "What steps are being taken to ensure reproducibility of the results?",
        "Are there plans to address potential overfitting through additional regularization or diverse data sources?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "4XCfu7fTgw",
    "title": "",
    "std_review": {
      "summary": "The paper introduces Lstd, a novel loss function designed to enhance adversarial robustness by encouraging proportional feature-label distances. Empirical experiments across multiple datasets demonstrate significant improvements over baseline models, supported by theoretical arguments and comprehensive evaluations. While the work shows strong promise, it could benefit from broader performance analysis and clearer explanations of terminology.",
      "strengths": [
        "Introduces a novel loss function (Lstd) that explicitly targets proportional feature-label distances, offering a fresh approach to adversarial training.",
        "Provides a clear theoretical rationale linking proportional distances to improved robustness, grounded in robust statistics.",
        "Demonstrates strong empirical improvements in adversarial robustness across several benchmark datasets.",
        "Includes thorough evaluation with ablation studies, visualizations, and ablations that support the proposed methodology."
      ],
      "weaknesses": [
        "Focuses primarily on adversarial robustness, potentially overlooking other performance metrics like clean-data accuracy.",
        "Ablation study on the hyperparameter β shows limited variation in metrics, which may understate its sensitivity.",
        "Visualizations could be enhanced with additional t-SNE plots for the singular-value loss term and combined loss.",
        "Terminology such as 'FT' (fine-tuning) is used without explicit definition, which may confuse readers."
      ],
      "questions": [
        "How does the proposed Lstd loss affect model performance on clean data compared to adversarial attacks?",
        "Could the sensitivity of the model to the hyperparameter β be further explored with a broader range of values?",
        "Would additional t-SNE visualizations for the singular-value loss term and combined loss provide clearer insights?",
        "Is there a clear discussion comparing the approach of maintaining proportional feature-label distances with existing adversarial training methods?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "4y3GDTFv70",
    "title": "A Latent Space Theory for Emergent Abilities in Large Language Models",
    "std_review": {
      "summary": "The paper introduces a novel concept of ε-ambiguity for universal approximators, linking it to neural network training dynamics and SGD. It provides a theoretical framework and explores implications for language modeling, particularly comparing character-based and BPE tokenizers. While the work is theoretically sound, it has practical and scope limitations that need addressing for broader applicability.",
      "strengths": [
        "Novel definition of ambiguity provides fresh perspective on expressiveness and generalization.",
        "Clear theoretical framework linking ambiguity to neural network training dynamics.",
        "Insightful analysis of tokenization methods and their impact on emergent properties."
      ],
      "weaknesses": [
        "Ambiguity of θ₀ is not clearly defined, potentially limiting practical applicability.",
        "Theorem's scope is tied to specific neural network architectures and SGD.",
        "Results are based on synthetic data, which may not capture real-world complexities.",
        "Analysis focuses on character-based and BPE tokenizers, potentially overlooking other methods."
      ],
      "questions": [
        "Clarify the role of θ₀ in the definition of ε-ambiguity.",
        "Explain the connection between the proof of Theorem 1 and neural network training.",
        "Address the implications of using synthetic data for the model's generalizability.",
        "Compare the theoretical results with real-world natural language data.",
        "Explore the applicability of the model to languages with complex morphology."
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "4yaFQ7181M",
    "title": "",
    "std_review": {
      "summary": "The paper presents a novel hybrid neural network model that integrates discrete and continuous dynamical systems within a graph neural network framework to simulate fluid dynamics. It effectively handles sparse data and offers interpretability through attention maps, while achieving computational efficiency gains over traditional methods. Despite promising results, the model's complexity and limited real-world validation raise concerns, suggesting further robustness and generalization studies.",
      "strengths": [
        "Innovative architecture combining discrete and continuous dynamical systems with GNNs and RNNs.",
        "Effective handling of sparse or missing data through learned latent representations.",
        "Provides interpretability via attention maps to highlight influential factors.",
        "Achieves significant computational efficiency improvements over traditional simulations."
      ],
      "weaknesses": [
        "The hybrid architecture introduces significant complexity, potentially hindering interpretability and requiring extensive hyperparameter tuning.",
        "Results are primarily validated on synthetic datasets, raising concerns about generalizability to real-world applications.",
        "Despite efficiency gains, the model still requires substantial computational resources, limiting accessibility for some users.",
        "Lack of thorough robustness analysis to hyper-parameter variations could affect practical deployment."
      ],
      "questions": [
        "How does the model perform on real-world datasets with varying levels of sparsity and noise?",
        "What are the specific hyperparameter sensitivities and how robust is the model to hyperparameter variations?",
        "What future work could address the limited validation and robustness concerns raised in the review?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "4YESQqIys7",
    "title": "NfgTransformer: Equivariant Representation Learning for Normal-form Games",
    "std_review": {
      "summary": "The NfgTransformer introduces a novel architecture that leverages permutation equivariance of normal-form games, showing promise in learning meaningful representations. While the theoretical foundation is solid, the model's reliance on assumed equivariance and lack of formal guarantees are concerns. Empirical results are promising but limited, and implementation details are not fully detailed, affecting reproducibility.",
      "strengths": [
        "Innovative architecture that explicitly incorporates permutation equivariance.",
        "Strong theoretical foundation leveraging a key property of normal-form games.",
        "Empirical validation demonstrating effectiveness across several game-theoretic tasks."
      ],
      "weaknesses": [
        "Relies on the assumption of inherent permutation equivariance, which may limit applicability.",
        "Lacks formal convergence or consistency guarantees.",
        "Limited scope of experiments may not fully capture the model's generalizability."
      ],
      "questions": [
        "What are the formal guarantees for convergence or consistency of the NfgTransformer?",
        "How can the model's performance be evaluated on a broader range of game-theoretic problems?",
        "Could the implementation details for handling invalid joint actions and DISC game generation be expanded?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "4YgfwJBJeQ",
    "title": "StructChart: Perception, Structuring, Reasoning for Visual Chart Understanding",
    "std_review": {
      "summary": "The paper proposes Structured Triplet Representation (STR) and StructChart, a two-stage pipeline that enhances chart image interpretability by reformating data into structured triplets and integrating a reasoning model (GPT-3.5). It introduces the SCRM metric for evaluating perception, showing superior results over benchmarks. The reviewer finds the approach promising, with strong empirical results and a clear evaluation framework, recommending acceptance.",
      "strengths": [
        "STR significantly improves interpretability by structuring chart data into triplets.",
        "The two-stage pipeline separates perception and reasoning, potentially leading to more efficient model performance.",
        "SCRM provides a robust evaluation metric tailored for chart understanding tasks."
      ],
      "weaknesses": [
        "Scalability of STR for large and complex datasets is not thoroughly analyzed.",
        "Evaluation focuses on a single reasoning model, limiting generalizability.",
        "Potential limitations in handling noisy or incomplete data are not extensively explored.",
        "Comparison with other methods is limited to specific evaluation settings."
      ],
      "questions": [
        "How does the STR approach scale to large and complex datasets?",
        "What are the robustness considerations for handling noisy or incomplete data in the perception stage?",
        "How does the performance of StructChart change when evaluated with different reasoning models?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "4YK1e3Ehdy",
    "title": "Understanding Deep Neural Networks as Dynamical Systems: Insights into Training and Fine-tuning",
    "std_review": {
      "summary": "The paper introduces a novel framework for interpreting deep neural networks (DNNs) by mapping them onto dynamical systems, defining a 'dynamical discrepancy' metric that correlates with the network's capacity to capture complex patterns. It provides a strong theoretical foundation linking dynamical discrepancy to model capacity and demonstrates empirical relevance across vision and language models. While the novelty is somewhat limited by its application of existing dynamical systems theory, the framework offers valuable insights into model interpretability and training dynamics.",
      "strengths": [
        "Innovative framework for interpreting DNNs as dynamical systems.",
        "Introduces a quantitative 'dynamical discrepancy' metric for assessing representational power.",
        "Provides a strong theoretical foundation with theorems linking discrepancy to model capacity.",
        "Demonstrates practical relevance through experiments on diverse datasets and architectures."
      ],
      "weaknesses": [
        "Novelty is limited to applying dynamical systems theory to DNNs rather than introducing new theory.",
        "Complex mathematical definitions and notation may be challenging for some readers.",
        "Empirical studies are limited to specific architectures and datasets, potentially limiting generalizability.",
        "Visualization techniques could be sensitive to noise, leading to misleading interpretations."
      ],
      "questions": [
        "How does the dynamical discrepancy compare to existing interpretability metrics in terms of predictive power and ease of use?",
        "What are the computational costs of calculating the dynamical discrepancy, and how does it scale with model size?",
        "How robust is the dynamical discrepancy to different types of noise or perturbations in the data?",
        "Can the framework be extended to other types of neural networks beyond feedforward and recurrent models?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "4zfbwpGhd8",
    "title": "",
    "std_review": {
      "summary": "The paper introduces VITAL, a method that enhances instruction tuning for efficient fine-tuning of large language models by combining multiple instruction sets. It demonstrates strong performance on several benchmarks and offers significant efficiency gains, though it also introduces computational overhead. The novelty of the instruction mixture and clear methodology are highlighted, but concerns about scalability and comprehensive baseline comparisons remain.",
      "strengths": [
        "Innovative Instruction Mixture: The use of an enhanced instruction mixture is a novel approach that differentiates VITAL from existing methods like LoRA and Adapter.",
        "Efficiency Gains: The method demonstrates significant efficiency gains, particularly in terms of reduced fine-tuning costs.",
        "Strong Benchmark Performance: VITAL achieves competitive results across multiple multimodal benchmarks, showcasing its effectiveness.",
        "Clear Methodology: The paper provides a clear and well-documented methodology, making it easy for readers to understand and replicate."
      ],
      "weaknesses": [
        "Computational Overhead: The introduction of an enhanced instruction mixture may increase computational overhead.",
        "Limited Baseline Comparison: The comparison with other recent methods is not exhaustive.",
        "Ablation Studies: While conducted, they could be more comprehensive.",
        "Scalability Concerns: The scalability of the method to very large models or datasets is not thoroughly addressed."
      ],
      "questions": [
        "How does the computational overhead of the enhanced instruction mixture scale with model size?",
        "Could more extensive ablation studies be conducted to better understand the impact of different components?",
        "What are the scalability implications for very large models or datasets?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "4znwzG92CE",
    "title": "Habitat 3.0: A Co-Habitat for Humans, Avatars and Robots",
    "std_review": {
      "summary": "The paper introduces Habitat 3.0, a co-habitat framework that integrates motion capture data with a physics-based simulator to generate realistic humanoid locomotion. It leverages VPoser to convert motion capture data into humanoid poses, which are then used in a simulator for improved realism. The method addresses common issues like rigid rotations and straight-line paths seen in existing humanoid agents. While promising, the approach has limitations in handling complex motions and relies on high-quality motion capture data. Overall, the paper is well-received for its innovative approach and clear demonstration of improved realism.",
      "strengths": [
        "Integrates motion capture data with a physics-based simulator for realistic humanoid locomotion.",
        "Utilizes VPoser to efficiently generate realistic poses from motion capture data.",
        "Demonstrates significant improvements in realism compared to baseline methods."
      ],
      "weaknesses": [
        "May struggle with complex motions beyond simple interpolation.",
        "Potential rigidity in motion, especially during transitions.",
        "Dependence on high-quality motion capture data for effectiveness."
      ],
      "questions": [
        "How can the method be extended to handle more complex and varied motion scenarios?",
        "What strategies can be employed to mitigate rigidity in motion, particularly during transitions?",
        "How does the approach perform with lower-quality or noisy motion capture data?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "4Zz5UELkIt",
    "title": "",
    "std_review": {
      "summary": "The paper introduces DIA, a distributed method for improving sample efficiency in machine learning by combining influence functions with multi-rejection importance sampling. It provides strong theoretical guarantees and demonstrates significant improvements in convergence speed and model performance on several datasets. While the method is computationally intensive and may require further validation on a broader range of data, its novelty and effectiveness are compelling.",
      "strengths": [
        "Introduces a novel approach to sample efficiency in high-dimensional settings.",
        "Combines influence functions with multi-rejection importance sampling for practical benefits.",
        "Provides strong theoretical guarantees for the estimator's consistency and normality.",
        "Demonstrates clear experimental improvements over existing methods."
      ],
      "weaknesses": [
        "Implementation complexity and high computational requirements may limit accessibility.",
        "Lack of detailed discussion on trade-offs between adaptivity and data independence.",
        "Experimental validation is limited to a few datasets, warranting broader testing.",
        "Theoretical guarantees are presented in an abstract manner, potentially confusing non-experts."
      ],
      "questions": [
        "How can the computational demands of DIA be reduced to improve its practical applicability?",
        "What are the specific trade-offs between adaptivity and data independence, and how are they managed?",
        "How generalizable is DIA to other domains and data types beyond the evaluated datasets?",
        "Can the theoretical guarantees be made more accessible to a wider audience?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "4zZFGliCl9",
    "title": "",
    "std_review": {
      "summary": "The paper provides novel theoretical insights into posterior collapse in Conditional Variational Autoencoders (CVAEs) and Hierarchical Linear Variational Autoencoders (MHVAEs), extending previous work on standard linear VAEs. It identifies key hyperparameters and the role of encoder variance in mitigating collapse, offering actionable recommendations for practitioners. The findings are supported by empirical evidence and contribute to a deeper understanding of latent space dynamics in advanced VAE models.",
      "strengths": [
        "Novel theoretical contributions extending posterior collapse analysis to CVAEs and MHVAEs.",
        "Empirical validation demonstrating the impact of identified hyperparameters and encoder variance.",
        "Practical implications with actionable recommendations for mitigating collapse in advanced VAE models.",
        "Comprehensive analysis of latent space dynamics and hyperparameter effects."
      ],
      "weaknesses": [
        "Focus on complex model architectures may limit generalizability to simpler or non-linear models.",
        "Empirical scope is limited to specific model configurations.",
        "Theoretical rigor could be further validated or extended to other model families.",
        "Lack of extensive comparison with a broader range of existing models."
      ],
      "questions": [
        "How do the identified hyperparameters and encoder variance generalize to other model architectures beyond CVAEs and MHVAEs?",
        "What is the impact of posterior collapse on downstream tasks, and how do the proposed mitigations affect performance?",
        "Can the theoretical conditions be extended to non-linear or non-conditional VAE variants?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "506Sxc0Adp",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a novel diversity coefficient metric designed to quantify the heterogeneity of pre‑training data for large language models (LLMs). The metric aims to correlate higher diversity with improved LLM performance, supported by empirical experiments and theoretical bounds. While the approach is theoretically grounded and empirically validated, it may have limited generalizability across different domains and datasets. The authors acknowledge these limitations and suggest future work to refine the metric and explore its broader applicability.",
      "strengths": [
        "Introduces a novel and theoretically grounded metric for assessing data diversity, which is crucial for LLM pre‑training.",
        "Provides clear theoretical bounds that help contextualize the metric's values and validate its relevance.",
        "Employs robust experimental evidence to demonstrate the correlation between data diversity and LLM performance.",
        "Offers a comparative analysis with existing metrics, highlighting the unique contributions of the proposed diversity coefficient."
      ],
      "weaknesses": [
        "The metric's reliance on specific theoretical bounds may limit its applicability to diverse datasets across different domains.",
        "The experimental validation is primarily focused on a limited set of datasets, which may not generalize well to all types of data.",
        "The paper lacks a detailed discussion on potential biases or limitations in the diversity coefficient that could affect its practical use.",
        "The comparison with cross‑diversity coefficients is somewhat superficial, potentially overlooking nuanced differences that could impact metric selection."
      ],
      "questions": [
        "How can the metric be validated across a broader range of datasets and domains?",
        "What are the potential biases or limitations in the diversity coefficient that could affect its practical use?",
        "How does the metric compare to other state‑of‑the‑art diversity measures in terms of computational efficiency and interpretability?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "50P9TDPEsh",
    "title": "Critique Ability of Large Language Models",
    "std_review": {
      "summary": "The paper introduces a benchmark for evaluating the critique ability of large language models across math, code, and commonsense reasoning. It proposes a self-check baseline that uses LLMs to critique their own outputs, aiming to improve self-critique. Evaluated on GSM8K, TruthfulQA, and HumanEval, the results show effectiveness in error identification and correction, though some limitations and biases are noted. Overall, the paper makes a valuable contribution to assessing LLM critique capabilities.",
      "strengths": [
        "Comprehensive benchmarking across multiple domains",
        "Innovative self-check baseline for evaluating LLM critique ability",
        "Clear and reproducible evaluation metrics"
      ],
      "weaknesses": [
        "Choice of k values is somewhat arbitrary without detailed justification",
        "Prompting strategy lacks detailed description",
        "Limited discussion on bias mitigation strategies",
        "Baseline compared to existing approaches only qualitatively"
      ],
      "questions": [
        "Could you provide more empirical justification for the selected k values?",
        "What specific prompt templates were used and how were critiques evaluated?",
        "What concrete bias mitigation techniques were employed and how were they validated?",
        "How does the self-check baseline perform compared to other quantitative baselines across tasks?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "50vyPuz0iv",
    "title": "Iteratively Refined Behavior Regularization for Offline Reinforcement Learning",
    "std_review": {
      "summary": "The paper introduces Iteratively Refined Behavior Regularization (IRBR), a method that enhances offline reinforcement learning by adding a KL regularization term to the TD3+BC objective. This approach improves policy stability and performance, as demonstrated on both toy datasets and the D4RL benchmark. While theoretically sound and empirically validated, the method's practical challenges and robustness to out‑of‑distribution data remain unexplored.",
      "strengths": [
        "Novel approach to refining behavior policies in offline RL",
        "Improved policy stability through KL regularization",
        "Strong theoretical foundation with convergence guarantees"
      ],
      "weaknesses": [
        "Computational complexity of iterative refinement",
        "Lack of analysis on sample efficiency and convergence speed",
        "Unclear generalization to complex tasks",
        "No robustness evaluation to out‑of‑distribution queries"
      ],
      "questions": [
        "How does the iterative refinement process affect sample efficiency and convergence speed?",
        "What are the trade‑offs between sample efficiency and robustness to out‑of‑distribution data?",
        "Can the theoretical convergence guarantees be extended to continuous or high‑dimensional state/action spaces?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "51cjeYcXjs",
    "title": "",
    "std_review": {
      "summary": "The paper introduces DDGs as a program representation for malware similarity analysis, arguing they capture operational semantics and structural characteristics more effectively than traditional graphs. It demonstrates the method on two Trojan samples, showing robustness to obfuscation and fine-grained similarity detection. The approach balances coarse-grained search with fine-grained accuracy, using specific metrics to validate functional overlap. The reviewer finds the method promising and recommends acceptance.",
      "strengths": [
        "Enhanced semantic capture through data dependencies",
        "Robustness to obfuscation and anti-debugging techniques",
        "Fine-grained similarity detection capabilities",
        "Efficient search and hashing using DDG representations"
      ],
      "weaknesses": [
        "Complexity and computational intensity of DDG extraction",
        "Potential information loss during static reverse-engineering",
        "Limited generalizability to other malware families",
        "Metric selection may not fully capture all aspects of functional overlap"
      ],
      "questions": [
        "How does the method scale to larger malware datasets?",
        "What are the specific techniques used to mitigate information loss during static reverse-engineering?",
        "How can the method be extended to other malware families beyond Trojans?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "52fz5sUAy2",
    "title": "",
    "std_review": {
      "raw_text": "{\n  \"summary\": \"KuaiRec proposes a novel recommendation framework using a custom probability density function (PDF) for personalized item scoring, incorporating both Epanechnikov and Gaussian kernels to model user-item interactions. The approach shows promise in improving recommendation quality on synthetic and semi-synthetic datasets, but lacks detailed justification for kernel selection and empirical validation of neighboring effect modeling. The paper also has some implementation ambiguities and lacks clarity on how to measure and record missing data metrics.\",\n  \"strengths\": [\n    \"Innovative PDF specification for personalized scoring\",\n    \"Flexible kernel selection strategy with clear rationale\",\n    \"Explicit modeling of neighboring effects\"\n  ],\n  \"weaknesses\": [\n    \"Lack of detailed justification for preferring Epanechnikov kernel\",\n    \"Ambiguous definition of neighboring set \\( N_{u,i} \\)\",\n    \"No quantitative validation of neighboring effect modeling\",\n    \"Unclear method for adjusting \\( p \\) to achieve observed sample size\",\n    \"Missing details on recording Missing At Random (MAR) metrics\"\n  ],\n  \"questions\": [\n    \"Could you provide a detailed empirical comparison or theoretical justification for preferring the Epanechnikov kernel over other kernels?\",\n    \"Please clarify the definition of \\( N_{u,i} \\) and how it is computed in practice.\",\n    \"What quantitative validation was performed to assess the effectiveness of the neighboring effect adjustment on \\( p_{u,i} \\)?\",\n    \"Could you describe the method used to adjust \\( p \\) to ensure the observed sample is 5% of the entire matrix?\",\n    \"How are Missing At Random (MAR) and MAR watching ratios recorded and measured in your experiments?\"\n  ],\n  \"overall_score\": \"5: borderline\",\n  \"confidence\": \"3: medium\"\n}",
      "parse_error": true
    }
  },
  {
    "paper_id": "52igC7K5Mf",
    "title": "GC-Mixer: A Novel Architecture for Time-varying Granger Causality Inference",
    "std_review": {
      "summary": "GC-Mixer presents a hierarchical causal discovery framework that extends cMLP with a graph-based architecture to capture multi-level dependencies in time-series data. The method improves accuracy and interpretability over traditional models, as shown on synthetic datasets. While promising, the paper has several methodological concerns, such as ambiguous loss function definitions and lack of detailed complexity analysis, which limit its overall impact.",
      "strengths": [
        "Hierarchical causal modeling captures both immediate and long-range dependencies.",
        "Parameter efficiency and reduced resource usage compared to cMLP and cLSTM.",
        "Scalability to larger datasets with faster training times."
      ],
      "weaknesses": [
        "Ambiguous loss function in Equation 12 regarding summation over time and series.",
        "Threshold ϵ for Granger causality inference not clearly derived.",
        "Limited evaluation on nonlinear or non-lag based datasets.",
        "Ambiguous time complexity notation and missing analysis of multi-level fine-tuning cost."
      ],
      "questions": [
        "How is the loss function in Equation 12 precisely defined and computed?",
        "What is the exact method for selecting the threshold ϵ in Equation 13?",
        "How does GC-Mixer perform on nonlinear or non-lag based datasets like Dream-3 or Lotka-Volterra?",
        "What is the computational cost of the multi-level fine-tuning process, and how does it compare to single-level training?",
        "Is manual splitting of data an option, and how does it compare to automatic splitting in terms of performance and parameter requirements?"
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "532tcx7IHF",
    "title": "RLLTE: Long-Term Evolution Project of Reinforcement Learning",
    "std_review": {
      "summary": "RLLTE introduces a modular RL framework that decouples RL algorithms from the exploitation-exploration trade-off, integrating large language models as a copilot to assist in RL research and application. The framework aims to improve modularity, ease of use, and performance, with preliminary results showing enhanced performance and flexibility across various RL tasks. While promising, the paper has some limitations, such as limited benchmarking, integration complexity, scalability concerns, and a lack of detailed implementation guidance.",
      "strengths": [
        "RLLTE effectively decouples RL algorithms from the exploitation-exploration trade-off, allowing for more flexible and modular design.",
        "The integration of an LLM as a copilot significantly enhances the research and application process by providing intelligent assistance and guidance.",
        "The framework is designed to be user-friendly, making it accessible for researchers and practitioners with varying levels of expertise.",
        "Preliminary results indicate that RLLTE outperforms existing RL frameworks in terms of performance and flexibility."
      ],
      "weaknesses": [
        "The paper lacks comprehensive benchmarking against a wide range of existing RL frameworks, which could strengthen the claim of superior performance.",
        "The integration of LLMs introduces additional complexity, which might be challenging for users unfamiliar with LLMs.",
        "There is a potential concern regarding the scalability of the framework, particularly in handling very large-scale RL problems.",
        "The paper could benefit from more detailed guidance on implementing the framework, especially for users who are not familiar with RL or LLMs."
      ],
      "questions": [
        "How does RLLTE compare to other RL frameworks in terms of performance across a broader range of benchmarks?",
        "What specific strategies are employed to address the scalability concerns of the framework?",
        "Could you provide more detailed implementation guidance or examples to help users unfamiliar with RL or LLMs adopt the framework effectively?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "53gU1BASrd",
    "title": "Evaluating and Finetuning Models For Financial Time Series Forecasting",
    "std_review": {
      "summary": "The paper introduces a novel evaluation framework for financial time series forecasting using large pre‑trained models, demonstrating superior risk‑adjusted returns compared to traditional baselines. While innovative, the study suffers from limited dataset scope, lack of reproducibility, and omission of alternative architectures and market frictions. Overall, it is a promising contribution with notable methodological concerns.",
      "strengths": [
        "Innovative use of Sharpe ratio as the primary performance metric.",
        "Demonstrates the potential of transfer learning with large pre‑trained models for financial forecasting.",
        "Provides a comprehensive back‑testing pipeline that includes transaction costs."
      ],
      "weaknesses": [
        "Reliance on web‑scraped data may introduce biases and limit generalizability.",
        "Absence of reproducibility details (open‑sourced code, API dependencies).",
        "Evaluation limited to Transformers, ignoring other architectures.",
        "Omitted consideration of other market frictions beyond transaction costs."
      ],
      "questions": [
        "What specific web‑scraping tools and validation methods were used for data collection?",
        "How does the evaluation pipeline handle transaction costs and slippage beyond the mentioned aspects?",
        "Are there plans to test model generalization on tasks other than price prediction?",
        "Will future work address the impact of model size and alternative architectures?",
        "How will the study be made reproducible, including code and dependency details?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "53kW6e1uNN",
    "title": "AFDGCF: Adaptive Feature De-correlation Graph Collaborative Filtering for Recommendations",
    "std_review": {
      "summary": "The paper proposes the Adaptive Feature Decorrelation (AFD) loss function to mitigate over-smoothing and over-correlation in GNNs used for recommendations. It establishes a theoretical link between correlated node embeddings and degraded recommendation quality, and demonstrates significant empirical improvements over existing methods on benchmark datasets. While the approach is innovative and well-supported by theory and experiments, concerns about dataset preprocessing and the potential benefits of integrating with self-supervised learning methods limit its overall acceptance.",
      "strengths": [
        "Clear theoretical foundation linking over-smoothing and over-correlation to recommendation quality.",
        "Innovative AFD loss function that directly addresses feature correlation in GNNs.",
        "Empirical validation showing substantial performance gains over existing methods."
      ],
      "weaknesses": [
        "Dataset preprocessing may introduce bias by excluding less active users/items.",
        "No exploration of integrating AFD with self-supervised learning techniques.",
        "Evaluation limited to a few benchmark datasets, potentially limiting generalizability."
      ],
      "questions": [
        "How does the AFD loss function compare to other regularization techniques for GNNs in recommendation systems?",
        "What are the computational implications of applying AFD to large-scale recommendation datasets?",
        "Could integrating AFD with self-supervised learning methods further enhance recommendation performance?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "5451cIQdWp",
    "title": "On Synthetic Data and Iterative Magnitude Pruning: A Linear Mode Connectivity Study",
    "std_review": {
      "summary": "The paper introduces a novel approach to pruning neural networks using synthetic data derived from distilled models, aiming to create more stable subnetworks. It employs loss landscape analysis and Hessian approximation to demonstrate that synthetic subnetworks exhibit smoother loss landscapes, leading to improved generalization and optimization. The findings are theoretically linked to the information bottleneck framework, suggesting that synthetic subnetworks achieve more effective information compression. While the approach shows practical benefits, such as serving as a stable initialization for iterative magnitude pruning, it faces limitations in scalability and requires further theoretical substantiation.",
      "strengths": [
        "Introduces a novel pruning approach using synthetic data.",
        "Provides comprehensive analysis of loss landscape and stability metrics.",
        "Connects findings to the information bottleneck framework.",
        "Demonstrates practical benefits for iterative magnitude pruning."
      ],
      "weaknesses": [
        "Scalability to larger models is not fully addressed.",
        "Lack of detailed exploration of retraining synthetic subnetworks.",
        "Theoretical connection to the information bottleneck framework lacks rigorous substantiation."
      ],
      "questions": [
        "How can the approach be scaled to larger model architectures?",
        "What are the specific steps for retraining synthetic subnetworks for different tasks?",
        "What further theoretical analysis is needed to substantiate the connection to the information bottleneck framework?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "54AwQUaDZo",
    "title": "Bounding the Robustness and Generalization for Individual Treatment Effect",
    "std_review": {
      "summary": "The paper introduces RITEWASS and RITEMMD, methods that estimate counterfactual treatment effects (CATE) using Lipschitz regularization with Wasserstein and MMD metrics. These methods improve robustness and interpretability, outperforming baselines across various datasets and noise levels. While innovative and theoretically grounded, the paper has several concerns regarding clarity, experimental design, and methodological details.",
      "strengths": [
        "Introduces a novel approach to CATE estimation using Lipschitz regularization.",
        "Provides strong theoretical foundations with theorems on Lipschitz continuity.",
        "Conducts comprehensive experimental evaluations across diverse datasets and noise levels."
      ],
      "weaknesses": [
        "Raises questions about the definition and necessity of the Lipschitz constant.",
        "Concerns about the Lipschitz constant for the loss and interpretation of covering numbers.",
        "Lacks detailed analysis of performance across different noise levels.",
        "Needs clearer explanation of why certain methods are more suitable in specific scenarios.",
        "Lacks detailed hyper-parameter tuning procedure and contains potential clerical errors."
      ],
      "questions": [
        "Clarify the definition and necessity of the Lipschitz constant used in the theorems.",
        "Provide a detailed analysis of performance across different noise levels.",
        "Explain why the Wasserstein-based method is more suitable for certain data distributions.",
        "Detail the hyper-parameter tuning procedure for reproducibility.",
        "Address any clerical errors in mathematical symbols or formulas."
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "55uj7mU7Cv",
    "title": "Towards Identifiable Unsupervised Domain Translation: A Diversified Distribution Matching Approach",
    "std_review": {
      "summary": "The paper presents a novel approach to unsupervised domain translation that tackles content misalignment by using auxiliary variables to eliminate the multiple translation functions (MPA) problem. Empirical results show improved content alignment and sample quality compared to existing methods. While the method has theoretical strengths and practical promise, it relies on several assumptions that may limit its generalizability and practical applicability.",
      "strengths": [
        "Introduces a novel method for addressing content misalignment in unsupervised domain translation.",
        "Proposes the use of auxiliary variables to eliminate the MPA issue, a significant advancement in the field.",
        "Provides a clear theoretical framework for understanding the identifiability of the proposed model."
      ],
      "weaknesses": [
        "The identifiability analysis relies on several key assumptions that may not hold in all scenarios.",
        "The justification for using auxiliary variables is based on theoretical considerations, but practical applicability may be limited.",
        "The proposed model assumes invertibility, which may not always be realistic in practice."
      ],
      "questions": [
        "How robust is the method to violations of the key assumptions underlying the identifiability analysis?",
        "What are the practical implications of the invertibility assumption in real-world applications?",
        "How does the method perform on a broader range of datasets beyond those evaluated in the empirical results?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "567BjxgaTp",
    "title": "How to Catch an AI Liar:",
    "std_review": {
      "summary": "The paper introduces a novel method for detecting lies in language models by analyzing their responses to unrelated follow-up questions. The approach leverages a set of follow-up questions designed to probe the model's knowledge and consistency, aiming to identify discrepancies that may indicate a lie. The method is evaluated on several language models, demonstrating its effectiveness in distinguishing truthful from deceptive outputs. The results highlight the potential of this technique to enhance the reliability and safety of large language models in real-world applications. Overall, the paper is well‑structured, with clear strengths in methodology and evaluation, though some limitations remain.",
      "strengths": [
        "Provides a clear and formal definition of what constitutes a 'lie' from a language model perspective.",
        "Introduces an innovative methodology using unrelated follow-up questions to probe model consistency.",
        "Demonstrates robust evaluation metrics and generalization across different language models and tasks."
      ],
      "weaknesses": [
        "Selection criteria for unrelated follow-up questions may be subjective.",
        "Evaluation metrics could benefit from additional benchmarks.",
        "Robustness against sophisticated lies is not fully explored.",
        "Generalization experiments could be expanded to more diverse models and tasks."
      ],
      "questions": [
        "How can the selection criteria for unrelated follow-up questions be made more objective?",
        "What additional benchmarks or comparisons would better contextualize the evaluation metrics?",
        "How does the method perform against sophisticated or nuanced lies?",
        "Could the generalization experiments be expanded to include more diverse language models and tasks?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "56jIlazr6a",
    "title": "Unified Uncertainty Calibration",
    "std_review": {
      "summary": "The paper introduces a unified framework for estimating both aleatoric and epistemic uncertainties in deep learning models, aiming to improve calibration and uncertainty estimation. It proposes a novel calibration function τᵤ and demonstrates strong empirical results on benchmark datasets. While the approach is theoretically sound and empirically validated, several concerns about calibration, estimator choice, and clarity in the theoretical framework need addressing.",
      "strengths": [
        "Unified Approach: Presents a single method for estimating both aleatoric and epistemic uncertainties.",
        "Calibration Focus: Emphasizes high calibration accuracy, crucial for safety-critical applications.",
        "Theoretical Foundation: Grounded in a solid theoretical framework with clear definitions."
      ],
      "weaknesses": [
        "Calibration Function Dependency: Unclear if τᵤ needs further calibration when used as logits for class c+1.",
        "Uncertainty Estimator Requirements: The choice of epistemic uncertainty estimator u is not clearly defined.",
        "Equation Ambiguity: Equation (7) uses τ̃ ambiguously; τᵤ(x) should be used instead.",
        "Interpretation of Non-linearity: The concept of τ̃ᵤ being non-linear is not well-explained.",
        "Philosophical Content: While insightful, the philosophical remarks may not be essential for understanding the technical contribution."
      ],
      "questions": [
        "Should τᵤ be further calibrated to avoid interference with logits for class c+1?",
        "What criteria should be used to select and validate the epistemic uncertainty estimator u?",
        "How should Equation (7) be corrected to use τᵤ(x) instead of τᵤ(u(x))?",
        "Can an example of a non-linear τ̃ᵤ (e.g., a ReLU MLP) be provided to clarify the approach?",
        "How essential are the philosophical remarks for understanding the technical contribution?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "59nCKifDtm",
    "title": "Improve Temporal Consistency In Diffusion Models through Noise Correlations",
    "std_review": {
      "summary": "ARTDiff introduces a novel approach to enhance temporal consistency in diffusion models by using an autoregressive temporal prior (ART) with an AR(1) model to predict future frames. The method improves temporal coherence of generated sequences, outperforming existing methods in complex scenarios. While showing strong promise, the approach has limitations such as hyperparameter sensitivity and increased computational cost, which may affect its real-time applicability.",
      "strengths": [
        "Innovative combination of autoregressive priors and AR(1) models to address temporal consistency.",
        "Significantly improves temporal coherence of generated sequences across different domains.",
        "Demonstrates broad applicability to various sequential data types."
      ],
      "weaknesses": [
        "High sensitivity to hyperparameter choices, requiring extensive tuning.",
        "Increased computational complexity may limit real-time use.",
        "Specifically designed for sequential data, requiring modifications for non-sequential data."
      ],
      "questions": [
        "How can the method be extended to handle highly irregular or rapidly changing dynamics?",
        "What strategies can be employed to reduce computational cost for real-time applications?",
        "How does ARTDiff perform on non-sequential data types beyond audio and motion?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "5a79AqFr0c",
    "title": "ControlVideo: Training-free Controllable Text-to-Video Generation",
    "std_review": {
      "summary": "The paper presents ControlVideo, a method for generating long-form videos from text prompts using a cross-frame interaction mechanism to ensure temporal consistency and reduce flickering. It integrates a diffusion-based text-to-video model with cross-frame attention, improving motion coherence and background synchronization. Experiments show strong quantitative performance, especially in long video generation and handling complex motion patterns, though some limitations remain in long-video validation and reproducibility.",
      "strengths": [
        "Innovative cross-frame interaction mechanism for temporal consistency",
        "Improved temporal consistency and reduced flickering",
        "Strong quantitative performance over existing methods"
      ],
      "weaknesses": [
        "Limited validation for long video generation",
        "Potential flickering issues not fully addressed",
        "Lack of reproducibility due to missing code/models/data"
      ],
      "questions": [
        "Could additional long-video results further validate the method's scalability?",
        "What strategies could be employed to address flickering caused by complex motion patterns?",
        "How can the method be made more reproducible by releasing code, models, and data?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "5AbtYdHlr3",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a novel learning algorithm for stochastic action models (SAM) that handles actions with multiple effects using tensor decomposition. It provides theoretical guarantees under a bounded tensor rank assumption and demonstrates improved learning efficiency and accuracy on synthetic and real-world datasets. The approach addresses a gap in existing literature by explicitly modeling multi-effect actions, offering a significant advancement over prior work focused on single-effect actions. Overall, the paper is well‑structured, clearly presented, and makes substantial contributions to the field.",
      "strengths": [
        "Novel handling of multi-effect actions, a significant gap in existing literature.",
        "Provides theoretical guarantees under a bounded tensor rank assumption.",
        "Demonstrates substantial improvements in learning efficiency and accuracy.",
        "Clearly distinguishes its contributions from prior work."
      ],
      "weaknesses": [
        "Relies on the assumption of a small, fixed number of effects per action, limiting applicability.",
        "Introduces computational complexity through tensor decomposition, which could be a bottleneck for large-scale problems.",
        "Lacks empirical validation across diverse domains, potentially limiting generalizability.",
        "Performance may be sensitive to the choice of tensor rank, requiring domain expertise."
      ],
      "questions": [
        "How does the algorithm perform on datasets with actions that inherently have a large number of effects?",
        "What is the impact of the tensor rank choice on the algorithm's performance, and how can practitioners determine an appropriate rank?",
        "Could the approach be extended to handle non‑deterministic or probabilistic effects of actions?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "5aHmaMFJns",
    "title": "Reason for Future, Act for Now: A Principled Architecture for Autonomous LLM Agents",
    "std_review": {
      "summary": "The paper proposes a novel architecture that integrates large language models (LLMs) with traditional planning techniques to enhance planning and optimization. It demonstrates significant improvements in task completion speed and accuracy across multiple benchmarks. While the approach is promising, it lacks detailed analysis of computational resources and a comprehensive comparison with existing methods, which limits its practical feasibility assessment.",
      "strengths": [
        "Integrates LLMs with traditional planning to address complex planning problems.",
        "Shows substantial improvements in task performance across various benchmarks.",
        "Provides insights into computational resource requirements and scalability."
      ],
      "weaknesses": [
        "Lacks detailed information on learning time for each task.",
        "Limited comparison with state-of-the-art planning methods.",
        "Does not quantify the effort spent on prompt tuning.",
        "Computational resource details are not fully detailed."
      ],
      "questions": [
        "Could you provide more detailed metrics on the learning time required for each task?",
        "How does the proposed method compare with the latest state-of-the-art planning and optimization techniques?",
        "What is the exact effort involved in prompt tuning, and how does it affect the method's effectiveness?",
        "Are there any specific scenarios where the method's computational requirements become prohibitive?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "5BCFlnfE1g",
    "title": "",
    "std_review": {
      "summary": "The paper introduces MetaCLIP, a curated image-text dataset that significantly improves CLIP's performance by filtering and balancing image-text pairs using Wikipedia and WordNet. The dataset outperforms existing benchmarks in image-text retrieval and zero-shot classification, with a transparent and reproducible curation process. While the choice of metadata sources may limit diversity, the methodology's strengths outweigh these concerns, leading to an acceptance.",
      "strengths": [
        "Innovative curation process using Wikipedia and WordNet.",
        "Demonstrated superior performance over existing datasets.",
        "Transparent and reproducible methodology."
      ],
      "weaknesses": [
        "Dependence on specific metadata sources may limit dataset diversity.",
        "Sensitivity to hyper-parameters affecting reproducibility.",
        "Randomness in balancing stage could introduce variability."
      ],
      "questions": [
        "How can the dataset be extended to cover underrepresented topics or languages?",
        "What strategies can be employed to reduce bias from source metadata?",
        "How does the dataset perform on more challenging downstream tasks?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "5bNYf0CqxY",
    "title": "Certified Adversarial Robustness for Rate Encoded Spiking Neural Networks",
    "std_review": {
      "summary": "The paper introduces a novel approach to enhance adversarial robustness in Spiking Neural Networks (SNNs) through rate encoding, establishing a formal connection to randomized smoothing. It proposes an adversarial training method that improves robust accuracy over existing methods, though it sacrifices some clean accuracy. The empirical analysis highlights trade-offs and provides insights into the limitations of current theoretical bounds, making a significant contribution to the field.",
      "strengths": [
        "Establishes a formal connection between rate encoding and randomized smoothing.",
        "Introduces a novel adversarial training method tailored for rate-encoded SNNs.",
        "Provides comprehensive empirical analysis of robustness trade-offs."
      ],
      "weaknesses": [
        "Empirical robustness comes with a lower clean accuracy, limiting practical applicability.",
        "Lacks detailed training parameters and hyperparameters.",
        "Does not comprehensively compare with the latest state-of-the-art methods.",
        "Insufficient discussion on generalization across attack types."
      ],
      "questions": [
        "Could the proposed method be extended to other types of spiking networks beyond SNNs?",
        "How does the method perform under more sophisticated adversarial attacks?",
        "What are the theoretical limits of the proposed adversarial training method?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "5BoXZXTJvL",
    "title": "Beyond Size: How Gradients Shape Pruning Decisions in Large Language Models",
    "std_review": {
      "summary": "The paper introduces GBLM‑Pruner, a gradient‑based pruning framework for LLMs that uses a novel metric combining weight magnitude and gradient information to guide pruning. It achieves high sparsity (2:4) while maintaining performance, outperforming existing methods on the LLaMA‑2‑70B model. The approach shows strong gains in computational efficiency and scalability, though it introduces a new hyperparameter that could complicate pruning.",
      "strengths": [
        "Introduces a novel pruning metric that combines weight magnitude and gradient information.",
        "Achieves high sparsity with minimal accuracy loss, demonstrating strong practical benefits.",
        "Shows significant improvements in computational efficiency, making it suitable for resource‑constrained deployment."
      ],
      "weaknesses": [
        "Introduces a new hyperparameter (α) that adds complexity to the pruning process.",
        "Lacks comprehensive ablation studies on the impact of α across different model scales and datasets.",
        "Baseline comparisons are limited to a single model, which may not fully capture general applicability."
      ],
      "questions": [
        "How does the scaling term α affect pruning performance across different model sizes and datasets?",
        "Could a more detailed ablation study on α help identify optimal settings for various applications?",
        "What are the generalization capabilities of GBLM‑Pruner beyond the evaluated LLaMA‑2‑70B model?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "5BXAXOpaWu",
    "title": "Image2Sentence based Asymmetric Zero-shot Composed Image Retrieval",
    "std_review": {
      "summary": "The paper presents ZSCIR, a novel asymmetric text-to-image retrieval approach that leverages a dual-stream architecture to capture semantic relationships between images and texts, achieving superior performance over existing symmetric methods across multiple benchmarks. While promising, the method has limitations such as limited comparison with other asymmetric methods, insufficient analysis of text augmentation techniques, and underexplored t-SNE visualizations. Despite these concerns, the empirical results and comprehensive analysis justify its acceptance.",
      "strengths": [
        "Introduces a novel text-to-image asymmetry approach in image retrieval, potentially offering improved performance over traditional symmetric methods.",
        "Utilizes a dual-stream architecture that effectively captures semantic relationships between images and texts, enhancing retrieval accuracy.",
        "Demonstrates strong empirical results across multiple benchmarks, showcasing the method's effectiveness.",
        "Provides a comprehensive analysis of the impact of token length on retrieval performance, offering valuable insights into the trade-offs involved."
      ],
      "weaknesses": [
        "Limited comparison with other asymmetric text-to-image retrieval methods, which could provide a more comprehensive evaluation of ZSCIR's performance.",
        "The effectiveness of the text augmentation techniques used to ensure diversity and representativeness of descriptive texts is not thoroughly analyzed.",
        "The t-SNE visualizations, while promising, are not fully explored to provide deeper insights into the feature distributions and separability of the methods.",
        "The explanation for the degradation in retrieval performance with larger token lengths could be more detailed, potentially revealing deeper insights into the underlying causes."
      ],
      "questions": [
        "How does ZSCIR compare to other state-of-the-art asymmetric text-to-image retrieval methods?",
        "What specific data augmentation techniques are employed to ensure the diversity and representativeness of descriptive texts, and how do they impact the model's performance?",
        "Could a more detailed analysis of the t-SNE visualizations provide deeper insights into the feature distributions and separability of the methods?",
        "What are the underlying causes of the degradation in retrieval performance with larger token lengths, and how can they be addressed?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "5Ca9sSzuDp",
    "title": "",
    "std_review": {
      "summary": "The paper introduces TextBase, a method for interpreting CLIP models by decomposing attention heads into roles based on a description pool. It demonstrates interpretability gains across zero‑shot classification, retrieval, and segmentation, while also highlighting performance trade‑offs. The reviewer finds the method valuable for model debugging and optimization, though it has limitations in human interpretability and computational cost.",
      "strengths": [
        "Decomposes attention heads into interpretable roles using a description pool.",
        "Extensively evaluates effectiveness across multiple tasks and model variants.",
        "Provides actionable insights for model debugging, optimization, and human‑AI collaboration."
      ],
      "weaknesses": [
        "Interpretability for non‑experts may still be challenging.",
        "Effectiveness depends on the quality and diversity of the description pool.",
        "Computational overhead may limit scalability."
      ],
      "questions": [
        "How can the method be made more accessible to non‑expert users?",
        "What strategies can improve the robustness of head role assignments with larger description pools?",
        "How does the method's performance compare across different CLIP variants and fine‑grained tasks?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "5CBxA1l5RO",
    "title": "TimewarpVAE: Simultaneous Time-Warping and Representation Learning of Trajectories",
    "std_review": {
      "summary": "TimewarpVAE introduces a variational autoencoder that jointly reconstructs spatial and temporal components of trajectory data, addressing variable-length challenges through a time-warping module. The model shows improved spatial reconstruction when temporal information is integrated, highlighting its potential for motion planning and trajectory prediction. While demonstrating strong performance, the paper acknowledges training complexity and the non-intuitive interpretation of the regularization parameter, suggesting areas for further exploration.",
      "strengths": [
        "Joint Spatial-Temporal Modeling: Captures complex dependencies by integrating spatial and temporal information in a single latent space.",
        "Flexibility with Variable-Length Trajectories: Handles trajectories of varying lengths without resampling, preserving natural variability.",
        "Improved Reconstruction Performance: Demonstrates better spatial reconstruction accuracy when temporal dynamics are included."
      ],
      "weaknesses": [
        "Complexity of Training: The time-warping module adds computational complexity, potentially increasing training time and difficulty in hyperparameter tuning.",
        "Interpretation of Regularization Parameter λ: The role of λ in controlling time-warping influence is not always intuitive, complicating model application and fine-tuning.",
        "Limited Comparison with State-of-the-Art: The paper could benefit from a more comprehensive comparison with other temporal-spatial models."
      ],
      "questions": [
        "How does the model perform on datasets with highly irregular or sparse trajectory data?",
        "What are the practical implications of the regularization parameter λ in real-world applications?",
        "How does TimewarpVAE compare to recent advancements in trajectory prediction that incorporate attention mechanisms?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "5COCYDObes",
    "title": "",
    "std_review": {
      "summary": "The paper proposes a bi-level framework for prompt selection and action in embodied domains, learning to generate prompts with chatGPT 3.5 and select the best one using a learned policy, then applying it with chain of thought reasoning. It shows effectiveness on several tasks, outperforming baselines, and demonstrates potential for image-based observations. The reviewer finds the contribution novel and the method clear, but notes formatting issues and a lack of illustrations, and questions the framework's applicability to image observations and its decision-making process.",
      "strengths": [
        "Proposes a novel bi-level mechanism for prompt selection and action in embodied domains.",
        "The method is generally clear and understandable.",
        "Demonstrates effectiveness on several tasks, outperforming baselines.",
        "Shows potential for image-based observations through GPT-4 Vision."
      ],
      "weaknesses": [
        "Paper formatting is odd with small spacing between headings and text.",
        "Results would benefit from more illustrations of the process.",
        "Use of text input for LLMs in image observations may limit applicability.",
        "Framework's decision-making process may not be clear for image observations."
      ],
      "questions": [
        "Why does the approach improve performance over baselines?",
        "How does the prompt generation policy learn to make the action policy more confident?",
        "Is non-stationarity during training a concern, and how does the alternative training scheme address it?",
        "Would a vanilla PPO use RNN/LSTM/transformer architecture instead of an MLP for POMDP settings?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "5dlfiJIXoh",
    "title": "Structured Video-Language Modeling with Temporal Grouping and Spatial Grounding",
    "std_review": {
      "summary": "The paper presents a novel video‑language pre‑training framework that uses a cut‑and‑paste operation within video clips to improve visual‑text alignment. It introduces a fixed set of group tokens aligned with nouns from video captions via a spatial grounding loss. Experiments show improvements over older baselines, though spatial‑temporal evaluation is limited. The authors propose future work to expand spatial‑temporal experiments and refine the method.",
      "strengths": [
        "Innovative intra‑clip temporal grouping loss with cut‑and‑paste.",
        "Dynamic noun‑group token alignment using spatial grounding.",
        "Robust evaluation against older baselines."
      ],
      "weaknesses": [
        "Limited spatial‑temporal evaluation on real‑world datasets.",
        "Potential overfitting with a fixed number of group tokens.",
        "Lack of ablation studies on loss weighting."
      ],
      "questions": [
        "How will future spatial‑temporal experiments be conducted?",
        "What ablation studies will explore the impact of loss weighting?",
        "How can the method be extended to handle videos with multiple actions or complex scene changes?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "5Dwqu5urzs",
    "title": "Physics-Regulated Deep Reinforcement Learning: Invariant Embeddings",
    "std_review": {
      "summary": "The paper proposes a Physics-Informed Deep Reinforcement Learning (Phy-DRL) framework that integrates a residual physics policy to ensure safety during learning. It demonstrates improved safety and faster training towards safety guarantees on a simulated robotic arm task compared to existing methods. While the approach is novel and promising, the paper lacks thorough justification of the physics policy's necessity, detailed comparisons with non‑safety‑constrained approaches, and comprehensive metrics to fully validate the fast training towards safety guarantees.",
      "strengths": [
        "Introduces a novel integration of residual physics into DRL to address safety in learning processes.",
        "Shows improved safety guarantees and faster convergence to safety in experimental results.",
        "Provides a clear and relevant context for evaluation using a simulated robotic arm task."
      ],
      "weaknesses": [
        "Does not thoroughly justify the necessity of the residual physics policy.",
        "Limited comparison with existing approaches that do not consider safety requirements.",
        "Reliance on specific state information may limit real-world applicability.",
        "Lacks detailed metrics (e.g., sample efficiency, wall-clock time) to demonstrate fast training towards safety."
      ],
      "questions": [
        "How critical is the residual physics policy for the learning process and safety guarantees?",
        "What is the impact of the state requirement on the framework's applicability in real-world scenarios?",
        "Could additional metrics (e.g., sample efficiency, wall-clock time) further demonstrate the fast training towards safety guarantee?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "5e0yWSNGIc",
    "title": "Exposing the Silent Hidden Impact of Certified Training in Reinforcement Learning",
    "std_review": {
      "summary": "The paper introduces an adversarial regularizer designed to train Q-functions that overestimate optimal actions while mis‑ranking sub‑optimal ones, aiming to improve policy safety. While the theoretical framework is novel and the empirical results on several environments are promising, the work lacks formal proofs, comprehensive generalization studies, and quantitative analysis of performance impacts. Baseline comparisons, mitigation strategies, and robustness evaluations are missing, which limits the practical applicability of the findings.",
      "strengths": [
        "Clear motivation for robust Q-function estimation to enhance policy safety.",
        "Introduces a novel adversarial regularizer with a fresh theoretical approach.",
        "Empirical validation across multiple environments demonstrates the desired Q-function behavior."
      ],
      "weaknesses": [
        "Lacks a formal proof that the regularizer forces the Q-function to overestimate optimal actions and mis‑rank sub‑optimal ones.",
        "Empirical results are limited to a few environments, raising questions about generalization.",
        "No quantitative analysis of how over‑estimated Q-values affect policy performance.",
        "Does not compare against strong baselines to isolate the impact of the regularizer.",
        "Missing mitigation strategies and trade‑off analysis.",
        "No human alignment or human‑subject studies to support the desirability of the mis‑rankings.",
        "No evaluation of robustness to real‑world perturbations."
      ],
      "questions": [
        "Can you provide a formal proof that the adversarial regularizer enforces the desired Q-function properties?",
        "Are the observed pathologies reproduced across a broader set of environments and adversarial training algorithms?",
        "What is the quantitative impact of over‑estimated Q-values on policy performance metrics?",
        "How do adversarially trained policies compare against strong baselines like double‑DQN?",
        "What mitigations or trade‑offs can be proposed to address over‑estimation and mis‑ranking while preserving robustness?",
        "How do the mis‑rankings relate to human decision‑making or preferences?",
        "What is the robustness of the policies to real‑world perturbations and high‑dimensional settings?"
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "5E1HnzEBSf",
    "title": "",
    "std_review": {
      "summary": "The paper introduces Low-Stochastic Surrogate (LSS), a method for federated learning that connects low-loss local minima across clients to improve generalization on non-IID data. Theoretical work in Section 3.2 provides a novel framework for modeling these connections, while extensive empirical experiments demonstrate clear performance gains over standard baselines. Despite some implementation and comparison concerns, the strong theoretical contribution and practical validation justify acceptance.",
      "strengths": [
        "Novel theoretical framework modeling connections between local minima",
        "Empirical validation showing clear performance improvements",
        "Innovative diversity/affinity terms enhancing robustness and generalization"
      ],
      "weaknesses": [
        "Implementation complexity and potential for overfitting",
        "Lack of detailed error landscape analysis",
        "Limited comparison with state-of-the-art methods"
      ],
      "questions": [
        "How can the computational cost of the diversity term be further reduced?",
        "What additional visualizations or metrics would strengthen the error landscape analysis?",
        "How does LSS compare to recent state-of-the-art federated learning approaches?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "5eLgTLusaR",
    "title": "Loco3D: Indoor Multiuser Locomotion 3D Dataset",
    "std_review": {
      "summary": "The paper introduces Loco3D, a large-scale multi‑person trajectory dataset generated in VR, and proposes a U‑Net‑based planner for predicting future trajectories. The dataset captures diverse interactions and the planner demonstrates improved trajectory quality over baselines, though evaluation focuses mainly on collision avoidance. While the dataset and approach are promising, the paper lacks comprehensive evaluation metrics, addresses ethical concerns, and does not fully explore real‑world generalization and multi‑person adaptability.",
      "strengths": [
        "Large and diverse dataset with rich training data for trajectory prediction.",
        "U‑Net architecture effectively generates smooth, realistic trajectories.",
        "Scalable model that generalizes across different datasets without significant retraining.",
        "Robustness to controlled scene variability in VR environments."
      ],
      "weaknesses": [
        "Limited evaluation metrics; primarily qualitative assessments.",
        "Lack of explicit consent information and public availability details for the dataset.",
        "Ethical concerns regarding privacy and re‑identification risks are not thoroughly addressed.",
        "No exploration of real‑world generalization or performance with more than two people.",
        "Missing quantitative metrics like FDE for a more comprehensive evaluation."
      ],
      "questions": [
        "Should the paper include quantitative metrics such as FDE for trajectory evaluation?",
        "What consent procedures were followed for releasing trajectory and pose data?",
        "Where will the dataset be made publicly available and how can researchers access it?",
        "How does the model perform on real‑world datasets with complex scene dynamics?",
        "What are the implications of releasing a dataset of human motion in a virtual environment?"
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "5EniAcsO7f",
    "title": "Tailoring Retrieval Representations to Long-term Visual Localization",
    "std_review": {
      "summary": "The paper presents Ret4Loc-HOW-Synth, a method that enhances location-based question answering by extending the tuple set and introducing a new loss function. It shows significant accuracy and efficiency gains over existing methods and explores the approach's impact on training time and its application to visual classification. While promising, the approach's generalizability and the need for a more detailed ablation study are noted.",
      "strengths": [
        "Introduces a novel loss function leveraging an extended tuple set to improve location-based question answering.",
        "Demonstrates significant improvements in accuracy and efficiency compared to existing methods.",
        "Provides a comprehensive evaluation, including analysis of training time impacts.",
        "Explores the application of the approach beyond question answering to a visual classification task."
      ],
      "weaknesses": [
        "The extended tuple set may limit the approach's generalizability.",
        "Lacks a detailed discussion of trade-offs between accuracy and training time improvements.",
        "Evaluation on visual classification is limited to a single dataset.",
        "Does not include a thorough ablation study to isolate the impact of the extended tuple set and the new loss function."
      ],
      "questions": [
        "How does the approach perform on a broader range of visual tasks beyond the evaluated datasets?",
        "What are the specific trade-offs between the extended tuple set and training time improvements?",
        "Could a more detailed ablation study provide clearer insights into the contributions of the extended tuple set and the new loss function?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "5ep85sakT3",
    "title": "Contextual Bandits with Online Neural Regression",
    "std_review": {
      "summary": "The paper introduces NeuFastCB, a reinforcement learning algorithm that uses KL‑loss for reward approximation, analyzed under the Neural Tangent Kernel framework. It provides theoretical regret bounds tied to network width and offers practical guidance on when to use KL‑loss over squared‑loss. While promising, the approach relies on strong assumptions about reward realizability and initialization, limiting its broad applicability.",
      "strengths": [
        "Introduces a novel reinforcement learning algorithm (NeuFastCB) using KL‑loss.",
        "Provides rigorous theoretical analysis under the NTK framework with insightful regret bounds.",
        "Offers clear guidance on choosing KL‑loss versus squared‑loss based on data characteristics."
      ],
      "weaknesses": [
        "Assumes the reward function can be perfectly interpolated by a neural network.",
        "Results are limited to Gaussian‑initialized networks with full‑rank NTK.",
        "Regret bounds depend explicitly on network width, which may be problematic for deep networks.",
        "Oversized notation (O~) is used without explicit definition."
      ],
      "questions": [
        "How robust is the performance of NeuFastCB when the reward function cannot be perfectly realized by a neural network?",
        "What are the practical implications of the Gaussian initialization and full‑rank NTK assumptions in real-world settings?",
        "Can the theoretical insights be extended to other initialization schemes or network architectures?",
        "How does the choice between KL‑loss and squared‑loss impact performance in high‑dimensional or sparse reward environments?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "5ES5Hdlbxw",
    "title": "A Theoretical Explanation of Deep RL Performance in Stochastic Environments",
    "std_review": {
      "summary": "The paper introduces SQIRL, a sample-efficient RL algorithm that leverages a k‑QVI solvable environment to improve learning efficiency. It provides a theoretical foundation and demonstrates strong empirical performance across benchmarks, especially in environments with sticky actions. While the method is innovative and well‑validated, concerns about hyperparameter sensitivity and the practical applicability of the theoretical bounds remain. Overall, the contribution is significant, and the paper is recommended for acceptance.",
      "strengths": [
        "Innovative approach to handling long horizons via k‑QVI solvability.",
        "Solid theoretical analysis with a clear bound on sample complexity.",
        "Empirical validation showing consistent improvements over PPO.",
        "Well‑designed experiments and ablation studies providing practical insights."
      ],
      "weaknesses": [
        "Limited exploration of hyperparameter sensitivity, particularly for k.",
        "Theoretical bound assumes k‑QVI solvability, which may not hold in practice.",
        "Empirical results sometimes deviate from theoretical predictions in highly stochastic settings.",
        "Lack of comparison with additional state‑of‑the‑art methods."
      ],
      "questions": [
        "How does SQIRL's performance scale with larger values of k beyond the minimum k‑QVI‑solvable threshold?",
        "What are the practical implications of the theoretical assumption that the environment is k‑QVI solvable?",
        "How does SQIRL compare to other recent methods in terms of sample efficiency and generalization?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "5EtSvYUU0v",
    "title": "Connecting NTK and NNGP:",
    "std_review": {
      "summary": "The paper introduces the Neural Dynamic Kernel (NDK), a framework that unifies the Neural Tangent Kernel (NTK) and Neural Network Gaussian Process Kernel (NNGP) by incorporating noise into training dynamics via Langevin equations. It derives the NDK through a path-integral formulation, identifying two distinct learning phases and linking the transition between NTK and NNGP to specific time-scale limits. The authors connect their theoretical insights to neuroscience, particularly representational drift, enhancing the practical relevance of the work. While the mathematical rigor and novel perspective are strengths, the complexity and limited experimental validation are concerns.",
      "strengths": [
        "Novel framework that bridges NTK and NNGP by incorporating noise into training dynamics.",
        "Mathematically rigorous derivation using a path-integral formulation.",
        "Provides deep insights into two distinct phases of learning dynamics.",
        "Links theoretical findings to neuroscience, enhancing practical relevance."
      ],
      "weaknesses": [
        "Mathematical derivation and path-integral formulation may be challenging for readers without advanced backgrounds.",
        "Limited experimental validation to support theoretical claims.",
        "Focus on theoretical aspects may limit appeal to audiences interested in practical applications."
      ],
      "questions": [
        "Could you provide additional experimental validation to support the theoretical claims about the NDK and its learning phases?",
        "How might the NDK framework be extended to other types of neural networks or learning algorithms?",
        "What are the potential implications of the NDK for understanding and mitigating representational drift in deep learning models?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "5Gt68fnttu",
    "title": "Dynamic Electroencephalography Representation Learning for Improved Epileptic Seizure Detection",
    "std_review": {
      "summary": "The paper presents a Dynamic Seizure Network (DSN) that uses a graph neural network to detect seizure onset in real-time from EEG data. While the approach shows promise and outperforms several baselines, it lacks comprehensive clinical validation and detailed discussion of model efficiency. The authors should address these gaps to strengthen the work.",
      "strengths": [
        "Innovative use of graph neural networks to capture temporal and spatial dependencies in EEG signals.",
        "Real-time processing capability suitable for clinical applications.",
        "Comprehensive evaluation across multiple datasets and metrics."
      ],
      "weaknesses": [
        "Limited clinical validation by lack of expert review of model predictions.",
        "Insufficient discussion on computational efficiency and resource requirements.",
        "Inadequate comparison with the latest state-of-the-art models."
      ],
      "questions": [
        "Should the model be validated by clinical experts to ensure reliability?",
        "What are the computational requirements and efficiency of the DSN for practical deployment?",
        "How does the DSN compare to the most recent state-of-the-art seizure detection models?"
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "5GX6s5TpmV",
    "title": "The Certification Paradox:",
    "std_review": {
      "summary": "The paper presents a novel method for certifying neural network robustness by combining interval bounding (IBP) with adversarial training, achieving tighter certification bounds on several datasets. While the approach shows promise and practical improvements, it faces challenges such as implementation complexity and performance variability, especially with MACER models. Overall, the work is innovative but requires further refinement.",
      "strengths": [
        "Innovative integration of IBP with adversarial training to improve certification bounds.",
        "Comprehensive experimental evaluation across multiple datasets and model architectures.",
        "Clear mathematical formulation and reproducibility, including the definition of the '%-C' metric."
      ],
      "weaknesses": [
        "Implementation complexity due to the combination of IBP and adversarial training.",
        "Significant performance drop in MACER models compared to PGD.",
        "Lack of detailed analysis on why the method underperforms in certain scenarios.",
        "Limited evaluation against a broader range of adversarial methods."
      ],
      "questions": [
        "How can the implementation complexity be mitigated to make the method more accessible to practitioners?",
        "What specific factors contribute to the method's poor performance with MACER models, and how can they be addressed?",
        "Could a more extensive evaluation against a wider array of adversarial methods provide additional insights?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "5h0qf7IBZZ",
    "title": "MiniLLM: Knowledge Distillation of Large Language Models",
    "std_review": {
      "summary": "The paper presents a white-box knowledge distillation framework for large language models that improves robustness and generalization by balancing teacher‑student alignment with a regularization term to reduce exposure bias. Experiments show significant gains in response distinctiveness and reduced hallucinations compared to existing baselines. The authors propose a 4‑gram proportion metric as an alternative to GPT‑4 feedback, offering a practical evaluation method. While innovative and empirically validated, the approach has some limitations, such as a complex loss function and reliance on GPT‑4 for evaluation, which could affect generalizability.",
      "strengths": [
        "Introduces a clear, white-box knowledge distillation framework that is interpretable and reproducible.",
        "Reduces exposure bias through a carefully designed regularization term, leading to more diverse and accurate outputs.",
        "Demonstrates consistent empirical improvements in response quality and distinctiveness across multiple datasets.",
        "Proposes a computationally efficient evaluation metric (4‑gram proportion) as an alternative to GPT‑4 feedback."
      ],
      "weaknesses": [
        "The loss function includes multiple terms, which may complicate training and require careful tuning.",
        "Relies on GPT‑4 for baseline evaluation, raising concerns about overfitting to the evaluator model.",
        "Evaluation focuses primarily on response distinctiveness and hallucination reduction, without comprehensive analysis of other aspects like factual accuracy or user engagement.",
        "Lacks extensive robustness analysis on adversarial or out‑of‑distribution inputs."
      ],
      "questions": [
        "How does the proposed 4‑gram proportion metric compare to other diversity metrics in terms of correlation with human judgments?",
        "What are the computational costs of applying the proposed KD framework to very large LLMs?",
        "How does the method perform under different teacher‑student model architectures or when the teacher model is not fully accessible?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "5hAMmCU0bK",
    "title": "Towards Robust Offline Reinforcement Learning under Diverse Data Corruption",
    "std_review": {
      "summary": "The paper introduces RIQL, a method that improves the robustness of imitation learning against data corruption by stabilizing Q-targets with Huber regression and normalizing observations. Empirical results across various corruption scenarios demonstrate significant robustness gains, supported by theoretical analysis. While the approach is promising, it has limitations such as limited corruption scenarios and hyperparameter sensitivity, and could benefit from broader comparisons and more rigorous theoretical justification.",
      "strengths": [
        "Clear identification of heavy-tailed Q-targets as a learning stability issue",
        "Practical mitigation using Huber regression, which is both novel and effective",
        "Strong empirical evidence of RIQL's robustness improvements across multiple corruption settings",
        "Solid theoretical foundation linking mitigation to statistical properties of Q-targets",
        "Potential for broad applicability across different RL frameworks"
      ],
      "weaknesses": [
        "Limited data corruption scenarios tested",
        "Empirical results heavily dependent on specific hyperparameter choices",
        "Comparison with baselines is limited, lacking diversity in RL methods",
        "Theoretical justification for robustness could be more rigorous",
        "Explanation of normalization's impact is somewhat vague"
      ],
      "questions": [
        "Could RIQL's robustness be further validated with a wider range of data corruption scenarios?",
        "What is the theoretical basis for the heavy-tailed nature of Q-targets in IQL?",
        "How sensitive are RIQL's performance improvements to hyperparameter settings?",
        "Would comparing RIQL to a broader set of baselines (e.g., transformer or diffusion models) strengthen the argument for its robustness?",
        "How does normalization affect performance in other RL algorithms beyond RIQL?",
        "How realistic are the corruption scenarios presented, and what methods could address more extreme cases?",
        "Could RIQL's robustness be evaluated against adversarial attacks specifically designed for the Q functions?",
        "What is the precise impact of normalization on algorithm performance, particularly regarding 'larger-scale features'?",
        "How does the theoretical robustness align with empirical findings, and where might the theory and practice diverge?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "5HCnKDeTws",
    "title": "When Scaling Meets LLM Finetuning:",
    "std_review": {
      "summary": "The paper investigates scaling laws for large language models across translation and summarization tasks, exploring how different finetuning methods interact with model size and data volume. It proposes a novel multiplicative joint scaling law that captures the interplay between model size, pretraining data, finetuning data, and PET parameter size, demonstrating its predictive power across various setups. While comprehensive and insightful, the study has limitations such as a narrow scope of tasks, potential overfitting in larger models, and a focus on parameter-efficient methods that may not generalize well.",
      "strengths": [
        "Comprehensive experimental design varying model sizes and finetuning methods across multiple tasks.",
        "Innovative multiplicative joint scaling law providing a novel framework for understanding scaling factors.",
        "Detailed hyperparameter analysis enabling reproducibility and comparison.",
        "Clear interpretation of results highlighting differences between translation and summarization tasks and finetuning methods."
      ],
      "weaknesses": [
        "Limited scope of tasks focusing only on two translation tasks and one summarization task.",
        "Potential overfitting or diminishing returns in larger models, such as the 30B model.",
        "Focus on parameter-efficient methods (Prompt Tuning, LoRA) which may have limitations in certain scenarios.",
        "Absence of cross-lingual transfer experiments limiting insights into generalization capabilities.",
        "Extensive computational resources required may limit accessibility for broader research communities."
      ],
      "questions": [
        "How do the scaling laws generalize to other tasks beyond translation and summarization?",
        "What are the implications of the scaling laws for parameter-efficient fine-tuning methods with very large datasets?",
        "Could the proposed scaling law be extended to models beyond 30B parameters?",
        "How does the performance of the scaling law change when using different types of parameter-efficient fine-tuning methods?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "5HGPR6fg2S",
    "title": "Normalized Space Alignment: A Versatile Metric for Representation Space Discrepancy Minimization",
    "std_review": {
      "summary": "The paper introduces the Neighborhood Similarity Score (NSA) as a metric for evaluating graph embeddings, aiming to capture how well embeddings preserve local graph structures. While the NSA definition is intuitive and the method is clear, the paper lacks thorough validation of its robustness, especially in non-linear embeddings like the Swiss Roll, and does not rigorously prove its invariance under isometries. The experimental results are strong, but the methodology for calculating representations in Section 3.6 is unclear, and the NSA is not explicitly computed for a specific dataset or batch of graphs. Overall, the NSA concept is innovative but needs more robust validation and clearer methodological details.",
      "strengths": [
        "The NSA definition is intuitive and directly relates to the preservation of local graph structures in the embedding space.",
        "The method provides a clear and interpretable way to assess embedding quality, which is valuable for practitioners.",
        "The experimental results on benchmark datasets are thorough and demonstrate the practical utility of the NSA measure."
      ],
      "weaknesses": [
        "The robustness of NSA to misleading ambient distances, such as those encountered in non-linear embeddings like the Swiss Roll, is not thoroughly addressed.",
        "The invariance of NSA under isometries is assumed but not rigorously proven or demonstrated.",
        "The calculation method for representations in Section 3.6 is not clearly explained, making it unclear whether the NSA is computed for a specific dataset or a batch of graphs."
      ],
      "questions": [
        "How robust is the NSA measure when applied to non-linear embeddings such as the Swiss Roll?",
        "Can you provide evidence or analysis demonstrating the invariance of NSA under isometries?",
        "Please clarify the process of calculating the representations in Section 3.6 and whether the NSA is computed for a specific dataset or a batch of graphs."
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "5HpZZbgdeK",
    "title": "Efficient calibration as a binary top-versus-all problem for classifiers with many classes",
    "std_review": {
      "summary": "The paper proposes a novel method, top-versus-all (TvA), for calibrating classifier outputs in multi-class settings by focusing on the top class probability. It leverages binary calibration techniques and demonstrates effectiveness using Expected Calibration Error (ECE) on various datasets. While computationally efficient, the approach may overlook information from other classes and lacks a thorough exploration of its practical utility and comparison with other methods.",
      "strengths": [
        "Introduces a computationally efficient calibration method for multi-class classifiers.",
        "Provides a clear theoretical framework and evaluation using ECE.",
        "Demonstrates practical relevance in selective classification and out-of-distribution detection."
      ],
      "weaknesses": [
        "Focuses solely on the top class, potentially ignoring useful information from other classes.",
        "Does not fully explore the impact of binning choices on calibration.",
        "Lacks comprehensive discussion on the method's practical utility and limitations."
      ],
      "questions": [
        "How does the method perform when the top class is not the most relevant class?",
        "What are the computational costs compared to other calibration methods in large-scale multi-class problems?",
        "Could extending calibration to the top few classes improve decision-making?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "5iENGLEJKG",
    "title": "Interpreting and Controlling Vision Foundation Models via Text Explanations",
    "std_review": {
      "summary": "The paper presents a method for generating attention maps that combines gradient-based and feature-based techniques to improve interpretability and accuracy over traditional saliency maps. Experiments on benchmark datasets show significant qualitative and quantitative improvements, suggesting clearer insights into model decision-making. While the method is effective and generalizable, its higher computational complexity and the need for further validation across diverse scenarios are noted as limitations.",
      "strengths": [
        "Combines gradient-based and feature-based information for more informative attention maps.",
        "Demonstrates superior interpretability and accuracy compared to standard saliency maps.",
        "Provides clear benefits for model debugging and understanding, aiding in the development of trustworthy AI systems."
      ],
      "weaknesses": [
        "Higher computational complexity may limit use in resource-constrained environments.",
        "Effectiveness varies across datasets and tasks, requiring further validation.",
        "Lacks detailed analysis of trade-offs between interpretability and computational efficiency.",
        "Builds on existing techniques rather than introducing a fundamentally new paradigm."
      ],
      "questions": [
        "How does the method perform on resource-constrained devices or real-time applications?",
        "What is the extent of generalization across different neural network architectures and tasks?",
        "Could the trade-offs between interpretability and computational efficiency be explored further?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "5IOKw3AQe4",
    "title": "On the Theoretical Analysis of Dense Contrastive Learning",
    "std_review": {
      "summary": "The paper proposes a self-supervised learning framework for dense prediction tasks using a patch-level adjacency matrix to capture local spatial relationships. It introduces a controllable parameter α to balance positive pair generation and labeling error, optimizing a patch-level contrastive loss and a projection contrastive ratio metric. While experiments on synthetic datasets show improvements over baselines, real-world applicability on COCO and ImageNet is unverified. The framework's strengths include innovative patch-level modeling, a flexible training strategy, and generalizable metrics, but weaknesses include limited empirical validation and unclear impact on dense prediction tasks.",
      "strengths": [
        "Introduces a novel patch-level adjacency matrix for modeling spatial dependencies.",
        "Provides a controllable parameter α to balance positive pair generation and labeling error.",
        "Proposes generalizable metrics (PCR and patch-level contrastive loss) applicable beyond PixPro."
      ],
      "weaknesses": [
        "Lacks real-world validation on COCO and ImageNet.",
        "Empirical evidence for the α trade-off is not directly provided.",
        "Impact of handling 'meaningless' patches on dense prediction is not thoroughly explored."
      ],
      "questions": [
        "How does the framework perform on real-world dense prediction datasets like COCO and ImageNet?",
        "What empirical evidence supports the trade-off between positive pairs and labeling error controlled by α?",
        "What is the quantitative impact of including 'meaningless' patches on downstream dense prediction tasks?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "5Itc7v0pnA",
    "title": "Quantile-Free Regression: A Flexible Alternative to Quantile Regression",
    "std_review": {
      "summary": "The paper introduces Quantile-Free Regression (QFR), a novel approach to regression that constructs prediction intervals without relying on quantile regression. QFR incorporates a regularization term into the loss function to achieve desired coverage properties, outperforming traditional methods in terms of interval width and coverage accuracy. The authors demonstrate effectiveness through experiments on synthetic and real-world datasets, though they acknowledge limitations such as the lack of a detailed theoretical analysis of convergence and sensitivity to regularization parameter choice.",
      "strengths": [
        "The paper presents a novel and innovative approach to regression that addresses the limitations of traditional quantile regression.",
        "The proposed QFR method provides a theoretically sound framework for constructing prediction intervals with desired coverage properties.",
        "The regularization term in the QFR loss function effectively controls the width of the prediction intervals, leading to more accurate and reliable coverage."
      ],
      "weaknesses": [
        "The paper lacks a detailed theoretical analysis of the convergence properties of the QFR method.",
        "The authors do not explore the sensitivity of QFR to the choice of the regularization parameter.",
        "The experiments are limited to synthetic and a few real-world datasets, and the authors do not provide a comprehensive evaluation on a wide range of datasets.",
        "The practical implementation of QFR may require careful tuning of the regularization parameter, which could be a challenge for practitioners."
      ],
      "questions": [
        "Can you provide a more detailed theoretical analysis of the convergence properties of the QFR method?",
        "How sensitive is QFR to the choice of the regularization parameter, and what are the implications for practical applications?",
        "Would a more comprehensive evaluation on a wider range of datasets from different domains strengthen the paper's claims?",
        "Are there any efficient and scalable algorithms that could be developed to improve the practical implementation of QFR?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "5j6wtOO6Fk",
    "title": "Hieros: Hierarchical Imagination on Structured State Space Sequence World Models",
    "std_review": {
      "summary": "The paper introduces a novel hierarchical reinforcement learning method that automatically determines hierarchy depth, improving efficiency in complex environments. It demonstrates improved performance on several Atari games compared to existing methods and includes ablation studies. However, the paper has several weaknesses, including misleading time comparisons, lack of exploration of automatic hierarchy depth, missing error bars in ablation experiments, non-representative ablation environments, and omission of prior work on image reconstruction impacts.",
      "strengths": [
        "Introduces a novel method for automatically determining hierarchy depth in HRL, potentially leading to more efficient learning.",
        "Shows improved performance on several Atari games compared to existing HRL methods.",
        "Provides ablation studies to validate the importance of different components."
      ],
      "weaknesses": [
        "Misleading comparison of 0.6 days to 0.5 hours, which may be misleading to readers.",
        "No exploration of automatically determining hierarchy depth, a key aspect of the proposed method.",
        "Ablation experiments lack error bars and specified epochs/steps, hindering assessment of impact.",
        "Selected ablation environments (Krull, Breakout, Freeway, Battle Zone) may not be representative of all Atari games.",
        "Omission of discussion on prior work addressing direct image reconstruction in pixel space."
      ],
      "questions": [
        "Could the method for automatically determining hierarchy depth be explored further?",
        "What are the specific impacts of direct image reconstruction in pixel space on learning minor details, and how does the proposed approach address this?",
        "How do the selected ablation environments compare to a broader range of Atari games in terms of generalizability?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "5jcav5RcKw",
    "title": "Jointly Training Large Autoregressive Multimodal Models",
    "std_review": {
      "summary": "The paper proposes JAM, a framework for jointly training multimodal models that generate both text and images. It introduces three fusion strategies—Uniform, Width, and Cross—and demonstrates improvements over CM3leon on the MS-COCO dataset, primarily through reduced perplexity. While the approach is innovative and theoretically sound, its reliance on perplexity as the sole evaluation metric and increased computational cost raise concerns about scalability and comprehensive assessment.",
      "strengths": [
        "Introduces a novel framework for jointly training multimodal models.",
        "Provides three distinct fusion strategies that enhance text-image generation.",
        "Demonstrates empirical improvements over a baseline model on a standard dataset."
      ],
      "weaknesses": [
        "Relies solely on perplexity, which may not fully capture content quality.",
        "Increased model complexity and parameter size raise computational demands.",
        "Lacks a broader comparative analysis with other state-of-the-art models."
      ],
      "questions": [
        "How do the proposed JAM models perform under more stringent evaluation metrics such as BLEU scores or visual similarity measures?",
        "What are the scalability implications of the increased model complexity on larger datasets or more complex tasks?",
        "How does the <break> token strategy handle prompts that require multiple images or complex interleaving?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "5JWAOLBxwp",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a novel feature representation for 3D point clouds by embedding orientations into a higher-dimensional rotation space. It defines a mapping from SO(3) to a subspace of SO(n) using three specially chosen rotation matrices, which theoretically provides a richer representation than traditional spherical harmonics or Fourier features. Experimental results on benchmark datasets show improved performance, supporting the practical viability of the approach. However, concerns about implementation complexity, scalability with increasing dimensionality, and potential overfitting are raised.",
      "strengths": [
        "Innovative feature representation for 3D point clouds",
        "Strong theoretical foundation linking to rotation matrices and group theory",
        "Demonstrated experimental improvements over existing methods"
      ],
      "weaknesses": [
        "Implementation complexity due to specific rotation matrix construction",
        "Limited discussion on scalability with increasing dimensionality n",
        "Potential for overfitting with higher-dimensional representations"
      ],
      "questions": [
        "How does the method scale with increasing dimensionality n?",
        "What strategies are employed to mitigate overfitting in higher-dimensional spaces?",
        "How does the computational cost increase with n, and what are the practical implications for large-scale 3D data?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "5jWsW08zUh",
    "title": "Some Intriguing Aspects about Lipschitz Continuity of Neural Networks",
    "std_review": {
      "summary": "The paper investigates the Lipschitz constant of deep neural networks, proposing a method to efficiently estimate a lower Lipschitz bound and demonstrating its reliability during training. Empirical results reveal a double‑descent phenomenon linking the Lipschitz constant to test loss, suggesting that increased model capacity can initially improve generalization despite higher expressivity. The study also explores the influence of label noise and network capacity on Lipschitz behavior, offering insights into model robustness.",
      "strengths": [
        "Proposes a practical and efficient method for estimating the Lipschitz constant.",
        "Demonstrates a clear double‑descent pattern linking Lipschitz constant to test loss.",
        "Conducts thorough experiments across various architectures and datasets."
      ],
      "weaknesses": [
        "Empirical evaluation is limited to specific architectures and datasets.",
        "Lacks thorough theoretical underpinnings for the double‑descent phenomenon.",
        "Relationship between lower Lipschitz bound and effective Lipschitz constant is not fully quantified.",
        "Training dynamics' impact on the lower bound is not explored."
      ],
      "questions": [
        "How does the method generalize to other architectures and datasets?",
        "What theoretical framework can explain the observed double‑descent behavior?",
        "How precisely does the lower Lipschitz bound approximate the effective Lipschitz constant under different noise conditions?",
        "How does the evolution of the lower bound during training relate to model robustness at the decision boundary?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "5KF3Q79t8B",
    "title": "Learning An Efficient-And-Rigorous Neural Multigrid Solver",
    "std_review": {
      "summary": "The paper introduces UGrid, a neural network-based method for solving PDEs by learning a mapping from coarse to fine grids. It shows potential for faster convergence and improved accuracy, especially on small-scale problems, and provides theoretical convergence guarantees. However, it lacks comprehensive scalability analysis, ablation studies, detailed proofs of convergence, and comparisons with legacy solvers on larger or more complex problems.",
      "strengths": [
        "Innovative integration of a learnable UGrid submodule with traditional grid transfer operators.",
        "Potential for improved convergence and solution quality through learned coarse-to-fine grid mappings.",
        "Provides theoretical convergence guarantees based on Theorem 2."
      ],
      "weaknesses": [
        "Limited scalability analysis for larger problems or complex geometries.",
        "Absence of ablation studies to isolate contributions of UGrid, residual loss, and grid transfer operators.",
        "Convergence guarantees are based on Theorem 2 but lack detailed proof.",
        "Comparison with legacy solvers is limited to small-scale problems.",
        "No justification for the one-time training cost against inference savings on large-scale problems.",
        "Lack of evaluation on robustness to irregular boundaries, non-uniform meshes, or non-linear PDEs."
      ],
      "questions": [
        "How does UGrid scale to larger problems or more complex geometries?",
        "What are the individual impacts of the UGrid submodule, residual loss, and grid transfer operators?",
        "Can the convergence guarantees be substantiated with a detailed proof?",
        "How does UGrid perform compared to legacy solvers on larger or more complex PDEs?",
        "What is the trade-off between the one-time training cost and the computational savings during inference?",
        "How robust is UGrid to irregular boundaries, non-uniform meshes, or non-linear PDEs?",
        "What are the potential performance improvements on GPU or other hardware accelerators?"
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "5KUiMKRebi",
    "title": "Implicit Neural Representation Inference",
    "std_review": {
      "summary": "The paper introduces an Integrate‑and‑Release (INR) hypernetwork that uses SIREN activations to generate neural network weights, achieving competitive or superior performance on several image datasets while using far fewer parameters than Bayesian baselines. The authors observe a stationary uncertainty pattern, hinting at kernel‑like behavior, and note that smaller INR models sometimes outperform larger ones on CIFAR. However, the review points out several concerns regarding input handling, activation choices, model capacity trade‑offs, and the lack of comparison with modern baselines.",
      "strengths": [
        "Innovative hypernetwork architecture leveraging SIREN activations for continuous, differentiable training.",
        "Significant parameter efficiency compared to traditional Bayesian deep learning methods.",
        "Novel observation of a stationary uncertainty pattern that may inform future research on uncertainty quantification."
      ],
      "weaknesses": [
        "Lack of clarity on whether tensor coordinate inputs are normalized or raw integers, which could affect training dynamics.",
        "No comprehensive comparison of SIREN activations with other alternatives, limiting generalizability.",
        "Observed performance benefit of smaller INR models on CIFAR is not fully explored or justified.",
        "Comparison with older Laplace‑based methods rather than more recent techniques, potentially understating the novelty."
      ],
      "questions": [
        "How are the tensor coordinate inputs to the INR network handled—are they normalized or raw integers?",
        "What is the rationale for choosing SIREN activations over other activation functions, and have they been compared comprehensively?",
        "Is the observed performance advantage of smaller INR models on CIFAR a general trade‑off between capacity and performance, or specific to the architecture/training regime?",
        "How do the results compare with more recent Laplace‑based baselines applied directly to the main network?"
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "5LhYYajlqV",
    "title": "In-Context Unlearning:",
    "std_review": {
      "summary": "The paper introduces ICUL, a framework for selective forgetting in large language models, demonstrating effectiveness on binary tasks and providing theoretical analysis. While innovative and practical, its limited scope, computational overhead, and theoretical guarantees are somewhat constrained. The review suggests ICUL is a promising step toward AI accountability but requires further work on scalability, robustness, and broader applicability.",
      "strengths": [
        "Innovative approach to selective forgetting in LLMs",
        "Empirical evidence across multiple binary classification tasks",
        "Theoretical analysis providing formal guarantees"
      ],
      "weaknesses": [
        "Limited validation to binary classification tasks",
        "Computational overhead for large datasets",
        "Theoretical guarantees are somewhat limited"
      ],
      "questions": [
        "How does ICUL scale for real-world applications requiring continuous unlearning?",
        "What are the theoretical underpinnings that explain ICUL's effectiveness?",
        "How does ICUL perform on multi-class or more complex NLP tasks beyond binary classification?",
        "How does ICUL compare to other unlearning methods in terms of robustness and adaptability?",
        "What are the theoretical underpinnings that explain ICUL's effectiveness?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "5liV2xUdJL",
    "title": "Time-Efficient Reinforcement Learning",
    "std_review": {
      "summary": "The paper introduces S2PG, a novel stochastic stateful policy gradient method that improves efficiency and applicability in reinforcement learning by reducing variance compared to BPTT. Theoretical analysis and empirical evidence across various tasks demonstrate its benefits, though concerns remain about its applicability in non-Markovian settings and robustness in high-variance environments. Overall, the work is well‑received for its innovative approach and strong empirical support.",
      "strengths": [
        "Introduces a stateful policy representation that effectively captures temporal dependencies.",
        "Provides theoretical analysis and variance bounds that enhance understanding of the method.",
        "Demonstrates empirical superiority over BPTT in multiple tasks, highlighting computational efficiency."
      ],
      "weaknesses": [
        "Theoretical assumptions may limit applicability to non-Markovian environments.",
        "Limited empirical evidence on robustness in high-variance or complex state spaces.",
        "Lack of detailed guidelines for initializing policy states could affect convergence."
      ],
      "questions": [
        "How does S2PG perform in non-Markovian environments, and what modifications are needed?",
        "What are the optimal initialization strategies for policy states to improve convergence?",
        "Can S2PG be extended to handle high-variance or complex state spaces more effectively?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "5Lp6qU9hzV",
    "title": "Multiscale Positive-Unlabeled Detection of AI-Generated Texts",
    "std_review": {
      "summary": "The paper introduces a novel MPU-based method for detecting short AI-generated texts, analyzing how text length affects model performance and comparing it to baselines. It highlights the challenges of short texts and proposes training on short texts alone as a potential benefit. However, it lacks detailed explanations of detection difficulties, thorough exploration of model behavior with varying text lengths, and comprehensive evaluation across datasets. The overall recommendation is weak accept.",
      "strengths": [
        "Introduces a novel approach to address the challenge of detecting short text using a modified MPU architecture.",
        "Provides a comprehensive analysis of the impact of text length on model performance.",
        "Compares the proposed method against state-of-the-art baselines, showcasing its effectiveness."
      ],
      "weaknesses": [
        "Lacks a detailed explanation of the specific factors contributing to the difficulty of detecting short text.",
        "The variation of π̃ with respect to text length is not thoroughly explored or justified.",
        "The performance gap between BERT-MPU and Roberta-MPU on short text is not adequately explained or hypothesized.",
        "The impact of the proposed method on the performance of extremely long texts is not clearly demonstrated.",
        "Does not provide a comprehensive evaluation of the proposed method across different datasets or domains."
      ],
      "questions": [
        "What are the specific factors contributing to the difficulty of detecting short text?",
        "Why does the variation of π̃ with respect to text length occur, and how can it be justified?",
        "What could explain the performance gap between BERT-MPU and Roberta-MPU on short text?",
        "How does the proposed method perform on extremely long texts, and what are the implications?",
        "What additional datasets or domains should be evaluated to assess the generalizability of the proposed method?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "5M2MjyNR2w",
    "title": "Adaptive Expansion for Hypergraph Learning",
    "std_review": {
      "summary": "AdE introduces an adaptive hypergraph expansion framework that learns optimal graph structures for specific tasks, leveraging a distance-aware kernel to capture complex high-order interactions. Theoretical analysis supports the method, and empirical results show significant improvements over baselines, especially in high heterophily scenarios. Overall, the paper makes substantial contributions to hypergraph learning.",
      "strengths": [
        "Adaptive Hypergraph Expansion: Dynamically learns optimal hypergraph structures for each task.",
        "Distance-Aware Kernel: Captures nuanced relationships between node pairs effectively.",
        "Theoretical Foundation: Provides a solid theoretical basis with convergence and optimality proofs."
      ],
      "weaknesses": [
        "Implementation Complexity: Adaptive nature may make it less accessible to practitioners.",
        "Scalability Concerns: Practical scalability for very large graphs is not fully addressed.",
        "Limited Datasets: Empirical evaluation focuses on a small set of datasets."
      ],
      "questions": [
        "How can the implementation complexity be reduced to make AdE more accessible?",
        "What strategies can be employed to improve the scalability of AdE for very large graphs?",
        "Could additional datasets be included to better demonstrate the method's performance across different applications?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "5MlPrLO52d",
    "title": "Neural Tangent Kernels for Axis-Aligned Tree Ensembles",
    "std_review": {
      "summary": "The paper introduces the Non‑Oblivious Tree Kernel (NOTK) for capturing both non‑oblivious and oblivious tree structures, showing empirical advantages of axis‑aligned inverted trees over axis‑aligned trees on tic‑tac‑toe. While theoretically interesting, the results are limited to a single dataset and lack comprehensive baseline comparisons, statistical significance analysis, and detailed computational cost assessments. The NOTK offers new insights into tree ensemble dynamics but its practical benefits are constrained by theoretical assumptions and limited experimental validation.",
      "strengths": [
        "Introduces a novel kernel (NOTK) tailored for non‑oblivious trees, providing a theoretical framework to unify both non‑oblivious and oblivious tree representations.",
        "Demonstrates practical benefits through empirical comparisons on a single dataset (tic‑tac‑toe), showing improved performance of AAI over AAA and a shallow random forest baseline.",
        "Offers insights into the training dynamics of tree ensembles, suggesting that the NOTK can capture complex tree structures effectively."
      ],
      "weaknesses": [
        "Theoretical results of Proposition 2 are limited to the infinite‑tree limit, which may not directly translate to practical applications with finite‑tree ensembles.",
        "Experiments are restricted to a single dataset (tic‑tac‑toe), raising concerns about the generalizability of the findings to other domains such as classification or regression tasks.",
        "The comparison with baselines, particularly the shallow random forest, lacks a comprehensive evaluation against more modern ensemble techniques like Gradient Boosting, and statistical significance is not assessed.",
        "The claim that feature selection is unimportant for AAI is not substantiated when considering non‑oblivious tree architectures, which could have implications for practical model building.",
        "The application of Multiple Kernel Learning (MKL) is theoretically explored but lacks detailed computational cost analysis, which is crucial for assessing practical feasibility.",
        "Theoretical assumptions (e.g., soft trees, gradient descent) may not directly translate to real-world model training scenarios, limiting the practical benefits of the derived results."
      ],
      "questions": [
        "How do the NOTK‑based methods perform on a broader range of datasets beyond tic‑tac‑toe?",
        "What is the statistical significance of the performance improvements observed for AAI over AAA and the random forest baseline?",
        "How does the NOTK compare to more modern ensemble techniques like Gradient Boosting in terms of both performance and computational efficiency?",
        "What are the practical implications of the theoretical claim that feature selection is unimportant for AAI, especially when applied to non‑oblivious tree architectures?",
        "Could you provide a detailed computational cost analysis for applying the NOTK in Multiple Kernel Learning scenarios?",
        "How does the flexibility of the NTK framework to allow non‑zero initialized split features to become zero during training impact dynamic tree shape adaptation in real-world applications?"
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "5mtwoRNzjm",
    "title": "",
    "std_review": {
      "summary": "The paper introduces ΨBR, a barrier-function-based stochastic optimization algorithm for constrained problems, demonstrating improved scalability and performance on large datasets. While offering theoretical insights and clear parameter guidelines, the work lacks detailed step‑size selection procedures, thorough comparisons with existing methods, and robust convergence guarantees. These omissions moderate its impact, leading to a weak accept recommendation.",
      "strengths": [
        "Introduces a barrier-function-based stochastic optimization method for constrained problems.",
        "Demonstrates strong scalability and performance on large-scale datasets.",
        "Provides clear guidelines for parameter tuning, enhancing usability."
      ],
      "weaknesses": [
        "Lacks systematic step‑size selection procedures for practical implementation.",
        "Does not provide thorough comparisons with other state‑of‑the‑art methods.",
        "Convergence results are described as relatively weak with no practical upper bounds."
      ],
      "questions": [
        "What systematic procedure should be used for selecting the stepsize η in practice?",
        "How does ΨBR compare to other modern methods like Multiplier Correction Methods or Gram‑Schmidt‑based approaches?",
        "What are the practical implications of the algorithm's sensitivity to the parameter ω?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "5nEmi3YIz4",
    "title": "",
    "std_review": {
      "summary": "The paper presents a method to interpret neural network predictions by decomposing learned representations into interpretable latent prototypes using NMF. These prototypes are visualized to provide insights into the model's decision-making process, with empirical evaluations on image classification tasks demonstrating its effectiveness. The reviewer finds the method promising, noting its clear approach and strong empirical support, despite some limitations related to NMF artifacts and prototype interpretability.",
      "strengths": [
        "Leverages NMF to decompose NN representations into interpretable latent prototypes.",
        "Provides clear visualizations of prototype contributions for human-readable interpretation.",
        "Applicable to a wide range of NN architectures, offering versatility.",
        "Empirical evaluations on multiple image classification tasks show practical utility."
      ],
      "weaknesses": [
        "Reliance on NMF may introduce artifacts or suboptimal decompositions.",
        "Performance depends on NMF quality, which can be sensitive to initialization and hyperparameters.",
        "Reconstruction quality may not always align perfectly with original images.",
        "Interpretability limited to decomposed prototypes, potentially missing all relevant features."
      ],
      "questions": [
        "How robust is the method to variations in NMF initialization and hyperparameters?",
        "Can the method be extended to other types of neural network outputs beyond image classification?",
        "What is the impact of residual prototypes on the interpretability of the model's decisions?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "5NJzNAXAmx",
    "title": "Informed POMDP: Leveraging Additional Information in Model-Based RL",
    "std_review": {
      "summary": "The paper introduces an informed POMDP framework that leverages additional information alongside standard observations in model-based RL, extending asymmetric learning approaches. It provides a rigorous theoretical foundation using sufficient statistics and demonstrates significant empirical improvements in convergence speed and performance across several environments. The authors clearly delineate their contributions, highlighting the practical benefits of informed learning. Overall, the paper is well‑structured, theoretically sound, and empirically validated, leading to an acceptance recommendation.",
      "strengths": [
        "Novel informed POMDP framework that systematically incorporates additional information into model‑based RL.",
        "Strong theoretical foundation using sufficient statistics, grounded in recent information theory literature.",
        "Empirical validation showing substantial improvements over uninformed baselines in multiple environments.",
        "Clear delineation of contributions, distinguishing the learning of a sufficient statistic for control from prior work."
      ],
      "weaknesses": [
        "Relies on ELBO as the learning objective, which may not fully capture the benefits of additional information.",
        "Variational encoder conditioning on both observation and additional information could complicate learning.",
        "Potential scalability issues in very high-dimensional or complex environments where extra information is less helpful.",
        "Empirical reporting could benefit from more detailed analysis of variability and robustness across seeds."
      ],
      "questions": [
        "How does the informed POMDP framework scale to environments with extremely high-dimensional state spaces?",
        "What are the theoretical guarantees on the convergence of the ELBO‑based learning objective when additional information is incorporated?",
        "Could alternative information‑state representations or second encoders improve the efficiency of learning sufficient statistics?",
        "How robust are the reported improvements to variations in the amount or quality of additional information?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "5nM2AHzqUj",
    "title": "Linear Log-Normal Attention with Unbiased Concentration",
    "std_review": {
      "summary": "The paper introduces Linear Log-Normal Attention (LLN Attention), a novel attention mechanism that leverages a log-normal distribution to achieve linear time complexity and reduced memory usage compared to traditional softmax attention. Empirical evaluations on NLP tasks demonstrate competitive performance with significant efficiency gains. While promising, the paper's exploration is limited to NLP, and further analysis is needed to assess its generalizability and practical applicability across other domains.",
      "strengths": [
        "Theoretical advantages over softmax attention, including improved distributional properties and computational efficiency.",
        "Linear time complexity enables scalability to larger models and datasets.",
        "Memory efficiency addresses a key limitation of traditional attention mechanisms.",
        "Empirical evidence shows competitive or superior performance on standard NLP tasks."
      ],
      "weaknesses": [
        "Limited domain exploration, primarily focusing on NLP tasks.",
        "Insufficient analysis of the temperature parameter's impact on performance.",
        "Comparative analysis lacks breadth across diverse models and datasets.",
        "Potential limitations in generalizability to other neural network architectures or tasks."
      ],
      "questions": [
        "How does LLN Attention perform on a broader range of tasks beyond NLP, such as computer vision?",
        "What is the optimal temperature parameter for LLN Attention in different scenarios?",
        "How does LLN Attention compare to other linear attention methods across a wider variety of models and datasets?",
        "What are the theoretical guarantees of LLN Attention's convergence and stability?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "5Nn2BLV7SB",
    "title": "PandalM: An Automatic Evaluation Benchmark for LLM Instruction Tuning Optimization",
    "std_review": {
      "summary": "The paper introduces PandaLM, a method for optimizing large language models (LLMs) through hyperparameter tuning and early stopping. It demonstrates strong performance across various models and domains, showing improved quality and reduced costs. The study also highlights PandaLM's generalization and scalability, though some results are missing. Overall, the paper is well-received for its innovative approach and comprehensive evaluation.",
      "strengths": [
        "Introduces a novel method for optimizing LLMs through hyperparameter tuning.",
        "Demonstrates strong performance and cost-effectiveness across multiple models and domains.",
        "Provides valuable insights into PandaLM's generalization and scalability."
      ],
      "weaknesses": [
        "Lacks detailed results for models optimized by optimal perplexity.",
        "Potential overfitting concerns with 'seen' models in the dataset.",
        "Lacks clear comparison with other state-of-the-art methods.",
        "Insufficient evaluation of generalization to unseen models."
      ],
      "questions": [
        "Could provide more detailed results for models selected based on optimal perplexity.",
        "How does PandaLM's performance compare to other state-of-the-art optimization methods?",
        "What are the specific hyperparameters that lead to the best performance, and how do they vary across different domains?",
        "How does PandaLM's generalization to unseen models like LLaMA-2-7B hold up under more rigorous testing?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "5o9G4XF1LI",
    "title": "Goodhart's Law in Reinforcement Learning",
    "std_review": {
      "summary": "The paper introduces a novel metric called 'angle' to evaluate reinforcement learning algorithms by measuring alignment between learned and target policies. It provides theoretical analysis and empirical evidence across various environments, demonstrating the metric's effectiveness. While promising, the metric's sensitivity to target policy choice and limited analysis in high-dimensional spaces are concerns. Overall, the work is a solid contribution with potential for future improvements.",
      "strengths": [
        "Introduces a novel metric ('angle') that offers a more nuanced view of policy quality.",
        "Provides theoretical analysis and empirical evaluations supporting the metric's effectiveness.",
        "Conducts clear ablation studies highlighting the metric's impact on algorithm performance."
      ],
      "weaknesses": [
        "Metric may be sensitive to the choice of target policy, introducing subjectivity.",
        "Lacks analysis of metric behavior in high-dimensional, continuous state-action spaces.",
        "Empirical evaluations are limited to a few benchmark environments.",
        "Theoretical analysis assumes a specific reward function form, limiting applicability."
      ],
      "questions": [
        "How does the 'angle' metric generalize to high-dimensional, continuous state-action, and long-horizon problems?",
        "What is the impact of choosing different target policies on the metric's performance?",
        "How does the metric compare to alternative metrics like Wasserstein distance or Maximum Mean Discrepancy in capturing policy alignment?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "5oJlyJXUxK",
    "title": "",
    "std_review": {
      "summary": "The paper presents a novel framework for probing and intervening in deep neural networks, offering a systematic approach to select layers, optimize intervention vectors, and choose concepts. It demonstrates effective modification of model behavior while preserving performance, contributing to interpretability and control of black-box DNNs. The method is theoretically grounded and has practical implications for fairness, robustness, and explainability, though it faces limitations in generalizability and computational cost.",
      "strengths": [
        "Clear and novel framework for probing and intervening in DNNs",
        "Theoretically grounded with well-defined procedures",
        "Empirical results show effective modification of model behavior",
        "Comprehensive analysis of computational cost and practical implications"
      ],
      "weaknesses": [
        "Effectiveness evaluated on a limited set of datasets",
        "High computational cost for large models",
        "Lack of detailed analysis of trade-offs between intervention effectiveness and cost",
        "Insufficient discussion of limitations and future research directions"
      ],
      "questions": [
        "How does the method generalize to other domains or model architectures?",
        "What are the trade-offs between intervention effectiveness and computational cost?",
        "Are there specific scenarios where the method is particularly beneficial or ineffective?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "5pKLogzjQP",
    "title": "Purify Perturbative Availability Poisoning Attacks via Rate-Constrained Variational Autoencoders",
    "std_review": {
      "summary": "The paper proposes a defense mechanism for Variational Autoencoders (VAEs) against poisoning attacks by purifying the training dataset using class-wise embeddings. It integrates seamlessly with existing VAE architectures and shows improved robustness in experiments. However, the defense is limited by its reliance on predefined embeddings, which may not generalize to novel attacks, and it incurs additional computational overhead. Overall, the method is promising but has notable limitations.",
      "strengths": [
        "Introduces a novel defense mechanism that purifies poisoned datasets using class-wise embeddings.",
        "Seamlessly integrates with existing VAE architectures without major modifications.",
        "Demonstrates empirical effectiveness and robustness across various poisoning scenarios."
      ],
      "weaknesses": [
        "Limited generalization to novel poisoning attacks not covered by the class-wise embeddings.",
        "Increased computational overhead due to additional forward propagations through the VAE and auxiliary decoder.",
        "Potential vulnerability to sophisticated attacks like those generated using white-box techniques."
      ],
      "questions": [
        "How does the defense perform against novel poisoning attacks not included in the class-wise embeddings?",
        "What is the impact of the additional computational cost on real-time applications?",
        "Can the method be extended to detect and remove poison patterns designed to evade detection by the VAE?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "5RielfrDkP",
    "title": "Learning Adaptive Multiresolution Transforms via Meta-Framelet-based Graph Convolutional Network",
    "std_review": {
      "summary": "The paper introduces MM-FGCN, a novel graph neural network that combines spectral graph theory with meta-learning to adaptively construct multiresolution transforms. It shows significant performance improvements on node and graph classification tasks across several benchmark datasets. While innovative, the approach's complexity and limited dataset coverage are noted as concerns.",
      "strengths": [
        "Innovative integration of spectral graph theory with meta-learning for adaptive multiresolution transforms.",
        "Demonstrated superior performance on several benchmark datasets compared to existing methods.",
        "Enhances flexibility and efficiency of graph neural networks by dynamically adjusting feature resolution."
      ],
      "weaknesses": [
        "High implementation complexity due to the combination of spectral graph theory and meta-learning.",
        "Limited evaluation on a diverse set of datasets, which may affect generalizability.",
        "Lack of comprehensive ablation studies to fully assess the impact of meta-learning."
      ],
      "questions": [
        "What are the computational costs of training and inference for MM-FGCN compared to existing methods?",
        "How does the model perform on a wider range of graph datasets beyond the current benchmarks?",
        "Could additional ablation studies provide clearer insights into the role of meta-learning in the model's performance?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "5rrYpa2vts",
    "title": "EA\\({}^{2}\\)N: Evidence-based AMR Attention Network for Fake News Detection",
    "std_review": {
      "summary": "The paper introduces EA2N, a novel fake news detection approach that leverages Abstract Meaning Representation (AMR) graphs and external knowledge from WikiAMR. It effectively integrates evidence from multiple sources into a graph-based framework, improving semantic relationship capture. Experiments on Politifact and Gossipcop datasets show significant improvements over existing methods, highlighting the model's effectiveness. However, concerns about scalability and reliance on external knowledge quality limit its broad acceptance.",
      "strengths": [
        "AMR provides a more nuanced representation of semantic relationships compared to dependency trees.",
        "Efficiently incorporates external knowledge from WikiAMR, enhancing contextualization without significant computational overhead.",
        "The WikiAMR graph significantly improves interpretability and reliability by providing a structured knowledge base."
      ],
      "weaknesses": [
        "Scalability concerns due to extensive graph construction and evidence integration.",
        "Effectiveness heavily dependent on the quality and comprehensiveness of external knowledge in WikiAMR.",
        "Limited evaluation beyond Politifact and Gossipcop datasets."
      ],
      "questions": [
        "How does EA2N handle scalability when dealing with very large datasets or real-time applications?",
        "What strategies can be employed to mitigate the impact of varying quality external knowledge on model performance?",
        "What additional datasets or evaluation metrics would provide a more comprehensive assessment of EA2N's performance across diverse fake news detection scenarios?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "5RUf9nEdyC",
    "title": "Teddy: Trimming Edges with Degree-based Discrimination Strategy",
    "std_review": {
      "summary": "The paper proposes TEDDY, a method that combines graph sparsification, model distillation, and parameter sparsification to train efficient neural networks. It demonstrates improved generalization and reduced training time compared to conventional approaches. While the approach is novel and shows promising results, concerns remain about the theoretical justification for some claims and the need for additional evidence to validate computational savings.",
      "strengths": [
        "Introduces a novel approach to training efficient neural networks by combining multiple techniques.",
        "Demonstrates improved generalization and reduced training time compared to conventional methods.",
        "Provides a clear theoretical basis for the proposed methods and their impact on generalization error.",
        "Includes ablation studies to highlight the contribution of each component in the proposed method."
      ],
      "weaknesses": [
        "The method relies on random sampling for graph sparsification, which may introduce training-related noise.",
        "The theoretical basis for the impact of removing low-degree edges on generalization error is not fully explored.",
        "The distillation training step may undermine the purpose of using sparse graphs and contradict the claim of 'a single training'.",
        "Additional results are needed to validate the claim that TEDDY significantly surpasses conventional iterative approaches in generalization.",
        "The computational savings from PGD training compared to iterative approaches are not fully substantiated."
      ],
      "questions": [
        "Can you provide a more detailed analysis of the theoretical basis for the impact of removing low-degree edges on generalization error?",
        "What additional results are needed to validate the claim that TEDDY significantly surpasses conventional iterative approaches in generalization?",
        "Could you clarify how the distillation training step interacts with the use of sparse graphs and its impact on computational cost?",
        "What are the specific computational savings demonstrated by PGD training compared to iterative approaches, and what additional results are required to substantiate this claim?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "5sixirvG0I",
    "title": "Whittle Index with Multiple Actions and State Constraint for Inventory Management",
    "std_review": {
      "summary": "The paper introduces the Weighted Inventory Management System (WIMS) policy, a novel multi-agent approach that uses a global dual variable to enforce joint inventory constraints while optimizing individual objectives. Theoretical analysis supports asymptotic optimality under finite capacity, and comparisons highlight its superior adaptability over single-agent methods. Despite promising results, the paper lacks empirical validation and detailed exploration of its integration into MARL frameworks, leaving open questions about scalability and practical applicability.",
      "strengths": [
        "Effectively ensures joint inventory level constraints are satisfied through a global dual variable.",
        "Provides theoretical guarantees of asymptotic optimality under finite capacity conditions.",
        "Demonstrates superior adaptability to varying constraint levels compared to single-agent methods."
      ],
      "weaknesses": [
        "Lacks empirical evidence to validate theoretical claims.",
        "Computational implications of adaptability to changes in capacity or SKU count are not fully explored.",
        "Limited discussion on integration with multi-agent reinforcement learning (MARL) settings."
      ],
      "questions": [
        "What are the computational costs associated with adapting the WIMS policy to changes in capacity limits or SKU count?",
        "How does the WIMS framework compare to existing MARL approaches in terms of scalability and adaptability?",
        "Could empirical studies or simulations be conducted to further validate the theoretical performance claims?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "5sjxMwWmk8",
    "title": "Robust Angular Synchronization via Directed Graph Neural Networks",
    "std_review": {
      "summary": "The paper proposes GNNSync, a synchronization loss for GNNs that enforces unit-modulus constraints on embeddings using novel upset and cycle losses. Experiments show consistent performance gains over baseline GNNs and fine-tuned baselines, highlighting practical utility. While the loss function introduces gradient complexity and lacks theoretical guarantees, the end-to-end training approach simplifies the pipeline. Overall, GNNSync is well-positioned to advance GNN synchronization, with promising empirical results.",
      "strengths": [
        "Introduces novel upset and cycle losses that enforce unit-modulus constraints effectively.",
        "End-to-end training eliminates the need for post-processing, simplifying the pipeline.",
        "Demonstrates consistent performance improvements over baseline GNNs and fine-tuned baselines."
      ],
      "weaknesses": [
        "Gradient complexity arises from non-differentiable minimum and modulo operations.",
        "Projection onto unit-modulus complex vectors lacks a closed-form expression, increasing computational cost.",
        "Hyper-parameter sensitivity, particularly the fixed number of projection iterations, may affect robustness.",
        "Lack of theoretical guarantees (e.g., convexity, Lipschitz continuity) for the loss functions."
      ],
      "questions": [
        "How can the gradient complexity of the loss function be mitigated to improve convergence?",
        "What are the theoretical implications of the Lipschitz continuity of the loss functions on the optimization landscape?",
        "Could a dynamic number of projection iterations be explored to balance convergence speed and accuracy?",
        "Are there alternative methods to enforce unit-modulus constraints that do not rely on iterative projection?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "5t44vPlv9x",
    "title": "",
    "std_review": {
      "summary": "The paper introduces an innovative approach to 3D human pose estimation using pose-dependent frequency modulation combined with a graph neural network to learn per-part weights. This method significantly improves pose estimation accuracy, especially for complex and occluded poses, as demonstrated on the Human3.6M dataset. While the release of code and supplementary material supports reproducibility, the paper lacks comprehensive comparative evaluations and full dataset generalization, and the provided code links are missing.",
      "strengths": [
        "Innovative pose-dependent frequency modulation effectively addresses similar frequency distributions across poses.",
        "Integration of graph neural networks to learn per-part weights enhances the model's ability to capture complex spatial relationships.",
        "Demonstrated significant improvements in pose estimation accuracy, particularly for complex and occluded poses."
      ],
      "weaknesses": [
        "Limited comparative evaluations with other state-of-the-art methods.",
        "Evaluation based on selected frames from the ZJU-Mocap dataset rather than the full dataset.",
        "Absence of additional ablation studies on the full dataset.",
        "Missing code links in the supplementary material."
      ],
      "questions": [
        "Could the method be evaluated against template/scan-based and template-free baselines such as HumanNeRF or MonoHuman for a more comprehensive comparison?",
        "How does the method generalize to the full ZJU-Mocap dataset, and are there additional ablations on this dataset?",
        "Are the code links provided in the supplementary material complete and functional?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "5T46w5X3Go",
    "title": "Theoretical Analysis on the Generalization Power of Overfitted Transfer Learning",
    "std_review": {
      "summary": "The paper presents a rigorous theoretical analysis of feature transfer in linear regression, deriving conditions under which transferring features from a source task to a target task improves performance. It provides explicit bounds on generalization error and highlights the importance of feature alignment. The work is well-supported by experiments and offers practical insights for practitioners, though it relies on assumptions that may not hold in all real-world scenarios.",
      "strengths": [
        "Clear theoretical framework with explicit conditions and bounds.",
        "Provides actionable insights for practitioners in multi-task learning.",
        "Extensive analysis covering feature transformation, correlation, and robustness.",
        "Strong experimental validation on synthetic and real-world datasets."
      ],
      "weaknesses": [
        "Assumes explicit knowledge of common and task-specific features.",
        "Limited to linear regression models, potentially overlooking non-linear relationships.",
        "Focuses on a single source task, not capturing complexities of multi-source scenarios.",
        "Does not fully address robustness to feature correlations like noise or redundancy."
      ],
      "questions": [
        "How can the analysis be extended to scenarios where common features are identified from unlabeled data?",
        "What are the implications of applying feature transformations to the source features before transfer?",
        "How can the results be generalized to models beyond linear regression, such as neural networks?",
        "What measures can be taken to ensure robustness when common features exhibit non-trivial correlations?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "5t57omGVMw",
    "title": "Learning to Relax: Setting Solver Parameters Across a Sequence of Linear System Instances",
    "std_review": {
      "summary": "The paper presents a novel online learning framework for automatically tuning the relaxation parameter ω in the Successive Over‑Relaxation (SOR) method for solving linear systems. It formulates ω selection as a learning problem and provides theoretical analysis with regret bounds and sample complexity guarantees. Empirical results on synthetic and real datasets validate the approach's practical benefits. While the framework is innovative and theoretically sound, it has some limitations, such as reliance on online learning and assumptions about independent target vectors. Overall, the paper is well‑received and recommended for acceptance.",
      "strengths": [
        "Innovative learning framework for tuning relaxation parameter.",
        "Strong theoretical analysis with regret bounds and sample complexity.",
        "Empirical validation on both synthetic and real datasets."
      ],
      "weaknesses": [
        "Reliance on online learning may lead to inefficient exploration.",
        "Assumes independent target vectors, which may not hold in practice.",
        "Theoretical results based on a surrogate loss function.",
        "Lacks direct empirical comparison with established heuristic methods."
      ],
      "questions": [
        "How does the method perform when applied to highly correlated or structured target vectors?",
        "What is the impact of warm‑starting on convergence speed and theoretical guarantees?",
        "How does the proposed method compare to adaptive stopping criteria or direct analysis of convergence rates?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "5tGGWOijvq",
    "title": "Prompt Risk Control: A Rigorous Framework for Responsible Deployment of Large Language Models",
    "std_review": {
      "summary": "The paper introduces Prompt Risk Control (PRC), a framework for managing undesirable outputs in LLM prompt engineering. It defines three methods—Learn‑Then‑Test, Quantile‑Based Risk Control, and Sample‑Draw‑Control—to construct safe prompt sets while preserving performance. Evaluated across code generation, chatbots, and medical question summarization, the framework effectively reduces risk with minimal performance loss. The reviewer finds the approach comprehensive and empirically validated, though some implementation details remain vague.",
      "strengths": [
        "Comprehensive risk management approach for LLM prompt engineering.",
        "Provides multiple optimization strategies (LTT, QRC, SDC) for flexibility.",
        "Demonstrates robustness across diverse domains with clear empirical results."
      ],
      "weaknesses": [
        "Lack of clear guidelines for selecting confidence level (α) and risk tolerance (δ).",
        "Choosing a set of prompts and then selecting the best may not be optimal compared to direct optimization.",
        "Insufficient guidance on interpreting and applying the three methods across different applications.",
        "Does not adequately address sample complexity and validation set size requirements."
      ],
      "questions": [
        "What are the recommended ranges for α and δ to balance risk reduction and performance?",
        "How can practitioners determine the optimal prompt set size for reliable risk estimation?",
        "What specific risk measures are most appropriate for different application domains (e.g., code generation vs. chatbots vs. medical question summarization)?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "5TlHjMVrNG",
    "title": "Evaluating Robustness to Unforeseen",
    "std_review": {
      "summary": "The paper investigates robustness of deep learning models on CIFAR-10 using a novel approach that combines corruptions with optimization techniques. It evaluates core attacks and introduces UA2 for averaging attack performance. While demonstrating improved robustness, the methodology and evaluation need clarification regarding attack selection and UA2 justification.",
      "strengths": [
        "Explores a wide range of robustness forms across a comprehensive benchmark.",
        "Proposes a novel combination of corruptions and optimization techniques to enhance robustness.",
        "Focuses on core attacks, potentially providing more meaningful insights into model performance.",
        "Introduces UA2, an ensemble method for averaging attack performance, which could be valuable for future research."
      ],
      "weaknesses": [
        "The relationship between different forms of robustness is not clearly established.",
        "Motivation behind combining corruptions and optimization techniques is not well-explained.",
        "Selection of core attacks is not justified, and it is unclear how these attacks represent the entire benchmark.",
        "Use of UA2 requires additional justification, particularly regarding the usefulness of averaging attack accuracy and the omission of individual attack accuracies.",
        "Figure 3 lacks clarity in terms of what is being optimized and the meaning of different arrow types and perturbation sizes."
      ],
      "questions": [
        "How does the relationship between different forms of robustness (e.g., glitch vs. JPEG attacks) impact the overall robustness?",
        "What is the motivation behind combining corruptions and optimization techniques, and how do they complement each other?",
        "Why are core attacks selected for evaluation, and how do they represent the entire benchmark?",
        "What additional justification is needed for using UA2 to average attack accuracy, and should individual attack accuracies be reported?",
        "In Figure 3, what exactly is being optimized, and how should the arrows and perturbation sizes be interpreted?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "5tSLtvkHCh",
    "title": "Learning Temporal Causal Representation Under Non-Invertible Generation Process",
    "std_review": {
      "summary": "The paper introduces Caring, a novel method for identifying latent causal factors in non-invertible temporal data, addressing a significant gap in existing literature. It provides a solid theoretical foundation and demonstrates effectiveness on both synthetic and real-world datasets. The approach leverages temporal context to make the non-invertible mixing function effectively invertible, offering clear insights into the required context and identifiability conditions. Overall, the paper is well-written and makes a valuable contribution to the field.",
      "strengths": [
        "Introduces a novel approach (Caring) specifically designed to handle non-invertible temporal data, addressing a significant gap in existing literature.",
        "Provides a comprehensive theoretical analysis that connects to and extends existing work on nonlinear ICA and identifiability in dynamic systems.",
        "Demonstrates practical applicability through comparisons with existing baselines on both synthetic and real-world datasets, highlighting the approach's effectiveness and limitations."
      ],
      "weaknesses": [
        "The theoretical analysis, while novel, may be challenging for readers without a strong background in nonlinear ICA and dynamic systems, potentially limiting its accessibility.",
        "The paper could benefit from a more detailed discussion on the practical implications of the required amount of temporal context (parameter μ) and its impact on computational efficiency and model performance.",
        "Empirical results on real-world datasets, while promising, are limited in scope and could be strengthened by additional experiments or comparisons with more state-of-the-art methods."
      ],
      "questions": [
        "How can the approach be extended to handle high-dimensional data or incorporate domain-specific knowledge?",
        "What are the computational implications of varying the amount of temporal context (parameter μ) in practice?",
        "How does Caring perform when compared to other state-of-the-art methods in more complex real-world scenarios?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "5twh6pM4SR",
    "title": "Automating Continual Learning",
    "std_review": {
      "summary": "The paper presents a novel approach to continual learning by framing it as a sequence‑learning problem and introducing a self‑referential weight matrix (SRWM) that efficiently captures past tasks. Empirical results across several benchmark datasets show that the method mitigates catastrophic forgetting with reduced memory overhead compared to existing techniques. While the approach is theoretically grounded and empirically validated, its evaluation is limited to a few datasets, and the added complexity of the SRWM may pose implementation challenges. Overall, the paper is well‑received for its innovative formulation and strong empirical support, though some concerns remain.",
      "strengths": [
        "Innovative formulation of continual learning as a sequence‑learning problem.",
        "Memory‑efficient self‑referential weight matrix (SRWM) that reduces overhead.",
        "Solid theoretical foundation linking continual learning to sequence models.",
        "Empirical validation across multiple benchmark datasets."
      ],
      "weaknesses": [
        "Limited experimental evaluation to a few benchmark datasets.",
        "Increased complexity of implementation due to the SRWM.",
        "Lack of robustness analysis for variations in task order, frequency, and difficulty.",
        "Insufficient comparative analysis with other state‑of‑the‑art methods."
      ],
      "questions": [
        "How does the method perform on a broader range of continual learning benchmarks?",
        "What are the practical guidelines for implementing the SRWM in real‑world scenarios?",
        "Could you provide a more detailed analysis of the method's robustness across different task sequences?",
        "How does the proposed approach compare to recent alternatives in terms of both memory usage and performance?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "5tYTCyYI27",
    "title": "Calibration Bottleneck: What Makes Neural Networks Less Calibratable?",
    "std_review": {
      "summary": "The paper investigates how compressing the top layers of deep neural networks affects their calibration, introducing a novel training method called Layer-Peeled Training (PLT) that freezes these layers and applies weight decay to preserve calibration. Experiments on multiple datasets show that compressing top layers leads to a U-shaped calibration curve, with PLT effectively mitigating calibration degradation. The study provides both theoretical insights and empirical evidence linking layer compression to calibration loss. Overall, the paper makes a significant contribution by addressing a key calibration issue with a practical solution.",
      "strengths": [
        "Clear definition of calibratability using expected calibration error (ECE) and calibration curves.",
        "Robust experimental design with controlled ablation studies to isolate the effect of top-layer compression.",
        "Innovative Layer-Peeled Training (PLT) method that offers a practical solution to maintain calibration after compression.",
        "Comprehensive analysis linking information loss to calibration, supported by clear visualizations."
      ],
      "weaknesses": [
        "Limited theoretical justification for why only top layers affect calibration.",
        "Potential sensitivity of PLT to hyperparameter choices, such as weight decay and number of frozen layers, not fully explored.",
        "Lack of cross-validation to assess generalization performance.",
        "No comparison with state-of-the-art calibration or compression techniques."
      ],
      "questions": [
        "How does the proposed PLT method perform when applied to models with different architectures or training regimes?",
        "Can the theoretical framework be extended to explain the calibration effects of compressing other layers beyond the top layers?",
        "What are the long-term implications of applying weight decay to frozen layers on model performance and interpretability?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "5VD7dS3cZX",
    "title": "Rethinking the Solution to Curse of Dimensionality on Randomized Smoothing",
    "std_review": {
      "summary": "The paper introduces novel EGG and ESG distributions for randomized smoothing, extending DSRS and improving certified radii on CIFAR-10 and ImageNet. It provides strong theoretical analysis and empirical evidence, addressing the curse of dimensionality. The work is well-received for its contributions, though some concerns about generalizability and implementation details remain.",
      "strengths": [
        "Introduces novel EGG and ESG distributions for randomized smoothing, offering a theoretical framework to improve certified radii.",
        "Provides rigorous theoretical analysis, including new theorems (Theorems 1 and 2) that support the proposed methods.",
        "Empirical results demonstrate significant improvements in certified radii on CIFAR-10 and ImageNet datasets compared to existing methods."
      ],
      "weaknesses": [
        "Theoretical analysis assumes certain conditions that may not hold in all practical scenarios, potentially limiting generalizability.",
        "Experimental evaluation focuses on two datasets (CIFAR-10 and ImageNet), which may not cover a broad enough range of applications.",
        "The paper does not extensively address potential limitations or challenges in implementing the EGG and ESG distributions in real-world scenarios.",
        "The comparison with prior work, particularly the work by Li et al. (2022), is not as comprehensive as it could be."
      ],
      "questions": [
        "How do the EGG and ESG distributions perform on more diverse datasets beyond CIFAR-10 and ImageNet?",
        "What are the computational complexities involved in implementing these distributions, and how do they compare to existing methods?",
        "Are there any specific scenarios or model architectures where the proposed distributions may underperform, and how can these be addressed?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "5Vh0XqOTGi",
    "title": "GAN-based Vertical Federated Learning for Label Protection",
    "std_review": {
      "summary": "The paper presents a novel GAN-based approach to federated learning that enhances privacy by perturbing gradients using a randomized response mechanism. It demonstrates improved robustness against adversarial attacks and provides a clear theoretical framework. While the method is innovative, it has some limitations, such as potential loss of information due to dimensionality reduction and a need for more comprehensive experimental comparisons.",
      "strengths": [
        "Introduces a novel randomized response mechanism to enhance privacy in federated learning.",
        "Demonstrates improved robustness against adversarial attacks.",
        "Provides a clear theoretical framework for understanding privacy and performance trade-offs.",
        "Offers a straightforward approach that can be easily integrated into existing frameworks."
      ],
      "weaknesses": [
        "Dimensionality reduction of model output to a single scalar may affect accuracy.",
        "Simplistic discriminator may not fully capture real-world complexity.",
        "Experimental setup lacks comprehensive comparisons with state-of-the-art methods.",
        "Lacks thorough discussion on trade-offs between privacy and performance."
      ],
      "questions": [
        "How does the dimensionality reduction to a single scalar value impact model accuracy and privacy?",
        "Could a more complex discriminator better capture real-world data characteristics?",
        "What are the specific trade-offs between privacy and performance that practitioners should consider?",
        "How does the GAN-based approach compare to existing gradient protection methods in terms of attack prevention?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "5vXDQ65dzH",
    "title": "ParFam - Symbolic Regression Based on Continuous Global Optimization",
    "std_review": {
      "summary": "ParFam is a symbolic regression framework that uses deep learning to discover polynomial function families, showing superior expressivity compared to traditional methods like EQL and FFX. The authors demonstrate its effectiveness on the Synthetic Regression Bench dataset, highlighting its ability to represent complex functions. However, the prototype version has limitations with large or complex datasets, and the paper lacks detailed analysis of hyperparameter sensitivity and computational cost. Overall, ParFam is promising but requires further refinement.",
      "strengths": [
        "Enhanced expressivity compared to traditional symbolic regression methods.",
        "Deep learning integration enables automatic discovery of complex polynomial structures.",
        "Designed to scale with input variables and polynomial degrees."
      ],
      "weaknesses": [
        "Prototype limitations with very large or complex datasets.",
        "Lack of detailed sensitivity analysis for the regularization hyperparameter.",
        "Potential computational cost due to parameter optimization in high-dimensional spaces."
      ],
      "questions": [
        "How does ParFam perform on real-world datasets beyond SRBench?",
        "What is the impact of the regularization hyperparameter on model performance?",
        "Can the computational cost be mitigated for high-dimensional data?"
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "5xadJmgwix",
    "title": "Scale-Adaptive Diffusion Model for Complex Sketch Synthesis",
    "std_review": {
      "summary": "The paper introduces a scale‑adaptive diffusion model for sketch synthesis, proposing a three‑phase sampling strategy that balances complexity and recognizability. It shows improved generation quality on QuickDraw but has limited analysis of hyperparameters, generalization to other datasets, and robustness of the scaling indicator. Overall, the method is promising yet requires further validation.",
      "strengths": [
        "Innovative three‑phase sampling strategy",
        "Dynamic classifier guidance mechanism",
        "Clear theoretical motivation and empirical evaluation"
      ],
      "weaknesses": [
        "Lack of comprehensive hyperparameter sensitivity analysis",
        "Limited evaluation to the QuickDraw dataset",
        "Insufficient exploration of scaling indicator robustness",
        "Absence of comparison with non‑classifier guidance methods"
      ],
      "questions": [
        "How do the hyperparameters α, β, and γ affect reproducibility and practical deployment?",
        "What is the model's performance on sketches from other datasets or styles?",
        "How robust is the scaling indicator to variations in dataset or sketch type?",
        "How does the method compare to non‑classifier guidance approaches?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "5xKixQzhDE",
    "title": "Calibrated Dataset Condensation for Faster Hyperparameter Search",
    "std_review": {
      "summary": "The paper introduces a novel approach to image dataset distillation that is applicable across different model architectures, enhancing its versatility and potential impact. It proposes distilling directly on the test set for hyperparameter search, which could lead to more efficient model training processes. The study explores various sampling methods and evaluates the method's time cost and potential extension to training set compression. While the paper shows promise, it lacks detailed comparisons with existing methods and quantitative assessments of its impact on model performance.",
      "strengths": [
        "Introduces a novel approach to image dataset distillation applicable across different model architectures.",
        "Proposes distilling directly on the test set for hyperparameter search, a unique contribution.",
        "Explores different sampling methods and evaluates practical concerns like time cost and extension to training set compression."
      ],
      "weaknesses": [
        "Lacks detailed comparison with existing distillation methods to highlight novelty and advantages.",
        "Experimental setup and dataset are not fully described, limiting reproducibility and generalizability.",
        "Does not quantitatively assess the impact on model performance and accuracy.",
        "Does not discuss potential limitations for very deep or complex architectures."
      ],
      "questions": [
        "How does the proposed method compare to existing distillation techniques in terms of efficiency and effectiveness?",
        "Could you provide more details on the experimental setup and dataset used for evaluation?",
        "What is the quantitative impact of the proposed method on model performance and accuracy?",
        "Are there any specific challenges or limitations when applying the method to very deep or complex architectures?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "5XUlfPcQnG",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a physics‑based simulator combined with a reinforcement learning agent to optimize building energy performance. While demonstrating promising results in both simulation and a single real‑world case, the study suffers from limited generalization evidence, insufficient real‑world validation, and a lack of detailed documentation of the simulator and RL system. These issues prevent a full endorsement.",
      "strengths": [
        "Innovative simulator‑tuning procedure that could reduce simulation time and resources.",
        "Demonstrates that the simulator trained on one building can generalize to another, indicating robustness.",
        "Shows that the RL agent trained on the simulator achieves effective energy optimization in a real case study."
      ],
      "weaknesses": [
        "Evidence of generalization across buildings is based on a limited set of test cases.",
        "Real‑world performance of the RL agent is not fully quantified.",
        "The simulator makes several assumptions (e.g., ignoring radiative gains) that could affect accuracy.",
        "Lack of prior work cited to substantiate the claim of first‑time tuning of EnergyPlus."
      ],
      "questions": [
        "How robust is the generalization of the simulator across a broader range of building types?",
        "What is the full extent of the RL agent's performance in diverse real‑world settings beyond the single case study?",
        "What detailed parameters (episode length, weather conditions, occupancy patterns) define the RL simulation system?",
        "What are the precise equations and derivation of the physics‑based simulator used?",
        "How does the observed temperature drift compare to realistic variations, and what assumptions affect the model's fidelity?"
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "5zwrpqYIK5",
    "title": "Outlier-Robust Orthogonal Regression",
    "std_review": {
      "summary": "The paper introduces a robust algorithm for estimating essential matrices on a sphere using a combination of robust sub-gradient method and iteratively reweighted least squares. It provides theoretical convergence guarantees under geometric assumptions and demonstrates superior robustness and convergence in experiments with high outlier ratios. The approach is novel, theoretically sound, and empirically validated, though it has some limitations in terms of assumptions and parameter sensitivity.",
      "strengths": [
        "Novel geometric framework combining manifold learning with robust statistical techniques.",
        "Strong theoretical foundation with geometric assumptions and convergence guarantees.",
        "Algorithmic innovation through the integration of RSGM and IRLS for outlier robustness.",
        "Empirical validation showing improved performance over existing methods, especially with outliers."
      ],
      "weaknesses": [
        "Complex geometric assumptions may limit broad applicability.",
        "Parameter selection for step-size and weighting could be more transparent.",
        "Focus on the sphere may restrict generalizability to other manifolds.",
        "Lack of clear quantitative benchmarks for theoretical metrics."
      ],
      "questions": [
        "How can the manifold geometry assumptions be relaxed to improve applicability?",
        "What are the theoretical implications of extending the framework to higher-dimensional manifolds?",
        "How can the selection of step-size and weighting parameters be made more systematic?",
        "What practical benchmarks can be derived from theoretical metrics like permeance and stability?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "5ZWxBU9sYG",
    "title": "How to Craft Backdoors with Unlabeled Data Alone?",
    "std_review": {
      "summary": "The paper presents a novel approach to backdooring self-supervised learning (SSL) models using only unlabeled data. It introduces two methods—clustering-based and contrastive— for selecting poison samples and compares their effectiveness. The authors demonstrate the feasibility of backdooring SSL models without labeled data, highlighting challenges and limitations. While the work is innovative, it has limitations in terms of method robustness and dataset generalization.",
      "strengths": [
        "Introduces a novel method for backdooring SSL models using unlabeled data, addressing a significant gap in the literature.",
        "Proposes two distinct methods (clustering and contrastive) for selecting poison samples, providing a comprehensive comparison.",
        "Conducts thorough experiments on multiple datasets and SSL models, demonstrating the effectiveness of the proposed methods.",
        "Provides a detailed analysis of the limitations and challenges of backdooring SSL models, contributing to the understanding of this problem."
      ],
      "weaknesses": [
        "The clustering-based method relies on the quality of the clustering algorithm, which may not always perform well on complex datasets.",
        "The contrastive method may struggle with high-dimensional data, potentially limiting its applicability.",
        "The paper lacks a detailed analysis of the trade-offs between the two proposed methods, making it difficult to determine the optimal approach in practice.",
        "The experiments primarily focus on a limited set of SSL models and datasets, which may not generalize well to other scenarios."
      ],
      "questions": [
        "How does the clustering-based method handle datasets with varying levels of complexity and noise?",
        "What are the specific trade-offs between the clustering and contrastive methods in terms of performance and computational efficiency?",
        "How can the proposed methods be adapted to work with high-dimensional data?",
        "What are the long-term implications of backdooring SSL models on the security and trustworthiness of AI systems?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "60e1hl06Ec",
    "title": "Mitigating Simplicity Bias in Deep Learning for Improved OOD Generalization and Robustness",
    "std_review": {
      "summary": "The paper introduces CMID, a conditional mutual information (CMI) regularization technique designed to mitigate spurious feature reliance in machine learning models. By distinguishing between simple (spurious) and complex (invariant) features, CMID aims to improve fairness without degrading overall model performance. Experiments across multiple datasets demonstrate that CMID outperforms existing debiasing methods, particularly in reducing worst‑group accuracy gaps while maintaining in‑distribution performance. The method is theoretically grounded and shows strong empirical results, though it has some theoretical and practical limitations.",
      "strengths": [
        "Clear theoretical foundation",
        "Empirical superiority over existing debiasing methods",
        "Novel approach leveraging CMI to regularize against spurious features",
        "Robustness across different data modalities"
      ],
      "weaknesses": [
        "Assumptions such as Gaussian features and linear predictors may not hold in real-world scenarios",
        "Additional computational cost due to training the simple model and the final CMI‑regularized model",
        "Limited theoretical exploration of non‑Gaussian and non‑linear scenarios",
        "Potential over‑regularization that could capture some invariant information"
      ],
      "questions": [
        "How does CMID perform when the assumptions of Gaussian features and linear predictors are violated?",
        "What is the impact of over‑regularization on model performance in scenarios where spurious features are minimal?",
        "How can the method be extended to non‑Gaussian feature distributions and non‑linear predictors?",
        "What are the theoretical guarantees for CMI regularization in more complex, real‑world settings?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "60lNoatp7u",
    "title": "NeurRev: Train Better Sparse Neural Network Practically via Neuron Revitalization",
    "std_review": {
      "summary": "NeurRev introduces a novel method for identifying and pruning dormant neurons in neural networks, improving model efficiency without significantly compromising accuracy. The approach uses a dynamic activation metric to distinguish dormant neurons, which are then pruned during training, achieving high sparsity levels across various architectures and datasets. While demonstrating strong performance in resource-constrained environments, the method's computational overhead, hyperparameter sensitivity, and scalability concerns are noted. Overall, NeurRev is a valuable contribution to the field of model efficiency.",
      "strengths": [
        "Innovative dormant neuron identification using dynamic activation metrics.",
        "Maintains high accuracy across various architectures and datasets.",
        "Reduces model size and computational requirements, making it suitable for edge devices.",
        "Demonstrates broad applicability across different neural network types."
      ],
      "weaknesses": [
        "Additional computational cost from dynamic tracking of neuron activations.",
        "Performance sensitivity to hyperparameters such as pruning thresholds.",
        "Limited benchmarking against a broader range of state-of-the-art methods.",
        "Scalability concerns for very large models or complex tasks."
      ],
      "questions": [
        "How does NeurRev compare to other dynamic pruning methods in terms of computational efficiency?",
        "What is the impact of hyperparameter tuning on the method's performance across different datasets?",
        "Can NeurRev be extended to handle very large models or more complex tasks without significant loss of efficiency?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "61DYdiyQqk",
    "title": "Two Heads Are Better Than One: Exploiting Both Sequence and Graph Models in AMR-To-Text Generation",
    "std_review": {
      "summary": "The paper introduces DualGen, a model that combines sequence (BART) and graph (graph neural network) encoders to generate text from AMR graphs. It uses a gating mechanism to dynamically balance the two encoders, achieving state-of-the-art results on AMR benchmarks and competitive performance against GPT‑4. While innovative, the model's complexity and resource demands are noted, and its generalization beyond AMR is not fully explored.",
      "strengths": [
        "Innovative integration of sequence and graph encoders to leverage linguistic and structural information.",
        "Effective gating mechanism that dynamically balances encoder outputs during generation.",
        "Strong performance on AMR benchmarks, outperforming existing baselines and even GPT‑4."
      ],
      "weaknesses": [
        "Increased model complexity due to dual encoder integration may hinder implementation and maintenance.",
        "Resource‑intensive training and ensembling could limit accessibility for some researchers.",
        "Limited evaluation of model generalization beyond AMR benchmarks.",
        "Lack of detailed training protocols for reproducibility."
      ],
      "questions": [
        "How does DualGen perform on AMR graphs with varying depths and node complexities beyond the evaluated benchmarks?",
        "What are the specific failure modes of DualGen when handling non‑AMR graph structures, and how can they be mitigated?",
        "Can the model be adapted to other natural language generation tasks with similar structural dependencies?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "61mnwO4Mzp",
    "title": "Denoising Diffusion Variational Inference",
    "std_review": {
      "summary": "DiffVAE presents a novel variational autoencoder that integrates diffusion processes with variational inference, achieving competitive performance on image generation tasks with improved stability and sample quality. Theoretical insights into the denoising variational lower bound support the model's design, and empirical evaluations demonstrate its effectiveness compared to existing baselines. Despite computational costs and implementation complexity, the paper is well-structured and provides a solid foundation for future work.",
      "strengths": [
        "Innovative integration of diffusion and variational inference.",
        "Improved sample quality and training stability.",
        "Strong theoretical foundation with denoising variational lower bound."
      ],
      "weaknesses": [
        "Significant computational overhead during training and inference.",
        "Increased implementation complexity.",
        "Lack of detailed convergence analysis."
      ],
      "questions": [
        "How does DiffVAE compare to recent diffusion models in terms of sample quality and computational efficiency?",
        "What are the specific convergence guarantees for the denoising variational lower bound?",
        "Could a more detailed analysis of the impact of the variational family on model performance be provided?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "62K7mALO2q",
    "title": "In-Context Learning Dynamics",
    "std_review": {
      "summary": "The paper investigates the dynamics of language models during in-context learning, proposing a framework to analyze how LLM predictions evolve over time. It introduces visualizations and statistical measures comparing LLM behavior to a window-average and Bernoulli model, showing smoother transitions in LLM predictions. While the theoretical framework and empirical rigor are strong, some notational ambiguities and figure label issues need clarification. Overall, the work contributes valuable insights to ICL research.",
      "strengths": [
        "Clear theoretical framework for analyzing LLM behavior during in-context learning.",
        "Innovative visualization techniques that intuitively convey model dynamics.",
        "Comprehensive empirical analysis with robust statistical support."
      ],
      "weaknesses": [
        "Ambiguous figure labels in Figure 2 could lead to misinterpretation.",
        "Notational confusion regarding $p(y=Random|x)$ and $p(y|x)$.",
        "Ambiguity in the definition of $C$ in Section 4."
      ],
      "questions": [
        "Please clarify the correspondence between colors in Figure 2 and their respective model behaviors.",
        "Provide a clear definition of $C$ in the main text to enhance understanding.",
        "Consider revising the notation $p(y=Random|x)$ to $p(h=Random|x)$ for consistency."
      ],
      "overall_score": "6: weak accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "639DcBewcJ",
    "title": "Low-Rank Robust Graph Contrastive Learning",
    "std_review": {
      "summary": "The paper introduces LR‑RGCL, a framework that integrates Bayesian non‑parametric prototype learning with contrastive learning for graph representation learning. It aims to improve clustering quality and noise robustness by learning low‑rank embeddings that are both discriminative and expressive. Experiments on several benchmark datasets demonstrate competitive performance against baselines, highlighting the benefits of the proposed hybrid approach. Overall, the paper makes a significant contribution to graph representation learning with a novel and theoretically grounded approach, though some areas for improvement are noted.",
      "strengths": [
        "Innovative Integration: Combines Bayesian non‑parametric prototype learning with contrastive learning, offering a novel approach to graph representation learning.",
        "Theoretical Foundation: Provides a rigorous theoretical justification for the combination of prototype learning and contrastive learning, supported by a generalization bound.",
        "Empirical Validation: Demonstrates strong empirical performance across multiple datasets, outperforming traditional baselines and other state‑of‑the‑art methods."
      ],
      "weaknesses": [
        "Complexity: The Bayesian non‑parametric framework introduces additional computational complexity, which may limit scalability to very large graphs.",
        "Hyper‑parameter Sensitivity: The choice of rank r and the mixing coefficient γ can significantly affect performance, and their optimal values may require extensive tuning.",
        "Lack of Ablation Studies: While the paper discusses the contributions of the two loss terms, more detailed ablation studies could further clarify their individual impacts.",
        "Comparison Scope: The comparison with baselines could be more comprehensive, including a broader range of noise‑robust methods beyond simple clustering approaches."
      ],
      "questions": [
        "How can the computational complexity of the Bayesian non‑parametric framework be reduced to improve scalability?",
        "What are the optimal values for the hyper‑parameters r and γ, and how can they be determined more systematically?",
        "Could more detailed ablation studies be conducted to better understand the individual contributions of the prototype learning and low‑rank factorization components?",
        "How does the proposed method compare with other advanced noise‑robust graph contrastive learning methods beyond those mentioned in the current comparison?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "64kSvC4iPg",
    "title": "Compressed Context Memory For",
    "std_review": {
      "summary": "The paper presents a novel framework for compressing context in machine learning models, achieving efficiency gains but requiring task-specific retraining and additional resources. While innovative, its practicality and generalizability are limited by these constraints. The authors should address these issues in future work.",
      "strengths": [
        "Introduces an innovative compression module that reduces context size while preserving performance.",
        "Demonstrates substantial efficiency improvements in computational resources and memory usage.",
        "Provides a thorough experimental setup with multiple baselines, enhancing the robustness of the findings."
      ],
      "weaknesses": [
        "Task-specific nature limits scalability and practicality in diverse real-world applications.",
        "Requires additional data and computational resources for training, which may be prohibitive in resource-constrained environments.",
        "Lacks generalization to new tasks without retraining, potentially limiting its applicability."
      ],
      "questions": [
        "How can the framework be made more task-agnostic to improve its scalability?",
        "What is the quantitative impact of additional training resources on the framework's performance?",
        "How does the performance gap between compressed and full context models vary across different types of tasks?",
        "Could more sophisticated memory update mechanisms enhance the framework's capabilities?",
        "How does the framework compare to recurrent memory approaches in terms of performance and resource usage?"
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "64t9er38Zs",
    "title": "Learning Deep O(\\(n\\))-Equivariant Hyperspheres",
    "std_review": {
      "summary": "The paper introduces an O(3)-equivariant neural network using equivariant hyperspheres to handle 3D rotations, showing competitive performance on synthetic and real datasets. While innovative and theoretically grounded, concerns remain about its expressiveness compared to higher-order methods, lack of robustness evaluation without augmentation, and omission of baseline comparisons. The exploration of higher-dimensional equivariance is also limited.",
      "strengths": [
        "Innovative equivariant design leveraging equivariant hyperspheres for O(3) symmetry.",
        "Strong theoretical grounding in group representations.",
        "Empirical results demonstrating practical viability on both synthetic and real datasets."
      ],
      "weaknesses": [
        "Potential expressiveness limitations compared to higher-order equivariant models.",
        "Lack of evaluation on real datasets without O(3) augmentation.",
        "Absence of baseline comparisons with other equivariant methods.",
        "Limited exploration of $O(n)$-equivariance for dimensions greater than 3."
      ],
      "questions": [
        "How does the proposed architecture compare in expressiveness to higher-order equivariant models like CGENN?",
        "What is the model's performance on real datasets without O(3) augmentation?",
        "How does the model perform against other equivariant baselines such as vector neurons or EGNN?",
        "What are the practical applications of $O(n)$-equivariance for $n>3$ beyond the examples provided?"
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "66arKkGiFy",
    "title": "Plug-and-Play Posterior Sampling under Mis-Matched Measurement and Prior Models",
    "std_review": {
      "summary": "The paper introduces a novel metric for assessing model mismatch in the Probabilistic Neural Portraits - Uniform Locality Assumption (PnP‑ULA) algorithm, providing theoretical stability guarantees and insights into the algorithm's behavior under mismatched models. It highlights the importance of kernel alignment for optimal performance, with practical implications discussed, though some limitations in accessibility and empirical validation are noted. Overall, the work is well-received with strong theoretical contributions and practical insights.",
      "strengths": [
        "Novel metric for assessing model mismatch",
        "Theoretical rigor with stability guarantees",
        "Insightful analysis of Wasserstein distance",
        "Concrete practical implications"
      ],
      "weaknesses": [
        "Complexity of theoretical results",
        "Limited scope of practical examples",
        "Assumption of known anisotropy",
        "Lack of empirical validation"
      ],
      "questions": [
        "Could empirical validation on diverse datasets further demonstrate the theoretical insights?",
        "How robust is the algorithm to more severe mismatches beyond isotropic vs. anisotropic scenarios?",
        "What are the computational costs associated with applying the posterior-$L_2$ pseudometric in practice?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "66e22qCU5i",
    "title": "Certified Copy: A Resistant Backdoor Attack",
    "std_review": {
      "summary": "The paper introduces Certified Copy, a novel attack on feature-level backdoors that uses a Mean Absolute Error (MAE) term to precisely place triggers in the feature space. It outperforms existing detection methods and demonstrates robustness against post-deployment fine-tuning. The authors provide a clear conceptual framework and discuss implications for real-world deployments, though some limitations remain.",
      "strengths": [
        "Innovative MAE cost function for precise trigger placement",
        "Strong performance against state-of-the-art detection methods",
        "Clear naming and conceptual clarity of 'Certified Copy'",
        "Broad applicability to both all-to-one and multi-class backdoors",
        "Robustness analysis against post-deployment fine-tuning"
      ],
      "weaknesses": [
        "Potential dataset bias from trigger-specific augmentation",
        "Lack of comparison with the most recent detection methods",
        "Ambiguity in the interpretation of the 'certified' term",
        "No explicit discussion of the trade-off between robustness and evasiveness"
      ],
      "questions": [
        "How does the attack perform when applied to multi-class backdoors beyond the all-to-one scenario?",
        "What is the impact of dataset bias on the attack's effectiveness in real-world settings?",
        "Can the authors provide a more detailed analysis of the trade-off between robustness and evasiveness?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "66wQM45W28",
    "title": "CEDNet: A Cascade Encoder-Decoder Network for Dense Prediction",
    "std_review": {
      "summary": "CEDNet introduces a novel cascade encoder-decoder network for dense prediction tasks, effectively fusing multi-scale features early in the architecture to improve speed and accuracy while drastically reducing computational cost. The paper demonstrates significant performance gains across object detection, instance segmentation, and semantic segmentation. Despite its innovative approach, the review highlights several areas for improvement, such as clearer feature definitions and a more comprehensive comparison with state-of-the-art methods.",
      "strengths": [
        "Innovative feature fusion strategy that leverages multi-scale features early in the network.",
        "Significant computational efficiency gains with three orders of magnitude reduction in FLOPs.",
        "Clear theoretical motivation for early fusion of multi-scale features to capture hierarchical visual information."
      ],
      "weaknesses": [
        "Ambiguity in distinguishing between low-level and high-level features.",
        "Lack of comprehensive comparison with state-of-the-art methods like InternImage.",
        "Potential reproducibility issues due to reliance on external visual results."
      ],
      "questions": [
        "How can the architecture more clearly distinguish between low-level and high-level features?",
        "What is the impact of the specific number of cascade stages on performance and efficiency?",
        "How does CEDNet compare to the latest state-of-the-art methods in terms of performance and computational cost?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "67t4ikhlvP",
    "title": "Agent-Centric State Discovery for Finite-Memory POMDPs",
    "std_review": {
      "raw_text": "{\n  \"summary\": \"The paper presents a novel method for handling POMDPs by predicting actions from observations and discovering a latent Markovian state space, showing improvements in offline reinforcement learning tasks. While the methodology is well-defined and the empirical results are strong, the paper suffers from unclear motivation for key assumptions, ambiguous notation, missing related work, and lack of evaluation metrics and scope clarity.\",\n  \"strengths\": [\n    \"Introduces a unique approach to POMDPs by combining action prediction with latent state discovery.\",\n    \"Provides clear and detailed mathematical formulation for state estimation and action prediction.\",\n    \"Demonstrates significant empirical improvements in offline reinforcement learning tasks.\"\n  ],\n  \"weaknesses\": [\n    \"Assumptions are not well-motivated, making it hard to understand their necessity.\",\n    \"The relationship between predicting actions and discovering the latent state space is not clearly explained.\",\n    \"Lacks comprehensive related work discussion, especially on learning approximate information states.\",\n    \"Notation $q(\\cdot|z)$ is ambiguous without further clarification.\",\n    \"Definition of $\\tilde{o}_F(h,n)$ on Page 3 is incorrect and needs revision.\",\n    \"Does not specify metrics for evaluating state estimation errors.\",\n    \"Title and abstract do not explicitly mention the focus on offline reinforcement learning.\",\n    \"Related work section is placed too late, which could be improved for better context.\"\n  ],\n  \"questions\": [\n    \"Could you provide a clearer motivation for the assumptions made in the model?\",\n    \"How exactly does the latent state space relate to the prediction of actions?\",\n    \"What specific related work should be included to provide a broader context for the proposed method?\",\n    \"Please clarify the intended meaning of the notation $q(\\cdot|z)$.\",\n    \"Could you correct the definition of $\\tilde{o}_F(h,n)$ on Page 3?\",\n    \"Which metrics are used to evaluate state estimation errors?\",\n    \"Should the title and abstract explicitly mention the focus on offline reinforcement learning?\",\n    \"Would moving the related work section earlier improve the paper's flow?\"\n  ],\n  \"overall_score\": \"5: borderline\",\n  \"confidence\": \"3: medium\"\n}",
      "parse_error": true
    }
  },
  {
    "paper_id": "68k0KcHFrW",
    "title": "Stochastic Unrolled Federated Learning",
    "std_review": {
      "raw_text": "{\n  \"summary\": \"SURF introduces a federated learning algorithm that ensures rate fairness among devices while maintaining convergence. Theoretical work provides convergence guarantees under convexity assumptions, and experiments show improved fairness and speed over standard averaging. However, the reliance on convexity, unclear convergence definitions, and lack of comparison with personalized methods are significant concerns.\",\n  \"strengths\": [\n    \"Introduces a novel rate‑fairness mechanism via convex combination of local models.\",\n    \"Provides strong theoretical convergence guarantees under convexity assumptions.\",\n    \"Empirical results demonstrate clear benefits in fairness and convergence speed.\"\n  ],\n  \"weaknesses\": [\n    \"Theoretical guarantees are limited to convex settings, which may not hold in practice.\",\n    \"Convergence definition in Theorem 2 is ambiguous.\",\n    \"No analysis of how model heterogeneity affects SURF's performance.\",\n    \"Lacks comparison with personalized federated learning methods.\"\n  ],\n  \"questions\": [\n    \"How can SURF be extended to non‑convex settings where convexity assumptions do not hold?\",\n    \"What strategies can be employed to ensure the conditions \\(g = f\\) and \\(g = \\| \\nabla f \\|\\) are met in practice?\",\n    \"How does SURF perform under varying degrees of model and data heterogeneity compared to personalized methods?\",\n    \"Can you clarify whether Theorem 2 guarantees convergence to a local minimum or a stationary point?\"\n  ],\n  \"overall_score\": \"6: weak accept\",\n  \"confidence\": \"3: medium\"\n}",
      "parse_error": true
    }
  },
  {
    "paper_id": "6ALuy19mPa",
    "title": "DreamClean: Restoring Clean Image Using Deep Diffusion Prior",
    "std_review": {
      "summary": "DreamClean introduces a novel approach to image restoration using Variance Preservation Sampling (VPS) within a diffusion model framework. The method effectively addresses noise and blur, particularly in high-resolution contexts, and outperforms several state-of-the-art techniques. While computational cost and parameter sensitivity are noted, the robustness across diverse datasets and superior visual quality make it a strong contribution to the field.",
      "strengths": [
        "Innovative use of VPS to enhance image quality by addressing noise and blur.",
        "Scalable to high-resolution images with good computational efficiency.",
        "Demonstrates superior performance over existing state-of-the-art methods."
      ],
      "weaknesses": [
        "Computational cost can be high, especially for high-resolution images.",
        "Performance is sensitive to hyperparameter tuning.",
        "Lack of extensive benchmarking against a broader range of methods."
      ],
      "questions": [
        "How does DreamClean perform on real-time applications with strict computational constraints?",
        "What are the specific guidelines for hyperparameter tuning to achieve optimal results across different datasets?",
        "Could automated methods for parameter optimization further enhance the usability of DreamClean?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6bAfAcuuZD",
    "title": "Emergence of surprise and predictive signals from local contrastive learning",
    "std_review": {
      "summary": "The paper introduces a predictive coding model for visual cortex neural coding, using hierarchical layers and a global supervisory signal. It employs PCA to assess representational power across layers, showing higher layers encode more abstract representations. While biologically plausible, the model has methodological issues such as inconsistent PCA component selection and ambiguous terminology, leading to a weak accept recommendation.",
      "strengths": [
        "Clear model proposal with hierarchical predictive coding framework",
        "Robust use of PCA to analyze representational content",
        "Strong biological relevance discussion"
      ],
      "weaknesses": [
        "Inconsistent PCA component selection across analyses",
        "Ambiguous use of 'surprise' term",
        "Simplification of linear analysis by approximating input to label",
        "Omission of layer normalization",
        "Truncated presentation phase affecting robustness"
      ],
      "questions": [
        "Should PCA component selection be standardized across analyses?",
        "Is a single global supervisory signal sufficient for capturing diverse biological mechanisms?",
        "How would extending the presentation phase impact model dynamics and performance?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "6bcAD6g688",
    "title": "Unmasking and Improving Data Credibility:",
    "std_review": {
      "summary": "The paper introduces a method for estimating transition matrices in Markov chains using embeddings that reflect safety issues, leveraging consensus vectors and k-Nearest Neighbors (KNN) to capture system dynamics. While demonstrating improved performance on various datasets, the approach has some limitations, such as potential bias from embeddings and unclear theoretical foundations. Overall, the method shows promise but requires further refinement.",
      "strengths": [
        "Integrates embeddings to reflect safety issues, providing a novel way to capture complex relationships.",
        "Uses consensus vectors for clear and intuitive transition matrix estimation, enhancing interpretability.",
        "Demonstrates broad applicability across different datasets, showing flexibility."
      ],
      "weaknesses": [
        "Reliance on embeddings may introduce bias if they do not accurately capture safety dynamics.",
        "The role of consensus vectors in estimating the transition matrix is not fully explored.",
        "Performance may be sensitive to parameter choices, which are not clearly optimized.",
        "Lacks comprehensive theoretical analysis linking consensus vectors to the transition matrix."
      ],
      "questions": [
        "How can the method be further validated to ensure embeddings accurately capture safety dynamics?",
        "What theoretical framework can be developed to better understand the relationship between consensus vectors and the transition matrix?",
        "How can parameter optimization be improved to enhance the robustness of the method across diverse datasets?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "6c4gv0E9sF",
    "title": "SpikeBert: A Language Spikformer Learned from BERT with Knowledge Distillation",
    "std_review": {
      "summary": "The paper introduces SpikeBERT, a spiking neural network model for NLP that aims to improve energy efficiency and performance. It demonstrates competitive results on several benchmarks compared to baseline models, but lacks detailed discussions on limitations, comparisons with recent advancements, and clear rationales for choosing SpikeBERT over other models with similar performance.",
      "strengths": [
        "Introduces a novel spiking neural network architecture for NLP tasks.",
        "Demonstrates improved energy efficiency and performance compared to baseline models.",
        "Provides a comprehensive evaluation on multiple NLP benchmarks."
      ],
      "weaknesses": [
        "Lacks a detailed discussion of limitations and potential drawbacks of the proposed model.",
        "Does not compare the model against recent advancements in SNNs and distillation techniques in NLP.",
        "Performance is comparable to TextCNN, making it unclear when to prefer one over the other.",
        "Math and notation in Section 3 are not precise, which may lead to confusion.",
        "Higher FLOPs for SpikeBERT despite lower energy consumption.",
        "Data augmentation strategies are not consistent across comparisons.",
        "Performance not compared against DistilBERT."
      ],
      "questions": [
        "Could you elaborate on the specific scenarios where SpikeBERT would be preferred over TextCNN despite similar performance?",
        "Why are the limitations of the proposed model not discussed in the conclusion?",
        "How do the data augmentation strategies differ across the methods compared in the study?",
        "What is the impact of the higher FLOPs for SpikeBERT compared to FT BERT, given its lower energy consumption?",
        "How does SpikeBERT compare to recent distilled BERT models like DistilBERT?"
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "6CetUU9FSt",
    "title": "Visual Encoders for Data-Efficient Imitation Learning in Modern Video Games",
    "std_review": {
      "summary": "The paper investigates the use of pre-trained visual encoders for training agents in modern video games, finding that these encoders generally outperform end-to-end trained ones, especially in fine-grained perception tasks. While comprehensive, the study is limited to three games and immediate decision-making tasks, and lacks comparison with state-of-the-art approaches like VPT. The authors should consider broader game diversity, longer-horizon tasks, and deeper analysis of image augmentation.",
      "strengths": [
        "Comprehensive evaluation of multiple visual encoders across several modern video games.",
        "Clear methodology facilitating reproducibility.",
        "Insights into the effectiveness of pre-trained encoders in bridging real-world and game visual distributions."
      ],
      "weaknesses": [
        "Evaluation restricted to three video games, limiting generalizability.",
        "Focus on immediate decision-making tasks, potentially overlooking long-horizon impacts.",
        "No comparison with state-of-the-art methods such as VPT.",
        "Insufficient exploration of image augmentation effects."
      ],
      "questions": [
        "How do the findings generalize to a broader range of modern video games?",
        "What is the impact of visual encoders on long-horizon decision-making tasks?",
        "Could a more detailed analysis of image augmentation enhance performance?",
        "How do the results compare with recent state-of-the-art approaches like VPT?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6cGiRiExUd",
    "title": "Efficient Point Cloud Matching",
    "std_review": {
      "summary": "The paper introduces PMT, a novel coarse‑to‑fine matching framework that enhances efficiency and accuracy of high‑order convolutions and attention mechanisms. It leverages a proxy tensor and an intermediate correlation term to improve feature representation and computational performance, achieving significant gains in CRD, CD, and RMSE compared to existing methods. The experimental validation across synthetic and real‑world datasets supports its effectiveness, though some concerns about model complexity and generalizability remain.",
      "strengths": [
        "Innovative proxy tensor mechanism for efficient coarse matching",
        "Intermediate correlation term captures higher‑order interactions",
        "Strong experimental validation across diverse datasets",
        "Significant reductions in computational cost and memory usage"
      ],
      "weaknesses": [
        "Increased model complexity may reduce interpretability",
        "Limited dataset diversity could affect generalizability",
        "Lack of detailed theoretical analysis linking to high‑order convolutions",
        "Potential overfitting on higher‑order interactions"
      ],
      "questions": [
        "How does PMT perform on highly variable dataset sizes and types?",
        "What is the theoretical justification for the proxy tensor's role in matching?",
        "Can PMT be integrated with other state‑of‑the‑art matching methods?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6CIGhcJYJH",
    "title": "Two-timescale Extragradient for Finding Local Minimax Points",
    "std_review": {
      "summary": "The paper introduces a novel timescale separation technique for analyzing the Extragradient Method (EG) in convex-concave optimization, extending the analysis to stochastic settings using stochastic differential equations (SDEs). It provides a new convergence framework and a restricted Schur complement condition, offering insights into minimax point stability. While the contributions are significant, the necessity of timescale separation and the impact of finite separation parameters remain underexplored, and some assumptions on the Hessian limit generality.",
      "strengths": [
        "Novel analysis framework using timescale separation for EG.",
        "Introduction of a restricted Schur complement for refined convergence conditions.",
        "Extension of EG analysis to stochastic settings via SDEs."
      ],
      "weaknesses": [
        "The necessity of timescale separation for EG is not fully justified.",
        "Impact of finite separation parameter τ is not thoroughly examined.",
        "Assumptions on the Hessian restrict the generality of the results."
      ],
      "questions": [
        "Can a single-timescale EG achieve similar convergence properties without timescale separation?",
        "How does the choice of the separation parameter τ affect convergence rates and stability?",
        "What are the implications of the Hessian assumptions on the generality of the analysis?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "6cMmSnOpCs",
    "title": "ScaLearn: Simple and Highly Parameter-Efficient Task Transfer by Learning to Scale",
    "std_review": {
      "summary": "ScaLearn presents a parameter‑efficient fine‑tuning method that dynamically scales the influence of multiple source tasks, enabling flexible knowledge transfer across NLI, QA, and classification tasks. The approach is theoretically grounded and empirically validated across several benchmarks, showing significant performance gains with fewer trainable parameters. While promising, the method faces challenges in scalability and generalization to new domains, and further investigation is needed for edge cases.",
      "strengths": [
        "Parameter Efficiency: Significantly reduces trainable parameters while maintaining or improving performance.",
        "Dynamic Scaling: Allows flexible adaptation of source task influences, enhancing adaptability.",
        "Theoretical Foundation: Grounded in a solid framework explaining how scaling improves knowledge transfer."
      ],
      "weaknesses": [
        "Complexity of Scaling Coefficients: Hyperparameter tuning for scaling coefficients may impact usability.",
        "Scalability Concerns: Managing scaling coefficients for many source tasks could become computationally expensive.",
        "Limited Domain Generalization: Insufficient evidence on performance in new domains or modalities."
      ],
      "questions": [
        "How can the scaling coefficients be tuned efficiently in practice?",
        "What strategies can be employed to ensure scalability when scaling up to many source tasks?",
        "How does ScaLearn perform when applied to tasks outside its source domain, such as vision?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6CZ50WgfCG",
    "title": "Learning Reusable Dense Rewards",
    "std_review": {
      "summary": "The paper introduces DrS, a novel reinforcement learning approach that uses discriminators and stage indicators to improve reward learning efficiency. It demonstrates significant reductions in training time and sample requirements compared to standard RL and GAIL methods. While the method shows promise, it introduces computational costs and implementation complexity that could limit its practicality in large-scale applications.",
      "strengths": [
        "Innovative use of discriminators to enhance reward learning.",
        "Effective incorporation of stage indicators for more focused learning.",
        "Demonstrated improvements in sample efficiency and reduced training time."
      ],
      "weaknesses": [
        "Increased computational costs due to additional discriminators.",
        "Complexity in implementation and potential for overfitting.",
        "Lack of comprehensive comparison with other state-of-the-art methods."
      ],
      "questions": [
        "How does DrS perform on larger, more complex environments compared to smaller benchmarks?",
        "What strategies can be employed to mitigate overfitting when using discriminators?",
        "How does the choice of stage indicators affect the generalization of learned rewards across different tasks?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6EQbYM0CIX",
    "title": "Conditional Generative Modeling for High-dimensional Marked Temporal Point Processes",
    "std_review": {
      "summary": "The paper presents a conditional generative model for high-dimensional marked temporal point processes, leveraging variational learning to optimize domain-specific losses. It demonstrates strong performance on both synthetic and real-world datasets, outperforming existing baselines. The model's ability to handle high-dimensional mark spaces is a significant advancement, though its complexity and computational cost may pose challenges for broader adoption.",
      "strengths": [
        "Introduces a novel conditional generative approach for high-dimensional mark spaces.",
        "Demonstrates strong empirical performance on both synthetic and real-world datasets.",
        "Leverages variational learning to optimize domain-specific losses effectively."
      ],
      "weaknesses": [
        "Complexity of implementation may limit accessibility for practitioners.",
        "Higher computational cost could restrict applicability to large-scale datasets.",
        "Lack of detailed analysis across diverse datasets and conditions."
      ],
      "questions": [
        "How does the model scale to extremely large datasets with high-dimensional mark spaces?",
        "What are the theoretical guarantees of the variational learning approach in this context?",
        "How does the model compare to recent state-of-the-art methods in related domains?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6Ey8mAuLiw",
    "title": "On the Power of Multitask Representation Learning with Gradient Descent",
    "std_review": {
      "summary": "The paper presents a theoretical framework for multi‑task learning using a synthetic data model with shared and noisy feature patches. It derives test‑error bounds that depend on parameters α (shared information proportion) and H (number of patches), showing how they influence learning dynamics. Empirical experiments on synthetic data validate these predictions, highlighting the impact of α and H. While the work offers valuable insights, its reliance on an idealized data structure limits its direct applicability to real‑world scenarios.",
      "strengths": [
        "Clear theoretical contributions with novel test‑error bounds dependent on key parameters.",
        "Well‑defined synthetic model that allows precise analysis of shared features and noise.",
        "Empirical validation that reinforces the theoretical findings and demonstrates robustness."
      ],
      "weaknesses": [
        "Artificial data structure may not reflect real‑world complexity, limiting generalizability.",
        "Assumptions about feature patch probabilities and number of patches may not hold for diverse datasets.",
        "Theoretical analysis depends on parameters like α and mixing constant c, which can be challenging to estimate in practice."
      ],
      "questions": [
        "How do the theoretical bounds scale with more complex real‑world data structures beyond the synthetic model?",
        "What is the impact of varying the mixing constant c on practical model performance?",
        "Can the framework be extended to handle non‑identical distributions across tasks or varying noise levels?"
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "6FAH0SgQzO",
    "title": "",
    "std_review": {
      "raw_text": "{\n  \"summary\": \"The paper introduces FedRC, a federated learning framework that detects and adapts to concept shifts using a hard clustering mechanism. It outperforms traditional methods like FedAvg on CIFAR100 and Tiny-ImageNet datasets, demonstrating strong theoretical foundations and practical advantages. The reviewer finds the work innovative and well-supported, with some minor concerns about experimental assumptions and clarity.\",\n  \"strengths\": [\n    \"Effective concept shift detection and adaptation\",\n    \"Theoretical comparison with existing methods\",\n    \"Improved accuracy on dynamic datasets\",\n    \"Clear and comprehensive experimental analysis\"\n  ],\n  \"weaknesses\": [\n    \"Workflow diagram could be more detailed\",\n    \"Assumptions about IID datasets may limit generalizability\",\n    \"Theoretical comparison could be more in-depth\",\n    \"Optimization details for Equation (2) are not fully explained\",\n    \"Handling of non-participating clients is not clearly defined\"\n  ],\n  \"questions\": [\n    \"How can the workflow diagram be improved to better illustrate the concept shift detection process?\",\n    \"What are the detailed steps for optimizing Equation (2) and the role of parameters \\(\\gamma\\), \\(\\omega\\), and \\(\\lambda_i\\)?\",\n    \"How does FedRC handle non-participating clients during testing?\",\n    \"How does the IID assumption in experiments affect the real-world applicability of the results?\"\n  ],\n  \"overall_score\": \"7: accept\",\n  \"confidence\": \"4: high\"\n}",
      "parse_error": true
    }
  },
  {
    "paper_id": "6fFd8QaPVx",
    "title": "OneBNet: Binarized Neural Networks",
    "std_review": {
      "summary": "OneBNet introduces a novel 1-D binarized convolution architecture integrated into a ResNet backbone, aiming to improve efficiency and accuracy for edge computing. The paper presents a dedicated 1-D downsampling layer and a learnable activation adjustment mechanism, achieving competitive performance on CIFAR-10 and ImageNet while reducing latency and memory footprint on CPU-based devices. Despite promising results, the evaluation is limited to specific datasets, and the paper lacks ablation studies and detailed hardware analysis, which could strengthen its claims.",
      "strengths": [
        "Innovative 1-D binarized convolutions extending beyond traditional 2-D BNNs.",
        "Dedicated 1-D downsampling layer tailored for binarized convolutions.",
        "Learnable activation distribution adjustment enhancing model flexibility.",
        "Clear heuristics and guidelines for practitioners.",
        "Comprehensive evaluation across multiple datasets."
      ],
      "weaknesses": [
        "Limited generalization to other datasets or tasks.",
        "Absence of ablation studies to assess component impact.",
        "Lack of detailed hardware compatibility and deployment analysis.",
        "Comparative scope limited to architecture-modifying BNN methods."
      ],
      "questions": [
        "How does OneBNet perform on non‑edge hardware or diverse datasets?",
        "What is the impact of each component (1-D downsampling, activation adjustment) on model performance?",
        "Could the proposed method be extended to other neural network architectures?",
        "What are the practical deployment challenges on real edge devices?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6FvBXs8t8K",
    "title": "Learn from the Past: A Proxy based Adversarial Defense Framework to Boost Robustness",
    "std_review": {
      "summary": "The paper presents a novel adversarial defense framework that uses historical model states as a proxy to iteratively update both the proxy and main models, improving robustness on CIFAR-10 and CIFAR-100 datasets. While showing strong empirical results against adversarial attacks and out-of-distribution samples, the framework's reliance on historical data and sensitivity to hyperparameters are noted as limitations. Overall, the innovative approach and robust performance justify an acceptance.",
      "strengths": [
        "Innovative proxy model approach leveraging historical model states.",
        "Two-stage update rule effectively enhances model robustness.",
        "Empirical evidence of improved adversarial performance on standard datasets."
      ],
      "weaknesses": [
        "Potential overfitting to historical data.",
        "Hyperparameter sensitivity affecting performance.",
        "Scalability concerns for larger datasets or more complex models."
      ],
      "questions": [
        "How can the framework be extended to handle more complex adversarial attacks?",
        "What strategies can be employed to mitigate overfitting to historical data?",
        "How does the two-stage update rule perform on larger datasets or more complex models?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6GySuKTJcd",
    "title": "Energy-Guided Continuous Entropic Barycenter Estimation for General Costs",
    "std_review": {
      "summary": "The paper introduces a novel algorithm that leverages neural networks to parameterize potentials for a specific computational task, aiming to improve both theoretical guarantees and practical performance. Experimental results demonstrate significant improvements over existing methods, highlighting the method's potential. However, concerns about computational overhead, the relevance of Energy-Based Models, and the lack of thorough convergence analysis prevent a stronger endorsement.",
      "strengths": [
        "Integrates neural networks for flexible and powerful potential parameterization.",
        "Provides clear theoretical guarantees enhancing reliability.",
        "Demonstrates superior performance over traditional methods."
      ],
      "weaknesses": [
        "High computational overhead with large K.",
        "Ambiguity in the relevance of Energy-Based Models.",
        "Lack of thorough convergence analysis.",
        "Potential inefficiencies with unadjusted Metropolis-Hastings MCMC."
      ],
      "questions": [
        "Can you provide a detailed analysis of the convergence properties of the algorithm?",
        "How do the proposed neural‑network parameterizations compare to other methods in terms of computational cost?",
        "What are the specific benefits of incorporating Energy-Based Models in this context?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "6Gzkhoc6YS",
    "title": "Personalize Segment Anything Model with One Shot",
    "std_review": {
      "summary": "The paper introduces PerSAM, a personalized segmentation model that leverages few-shot learning to fine-tune the Segment Anything Model (SAM) for specific objects or styles. It builds on SAM by incorporating a personalized memory bank of reference embeddings, enabling the model to adapt with minimal examples. Experiments show improved segmentation quality and flexibility, especially in customizing styles and handling multi-object scenarios. The integration with DreamBooth further enhances background generation while preserving object fidelity. While the approach is promising, it lacks comprehensive baseline comparisons and detailed analysis of performance metrics.",
      "strengths": [
        "Personalization through Few-Shot Learning: PerSAM effectively adapts to new objects using only a few reference images, addressing a key limitation of zero-shot methods.",
        "Integration with SAM: By extending SAM, PerSAM retains the strengths of the original framework while adding the capability for personalized segmentation.",
        "Improved Customization with DreamBooth: The approach enhances DreamBooth's ability to generate diverse backgrounds, demonstrating practical benefits for style transfer and image generation tasks."
      ],
      "weaknesses": [
        "Baseline Comparison: The paper lacks a comprehensive comparison with state-of-the-art few-shot segmentation methods, which could provide a clearer benchmark for PerSAM's performance.",
        "Few-Shot Generalization: While the model improves with more reference images, the extent of its generalization to unseen objects within the same category remains underexplored.",
        "Parameter Generalization: It is unclear whether the same set of parameters can effectively generalize to different objects within the same category, especially when using standard fine-tuning approaches.",
        "Performance Metrics: The paper could benefit from more detailed analysis of running speed and memory consumption, particularly when comparing PerSAM to SAM and other segmentation models."
      ],
      "questions": [
        "How does PerSAM's performance compare to state-of-the-art few-shot segmentation methods like DenseCLIP?",
        "What is the extent of PerSAM's generalization to unseen objects within the same category, and how does it compare to standard fine-tuning approaches?",
        "How does the model's parameterization handle multi-object generalization within the same category, and what are the trade-offs with methods like LoRA?",
        "Could a detailed analysis of PerSAM's running speed and memory consumption provide additional insights into its practical applicability?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6hP9JcXpNk",
    "title": "Going Beyond Familiar Features for",
    "std_review": {
      "summary": "The paper presents a novel anomaly detection framework that combines familiarity and novelty branches to improve detection performance. The familiarity branch uses nearest-neighbor encodings to assess known patterns, while the novelty branch leverages B‑cos network explanations to identify features not meaningfully represented by the encoder. Experiments show that the combined approach outperforms existing methods, especially in novelty‑only detection scenarios. The method is interpretable and robust, with strengths in performance and flexibility, though it introduces computational overhead and requires careful tuning.",
      "strengths": [
        "Dual branch architecture effectively combines familiarity and novelty for robust detection.",
        "Explainability via B‑cos network explanations adds interpretability to the model's decisions.",
        "Improved performance across multiple datasets compared to baseline methods."
      ],
      "weaknesses": [
        "Increased computational complexity due to dual branch architecture and B‑cos explanations.",
        "Parameter sensitivity, particularly the choice of threshold and number of nearest neighbors.",
        "Lack of strong theoretical justification for the effectiveness of the combined approach."
      ],
      "questions": [
        "How does the method scale to high-dimensional or real-time anomaly detection scenarios?",
        "What is the impact of the choice of background class on the novelty branch's performance?",
        "Can the method be extended to unsupervised or semi-supervised anomaly detection settings?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6hvtSLkKeZ",
    "title": "Learning to solve Class-Constrained Bin Packing Problems via Encoder-Decoder model",
    "std_review": {
      "summary": "The paper proposes an encoder-decoder framework for solving combinatorial optimization problems, specifically the Capacitated Vehicle Routing Problem, using a heat-map representation of connection probabilities. While the approach shows promise and improves performance over existing methods, its novelty is not well-established, and several aspects such as the motivation behind the heat-map, the role of the First Fit scheme, and the dataset construction are not clearly explained. The active search strategy and its integration with the model are also not fully detailed.",
      "strengths": [
        "Introduces a novel encoder-decoder framework for combinatorial optimization problems.",
        "Proposes a heat-map representation of connection probabilities, differing from traditional node classification models.",
        "Demonstrates improved performance on the CVRP compared to existing methods."
      ],
      "weaknesses": [
        "The novelty of the heat-map representation is not well-established compared to other problems like TSP and VRP.",
        "The motivation behind using a heat-map to classify items is not clearly explained.",
        "The role of the First Fit (FF) scheme in the cluster decoder is not thoroughly discussed.",
        "The dataset used for generating ideal data is not described in detail.",
        "The process of active search and finetuning the model on a per-instance basis is not well-explained.",
        "The extension of the cluster decoder to consider additional constraints beyond class numbers is not explored.",
        "The main contributions of the encoder-decoder structure apart from active search are not clearly articulated."
      ],
      "questions": [
        "How does the heat-map representation compare to other problem-specific encodings in terms of novelty and effectiveness?",
        "What is the specific motivation for using a heat-map to classify items rather than direct node classification?",
        "How does the First Fit scheme in the cluster decoder contribute to the overall solution quality?",
        "Could you provide more details on the dataset used for generating ideal data and its construction method?",
        "How does the active search strategy iteratively refine the solution, and what are the key differences compared to other search methods in neural combinatorial optimization?",
        "What are the main contributions of the encoder-decoder structure beyond the active search mechanism?",
        "How can the cluster decoder be extended to incorporate additional constraints beyond class numbers?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "6HwamHLDa6",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a Multi‑In‑Single‑Out (MISO) architecture for video frame interpolation, using a shared network to predict multiple future frames from a single input. It extends perceptual loss to 3D to capture temporal dynamics, achieving significant improvements on Vimeo‑90K, Middlebury, and UCF101. The method shows strong performance and robustness across diverse datasets, though it may face scalability and overfitting challenges.",
      "strengths": [
        "Introduces a novel MISO architecture that predicts multiple future frames from a single input, improving temporal coherence.",
        "Extends perceptual loss to 3D to effectively capture both spatial and temporal features, leading to more realistic interpolation results.",
        "Demonstrates strong performance across diverse datasets, including challenging scenarios with occlusions and varying motion patterns."
      ],
      "weaknesses": [
        "The multi‑output model may increase computational complexity and training time, potentially limiting scalability.",
        "There is a risk of overfitting due to multiple outputs, especially if the training dataset is not sufficiently large or diverse.",
        "Specific edge cases, such as extreme occlusions or rapid frame changes, may still pose challenges."
      ],
      "questions": [
        "How does the model handle extremely long video sequences with limited memory resources?",
        "Could the temporal embedding be further improved by incorporating additional temporal cues, such as optical flow?",
        "What are the implications of using a fixed batch size and learning rate across different datasets?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6hzNVNSz8O",
    "title": "No learning rates needed: Introducing SALSA",
    "std_review": {
      "summary": "The paper introduces SaLSa, a novel learning‑rate scheduling method that integrates a line‑search mechanism with a smoothed Armijo condition to adaptively adjust learning rates during training. SaLSa aims to enhance convergence stability and performance across various tasks, including image classification on ImageNet and natural language processing tasks. Experimental results demonstrate competitive or superior performance compared to traditional learning‑rate schedules and baseline optimizers, highlighting SaLSa's robustness and efficiency. The reviewer finds the method promising and recommends acceptance.",
      "strengths": [
        "Innovative learning‑rate scheduling combining line‑search with smoothed Armijo conditions.",
        "Strong theoretical foundation ensuring convergence guarantees.",
        "Competitive or superior empirical performance across multiple datasets and model architectures.",
        "Simplifies learning‑rate tuning by reducing the need for extensive manual adjustments."
      ],
      "weaknesses": [
        "Lack of comprehensive ablation study on hyperparameter sensitivity.",
        "Baseline comparisons may underestimate SaLSa's performance due to suboptimal flat schedules.",
        "Additional computational overhead from line‑search steps could impact scalability.",
        "Reproducibility concerns due to unspecified training details."
      ],
      "questions": [
        "Conduct a detailed ablation study to quantify hyperparameter sensitivity.",
        "Compare SaLSa against more sophisticated learning‑rate schedules like cosine decay.",
        "Validate reproducibility of training details, including data augmentation and batch size.",
        "Provide quantitative evidence of SaLSa's robustness to mini‑batch noise.",
        "Explore evaluation on larger models and more demanding pretraining regimes."
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6I7UsvlDPj",
    "title": "LAMPP: Language Models as Probabilistic Priors for Perception and Action",
    "std_review": {
      "summary": "The paper introduces LaMPP, a framework that integrates large language models with multimodal data for tasks like semantic segmentation and video action recognition. It shows significant performance improvements over traditional models, highlighting the potential of multimodal prompting with LLMs. While the approach is innovative and flexible, it faces challenges in implementation complexity and scalability, and could benefit from deeper analysis of its prompting mechanism.",
      "strengths": [
        "Innovative multimodal prompting with LLMs",
        "Significant performance improvements over baselines",
        "Versatile approach applicable across various tasks",
        "Clear methodology and experimental setup"
      ],
      "weaknesses": [
        "Complexity of integrating LLMs with multimodal data",
        "Scalability concerns for larger datasets",
        "Lack of detailed analysis on model behavior",
        "Benchmarking limited to specific tasks"
      ],
      "questions": [
        "How does the prompting mechanism affect model interpretability and robustness?",
        "What are the scalability strategies for applying LaMPP to larger datasets?",
        "Can the model's performance be generalized to more abstract or less structured environments?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6IjN7oxjXt",
    "title": "Conserve-Update-Revise to Cure Generalization and Robustness Trade-off in Adversarial Training",
    "std_review": {
      "summary": "The paper introduces CURE, a novel adversarial training method that balances standard and robust generalization by selectively conserving, updating, and revising weights based on a gradient prominence criterion. CURE shows improved performance on natural and robust accuracy across various datasets compared to baselines, but its effectiveness may be dataset-dependent, and further analysis of computational complexity and robustness against diverse adversarial attacks is needed.",
      "strengths": [
        "Introduces a novel gradient prominence criterion for selective weight management in adversarial training.",
        "Demonstrates improved performance in both natural and robust accuracy compared to existing methods.",
        "Provides a clear theoretical framework for understanding the trade-off between standard and robust generalization.",
        "Offers a practical solution to the problem of robust overfitting, maintaining a balance between natural and adversarial generalization."
      ],
      "weaknesses": [
        "Effectiveness may be dataset-dependent, as shown in some experimental results.",
        "Performance on more complex datasets or real-world applications has not been thoroughly explored.",
        "Lacks detailed analysis of the computational complexity and scalability of the CURE method.",
        "Robustness against various types of adversarial attacks is not comprehensively evaluated."
      ],
      "questions": [
        "How does CURE perform on more complex datasets or real-world applications?",
        "What is the computational complexity and scalability of the CURE method?",
        "How robust is CURE against various types of adversarial attacks?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6INCxtPVXd",
    "title": "Mode-Aware Continual Learning for Conditional Generative Adversarial Networks",
    "std_review": {
      "summary": "The paper presents a novel continual learning approach for conditional GANs called Discriminator-based Mode Affinity Score (dMAS), which mitigates catastrophic forgetting by measuring similarity between target and source classes using a discriminator. Empirical results on MiniImagenet, Omniglot, and CIFAR-10 datasets show effectiveness compared to baselines. While innovative, the method's reliance on labeled data and lack of theoretical justification are notable limitations.",
      "strengths": [
        "Introduces a novel approach to continual learning for cGANs, addressing catastrophic forgetting.",
        "Proposes a Discriminator-based Mode Affinity Score (dMAS) to measure similarity between target and source classes.",
        "Incorporates a replay mechanism to store and reuse information from previous tasks, enhancing learning of new tasks without forgetting.",
        "Empirical results demonstrate effectiveness compared to existing baselines."
      ],
      "weaknesses": [
        "Limited applicability to unsupervised learning settings due to reliance on labeled source classes.",
        "Effectiveness in preventing catastrophic forgetting is not theoretically justified, relying primarily on empirical results.",
        "Choice of datasets may not fully capture current trends in generative model and continual learning research.",
        "Performance on unsupervised learning tasks is not evaluated, limiting generalizability."
      ],
      "questions": [
        "How does the method perform in unsupervised learning settings where labeled source classes are unavailable?",
        "What is the theoretical justification for the effectiveness of the proposed approach in preventing catastrophic forgetting?",
        "How does the choice of datasets impact the generalizability of the proposed method to other domains or tasks?",
        "Can the replay mechanism be adapted or extended to handle scenarios with limited storage capacity?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6iwg437CZs",
    "title": "STanHop: Sparse Tandem Hopfield Model for Memory-Enhanced Time Series Prediction",
    "std_review": {
      "summary": "The paper introduces STanHop-Net, a neural network that combines sparse Hopfield networks with alpha-entropy regularization to improve memory recall in multivariate correlated environments. The authors demonstrate that STanHop-Net outperforms existing methods like DLinear, achieving better sparsity, stability, and recall accuracy. While the innovative regularization technique and improved performance are strengths, the complexity of implementation, potential for overfitting, and lack of detailed complexity analysis are noted weaknesses. Overall, the paper is recommended for acceptance.",
      "strengths": [
        "Innovative use of alpha-entropy regularization for maintaining sparsity.",
        "Improved sparsity and stability enhance recall accuracy and computational efficiency.",
        "Demonstrated superior performance in environments with multivariate correlations compared to traditional methods."
      ],
      "weaknesses": [
        "Complexity of implementing alpha-entropy regularization may hinder adoption.",
        "Potential for overfitting due to high sparsity, especially with limited training data.",
        "Lack of comprehensive analysis on time complexity and parameter count."
      ],
      "questions": [
        "How does the model perform on datasets with varying levels of noise and sparsity?",
        "What specific strategies can be employed to mitigate overfitting in scenarios with limited data?",
        "Could a detailed analysis of time complexity and parameter count be provided to better understand computational demands?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6J3ehSUrMU",
    "title": "Principled Federated Domain Adaptation:",
    "std_review": {
      "summary": "The paper proposes two federated learning aggregation schemes, FedDA and FedGP, with auto‑weighting variants that dynamically adjust client influence based on domain similarity. Experiments show improved performance across varying target data levels and domain shift magnitudes, with FedDA_Auto demonstrating robustness. Theoretical guarantees and scalability considerations are discussed, but implementation complexity and limited benchmark datasets are noted as weaknesses.",
      "strengths": [
        "Innovative aggregation schemes that balance source domain knowledge with target domain adaptation.",
        "Auto‑weighting mechanism provides a practical solution for dynamic client influence adjustment.",
        "Theoretical guarantees and comprehensive experimental evaluation across different data and shift scenarios."
      ],
      "weaknesses": [
        "Potential computational overhead from the auto‑weighting mechanism.",
        "Experiments rely on synthetic datasets, limiting real‑world generalizability.",
        "Absence of extensive baseline comparisons could weaken the claim of superiority."
      ],
      "questions": [
        "How does the auto‑weighting mechanism perform in highly imbalanced client distributions?",
        "What are the theoretical limits of the noise reduction and domain‑shift robustness guarantees?",
        "How can the framework be adapted for non‑IID data across multiple target clients?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6jBNQ8nSxA",
    "title": "Just-in-Time Security Patch Detection - LLM At the Rescue for Data Augmentation",
    "std_review": {
      "summary": "The paper introduces LLMDA, a method that uses large language models to generate textual explanations for software security patches, enhancing interpretability and trustworthiness. Experiments on PatchDB and SPI-DB show LLMDA outperforms baselines like GraphSPD in predicting patch effectiveness. While innovative, the paper lacks detailed model configurations, thorough ablation studies, and comprehensive ethical considerations, leading to concerns about reproducibility and generalizability.",
      "strengths": [
        "Innovative integration of LLMs to generate contextual textual information for source code.",
        "Effective use of hierarchical attention mechanisms to integrate multi-modal inputs.",
        "Empirical validation on real-world datasets demonstrating improved performance."
      ],
      "weaknesses": [
        "Lack of detailed model configuration details hindering reproducibility.",
        "Potential overfitting to textual explanations limiting generalizability.",
        "Unclear data leakage prevention measures.",
        "Insufficient explanation of hierarchical attention mechanisms.",
        "Omission of comparison with recent syntax/structure-based methods.",
        "Ambiguity in defining positive and negative pairs for contrastive loss.",
        "Limited exploration of LLMDA's generalizability across software systems.",
        "Absence of detailed ethical considerations regarding model outputs."
      ],
      "questions": [
        "Could you provide detailed configurations of LLMDA and baselines for reproducibility?",
        "What ablation studies were conducted to isolate the impact of textual explanations?",
        "How were data leakage concerns addressed and validated?",
        "Please elaborate on the application of hierarchical attention mechanisms.",
        "How does LLMDA compare with recent syntax/structure-based methods?",
        "Could you clarify the criteria for defining positive and negative pairs in contrastive loss?",
        "What are the limitations of LLMDA's generalizability across different software systems?",
        "What safeguards are in place to ensure unbiased and reliable model outputs?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "6jFjYmahxu",
    "title": "DiffSound: Differentiable Modal Sound Simulation for Inverse Reasoning",
    "std_review": {
      "summary": "DiffSound presents a novel framework that combines physics-based shape recovery with deep learning-driven sound synthesis. By leveraging Signed Distance Functions and tetrahedral mesh reconstruction, it achieves high accuracy in shape recovery with reduced computational overhead compared to traditional methods. The paper demonstrates significant improvements in sound synthesis fidelity and efficiency, supported by rigorous experimental results on a diverse dataset. Overall, the work is well‑received for its innovative approach and strong empirical validation, leading to an acceptance recommendation.",
      "strengths": [
        "Innovative integration of physics-based modeling with deep learning for both shape recovery and sound synthesis.",
        "Efficient shape recovery using Signed Distance Functions and tetrahedral mesh reconstruction, reducing computational overhead.",
        "Comprehensive experimental validation on a diverse dataset, showcasing effectiveness in medical imaging and beyond."
      ],
      "weaknesses": [
        "Complex implementation involving multiple components, such as the hybrid loss function and eigen-decomposition.",
        "Potential scalability issues for very large or complex geometries.",
        "Dependence on high-quality training data may limit real-world applicability.",
        "Limited generalizability due to experiments focused on a specific dataset."
      ],
      "questions": [
        "How can the framework be adapted for real-time applications with very large or complex geometries?",
        "What strategies can be employed to improve the framework's performance when training data is limited or noisy?",
        "How does the framework's performance compare to other state-of-the-art methods in different application domains?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6K81ILDnuv",
    "title": "Learning from Integral Losses in Physics Informed Neural Networks",
    "std_review": {
      "summary": "The paper introduces a delayed target method for solving integro‑differential equations using physics‑informed neural networks, showing strong empirical performance on synthetic benchmarks. While the approach is theoretically justified and offers multiple techniques to improve convergence, its generalization to real‑world problems and comprehensive comparison with existing methods remain underexplored. The reviewer recommends a weak accept.",
      "strengths": [
        "Introduces a novel delayed target mechanism that addresses known issues of naive PINN estimators.",
        "Provides a clear theoretical rationale for why the delayed target reduces bias introduced by variance in naive estimators.",
        "Demonstrates strong empirical performance on synthetic benchmarks, outperforming standard PINN methods."
      ],
      "weaknesses": [
        "Results are based on three synthetic problems; it is unclear if the method generalizes to real-world IDEs.",
        "Lacks quantitative measures such as wall‑time or FLOPs for computational efficiency.",
        "Does not provide guidance on tuning problem‑specific hyper‑parameters like M, γ, or λ.",
        "Theoretical arguments lack formal variance decomposition or detailed assumptions.",
        "Some figures and tables are difficult to interpret, potentially obscuring key results."
      ],
      "questions": [
        "How does the delayed target method perform on real‑world IDEs beyond the three synthetic benchmarks?",
        "What are the optimal hyper‑parameter settings for M, γ, and λ in different problem settings?",
        "Can you provide quantitative metrics (e.g., wall‑time, FLOPs) to evaluate computational efficiency?",
        "How robust are the divergence mitigation strategies across diverse problem settings?",
        "What is the theoretical foundation for the bias reduction claim, particularly regarding the assumptions in equations (19) and (20)?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "6LLho5X6xV",
    "title": "UniTabE: A Universal Pretraining Protocol",
    "std_review": {
      "summary": "UniTabE introduces a transformer-based model for tabular data understanding, pre-trained on a large Kaggle dataset and demonstrating strong performance on tasks like table-to-text generation and question answering. While the model shows promise and flexibility across domains, its evaluation is limited to a narrow set of datasets, and the choice of baselines may not fully represent the state-of-the-art. Ethical and legal aspects of using Kaggle data are not addressed, and the handling of complex table structures is not fully detailed. Overall, the paper is a strong contribution with some limitations.",
      "strengths": [
        "Innovative pre-training approach using a large-scale tabular dataset",
        "Strong performance on various tabular understanding tasks",
        "Demonstrated flexibility and generalizability across domains"
      ],
      "weaknesses": [
        "Limited evaluation scope with narrow dataset selection",
        "Baseline selection may not fully represent state-of-the-art",
        "Lack of discussion on ethical and legal considerations of data usage",
        "Insufficient details on handling complex table structures"
      ],
      "questions": [
        "How can the evaluation be expanded to include a broader range of tabular datasets?",
        "Could you clarify the ethical and legal considerations of using Kaggle data for pre-training?",
        "What specific mechanisms in the TabUnit architecture enable handling of complex table structures?",
        "How does the model's performance compare to other state-of-the-art models not included in the current baseline selection?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "6LNTSrJjBe",
    "title": "Language Agent Tree Search Unifies Reasoning Acting and Planning in Language Models",
    "std_review": {
      "summary": "The paper introduces LATS, a framework that integrates search algorithms with large language models to enhance reasoning and decision-making. It demonstrates improved performance on reasoning benchmarks compared to existing prompting techniques. However, it faces limitations in scalability and applicability to complex environments. Overall, the framework is promising with notable technical innovations.",
      "strengths": [
        "Combines search algorithms with LLMs to improve reasoning and decision-making abilities.",
        "Introduces key technical innovations like self-reflection and external feedback.",
        "Shows improved performance on reasoning benchmarks compared to existing methods."
      ],
      "weaknesses": [
        "Limited scalability and applicability to large-scale problems or complex environments.",
        "Potential limitations in handling complex environments or large-scale problems."
      ],
      "questions": [
        "How can LATS be adapted to handle more complex environments beyond current benchmarks?",
        "What further refinements are needed to address scalability and applicability concerns?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6LyO8WTVTU",
    "title": "A Teacher-Guided Framework for Graph Representation Learning",
    "std_review": {
      "summary": "The paper introduces TGCL, a teacher-guided contrastive learning approach for knowledge distillation that outperforms traditional methods on downstream tasks like image classification and NLP. It leverages a well-pretrained teacher to guide a student model, demonstrating robustness to overfitting and versatility across domains. While computationally intensive and sensitive to hyperparameters, TGCL's theoretical foundation and superior performance justify its acceptance.",
      "strengths": [
        "Effective knowledge transfer from a well-pretrained teacher to a student model.",
        "Robustness to overfitting, maintaining high performance even when the teacher model is overfitted.",
        "Strong theoretical basis grounded in contrastive learning principles."
      ],
      "weaknesses": [
        "High computational cost due to contrastive learning component.",
        "Performance sensitivity to hyperparameter choices, particularly those related to contrastive learning.",
        "Dependence on the quality and appropriateness of the teacher model's pretraining."
      ],
      "questions": [
        "How can TGCL be adapted for scenarios with limited high-quality pretraining data?",
        "What are the long-term scalability implications of the contrastive learning component?",
        "Can formal theoretical guarantees be established for TGCL's convergence and generalization?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6mLjDwYte5",
    "title": "Mixture-of-Experts Meets Instruction Tuning: A Winning Combination for Large Language Models",
    "std_review": {
      "summary": "The paper demonstrates that instruction‑tuned mixture‑of‑experts (MoE) models, specifically Flan‑MoE, achieve state‑of‑the‑art results on GLUE, SuperGLUE, and MMLU benchmarks, outperforming dense models. It provides a clear evaluation framework and explores routing strategies, showing that Switch routing yields the best performance. While the work is technically strong and practically relevant, it lacks a broader comparison with other MoE architectures and does not fully address computational cost or long‑term stability.",
      "strengths": [
        "Clear contribution: defines a novel approach to improve MoE models through instruction tuning.",
        "State‑of‑the‑art results on multiple benchmarks, highlighting practical relevance.",
        "Innovative evaluation of routing strategies and expert utilization, offering insights for future research."
      ],
      "weaknesses": [
        "Limited comparison with other MoE models may understate the generality of the benefits.",
        "Computational cost of instruction‑tuned MoE models is not fully addressed.",
        "Absence of long‑term stability analysis could affect real‑world deployment."
      ],
      "questions": [
        "How do the findings generalize to other MoE architectures beyond Flan‑MoE?",
        "What is the computational cost of instruction‑tuned MoE models compared to dense models in practical settings?",
        "How does the paper assess the long‑term stability and generalization of instruction‑tuned MoE models?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6MRm3G4NiU",
    "title": "SaProt: Protein Language Modeling with Structure-aware Vocabulary",
    "std_review": {
      "summary": "The paper introduces SaProt, a protein language model that integrates structural information using Foldseek tokens alongside sequence data, showing improved performance on downstream tasks compared to ESM-2. While innovative, the model's evaluation is limited by the lack of extensive hyperparameter tuning, dataset consistency, and ablation studies, which could deepen insights into its effectiveness. Overall, SaProt demonstrates promise but requires further refinement to fully validate its approach.",
      "strengths": [
        "Innovative integration of structural information using Foldseek tokens.",
        "Strong pre-training strategy on a large protein dataset.",
        "Comprehensive evaluation across multiple downstream tasks."
      ],
      "weaknesses": [
        "Limited exploration of Foldseek hyperparameters.",
        "Dataset inconsistency between pre-training and model evaluation.",
        "Absence of ablation experiments to isolate structural contributions.",
        "Comparison with other models is not exhaustive."
      ],
      "questions": [
        "How do different Foldseek hyperparameters affect model performance?",
        "What impact does dataset consistency have on model generalizability?",
        "Could alternative structural representations improve results?",
        "How does SaProt compare to other recent structure-aware models like MSA Transformer or GearNet?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "6N8TW504aa",
    "title": "Graphical Multioutput Gaussian Process with Attention",
    "std_review": {
      "summary": "The paper introduces GMOGP, an extension of MOGP that uses asymmetric attention coefficients to model dependencies between multiple outputs, handling unbalanced datasets effectively. While demonstrating strong empirical results on synthetic and real-world datasets, the model's increased computational complexity and scalability concerns limit its broad applicability. The reviewer finds the theoretical foundation solid and the empirical validation convincing, but recommends further research to address scalability and initialization issues.",
      "strengths": [
        "Introduces asymmetric attention coefficients to model directional dependencies between outputs.",
        "Effectively handles datasets with unbalanced numbers of observations per output.",
        "Provides a solid theoretical foundation with detailed derivations and proofs."
      ],
      "weaknesses": [
        "Increased computational complexity due to asymmetric attention coefficients.",
        "Lack of comprehensive guidelines for initializing model weights, especially in unbalanced data scenarios.",
        "Scalability concerns for large datasets or high numbers of outputs."
      ],
      "questions": [
        "How can the computational complexity of GMOGP be further reduced for large-scale applications?",
        "What initialization strategies can be employed to improve model convergence and performance in unbalanced data scenarios?",
        "What are the specific scalability challenges when applying GMOGP to real-world datasets with a large number of outputs?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "6NEJ0ReNzr",
    "title": "",
    "std_review": {
      "summary": "The paper proposes a novel blueprint generation approach to improve summary attribution quality by structuring the summarization process with a sequence of questions. While innovative, the method lacks direct comparisons isolating blueprint generation from document retrieval and does not fully detail human evaluation metrics or ablation studies. These omissions reduce the overall impact despite promising results.",
      "strengths": [
        "Introduces a novel blueprint generation process for structured summarization.",
        "Demonstrates improved attribution quality through quantitative and qualitative evaluations.",
        "Compares against multiple baselines, showing robustness of the approach."
      ],
      "weaknesses": [
        "Lacks a direct apples-to-apples comparison by not evaluating models without the retriever component.",
        "Human evaluation details are insufficient, lacking dataset, annotator qualifications, and inter‑annotator agreement.",
        "Ablation studies are missing, hindering understanding of the model's robustness and necessity.",
        "Training mechanisms and copy supervision details for extractive and abstractive models are not fully clarified."
      ],
      "questions": [
        "Could a direct apples-to-apples comparison be provided by evaluating models without the retriever component?",
        "What dataset and annotator qualifications were used in the human attribution evaluation?",
        "Please present ablation studies to assess the importance of the attribution step versus blueprint generation.",
        "Could additional details on training mechanisms and copy supervision for the models be provided?"
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "6NO5UVWvo6",
    "title": "",
    "std_review": {
      "summary": "The paper introduces PSCV, a point‑supervised contrastive variance loss for medical image segmentation that uses random point annotations to guide the model. It combines partial cross‑entropy loss with a contrastive variance loss using variance distribution maps, achieving competitive performance on the Synapse dataset. While innovative, the method has some limitations, such as a lack of clear theoretical justification and reliance on random annotations, which could affect reproducibility and generalization. Overall, the paper makes a valuable contribution with strong potential for weakly supervised segmentation.",
      "strengths": [
        "Introduces a novel contrastive variance loss that leverages variance distribution maps to enhance segmentation quality.",
        "Utilizes random point annotations, reducing annotation effort while maintaining strong performance.",
        "Demonstrates competitive results on the Synapse dataset, comparable to fully supervised methods.",
        "Provides a solid theoretical foundation for using variance distribution maps as a contrastive feature."
      ],
      "weaknesses": [
        "Lacks a fully elaborated theoretical justification for the contrastive variance loss.",
        "Relies on random point annotations, which may introduce variability and affect reproducibility.",
        "Evaluation is limited to the Synapse dataset, potentially limiting the method's generalizability.",
        "Dependence on random annotations could impact model performance and generalization."
      ],
      "questions": [
        "How can the theoretical justification for the contrastive variance loss be further elaborated?",
        "What impact does the choice of random point locations have on convergence and final performance?",
        "Could the method be evaluated on additional medical imaging datasets to assess its generalizability?",
        "What strategies could be employed to improve robustness to noisy or poorly chosen annotations?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6O3Q6AFUTu",
    "title": "",
    "std_review": {
      "summary": "The paper presents a novel approach to image editing by combining stochastic differential equations (SDEs) with diffusion models, aiming to improve interpolation quality. It introduces a boundary control mechanism to prevent artifacts, outperforming existing methods on several datasets. While the method shows promise, concerns about computational cost, hyperparameter selection, and limited evaluation scope remain.",
      "strengths": [
        "Integrates SDEs with diffusion models for effective image editing.",
        "Introduces a boundary control method to reduce artifacts.",
        "Demonstrates improved interpolation quality on multiple datasets."
      ],
      "weaknesses": [
        "High computational cost for real-time or large-scale applications.",
        "Lack of detailed hyperparameter selection strategy.",
        "Limited evaluation across diverse datasets and image types.",
        "Insufficient theoretical justification for the boundary control method."
      ],
      "questions": [
        "Could you provide more detailed guidance on selecting hyperparameters for practical use?",
        "What optimizations can be applied to reduce the computational overhead of latent space mapping?",
        "How can the method's generalization be evaluated across more datasets and image styles?",
        "Please elaborate on the theoretical basis for the boundary control mechanism."
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "6okaSfANzh",
    "title": "Large Language Model Cascades with Mixture of Thought Representations for Cost-Efficient Reasoning",
    "std_review": {
      "summary": "The paper introduces MoT-2D, a two-prompt verification framework that combines a chain-of-thought (CoT) prompt with a prompt-only (PoT) prompt to verify language model outputs. It shows strong empirical improvements on reasoning tasks, providing a quantitative consistency measure and demonstrating scalability to stronger models. While innovative, the framework's temperature sensitivity and reliance on a less capable verifier limit its general applicability. Overall, the work is well-executed and makes a valuable contribution.",
      "strengths": [
        "Introduces a novel two-prompt mechanism (CoT + PoT) that leverages both structured reasoning and raw output, potentially reducing hallucinations.",
        "Demonstrates scalability to stronger models without extensive fine-tuning.",
        "Provides a clear, reproducible method for assessing answer consistency.",
        "Empirical validation across a variety of reasoning tasks highlights its robustness."
      ],
      "weaknesses": [
        "Performance is highly sensitive to temperature settings, with the best results achieved at 0.8, limiting general applicability.",
        "External verification using GPT-3.5 yields poor performance, suggesting the verifier may not reliably distinguish correct from incorrect answers.",
        "Risk of over-confidence in the weaker LLM could lead to incorrect routing decisions.",
        "Lack of exploration of higher temperature settings for the CoT prompt could miss optimal configurations."
      ],
      "questions": [
        "How does the framework perform under different temperature settings beyond 0.8?",
        "What are the specific failure modes when the weaker LLM is overly confident in incorrect answers?",
        "Could exploring higher temperature settings for the CoT prompt improve performance or consistency?",
        "How does the framework handle tasks that require specialized knowledge where the weaker LLM might be insufficient?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6p8lpe4MNf",
    "title": "A Semantic Invariant Robust Watermark",
    "std_review": {
      "summary": "The paper introduces a watermarking technique for LLM-generated text that embeds imperceptible markers using green tokens and controlled prompt engineering. It demonstrates robust detection across multiple models and supports multi-key watermarking for enhanced security. While the method shows promise, it has limitations such as prompt dependency and limited analysis of parameter sensitivity, which could affect its practical deployment.",
      "strengths": [
        "Innovative detection mechanism that remains effective even when the original prompt is hidden.",
        "Demonstrated robust performance across various LLMs, indicating broad applicability.",
        "Supports multi-key watermarking, enhancing security and privacy for personalized detection."
      ],
      "weaknesses": [
        "Effectiveness is contingent on having access to the original prompt, which may limit use in fully anonymized applications.",
        "Lack of comprehensive analysis on optimal values for parameters δ and γ, impacting detection performance.",
        "Limited discussion on handling sophisticated attacks, such as prefix injection or shared text attacks.",
        "Potential scalability issues due to computational and storage requirements for large-scale deployments."
      ],
      "questions": [
        "How can the method be adapted for fully anonymized applications where the original prompt is not available?",
        "What is the optimal range of δ and γ values for balancing detectability and text quality?",
        "What mitigation strategies can be employed to improve detection against shared text attacks?",
        "How does the method scale to large‑scale deployments, and what are the computational/storage trade‑offs?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6PbvbLyqT6",
    "title": "Dynamic Discounted",
    "std_review": {
      "summary": "The paper introduces DDCFR, a novel approach that combines CFR with deep learning and incorporates a discount factor to improve convergence and scalability. Empirical evaluations show that DDCFR outperforms traditional CFR and Deep CFR, especially in larger games, and offers theoretical insights into discounting's impact on CFR. While the paper has some theoretical and practical concerns, its innovative approach and robust performance justify acceptance.",
      "strengths": [
        "Innovative integration of discounting into CFR",
        "Demonstrated scalability to larger games compared to traditional CFR and Deep CFR",
        "Consistently high solution quality across various game sizes and player counts"
      ],
      "weaknesses": [
        "Does not rigorously address the boundedness of the discount factor τ",
        "Lacks exploration of alternative optimization strategies for hyperparameters",
        "Limited comparison with more recent and advanced methods",
        "Scalability to extremely large games is not conclusively demonstrated"
      ],
      "questions": [
        "How can the boundedness of the discount factor τ be rigorously addressed to ensure stability?",
        "What alternative optimization strategies, such as bandit-based approaches, could be explored for tuning discount rates?",
        "How does DDCFR compare to more recent and advanced methods in the field?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6PjS5RnxeK",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a novel theoretical framework linking the Jacobian norm of neural network outputs to a notion of 'progressive sharpening' during training. It presents two key theorems that relate model capacity to generalization and provide a generalization bound sensitive to data dimensionality. Empirical experiments support the hypothesis that higher Jacobian norms correlate with improved model sharpness and generalization, suggesting Jacobian regularization as a practical approach. While the theoretical claims are strong, some aspects lack formal precision and the empirical generalization of the bounds is limited by data dimensionality.",
      "strengths": [
        "Novel theoretical contribution linking Jacobian norms to model generalization.",
        "Clear empirical validation showing correlation between Jacobian norms and model sharpness.",
        "Practical implications for practitioners with actionable insights on Jacobian regularization."
      ],
      "weaknesses": [
        "Formal mathematical precision is lacking in some theoretical claims.",
        "Empirical generalization of the bounds is highly sensitive to intrinsic data dimensionality.",
        "Causal link between Jacobian norms and sharpening is not fully established."
      ],
      "questions": [
        "How can the formalization of Ansatz 3.1 be improved to enhance its theoretical rigor?",
        "What additional empirical studies are needed to validate the generalization bounds across diverse datasets?",
        "How can practitioners effectively monitor and balance Jacobian norm increases to avoid over-regularization?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6PmJoRfdaK",
    "title": "LongLoRA: Efficient Fine-tuning of LongContext Large Language Models",
    "std_review": {
      "summary": "LongLoRA introduces an efficient fine-tuning method for long-context LLMs using a novel S²-Attention mechanism that reduces computational costs while preserving performance. The method shows strong efficiency gains on a 32K-token retrieval benchmark, achieving results comparable to full fine-tuning with far fewer parameter updates and training time. However, the evaluation is limited to retrieval tasks, and the generalizability of the proposed 25% group size heuristic beyond 8192 tokens remains unproven. Theoretical justifications and some methodological details are provided, but clarity on FLOP estimation and memory usage could be improved.",
      "strengths": [
        "Introduces a novel S²-Attention mechanism that maintains long-context performance while significantly cutting computational costs.",
        "Demonstrates substantial efficiency gains on long-context fine-tuning, making the approach more practical.",
        "Provides a clear theoretical foundation and ablations comparing to full fine-tuning and from-scratch training on long contexts."
      ],
      "weaknesses": [
        "Evaluation is limited to retrieval tasks, limiting the claim of general applicability to other generative tasks.",
        "The 25% group size heuristic is validated only up to 8192 tokens, leaving its effectiveness for longer contexts unclear.",
        "Lack of detailed methodology for FLOP estimation and memory usage analysis.",
        "No systematic hyper-parameter sensitivity analysis, which could impact practical deployment.",
        "Training speed claim lacks concrete benchmarks or ablations."
      ],
      "questions": [
        "How does LongLoRA perform on broader generative tasks beyond retrieval, such as document QA or summarization?",
        "What is the exact formula or methodology for estimating FLOPs in Table 10, and how does it scale for contexts longer than 8192 tokens?",
        "What is the impact of freezing or unfreezing embedding and normalization layers on model performance, and how does it compare to other adaptations?",
        "How does the 25% group size heuristic generalize to contexts longer than 8192 tokens, and what is the optimal group size for even longer sequences?",
        "What are the concrete benchmarks or ablations that support the reported 2.1× speedup achieved by S²-Attention?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "6pPYRXKPpw",
    "title": "Towards Diverse Behaviors: A Benchmark for Imitation Learning with Human Demonstrations",
    "std_review": {
      "summary": "The paper introduces a novel framework that integrates diffusion models with reinforcement learning to enhance sample efficiency and policy stability. It demonstrates significant improvements on benchmark tasks, offering a fresh perspective on policy learning. While the approach is theoretically sound and empirically validated, its complexity and limited evaluation scope raise some concerns about practical implementation and generalizability.",
      "strengths": [
        "Introduces a novel integration of diffusion models with reinforcement learning, offering a fresh perspective on policy learning.",
        "Demonstrates improved sample efficiency and policy stability, which are critical challenges in RL.",
        "Provides a comprehensive evaluation across multiple benchmark tasks, showcasing the method's broad applicability."
      ],
      "weaknesses": [
        "The complexity of the proposed framework may make it challenging for practitioners to implement and fine-tune.",
        "The evaluation is limited to a few benchmark tasks, which may not fully capture the method's potential across all domains.",
        "The paper lacks a detailed discussion on the computational costs associated with training diffusion policies, which could be a significant concern for large-scale applications."
      ],
      "questions": [
        "The action space used by the environments is not explicitly detailed in the paper. Further clarification on the specific action spaces used in their experiments would strengthen the paper.",
        "The argument against providing additional context to the policy on how to perform the task is rooted in the principle of maximizing the policy's autonomy and generalizability. Further exploration of this trade-off could be valuable."
      ],
      "overall_score": "6: weak accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6PVgHZUepm",
    "title": "Rep-Adapter: Parameter-free Automatic Adaptation of Pre-trained ConvNets via Parameterization",
    "std_review": {
      "summary": "Rep-Adapter presents a parameter‑free fine‑tuning technique for convolutional neural networks by introducing learnable scaling factors for each filter branch. It dynamically adjusts the learning rate of each filter during training, achieving comparable or better performance with significantly reduced computational cost. The method is simple, efficient, and versatile, working well across multiple vision tasks and datasets. Overall, the paper makes a valuable contribution to efficient model adaptation.",
      "strengths": [
        "Parameter‑free adaptation: Achieves fine‑tuning without adding extra parameters, preserving the efficiency of pre‑trained models.",
        "Dynamic learning rate scaling: Learnable scaling factors (ωR) allow each filter to adapt its learning rate, potentially improving convergence and performance.",
        "Two‑branch architecture: Simplifies the design by using a single shared backbone with two distinct branches, facilitating straightforward implementation.",
        "Batch‑normalization integration: Utilizes batch‑normalization to stabilize scaling factor computation, enhancing training stability.",
        "Versatility: Demonstrates effectiveness across multiple vision tasks and datasets, indicating broad applicability."
      ],
      "weaknesses": [
        "Complexity in scaling factor computation: The computation of scaling factors may introduce additional computational overhead during training.",
        "Potential over‑fitting risk: With more adaptive parameters, there is a risk of over‑fitting, especially on small datasets.",
        "Limited to convolutional layers: Current implementation focuses on convolutional architectures, with limited exploration of other architectures like transformers.",
        "Hyperparameter sensitivity: Performance may be sensitive to the choice of scaling factor initialization and learning rate schedules."
      ],
      "questions": [
        "How does the method generalize to other model architectures beyond convolutional networks, such as transformers?",
        "What are the long‑term computational benefits of using learnable scaling factors compared to other parameter‑efficient fine‑tuning techniques?",
        "Can the scaling factor computation be further optimized to reduce computational overhead during training?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6qtDu7hVPF",
    "title": "Generative Reinforcement Learning",
    "std_review": {
      "summary": "The paper proposes a generative approach to model state distributions in reinforcement learning by conditioning a pre-trained transformer on both returns and actions, aiming to improve training efficiency and sample usage. Experiments on Atari games show faster convergence and competitive performance compared to a discriminative baseline, though the Elo gap remains modest. While the method is innovative and theoretically sound, concerns about limited policy comparisons, modest performance gains, environment‑dependent impact, and unclear implementation details prevent a stronger endorsement.",
      "strengths": [
        "Innovative generative state modeling that conditions on both returns and actions.",
        "Demonstrated substantial reduction in training time and board evaluations.",
        "Strong theoretical foundation with clear decomposition of value functions."
      ],
      "weaknesses": [
        "Primary comparison is with a behavioral cloning baseline rather than a true policy‑based method.",
        "Modest Elo gap suggests benefits may plateau with larger models.",
        "Uniform return model's impact appears environment‑dependent.",
        "Lack of detailed implementation details may hinder reproducibility."
      ],
      "questions": [
        "Should future work compare the generative approach with policy‑based methods like the decision transformer?",
        "How does the method's performance scale with larger models, and does the Elo gap diminish?",
        "What are the specific details of return‑action conditioning beyond concatenation?"
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "6r0BOIb771",
    "title": "Sequential Bayesian Continual Learning with Meta-Learned Neural Networks",
    "std_review": {
      "summary": "The paper introduces SB‑MCL, a continual learning framework that uses exponential family posteriors to constrain model capacity and prevent catastrophic forgetting. Empirical results show it outperforms baselines on several datasets, demonstrating its effectiveness. The approach balances simplicity and efficiency with strong theoretical guarantees, making it a valuable contribution to continual learning.",
      "strengths": [
        "Theoretical Foundation: Uses exponential family posteriors to constrain model capacity in a principled way.",
        "Empirical Performance: Outperforms baselines on benchmark continual learning datasets.",
        "Simplicity and Efficiency: Relies on Gaussian distributions for computational simplicity and practicality."
      ],
      "weaknesses": [
        "Limited Representational Power: The simplicity of the exponential family posterior may restrict capturing complex task relationships.",
        "Assumption of Gaussian Distributions: Gaussian distributions may not always be suitable for all data or tasks.",
        "Empirical Validation: Could benefit from more extensive ablation studies or broader baseline comparisons.",
        "Scalability: Effectiveness in very large-scale scenarios has not been explored."
      ],
      "questions": [
        "How does SB‑MCL perform in very large-scale continual learning scenarios?",
        "What are the theoretical guarantees when using non-Gaussian exponential family distributions?",
        "Could the framework be extended to handle multimodal or highly complex data distributions?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6rEcB9m9AI",
    "title": "Promoting Exploration in Memory-Augmented Adam using Critical Momenta",
    "std_review": {
      "summary": "The paper introduces Critical Momentum (CM), a modification to the Adam optimizer that uses a gradient buffer to prioritize large gradients, aiming to drive the optimizer towards flat minima for better generalization. Empirical results on several datasets show that Adam+CM outperforms standard Adam and SGD variants, supporting the idea that flat minima may correspond to better generalization. While innovative and empirically promising, the paper lacks some theoretical rigor and a direct comparison with SGD, and it does not fully explore hyperparameter sensitivity and learning rate robustness.",
      "strengths": [
        "Introduces a novel optimization technique with a compelling empirical impact.",
        "Provides strong empirical evidence across multiple datasets.",
        "Offers a theoretical argument linking flat minima to better generalization."
      ],
      "weaknesses": [
        "Lacks a direct comparison with SGD to evaluate the generality of the CM technique.",
        "Does not thoroughly investigate the impact of the hyperparameter controlling buffer size.",
        "Does not adequately assess learning rate sensitivity of the results."
      ],
      "questions": [
        "How does CM compare to SGD (or SGD+SAM) across different datasets?",
        "What is the optimal value of the buffer size hyperparameter C for various problems?",
        "How robust are the findings to variations in learning rate?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "6RR3wU4mSZ",
    "title": "IceFormer: Accelerated Inference with Long-Sequence Transformers on CPUs",
    "std_review": {
      "summary": "IceFormer introduces a novel Prioritized DCI algorithm for accelerating k‑NNS on CPUs, achieving significant speed improvements while maintaining acceptable accuracy. The method offers flexibility in key selection and broad applicability across datasets, though its performance is primarily evaluated on CPUs. While promising, the paper acknowledges limitations such as hardware dependency, parameter sensitivity, and limited scalability evaluation, suggesting future work to address these issues.",
      "strengths": [
        "Introduces a novel Prioritized DCI algorithm tailored for k‑NNS, offering a fresh perspective on reducing computational overhead.",
        "Demonstrates substantial speed improvements over existing methods, making it a practical solution for resource-constrained environments.",
        "Provides a systematic way to choose the top‑k keys, allowing for trade‑offs between speed and accuracy based on specific application needs.",
        "The method is applicable to a wide range of datasets and can be integrated into existing systems with relative ease."
      ],
      "weaknesses": [
        "Performance gains are primarily observed on CPUs, with limited evaluation on other hardware types like GPUs or TPUs.",
        "The choice of k significantly impacts the method's performance, and there is a lack of comprehensive guidance for selecting an optimal k in practice.",
        "Scalability concerns arise as the method's promise for small to medium datasets remains unverified for very large datasets.",
        "Experimental results are based on a limited set of datasets, which may not fully represent the method's capabilities across all possible use cases."
      ],
      "questions": [
        "How can the method be adapted for other hardware types, such as GPUs or TPUs, to leverage parallel processing capabilities?",
        "What framework or heuristic can be developed to provide more robust guidance for selecting an optimal k value?",
        "What are the scalability implications of the method for very large datasets, and how can they be addressed?",
        "How can the method be integrated with other machine learning models, such as deep learning architectures, to enhance its applicability in real-world scenarios?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6sfRRcynDy",
    "title": "Out-of-Distribution Detection With Hyperspherical Energy",
    "std_review": {
      "summary": "The paper introduces a novel out‑of‑distribution (OOD) detection method using a hyperspherical energy model, achieving competitive performance on standard benchmarks. While innovative and theoretically grounded, the method shows limitations in generalization, robustness, and parameter sensitivity, particularly on diverse datasets like Places 365. The reviewer recommends cautious acceptance, suggesting further exploration of theoretical boundaries and practical robustness.",
      "strengths": [
        "Innovative Hyperspherical Energy Framework: The use of a hyperspherical embedding to interpret model outputs as a Helmholtz free energy score provides a novel and theoretically grounded approach to OOD detection.",
        "Efficient Training Strategy: By fine‑tuning only the last residual blocks of a pre‑trained ResNet, the method balances computational efficiency with the ability to capture task‑specific OOD cues.",
        "Strong Performance on Standard Benchmarks: Achieving an average FPR95 of 38.55 % on CIFAR‑100 and comparable results on other datasets demonstrates robustness and effectiveness."
      ],
      "weaknesses": [
        "High False Positive Rate on Places 365: The method exhibits a notably high FPR95 on the Places 365 dataset, which may indicate limitations in handling diverse real‑world scenes.",
        "Limited Generalization Beyond Image Classification: Experiments are confined to image classification tasks, raising questions about the method's applicability to other domains such as natural language processing or time‑series analysis.",
        "Parameter Sensitivity: The temperature parameter, crucial for the Helmholtz free energy score, is not thoroughly analyzed, potentially affecting model performance and interpretability."
      ],
      "questions": [
        "How does the method perform under image corruptions, and what are the implications for real‑world deployment?",
        "What is the theoretical expressiveness of the Helmholtz free energy approach compared to more general energy‑based models?",
        "How can the method be extended to non‑image domains, and what additional experiments are needed to evaluate its scalability?",
        "What is the optimal range for the temperature parameter, and how does it affect model interpretability and performance?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "6SNyuiph3F",
    "title": "Chat Vector: A Simple Approach to Equip LLMs With New Language Chat Capabilities",
    "std_review": {
      "summary": "The paper introduces Chat Vector, a novel method for equipping large language models (LLMs) with chat capabilities by using a chat vector as a parameter shift. This approach improves instruction following and safety without extensive fine-tuning, showing strong empirical results across multiple languages and architectures. While promising, the method's scalability and computational implications remain unexplored, and further comparative analysis is needed.",
      "strengths": [
        "Innovative parameter shift approach for chat capabilities",
        "Efficiency gains by reducing fine-tuning requirements",
        "Empirical validation across languages and architectures"
      ],
      "weaknesses": [
        "Limited evaluation scope focusing on instruction-following benchmarks",
        "Potential biases in evaluation using GPT-4",
        "Scalability and computational implications not thoroughly addressed"
      ],
      "questions": [
        "How does the chat vector approach scale to larger or more complex LLMs?",
        "What is the impact of the chat vector on model safety beyond instruction-following benchmarks?",
        "How does the chat vector compare to other methods like RLHF in terms of safety and user interaction?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6ssOs9BBxa",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a pipeline that combines behavior cloning with deep reinforcement learning to enable an agent to adapt to unseen maps in the microRTS domain. It shows improved performance over a baseline DRL agent on various map layouts, leveraging action masking for training stability. While promising, the paper lacks comprehensive evaluation of generalization and scalability, and deeper insights into the imitation learning component are needed.",
      "strengths": [
        "Integrative Approach: Combines imitation learning (behavior cloning) with DRL, leveraging strengths of both paradigms to improve sample efficiency and stability.",
        "Action Masking: Systematically masks actions to prevent catastrophic failures during training, enhancing robustness across different map configurations.",
        "Generalization Evidence: Demonstrates improved performance on unseen maps, indicating effective transfer learning from the training environment."
      ],
      "weaknesses": [
        "Limited Generalization Evidence: Lacks comprehensive experiments to evaluate how performance scales with map complexity or the number of fine‑tuned models.",
        "Insufficient Exploration of Imitation Learning Details: Brief description of behavior cloning without delving into specific reward weighting or policy architecture choices.",
        "Scalability to Larger Games: Focus on microRTS limits discussion on transferring the approach to more complex games like StarCraft II.",
        "Absence of Comprehensive Transfer Learning Evaluation: Does not explore the trade‑off between using a single generalized policy versus multiple fine‑tuned policies for different maps."
      ],
      "questions": [
        "How does the performance of the pipeline scale with increasing map complexity or the number of fine‑tuned models?",
        "What specific reward weighting and policy architecture choices were made in the behavior cloning step, and how do they impact reproducibility and further improvements?",
        "What are the key challenges and adaptations needed to scale the pipeline to larger strategy games like StarCraft II?",
        "How does the trade‑off between using a single generalized policy versus multiple fine‑tuned policies for different maps affect scalability and efficiency?"
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "6tazBqPem3",
    "title": "Capacity Analysis of Vector Symbolic Architectures",
    "std_review": {
      "summary": "The paper introduces a novel approach to dimensionality reduction for Vector Symbolic Architectures (VSAs) by leveraging lower‑rank weight matrices in Hopfield networks. It derives tight bounds on the number of vectors that can be stored and retrieved with minimal error, extending the analysis to Hopfield+ networks. The theoretical contributions are significant and have clear practical implications, though the paper could benefit from more experimental validation and a broader scope.",
      "strengths": [
        "Relevance to VSAs: Directly addresses efficient similarity search and storage by focusing on dimensionality reduction.",
        "Theoretical Rigor: Provides tight bounds for both standard and extended Hopfield networks with clear quantitative guarantees.",
        "Broader Impact: Results extend beyond theory to practical applications in machine learning where efficient similarity search is essential."
      ],
      "weaknesses": [
        "Complexity of Proofs: Mathematical derivations may be challenging for readers without a strong background in linear algebra and information theory.",
        "Limited Experimental Validation: Theoretical contributions are significant but could be strengthened with empirical studies.",
        "Scope of Application: Analysis is primarily focused on binary, sparse, and integer‑bundled vectors, limiting applicability to other VSA variants."
      ],
      "questions": [
        "Could the authors provide empirical studies to validate the practical implications of the derived bounds?",
        "How do the results generalize to other types of VSA variants beyond binary, sparse, and integer‑bundled vectors?",
        "What are the computational trade‑offs of using lower‑rank weight matrices in large‑scale applications?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6tDPefQyvB",
    "title": "Rotation-Equivariance and Position Encodings for Enhancing Local Descriptors",
    "std_review": {
      "summary": "The paper introduces a rotation‑equivariant descriptor that fuses local rotational information with global positional cues, achieving strong performance gains over existing methods while maintaining runtime efficiency. Its integration with both classical and deep‑learning matchers is demonstrated, though the experimental scope is primarily sparse matching. The method shows promise but lacks comprehensive ablation studies and detailed comparisons with dense matching approaches.",
      "strengths": [
        "Innovative multi‑scale feature fusion that combines local rotational equivariance with global positional information.",
        "Seamless integration with both classical (e.g., RANSAC) and deep‑learning based matchers, showcasing versatility.",
        "Significant performance improvements, especially in tasks requiring rotational equivariance, and competitive runtime efficiency."
      ],
      "weaknesses": [
        "Limited ablation study on the specific components of the feature fusion method.",
        "Experimental focus on sparse matching with limited comparison to dense methods like LoFTR.",
        "Insufficient experimental validation of rotation equivariance, particularly under substantial rotations.",
        "Broad benchmark scope that could benefit from a more focused analysis on rotationally equivariant descriptors."
      ],
      "questions": [
        "Could you provide a detailed ablation study on the impact of retaining local rotational equivariance and the smooth integration process?",
        "How does the descriptor interact with different matchers, and what optimizations are applied for each?",
        "What are the performance nuances when compared to dense matching methods such as LoFTR?",
        "Could you expand the experimental validation to include substantial rotation scenarios using benchmarks like RELF?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "6tqgL8VluV",
    "title": "Towards Establishing Guaranteed Error for Learned Database Operations",
    "std_review": {
      "summary": "The paper presents a novel framework for learning database operations that can be queried with worst-case/average-case error guarantees. It proposes a method to train machine learning models for operations like joins and selections while providing formal error bounds. Experimental evaluations on synthetic and real-world datasets show that learned models can match or exceed traditional algorithms in accuracy and efficiency. Despite some limitations in generality and scalability, the work makes a significant contribution by bridging machine learning and database theory.",
      "strengths": [
        "Introduces a novel approach to learning database operations with provable error bounds.",
        "Provides a solid theoretical foundation with clear insights into trade-offs between model complexity, query types, and error guarantees.",
        "Demonstrates practical viability and potential benefits of learned models over traditional algorithms through experimental evaluations."
      ],
      "weaknesses": [
        "Experimental evaluation is limited to a small set of query types and data distributions.",
        "Theoretical bounds are derived under specific assumptions about data distribution and query types.",
        "Lacks a comprehensive comparison with existing state-of-the-art learned models or traditional algorithms.",
        "Scalability to large-scale databases and complex operations remains an open question."
      ],
      "questions": [
        "How do the learned models perform on a broader range of query types and data distributions?",
        "What is the impact of relaxing the assumptions on data distribution and query types on the theoretical bounds?",
        "How do the learned models scale to large-scale databases and complex query operations?",
        "Can the theoretical bounds be tightened or made more practical for real-world deployment?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6u6GjS0vKZ",
    "title": "Coloring Deep CNN Layers with Activation Hue Loss",
    "std_review": {
      "summary": "The paper proposes an 'activation hue loss' that guides neural network activations towards a hue‑like representation during training, applied alongside standard cross‑entropy loss. Experiments on ImageNet, DTD, and other datasets show consistent improvements in classification accuracy and training stability. While promising, the paper lacks detailed implementation, thorough baseline comparisons, and comprehensive qualitative analysis, and introduces modest computational overhead.",
      "strengths": [
        "Introduces a novel loss function that encourages activations to align with a circular representation, potentially improving interpretability and robustness.",
        "Demonstrates consistent empirical improvements across multiple datasets and model architectures without requiring major architectural changes.",
        "Suggests broader applicability to tasks like detection and segmentation and larger models such as Vision Transformers."
      ],
      "weaknesses": [
        "Does not compare against state‑of‑the‑art baselines for the specific architectures used, making quantitative assessment of improvements difficult.",
        "Lacks detailed description of the hue loss formulation and its integration into the network architecture, hindering reproducibility.",
        "Provides limited qualitative insights, such as activation map visualizations, to illustrate the impact of the hue loss.",
        "Adds computational cost by outputting hue coordinates, which could be a concern for large‑scale or resource‑constrained applications."
      ],
      "questions": [
        "How do the proposed hue coordinates compare to other interpretability techniques, such as Grad‑CAM or Grad‑REINFORCE, in terms of visual quality and interpretive value?",
        "What are the long‑term stability and convergence benefits of the hue loss, especially in very deep or large models?",
        "Could the hue loss be combined with other regularization techniques to further enhance model robustness and performance?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6Uc7Fgwrsm",
    "title": "OmnMixup: Generalize Mixup with Mixing-Pair Sampling Distribution",
    "std_review": {
      "summary": "OmniMixup introduces a learnable Mixing-Pair Sampling Distribution (MPSD) that extends Mixup beyond sample-level mixtures to operate directly in the latent space. The framework OmniEval automatically selects the optimal MPSD using a Mahalanobis distance-based metric (M‑Score) to maximize generalization. Experiments on CIFAR-10/100 and molecular property prediction demonstrate significant improvements over baseline mixup methods, indicating strong general applicability. The approach is positioned as a versatile tool that can complement existing techniques rather than replace them.",
      "strengths": [
        "Novel MPSD Framework: Extends Mixup to a learnable, data-driven distribution, offering a flexible way to generate mixing pairs in the latent space.",
        "Automatic Optimization: OmniEval’s use of the M‑Score for MPSD selection provides a theoretically grounded method to improve generalization without manual tuning.",
        "Broad Applicability: Demonstrated effectiveness across diverse datasets (image classification, molecular property prediction), suggesting strong generalization capabilities."
      ],
      "weaknesses": [
        "Computational Overhead: The process of searching the MPSD may introduce significant computational costs compared to training a model from scratch.",
        "Limited Baseline Comparisons: While comparisons with CutMix and ManifoldMixup are provided, a more comprehensive evaluation across a wider range of state-of-the-art mixup techniques would strengthen the claim of broad applicability.",
        "Lack of Qualitative Validation: The paper could benefit from visualizations or qualitative analyses of the sampled pairs to provide intuitive support for the theoretical claims.",
        "Potential Overfitting: The learnability of the MPSD might lead to overfitting if not properly regularized, especially in high-dimensional latent spaces."
      ],
      "questions": [
        "How does the computational cost of searching the MPSD compare to other regularization techniques in terms of practical deployment?",
        "Could additional qualitative analyses, such as visualizations of sampled pairs, further illustrate the benefits of the MPSD?",
        "What are the specific conditions under which OmniMixup is expected to outperform traditional mixup methods, and how can these be quantified?",
        "How robust is the M‑Score metric to variations in dataset size and complexity, and are there alternative metrics that could be explored?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6ujgouOiAA",
    "title": "Use Your INSTINCT:",
    "std_review": {
      "summary": "The paper presents INSTINCT, an algorithm that optimizes instructions for black-box large language models (LLMs) by combining white-box and black-box techniques. It demonstrates significant performance and efficiency gains over existing methods like InstructZero and EvoPrompt, while also showing strong generalization across various LLM configurations. The experimental validation is thorough, but concerns remain about computational cost and scalability for very large models.",
      "strengths": [
        "Algorithmic novelty combining white-box and black-box strategies",
        "Significant performance improvements in accuracy and efficiency",
        "Strong generalization across different LLM configurations"
      ],
      "weaknesses": [
        "Potential computational cost for training",
        "Scalability concerns for very large models",
        "Limited comparison with other recent state-of-the-art methods"
      ],
      "questions": [
        "How does INSTINCT perform on very large-scale models?",
        "What are the computational costs associated with training INSTINCT?",
        "How does INSTINCT compare to other recent advancements in instruction tuning?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6UQaXJm53B",
    "title": "DfPO: Degeneration-free Policy Optimization via Action Masking in Natural Language Action Spaces",
    "std_review": {
      "summary": "The paper introduces DfPO, a novel policy optimization method for text generation that improves task performance while preserving naturalness through an action‑masking mechanism guided by a reference policy. Empirical results show significant gains in task performance and naturalness across multiple tasks, with improved sample efficiency compared to PPO. The method is theoretically motivated and empirically validated, though it introduces computational overhead and could benefit from additional baselines and qualitative evaluations.",
      "strengths": [
        "Innovative action‑masking mechanism that explicitly excludes undesirable actions from likelihood maximization.",
        "Clear theoretical framework linking task advantage and naturalness advantage.",
        "Empirical validation demonstrating consistent improvements in task performance and naturalness across multiple tasks."
      ],
      "weaknesses": [
        "Computational overhead due to forward passes through the reference policy during inference.",
        "Hyperparameter sensitivity, particularly the choice of β in the action‑masked policy.",
        "Limited baseline comparisons, such as those involving supervised fine‑tuning."
      ],
      "questions": [
        "How does the action‑masked policy ensure that masked actions do not contribute to enhancing the task score while maintaining naturalness?",
        "What are the theoretical implications of the trade‑off between sample efficiency and the ability to maintain naturalness?",
        "How does DfPO's performance vary across tasks with different levels of naturalness requirements?",
        "What additional baselines (e.g., combining PPO with supervised fine‑tuning) could provide a more comprehensive comparison?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6uUmpPvqUU",
    "title": "The Closeness of In-Context Learning and Weight Shifting for Softmax Regression",
    "std_review": {
      "summary": "The paper provides a rigorous theoretical analysis of the relationship between in-context learning and weight shifting in softmax regression models. It introduces a detailed mathematical framework and derives key theorems that quantify the impact of Lipschitz bounds on weight shifts, supported by experimental validation. The work extends prior research by Deng et al. (2023b) and offers valuable insights into the mechanisms of in-context learning, though it could benefit from clearer presentation and broader scope.",
      "strengths": [
        "Clear theoretical formulation of softmax regression within in-context learning.",
        "Novel theorems (5.1 and 5.2) that quantify the relationship between Lipschitz bounds and weight shifts.",
        "Empirical validation that supports and extends prior work."
      ],
      "weaknesses": [
        "Complex mathematical derivations may limit accessibility for readers without strong ML theory background.",
        "Focus on softmax regression may restrict generalizability to other models or paradigms.",
        "Experimental setup could be more comprehensive to capture real-world variability."
      ],
      "questions": [
        "How can the theoretical framework be extended to other types of models or learning paradigms?",
        "What are the practical implications of the weight shifts identified in real-world applications?",
        "How do the results compare with other recent works on in-context learning beyond softmax regression?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6vF0ZJGor4",
    "title": "ImplicitSLIM and How it Improves",
    "std_review": {
      "summary": "ImplicitSLIM presents a scalable and efficient approach to collaborative filtering by leveraging the Locality Preserving Embedding (LLE) framework to enhance the Scalable Low-rank Matrix (SLIM) model. It focuses on implicit feedback signals, improving both scalability and accuracy for large-scale recommender systems. The method shows strong performance gains over baselines like EASE, with theoretical justifications in LLE, but its applicability is limited to embedding-based models and the lack of source code may hinder reproducibility.",
      "strengths": [
        "Significant scalability and efficiency improvements for large-scale recommender systems.",
        "Strong theoretical foundation based on the LLE framework, preserving local data geometry.",
        "Demonstrated performance gains over baseline models like EASE in various metrics."
      ],
      "weaknesses": [
        "Implementation complexity due to reliance on LLE, which may be challenging for practitioners.",
        "Limited applicability to non-embedding-based recommender systems.",
        "Absence of publicly available source code hinders reproducibility and further research."
      ],
      "questions": [
        "How can the method be extended to non-embedding-based recommender systems?",
        "What are the specific neighborhood definitions used in practice, and how do they impact performance?",
        "Could the source code be made available to facilitate reproducibility and further research?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6vtGG0WMne",
    "title": "Regulating Imbalanced Deep Models with User-Specified Metrics",
    "std_review": {
      "summary": "The paper introduces a Bias Adjustment (BA) method to improve model performance on imbalanced datasets by modifying the loss function. Experiments show that BA outperforms several state-of-the-art techniques across various benchmarks, while also being computationally efficient. The method is versatile for both multi-class classification and regression tasks, though its evaluation is limited to smaller datasets and further analysis is needed for larger datasets and multi-class performance.",
      "strengths": [
        "Improved performance on imbalanced datasets",
        "Computational efficiency with negligible overhead",
        "Versatility across multi-class classification and regression tasks",
        "Provides theoretical guarantees on error bounds"
      ],
      "weaknesses": [
        "Limited evaluation on large datasets",
        "Lack of detailed analysis on multi-class performance",
        "Potential sensitivity to hyperparameter choices"
      ],
      "questions": [
        "How does the BA method perform on larger, more complex datasets like CIFAR-10/100, ImageNet, or iNaturalist2018?",
        "What is the impact of hyperparameter tuning on the method's performance?",
        "Can the method be extended to handle highly imbalanced datasets with extreme class distribution?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6W35Wcs077",
    "title": "Decomposition Ascribed Synergistic Learning for Unified Image Restoration",
    "std_review": {
      "summary": "The paper introduces DASL, a method that uses singular value decomposition (SVD) to analyze and mitigate image degradation by decomposing it into singular vectors and singular values. This allows for targeted restoration techniques, integrating seamlessly with existing convolutional models and offering computational benefits. Experiments demonstrate robustness across various degradation scenarios, supporting the method's generality and effectiveness.",
      "strengths": [
        "Innovative use of SVD to decompose image degradation into singular vectors and singular values, providing a novel framework for addressing different types of degradation.",
        "Targeted restoration techniques (SVEO and SVAO) that enhance accuracy by distinguishing between singular vector‑dominated and singular value‑dominated degradations.",
        "Seamless integration with existing convolutional image‑restoration models, offering significant computational efficiency improvements.",
        "Robust experimental validation across diverse degradation scenarios, strongly supporting the method's robustness and effectiveness."
      ],
      "weaknesses": [
        "Complexity of implementation due to reliance on SVD and introduction of specialized operators (SVEO and SVAO).",
        "Limited scope of degradation types explored; further investigation needed for all possible degradation scenarios.",
        "Potential computational overhead from the initial SVD decomposition, especially for high-resolution images."
      ],
      "questions": [
        "How can the method be extended to handle non‑standard or hybrid degradation types that combine singular vector and singular value characteristics?",
        "What are the practical performance implications of the SVD decomposition step on real‑time image restoration applications?",
        "Could the integration of DASL with non‑convolutional restoration models be explored to broaden its applicability?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6werMQy1uz",
    "title": "Rethinking the Buyer's Inspection Paradox in Information Markets with Language Agents",
    "std_review": {
      "summary": "The paper introduces a novel theoretical framework for using large language models (LLMs) like GPT‑4 and Llama‑2‑70B in information markets to address the inspection paradox, where agents cannot fully verify information quality. It proposes mechanisms for information retention and forgetting and demonstrates through experiments that LLMs can improve decision-making efficiency. While the work shows promise, it has limitations in security, generalization, and the thoroughness of rationality improvements. Overall, the paper is well‑received with a strong acceptance recommendation.",
      "strengths": [
        "Innovative theoretical framework addressing the inspection paradox in LLM-based information markets.",
        "Empirical validation through comprehensive experimental comparisons of LLM implementations.",
        "Practical mechanisms for information management that enhance LLM decision-making."
      ],
      "weaknesses": [
        "Limited scope of baselines, with only a keyword‑matching baseline compared to LLMs.",
        "Security concerns are discussed but not fully explored in real-world implementation.",
        "Irrational behavior of LLMs is acknowledged but not deeply addressed.",
        "Findings are specific to certain LLMs and market scenarios, limiting generalizability."
      ],
      "questions": [
        "How can the proposed security measures be practically implemented in real-world settings?",
        "What additional baselines would provide a more robust evaluation of LLM performance?",
        "How can the rationality of LLMs be consistently improved for more reliable economic decisions?",
        "What future work is needed to explore the scalability and generalization of the proposed mechanisms?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6xfe4IVcOu",
    "title": "Chain of Hindsight aligns Language Models with Feedback",
    "std_review": {
      "summary": "The paper presents Chain of Hindsight (CoH), a method that uses natural language feedback to improve language model outputs without explicit annotations. CoH constructs hypothetical scenarios leading to desired feedback, enabling the model to learn from feedback efficiently. The method is evaluated against rejection sampling and Conditional Self‑Finetuning (C‑SFT) across various model sizes, showing improved performance and scalability. The reviewer finds CoH to be a valuable contribution due to its performance improvements and scalability.",
      "strengths": [
        "Scalability: CoH effectively scales with model size, maintaining performance improvements.",
        "Efficiency: Reduces the need for explicit feedback annotations, streamlining the feedback loop.",
        "Performance: Outperforms rejection sampling and achieves comparable results to C‑SFT with fewer resources."
      ],
      "weaknesses": [
        "Complexity: Constructing hypothetical scenarios may introduce computational overhead.",
        "Feedback Quality: Natural language feedback can be subjective and noisy.",
        "Post‑Processing: May require additional steps to refine outputs."
      ],
      "questions": [
        "How does CoH handle feedback that is ambiguous or contradictory?",
        "What is the impact of the complexity of the hypothetical scenarios on the overall training time?",
        "Can CoH be integrated with existing feedback collection pipelines without significant modifications?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6ZuDeSHzjj",
    "title": "Outliers Memorized Last:",
    "std_review": {
      "summary": "The paper investigates memorization in diffusion models, using a toy dataset and simplified model to study how inliers and outliers affect performance. It finds strong memorization tendencies, impacting generalization, and provides insights into when and how memorization occurs. While technically sound and offering valuable insights, the findings are limited by the narrow scope of the toy model and lack of exploration of mitigation strategies.",
      "strengths": [
        "Clear definition and operationalization of inliers and outliers.",
        "Use of a single, well-defined toy model for focused study.",
        "Detailed hyperparameter settings and training procedures for reproducibility."
      ],
      "weaknesses": [
        "Reliance on a single toy model limits generalizability.",
        "No exploration of hyperparameter impact across different architectures.",
        "Lack of formal memorization metrics makes assessment challenging.",
        "No discussion of mitigation strategies for memorization."
      ],
      "questions": [
        "How do the observed memorization patterns generalize to larger, more complex datasets?",
        "What impact do varying hyperparameters have on memorization across different model architectures?",
        "Are there effective mitigation strategies for reducing memorization in diffusion models?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "70A6oo3Il2",
    "title": "",
    "std_review": {
      "summary": "The paper introduces AdaFlood, an adaptive flood regularization technique that dynamically adjusts flood levels during training based on difficulty estimates from a lightweight auxiliary network. AdaFlood combines instance‑wise adaptive weighting with traditional flood regularization, aiming to improve calibration, robustness, and generalization, especially in noisy‑label settings. Experiments on toy datasets demonstrate significant gains over baseline flood methods, with further validation on larger datasets like ImageNet and LAION confirming the method's scalability and effectiveness. The reviewer finds the approach novel, theoretically sound, and empirically effective, recommending acceptance.",
      "strengths": [
        "Novel combination of adaptive instance weighting with flood regularization.",
        "Solid theoretical foundation with Proposition 1.",
        "Efficient training by re‑initializing only the last layer(s) for difficulty estimation.",
        "Demonstrated robustness and scalability across noisy‑label datasets and large models."
      ],
      "weaknesses": [
        "Limited baseline comparison with other flood methods.",
        "Lack of detailed analysis on extremely large datasets or very deep models.",
        "Theoretical rigor could be further strengthened.",
        "Implementation details of the auxiliary network could be more explicit.",
        "Potential risk of overfitting with adaptive flood levels."
      ],
      "questions": [
        "How does AdaFlood compare to other adaptive regularization techniques in terms of convergence speed?",
        "What is the impact of the auxiliary network's architecture on the overall performance?",
        "Can AdaFlood be integrated with other regularization methods without significant loss of effectiveness?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "70IgE3tRbu",
    "title": "",
    "std_review": {
      "summary": "The paper introduces Continuous Invariance Learning (CIL), a method for learning invariant features across multiple environments to improve model generalization. It provides a solid theoretical foundation and demonstrates effectiveness on various datasets. However, it faces challenges such as sensitivity to domain size, reliance on manual environment splitting, and suboptimal in-domain performance. The reviewer finds the method promising but with practical limitations that need addressing.",
      "strengths": [
        "Introduces a novel method for learning invariant features across multiple environments.",
        "Provides a solid theoretical analysis with assumptions about domain countability.",
        "Demonstrates empirical effectiveness through experiments on diverse datasets."
      ],
      "weaknesses": [
        "Performance may be sensitive to the size of the domain index.",
        "Relies on manual splitting of environments for baselines, which may not be feasible in all scenarios.",
        "Shows suboptimal in-domain prediction accuracy and high variance.",
        "Theoretical analysis assumes countably many domains, limiting applicability to continuous settings.",
        "Implementation complexity may hinder adoption."
      ],
      "questions": [
        "How does CIL handle domains with a large number of environments?",
        "What are the detailed neural network architectures and hyperparameters used for baselines?",
        "How does the penalty scale with the number of environments when using the spurious mask?",
        "Could CIL be compared with environment inference methods in future work?",
        "What is the theoretical justification for the failure rate of REx/IRM with a domain growth rate of O(√n)?",
        "How does CIL perform in discrete-domain continuous-label settings?",
        "How does the proof in Appendix F clarify the theoretical underpinnings?"
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "70PPJo3DwI",
    "title": "Towards Out-of-Federation Generalization in Federated Learning",
    "std_review": {
      "summary": "The paper proposes a federated learning method that emphasizes influential clients to improve model performance and reduce communication overhead. It achieves higher ROC‑AUC scores on benchmark datasets while communicating fewer parameters. However, it lacks a clear definition of what constitutes an influential client, does not compare with prototype‑based methods, and may overfit to similar clients.",
      "strengths": [
        "Introduces a novel client weighting strategy that can enhance model generalization.",
        "Demonstrates improved performance and communication efficiency on several datasets.",
        "Provides a thorough experimental evaluation with clear comparisons to baselines."
      ],
      "weaknesses": [
        "Lacks a precise metric for client influence, affecting reproducibility.",
        "Does not compare against existing prototype‑based methods for client similarity.",
        "Potential overfitting to the most similar clients could limit effectiveness."
      ],
      "questions": [
        "How is the influence of a client defined and measured?",
        "Why was wall-clock time chosen as the primary scalability metric?",
        "How does the method compare to prototype‑based approaches for client similarity?",
        "What safeguards are in place to prevent overfitting to influential clients?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "70xhiS0AQS",
    "title": "TaskBench: Benchmarking Large Language Models for Task Automation",
    "std_review": {
      "summary": "The paper presents TaskBench, a benchmark for evaluating large language models' ability to decompose tasks into subtasks using tool graphs. It introduces a method to construct tool graphs from task graphs, sample subgraphs for user instructions, and evaluates the approach across three domains. The results show improved quality and coherence of generated instructions, though some limitations exist in handling very large graphs and the lack of comprehensive error analysis.",
      "strengths": [
        "Introduces a novel method for generating task decomposition through tool graph construction, enhancing interpretability and modularity of LLMs.",
        "Effectively handles complex tasks by breaking them down into smaller subtasks, improving LLM performance in real-world applications.",
        "Provides a systematic analysis of the relationship between tool graph complexity and instruction difficulty, offering new insights into task complexity in LLMs."
      ],
      "weaknesses": [
        "Tool graph construction may struggle with very large or highly interconnected task graphs, leading to performance bottlenecks.",
        "Evaluation of generated instructions is primarily qualitative, potentially missing nuances of instruction quality.",
        "Lack of comprehensive error analysis limits understanding of common pitfalls and areas for improvement.",
        "Benchmark relevance may be compromised as more powerful LLMs are developed, potentially leading to saturation."
      ],
      "questions": [
        "How does the method handle tool graphs with a very large number of nodes or highly interconnected components?",
        "What quantitative metrics are proposed for evaluating the quality of generated user instructions beyond qualitative analysis?",
        "How can the benchmark be adapted to remain relevant as LLM capabilities continue to advance?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "73dhbcXxtV",
    "title": "LoLaMeMe: Logic, Language, Memory, Mechanistic Framework",
    "std_review": {
      "summary": "The paper introduces T HEX, a hybrid model that combines GPT‑2's attention mechanism with Hyena's hyena operator to improve logical reasoning and memory. Using the LOLAMEME framework, it creates LoLa and MeMe datasets to evaluate the model's performance on language tasks. T HEX outperforms both GPT‑2 and Hyena on these benchmarks, demonstrating the effectiveness of the hybrid approach.",
      "strengths": [
        "Innovative hybrid architecture combining attention and memory mechanisms.",
        "Targeted dataset construction using LOLAMEME to evaluate specific language aspects.",
        "Demonstrated improved performance across benchmarks compared to individual models."
      ],
      "weaknesses": [
        "Implementation complexity and computational demands of integrating two distinct architectures.",
        "Synthetic datasets may not fully capture real-world language complexity and variability.",
        "Limited validation on practical applications beyond synthetic benchmarks."
      ],
      "questions": [
        "How does the T HEX model perform on real-world language tasks beyond the synthetic benchmarks?",
        "What are the computational and resource requirements for implementing the T HEX architecture?",
        "How can the model's performance be further validated in diverse language understanding scenarios?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "73lu1yw6At",
    "title": "",
    "std_review": {
      "summary": "The paper introduces AXp and CXp algorithms for generating abductive and counterfactual explanations for sequential data using RNNs. It demonstrates improved interpretability and transparency on benchmark datasets compared to traditional baselines. While the algorithms are innovative and practical, concerns about computational complexity and the lack of a formal definition for the '1 k' notation remain. Overall, the work is well‑received with a strong acceptance recommendation.",
      "strengths": [
        "Introduces a novel framework for generating explanations tailored to sequential data.",
        "Provides practical algorithms (AXp and CXp) that can be directly applied to RNNs.",
        "Shows strong empirical results on benchmark datasets, enhancing model interpretability."
      ],
      "weaknesses": [
        "The proposed algorithms may be computationally intensive, limiting scalability.",
        "Lacks a detailed analysis of computational complexity, which could affect practical deployment.",
        "Uses informal notation ('1 k') for counterfactual explanations, potentially causing confusion."
      ],
      "questions": [
        "How does the proposed framework scale to very large sequential datasets?",
        "Can the '1 k' notation be formalized to improve clarity for readers?",
        "What are the trade-offs between interpretability gains and computational overhead?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "74IIsh2kM6",
    "title": "SMILE: Audio-visual Speech Recognition with Siamese Masked Interaction Learning",
    "std_review": {
      "summary": "The SMILE model introduces a novel Siamese transformer architecture for audio-visual speech recognition, leveraging adaptive multimodal fusion primarily driven by audio. It demonstrates strong performance and robustness to noise, outperforming state-of-the-art acoustic-only models. While the model effectively integrates audio and visual modalities, its heavy reliance on audio and limited exploration of visual-only data suggest areas for further investigation.",
      "strengths": [
        "Innovative adaptive multimodal fusion mechanism using a weighted sum over transformer layers.",
        "Demonstrated robustness to acoustic noise when visual information is available.",
        "Competitive word error rate (WER) performance compared to existing acoustic-only models."
      ],
      "weaknesses": [
        "Primary dependence on audio modality may limit the model's reliance on visual information.",
        "Limited experimentation on visual-only data could provide additional insights.",
        "Impact of different training strategies on the Siamese network's performance is not thoroughly examined."
      ],
      "questions": [
        "How does the model's performance vary when visual information is the primary input (video-only data)?",
        "What is the impact of different training strategies (e.g., stop‑gradient vs. direct parameter sharing) on the Siamese network's learning dynamics?",
        "How sensitive is the model's performance to hyperparameters α and β, and the choice between layer-dependent and shared weights for visual contributions?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "74YdSRFORA",
    "title": "Out of Sight: A Framework for Egocentric Active Speaker Detection",
    "std_review": {
      "summary": "The paper presents the Out‑of‑Sight (O2S) framework for Active Speaker Detection (ASD) in egocentric video, addressing the challenge of the camera wearer being invisible to the model. O2S integrates a multimodal transformer that fuses audio and video information, with a novel visual token representation derived from the wearer’s face to bridge the invisibility gap. Experiments demonstrate competitive performance against third‑person ASD baselines on the Ego4D benchmark, highlighting the method's ability to handle scenarios with multiple off‑screen speakers and noisy visual data. The O2S approach introduces a novel visual token representation and a weighted visual loss, enhancing model robustness and accuracy. Despite its strong empirical results, the framework incurs high computational costs and relies on specific dataset characteristics, which may limit its generalization to diverse scenarios.",
      "strengths": [
        "Introduces a novel visual token representation to address the invisibility of the camera wearer in egocentric ASD.",
        "Demonstrates competitive performance against third‑person ASD baselines on the Ego4D benchmark.",
        "Enhances model robustness through a multimodal mixer and weighted visual loss, improving detection in challenging scenarios."
      ],
      "weaknesses": [
        "High computational complexity may limit real‑time applicability.",
        "Performance heavily depends on the quality of face detection and the distribution of the Ego4D dataset.",
        "Sensitivity to hyper‑parameters such as α, k, and n, requiring careful tuning.",
        "Potential limited generalization to diverse speaker appearances, expressions, and environments."
      ],
      "questions": [
        "How does the O2S framework perform on datasets with less controlled face detection quality or varied camera angles?",
        "What are the specific ablations performed on the hyper‑parameters α, k, and n, and how do they influence model performance?",
        "Can the model be adapted to handle scenarios where the camera wearer is occluded by objects other than the camera itself?",
        "What are the computational trade‑offs of scaling the transformer architecture for real‑time applications?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "760br3YEtY",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a novel model that integrates SMILES representations of ligands with protein sequence data to enhance functional annotation using EC numbers. It employs a self-attention mechanism to identify key residues and a hierarchical loss function based on EC numbers to guide learning. The benchmarking setup ensures fairness, and results show improved annotation accuracy compared to existing methods. Overall, the approach is promising, though implementation complexity and scope limitations are noted.",
      "strengths": [
        "Innovative integration of ligand information to enhance functional annotation.",
        "Effective use of self-attention to capture important protein interactions.",
        "Hierarchical loss function provides structured guidance for learning at multiple functional levels."
      ],
      "weaknesses": [
        "Complex implementation requiring significant computational resources.",
        "Performance comparison between fusion methods could benefit from additional analysis.",
        "Benchmarking may not fully capture real-world variability."
      ],
      "questions": [
        "How does the model handle ligands with varying structural complexities?",
        "What are the computational costs associated with the self-attention mechanism?",
        "Could the model be adapted for other types of biological data beyond protein sequences?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "770DetV8He",
    "title": "RetroBridge: Modeling Retrosynthesis with Markov Bridges",
    "std_review": {
      "summary": "RetroBridge introduces a Markov Bridge Model (MBM) for generative modeling of chemical structures, achieving competitive performance on the USPTO-50K benchmark. The model leverages Markov bridges to capture the probabilistic nature of chemical synthesis, offering strong inductive biases and explainability. While it outperforms template-free methods, concerns about computational cost and sensitivity to the fixed number of time steps remain. Overall, the paper is well-received with a strong accept recommendation.",
      "strengths": [
        "Innovative approach to modeling discrete chemical structures using Markov bridges.",
        "Clear inductive biases that guide probabilistic generation of reactants.",
        "Strong performance on the USPTO-50K benchmark, especially with top-k accuracy.",
        "Provides explainability and interpretability of the generation process."
      ],
      "weaknesses": [
        "Computational cost associated with sampling using a fixed number of time steps.",
        "Performance sensitivity to the choice of time steps, requiring extensive tuning.",
        "Limited exploration of alternative distributions may restrict the model's generality.",
        "Potential underperformance compared to highly optimized template-based methods."
      ],
      "questions": [
        "How can the model's performance be further evaluated against highly optimized template-based methods like RetroFormer?",
        "What strategies can be employed to reduce the computational cost associated with fixed time steps?",
        "Could the model benefit from incorporating alternative distributions or probabilistic frameworks to enhance its generality?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "774elYc5tw",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a future‑constraint satisfaction score (R) for controllable text generation, aiming to guide models to produce text that satisfies specific constraints while maintaining quality. Experiments show significant improvements in aligning generated text with user‑specified constraints compared to baselines. However, the approach introduces computational overhead, has scalability concerns for longer sequences, lacks comprehensive human evaluation, and does not thoroughly explore the robustness of the satisfaction score.",
      "strengths": [
        "Introduces a novel constraint satisfaction mechanism that penalizes deviations in future states of generated text.",
        "Demonstrates significant improvements in aligning generated text with user‑specified constraints.",
        "Provides a clear theoretical foundation linking the approach to constraint satisfaction and optimization."
      ],
      "weaknesses": [
        "Adds computational complexity, potentially limiting applicability to real‑time or resource‑constrained environments.",
        "Scalability concerns are not thoroughly addressed, especially for longer‑form generation tasks.",
        "Lacks comprehensive human evaluation to assess fluency, informativeness, and correctness.",
        "The robustness and accuracy of the satisfaction score are not fully explored."
      ],
      "questions": [
        "How can the computational overhead be mitigated to improve real‑time applicability?",
        "What strategies can be employed to evaluate and improve the method's scalability for longer sequences?",
        "What additional human evaluation metrics (e.g., entailment, faithfulness, toxicity) could provide a more complete picture of the generated text's quality?",
        "How can the satisfaction score be refined or improved for different types of constraints?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "776lhoaulC",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a novel framework for domain adaptation in optical flow estimation by aligning boundary regions between source and target domains. It demonstrates significant improvements over baselines in various domain-shifted scenarios, highlighting its practical relevance. While effective, the method has limitations such as higher computational demand and inability to model z-axis motion, which could restrict its applicability in certain contexts.",
      "strengths": [
        "Addresses a critical domain adaptation challenge in optical flow estimation.",
        "Effectively reduces domain shift by focusing on boundary alignment.",
        "Shows strong empirical performance compared to existing techniques."
      ],
      "weaknesses": [
        "Primarily handles domain shifts due to appearance changes, potentially overlooking other types of differences.",
        "Computational overhead from boundary alignment may be a limitation in resource-constrained environments.",
        "Does not account for z-axis radial motion, which can be significant in depth-varying scenarios."
      ],
      "questions": [
        "How does the method perform when applied to domains with non-appearance-based shifts, such as those involving texture or lighting changes?",
        "What runtime optimizations or efficient optical flow estimation techniques could be explored to address computational demands?",
        "How can the framework be extended to incorporate z-axis radial motion for improved accuracy in depth-varying environments?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "77N93tc3o5",
    "title": "",
    "std_review": {
      "summary": "The paper introduces DeepIVA, a two‑step model combining an information‑preserving variational autoencoder with a multi‑modal information source framework to jointly learn cross‑modal latent representations. Theoretical guarantees for identifiability are provided, and extensive empirical evaluations demonstrate improved cross‑modal linkage over single‑modality baselines. While the approach is innovative and theoretically sound, concerns about computational complexity and reliance on strong assumptions are noted.",
      "strengths": [
        "Unified framework for cross‑modal learning",
        "Theoretical guarantees for identifiability",
        "Empirical validation across diverse datasets",
        "Innovative linkage mechanism ensuring meaningful cross‑modal relationships"
      ],
      "weaknesses": [
        "Complexity of the two‑step training process",
        "Assumption reliance for identifiability",
        "Metric limitations in capturing nuances of linkage",
        "Lack of ablation studies to isolate component impacts"
      ],
      "questions": [
        "How does the model scale to very large datasets or complex multimodal data?",
        "What are the practical implications of the strong identifiability assumptions?",
        "Could joint training of the entire model improve computational efficiency?",
        "How robust are the linkage guarantees to variations in auxiliary variables?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "78iGZdqxYY",
    "title": "Mirage: Model-Agnostic Graph Distillation for Graph Classification",
    "std_review": {
      "summary": "MIRAGE presents a model-agnostic method for distilling large graph datasets into smaller, efficient representations while preserving essential graph properties. The approach leverages the frequency distribution of computation trees to capture structural and spectral characteristics, enabling effective use with various GNN architectures. Experimental results show high accuracy on multi-class classification tasks with reduced computational requirements. Overall, the paper is well-received for its innovative technique and practical benefits.",
      "strengths": [
        "Model-agnostic nature allows the distilled dataset to be used with any GNN architecture.",
        "Efficient representation reduces computational burden and memory usage.",
        "Preserves key graph properties such as node/edge features and spectral characteristics."
      ],
      "weaknesses": [
        "Scalability may be limited for very large datasets due to computational complexity.",
        "Assumes computation tree structure suffices for all graph types, which may not hold for complex or non-tree-like graphs.",
        "Potential for overfitting with a limited set of features derived from computation trees."
      ],
      "questions": [
        "How does MIRAGE handle graphs with highly irregular or non-tree-like structures?",
        "What strategies can be employed to mitigate overfitting when using a limited feature set?",
        "How does the method scale to extremely large datasets, and what are the practical implications?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "79FVDdfoSR",
    "title": "A Characterization Theorem for Equivariant Networks with Point-wise Activations",
    "std_review": {
      "summary": "The paper introduces a novel characterization theorem for equivariant neural networks (EoNNs) that incorporates point‑wise activation functions. It proves that a neural network is equivariant under a transformation group G if and only if it satisfies a specific condition involving point‑wise activations and the group's action on the input space. This extends prior work on DeepSets and invariant networks by providing a unified framework for both point‑wise and non‑point‑wise activations, offering new insights into the design of equivariant models for various group representations. The authors provide rigorous proofs and examples, making the theoretical contributions accessible, and offer practical guidance for designing equivariant networks, especially when point‑wise activations are preferred. However, the paper lacks empirical validation and may have limited scope by focusing only on point‑wise activations.",
      "strengths": [
        "Novel theorem linking equivariance with point‑wise activations",
        "Broad applicability to geometric deep learning and various group representations",
        "Clear mathematical proofs and concrete examples",
        "Practical guidelines for designing equivariant neural networks"
      ],
      "weaknesses": [
        "Focus on point‑wise activations may overlook other relevant activation functions",
        "Assumes a specific structure for the input space",
        "Lacks empirical validation of the theoretical results",
        "Mathematical depth may make it challenging for non‑specialists"
      ],
      "questions": [
        "How can the characterization be extended to non‑point‑wise activation functions?",
        "What are the empirical performance implications of using point‑wise activations in equivariant networks?",
        "How does the framework handle input spaces that do not conform to the assumed structure?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "79rfgv3jw4",
    "title": "Designing Skill-Compatible AI: Methodologies and Frameworks in Chess",
    "std_review": {
      "summary": "The paper introduces three novel reinforcement‑learning agents—Tree, Expector, and Attuned—designed to collaborate with human partners in chess. Across speech‑to‑text and human‑board benchmarks, the agents outperform a naive baseline, achieving higher win rates and more effective move‑selection probabilities. The work highlights the importance of skill‑compatibility in human‑AI teamwork, suggesting future research should explore broader applicability and cross‑domain collaboration. Overall, the paper is well‑structured, methodologically rigorous, and provides strong empirical evidence, though its findings are currently domain‑specific.",
      "strengths": [
        "Innovative agent design with three distinct strategies",
        "Comprehensive evaluation across two distinct benchmarks",
        "Clear methodological rigor and detailed methodology"
      ],
      "weaknesses": [
        "Findings are heavily reliant on the chess domain",
        "Success depends on accurate opponent modeling",
        "Focus on skill‑compatibility may overlook human‑compatibility factors"
      ],
      "questions": [
        "How can the proposed methods be generalized to other domains or tasks?",
        "What is the impact of dynamic or unpredictable opponent behavior on agent performance?",
        "How do the agents handle variations in human communication styles or emotional engagement?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "79tJB1eTmb",
    "title": "",
    "std_review": {
      "summary": "The paper introduces Meta-Cot, a method that dynamically selects examples to guide a large language model in solving complex reasoning problems. It shows improved performance in out-of-domain scenarios compared to few-shot prompting and zero-shot CoT, but the evaluation includes datasets that are not genuinely out-of-domain, raising questions about its true generalizability. The method's scalability is limited by the computational cost of scenario identification, and its data requirements are not clearly justified. The reviewer finds the method promising but recommends further work to address these concerns.",
      "strengths": [
        "Dynamic Scenario Identification: The method dynamically identifies scenarios, which can adapt to a wide range of problems without predefined templates.",
        "Improved Performance: Meta-Cot outperforms few-shot prompting and zero-shot CoT in out-of-domain scenarios, demonstrating the effectiveness of dynamic example selection.",
        "Scalability Potential: The approach can potentially scale with the number of categories, though the computational cost of matching questions to scenarios is a concern."
      ],
      "weaknesses": [
        "Scalability Concerns: The scenario identification step's computational cost increases with the number of categories, potentially limiting scalability.",
        "Out-of-Domain Performance: The lack of genuine out-of-domain datasets in the evaluation questions the method's ability to generalize to unseen domains.",
        "Baseline Comparison: The comparison with few-shot prompting and zero-shot CoT is not comprehensive, as it omits specific prompts and CoT demonstrations.",
        "Data Requirements: Despite its complexity, Meta-Cot's data requirements are not clearly justified, and the experimental results are considered weak.",
        "Lack of Citations: The dynamic example selection process is mentioned without citation, raising questions about its origin and relevance.",
        "Zero-Shot CoT Generation: The generation of zero-shot CoT demonstrations is not fully addressed, and the potential for mistakes could impact the results."
      ],
      "questions": [
        "How can the computational cost of scenario identification be reduced to improve scalability?",
        "What is the impact of using datasets labeled as out-of-domain but generated using GSM prompts for ASDiv?",
        "How can the method's data requirements be better justified and demonstrated?",
        "What are the specific citations for the dynamic example selection idea?",
        "How can the generation of zero-shot CoT demonstrations be improved to ensure their correctness?"
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "7AB077M4TY",
    "title": "Dynamic Training Guided by",
    "std_review": {
      "summary": "The paper introduces Koopman Gradient Acceleration (KGA), a novel optimization technique that enhances training speed and stability by dynamically accelerating gradients along specific Koopman modes. The authors also propose Koopman Weight Masking (KWM) to reduce computational overhead. Experiments show KGA outperforms standard SGD and Adam across various tasks, achieving faster convergence and improved accuracy. While the approach is innovative and theoretically justified, it may be challenging for readers unfamiliar with Koopman theory, and its scalability and parameter sensitivity require further investigation.",
      "strengths": [
        "Innovative approach leveraging Koopman operator theory for dynamic gradient acceleration.",
        "Strong theoretical foundation linking Koopman modes to optimization benefits.",
        "Computational efficiency through lightweight Koopman Weight Masking.",
        "Empirical validation demonstrating clear performance gains over established optimizers."
      ],
      "weaknesses": [
        "Complexity due to reliance on Koopman theory, potentially limiting accessibility.",
        "Parameter sensitivity, particularly the acceleration parameter α, may require extensive tuning.",
        "Scalability to large models or datasets has not been thoroughly demonstrated.",
        "Evaluation focuses on speed and accuracy, potentially overlooking other performance aspects."
      ],
      "questions": [
        "How can the approach be extended to other optimization algorithms or model architectures?",
        "What are the theoretical guarantees for convergence and stability of KGA in different learning scenarios?",
        "How does KGA perform on very large-scale models or datasets, and what are the computational trade-offs?",
        "Can the selection of Koopman modes be automated to reduce manual tuning of the acceleration parameter α?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7AiPfnM73h",
    "title": "Projected Off-Policy Q-Learning (POP-QL) for Stabilizing Offline Reinforcement Learning",
    "std_review": {
      "summary": "The paper introduces POP-QL, an offline policy optimization algorithm that improves sample efficiency in reinforcement learning by addressing distributional shift in off-policy data. It builds on Kolter (2011) with a novel objective that regularizes the policy while preserving off-policy benefits. Empirical evaluations on D4RL benchmarks show competitive performance, though some results are less favorable compared to state-of-the-art methods, especially on severely sub-optimal datasets. The method is theoretically grounded, scalable, and integrates well with existing RL frameworks, but concerns remain about empirical robustness and baseline reproducibility.",
      "strengths": [
        "Novel objective function that balances policy improvement with distributional regularization.",
        "Strong theoretical foundation leveraging probability theory and optimization.",
        "Improved scalability compared to the original Kolter approach.",
        "Easy integration with existing off-policy learning frameworks."
      ],
      "weaknesses": [
        "Empirical performance on benchmark datasets like D4RL is often lower than state-of-the-art methods.",
        "Baseline reproducibility issues may affect comparability of results.",
        "Increased algorithmic complexity due to policy projection and dual optimization.",
        "Limited comparison with other off-policy methods to assess relative strengths."
      ],
      "questions": [
        "Can POP-QL demonstrate consistent performance improvements on severely sub-optimal datasets compared to state-of-the-art methods?",
        "What are the detailed implementation steps for reproducing the baselines to ensure reproducibility?",
        "How does POP-QL compare to other scalable off-policy methods in terms of both scalability and practical adoption?",
        "What additional ablations or experiments are planned to validate POP-QL's advantages in challenging scenarios?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "7ArYyAmDGQ",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a novel theoretical framework for analyzing the ridgeless least squares estimator under non‑i.i.d. regression errors, leveraging left‑spherical symmetry (LSS) to derive new insights into the double‑descent phenomenon. It provides a clear, mathematically rigorous exposition of how LSS allows the expected variance to be factorized, explaining the observed behavior of the double‑descent curve. While the analysis is limited to the ridgeless case and under‑parameterized regime, it makes significant theoretical contributions by relaxing the i.i.d. assumption and offering a structured way to understand error dependence.",
      "strengths": [
        "Novel relaxation of the i.i.d. assumption for the ridgeless least squares estimator.",
        "Innovative use of left‑spherical symmetry (LSS) to factorize expected variance and explain double descent.",
        "Clear and mathematically rigorous theoretical contributions."
      ],
      "weaknesses": [
        "Focuses only on the ridgeless case, not on ridge regularization.",
        "Results are limited to the under‑parameterized regime.",
        "Relies on the LSS assumption, which may not hold in all practical scenarios.",
        "Lack of empirical validation to support practical relevance."
      ],
      "questions": [
        "How can the results be extended to the case of ridge regularization?",
        "What is the behavior of the estimator in the over‑parameterized regime?",
        "How generalizable is the LSS assumption beyond the specific error dependence structures considered?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7AS7vaVU8d",
    "title": "Learning Personalized Story Evaluation",
    "std_review": {
      "summary": "The paper introduces PerSE, a model that evaluates story quality using historical movie review data, aiming to mitigate biases present in GPT-4. It compares PerSE's performance against LLaMA and highlights statistical significance in its results. While innovative, the paper has methodological gaps, such as unclear data selection strategies and assumptions about data independence, which affect its overall evaluation.",
      "strengths": [
        "Innovative approach using historical movie review data for story quality evaluation.",
        "Explicit focus on bias mitigation, addressing a significant concern in language model evaluations.",
        "Demonstrates statistical rigor through t-tests and analysis in Table 4."
      ],
      "weaknesses": [
        "Assumes movie review data is not part of LLaMA's pretraining, which may not be verifiable.",
        "Unclear method for selecting historical reviews, potentially introducing bias.",
        "Repeats questions about bias without fully addressing them."
      ],
      "questions": [
        "How is the selection of historical reviews from movie reviewers defined and executed?",
        "What evidence supports the assumption that movie review data is not part of LLaMA's pretraining?",
        "How can the paper quantify the bias of PerSE towards LLaMA generations?",
        "Should the comparison results between PerSE models be accompanied by statistical significance tests?"
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "7avlrpzWqo",
    "title": "",
    "std_review": {
      "raw_text": "{\n  \"summary\": \"The paper introduces the Flag Aggregator (FA), a Byzantine‑resilient aggregation method that projects worker gradients into a carefully selected subspace to mitigate faulty workers' influence. FA is theoretically justified, computationally efficient, and empirically outperforms existing methods in robustness against Byzantine attacks. While computational complexity and hyper‑parameter sensitivity are noted, the method shows strong potential with clear theoretical foundations and practical advantages.\",\n  \"strengths\": [\n    \"Theoretical robustness with clear conditions for superiority.\",\n    \"Adaptive subspace selection balances robustness and efficiency.\",\n    \"Computational efficiency suitable for large‑scale distributed settings.\"\n  ],\n  \"weaknesses\": [\n    \"Computational complexity due to SVD for subspace determination.\",\n    \"Hyper‑parameter sensitivity, particularly the discrete choice of subspace dimension.\",\n    \"Limited exploration of non‑linear noise handling.\"\n  ],\n  \"questions\": [\n    \"How can the computational overhead of SVD be reduced for very large‑scale systems?\",\n    \"What are the practical guidelines for selecting the optimal subspace dimension \\(m\\) in real‑world scenarios?\",\n    \"Can the method be extended to handle non‑linear noise more effectively, and what are the performance trade‑offs?\"\n  ],\n  \"overall_score\": \"7: accept\",\n  \"confidence\": \"4: high\"\n}",
      "parse_error": true
    }
  },
  {
    "paper_id": "7b2itdrxMa",
    "title": "From Child's Play to AI: Insights into Automated Causal Curriculum Learning",
    "std_review": {
      "summary": "The paper proposes a curriculum learning approach for reinforcement learning agents inspired by children's education, using level progress as an intrinsic reward. It demonstrates improved learning efficiency and performance through both human experiments and RL experiments. While the approach is innovative and shows promise, there are concerns about the generalizability of the human experiments and the lack of exhaustive baseline comparisons. Overall, the paper is well‑structured and makes a valuable contribution to curriculum learning in RL.",
      "strengths": [
        "Bridges human learning and RL by proposing a curriculum learning approach inspired by children's education.",
        "Introduces an auxiliary reward based on level progress, a novel and potentially effective intrinsic signal for RL.",
        "Conducts comprehensive evaluations with both human experiments and RL experiments.",
        "Demonstrates clear improvements in learning efficiency and performance compared to a stochastic curriculum."
      ],
      "weaknesses": [
        "Human experiments may have limited generalizability due to the specific context and population studied.",
        "Lacks detailed analysis of potential limitations, such as overfitting or difficulty defining level progress in complex tasks.",
        "Comparison with a stochastic curriculum is not exhaustive, and other baselines could provide a more comprehensive evaluation.",
        "Does not thoroughly discuss ethical considerations of human subject experiments."
      ],
      "questions": [
        "How can the proposed level progress metric be generalized to more complex tasks beyond the current study?",
        "What are the long-term effects of using intrinsic rewards based on level progress on RL agent behavior?",
        "How does the proposed approach compare to other intrinsic reward methods, such as curiosity-driven learning or meta-learning?",
        "What ethical guidelines should be followed when conducting human subject experiments in AI research?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7bIpWYhCdu",
    "title": "Fili: Syntax Repair By Learning From Own Mistakes",
    "std_review": {
      "summary": "The paper introduces BIFI, a two-stage method that trains a model to generate syntactically incorrect programs (breakers) and then corrects them (fixers) through iterative refinement. Evaluated on a synthetic Python dataset, the approach shows significant improvements in fixer accuracy but highlights challenges in training breakers and limitations of using edit distance as a metric. While innovative and offering practical insights, the method's complexity and computational cost prevent full acceptance.",
      "strengths": [
        "Innovative two-stage training approach leveraging model capabilities for program repair.",
        "Clear evaluation metrics using parse rate and edit distance.",
        "Empirical insights from ablation studies on diminishing returns and model proficiency."
      ],
      "weaknesses": [
        "Complexity of training a model to generate realistic errors (breakers).",
        "Edit distance metric only considers edit count, not semantic correctness.",
        "Increased computational burden and complexity due to separate breaker and fixer models.",
        "Limited generalization from a synthetic dataset to real-world programming scenarios."
      ],
      "questions": [
        "How can the method be adapted to handle more realistic error patterns beyond the synthetic dataset?",
        "What alternative metrics could better capture the semantic correctness of generated fixes?",
        "How does the performance of BIFI compare to single-model approaches in terms of computational efficiency?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "7CLvyZ6Xn7",
    "title": "Cross-domain Adaptation for Few-shot 3D Shape Generation",
    "std_review": {
      "summary": "The paper presents a novel few-shot 3D shape generation framework that adapts a pre-trained generative model across domains with minimal labeled data. It introduces a domain-adaptation loss that aligns both feature distributions and shape geometry, along with a regularization term that preserves relative distances between generated shapes. Experiments on several domain adaptation tasks show significant improvements over existing methods using multiple quantitative metrics and visual comparisons. The authors highlight the method's robustness across diverse shape categories but note limitations in handling large domain gaps and the need for high-quality source data.",
      "strengths": [
        "Introduces a dual-level domain-adaptation loss that aligns feature distributions and shape geometry.",
        "Preserves relative distances between generated shapes through a regularization term.",
        "Demonstrates strong performance across multiple domain adaptation tasks with comprehensive evaluation metrics.",
        "Provides clear baselines and thorough comparisons, establishing a solid benchmark."
      ],
      "weaknesses": [
        "Limited evaluation on large domain gaps between highly dissimilar shape categories.",
        "Relies heavily on the quality and diversity of source domain data.",
        "Adds computational overhead, potentially limiting real-time or resource-constrained applications.",
        "Lacks extensive hyperparameter sensitivity analysis.",
        "May overfit to specific domain pairs without further adaptation."
      ],
      "questions": [
        "How does the method perform on large domain gaps, such as Cars → Abstract Shapes?",
        "What is the impact of source data quality and diversity on the model's performance?",
        "Could a more thorough hyperparameter sensitivity analysis provide additional insights into robustness?",
        "What future work could address the potential overfitting to specific domain pairs?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7D9X2cFnt1",
    "title": "Elastic Feature Consolidation for Cold Start Exemplar-free Incremental Learning",
    "std_review": {
      "summary": "The paper introduces Elastic Feature Consolidation (EFC), a novel approach to class‑incremental learning (CIL) that effectively balances plasticity and stability. EFC uses an Empirical Feature Matrix (EFM) to capture task‑specific feature distributions and an Asymmetric Prototype Replay loss (PR‑ACE) to stabilize feature representations. Experimental results show strong performance, especially in cold‑start scenarios, outperforming existing exemplar‑free CIL methods.",
      "strengths": [
        "Introduces the Empirical Feature Matrix (EFM) as a novel alternative to the Fisher Information Matrix (FIM) for exemplar‑free CIL.",
        "Balances plasticity and stability in learning new tasks while retaining knowledge from previous tasks.",
        "Proposes the Asymmetric Prototype Replay loss (PR‑ACE) to address feature drift and enable adaptive learning.",
        "Demonstrates robust performance across both cold‑start and warm‑start scenarios."
      ],
      "weaknesses": [
        "The introduction of the EFM and PR‑ACE loss may increase implementation complexity and computational requirements.",
        "Empirical validation could be strengthened with results across a wider range of datasets and tasks.",
        "Comparison with the latest state‑of‑the‑art methods, including both exemplar‑based and exemplar‑free approaches, would better highlight EFC's unique contributions."
      ],
      "questions": [
        "How does EFC perform on very large datasets with a high number of tasks?",
        "What is the computational cost of maintaining and updating the EFM during incremental learning?",
        "How does EFC compare to recent exemplar‑based CIL methods in terms of generalization across diverse domains?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7duh4Ml5rc",
    "title": "Based on What We Can Control Artificial Neural Networks",
    "std_review": {
      "summary": "The paper interprets neural‑network training as a control problem, framing optimizers as controllers and analyzing their effects on stability and performance across various architectures and datasets. It provides a novel control‑theoretic perspective that complements existing views of training dynamics. While the study is comprehensive and insightful, it could benefit from deeper theoretical foundations and more extensive hyperparameter analysis. Overall, the findings are significant and warrant acceptance.",
      "strengths": [
        "Introduces a novel control‑theoretic framework for understanding neural‑network training.",
        "Comprehensively compares a wide range of optimizers, including traditional and novel approaches.",
        "Tests optimizers across diverse neural‑network architectures and datasets, enhancing generalizability.",
        "Offers clear experimental design and actionable insights into optimizer control characteristics."
      ],
      "weaknesses": [
        "Lacks a deeper theoretical foundation linking control theory to neural‑network dynamics.",
        "May overemphasize control metrics at the expense of other important aspects like convergence speed.",
        "Focuses on established architectures, limiting applicability to novel designs.",
        "Insufficient exploration of hyperparameter sensitivity.",
        "Potential reproducibility challenges due to the complexity of the control framework."
      ],
      "questions": [
        "How can the theoretical link between control theory and neural‑network dynamics be further strengthened?",
        "Could additional hyperparameter sweeps provide more nuanced insights into optimizer performance?",
        "Would exploring the sensitivity of optimizers to hyperparameter variations yield additional practical guidance?",
        "How do the findings generalize to emerging neural‑network architectures beyond those tested?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7em7Jl0qMm",
    "title": "",
    "std_review": {
      "summary": "The paper introduces FODE, a physics‑informed neural network that combines learnable Fourier transforms with sliding‑window forecasting to capture temporal dependencies in time‑series data. Experiments show that FODE outperforms established baselines like FNO, DeepONet, and RNN/LSTM across synthetic and real‑world datasets, achieving higher accuracy and better data efficiency. Despite increased computational costs and hyperparameter complexity, the model demonstrates strong scalability and robustness, especially in noisy data scenarios. Overall, the innovative approach and performance gains justify its acceptance.",
      "strengths": [
        "Innovative integration of learnable Fourier transforms and element‑wise filters for dynamic temporal modeling.",
        "Demonstrated scalability to high‑dimensional, complex time series with minimal performance degradation.",
        "Improved data efficiency, achieving comparable or superior results with less training data."
      ],
      "weaknesses": [
        "Higher computational cost during training due to learnable filters and Fourier transforms.",
        "Increased complexity in hyperparameter tuning for optimal performance.",
        "Reliance on a sliding‑window approach may limit long‑term forecasting capabilities."
      ],
      "questions": [
        "How does FODE perform on extremely long‑term forecasting tasks beyond the initial data window?",
        "What are the specific strategies for mitigating overfitting when trained on very small datasets?",
        "Can the model be extended to handle non‑stationary time series with evolving statistical properties?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7ErllmwXym",
    "title": "Interpreting and Improving Diffusion Models Using the Euclidean Distance Function",
    "std_review": {
      "summary": "The paper introduces a novel sampler for diffusion models that improves efficiency and convergence, supported by theoretical guarantees in Theorem 4.2. Experimental results on various datasets show significant performance gains over existing methods, though some experimental coverage and theoretical details remain incomplete.",
      "strengths": [
        "Novel theoretical contributions with Theorem 4.2 providing a solid mathematical foundation.",
        "Practical improvements demonstrated through experimental results.",
        "Clear definitions and assumptions, enhancing clarity and reproducibility."
      ],
      "weaknesses": [
        "Incomplete experimental coverage may limit generalizability.",
        "Lack of detailed proofs for some theoretical results.",
        "Interpretation of theoretical results and practical implications are not fully explored."
      ],
      "questions": [
        "Should additional experiments be conducted on more datasets and noise levels?",
        "Can a detailed proof for Theorem 4.4 be provided to strengthen theoretical claims?",
        "What are the practical limitations of the assumptions (e.g., unique projection and relative error) in real-world scenarios?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7erlRDoaV8",
    "title": "Can Sensitive Information Be Deleted From LLMs? Objectives for Defending Against Extraction Attacks",
    "std_review": {
      "summary": "The paper introduces a novel threat model for evaluating language models against extraction attacks, focusing on the recovery of a single token. It evaluates several defense strategies across white‑box and black‑box scenarios, and compares them with existing unlearning metrics. The study highlights the impact of model editing techniques on defense effectiveness, with practical implications for developing more robust models. Despite some limitations, such as the focus on single-token answers and assumptions about attacker budgets, the paper is valuable for advancing robustness in language models.",
      "strengths": [
        "Introduces a novel threat model focusing on single-token recovery, which is more realistic and challenging than existing unlearning metrics.",
        "Comprehensively evaluates a wide range of defense strategies across both white‑box and black‑box attacks.",
        "Provides detailed analysis of how different model editing techniques (ROME, MEMIT, constrained fine‑tuning) affect model vulnerability.",
        "Demonstrates practical implications for improving the robustness of language models, especially in scenarios where single-token information recovery is critical."
      ],
      "weaknesses": [
        "Experiments primarily focus on single-token answers, which may not fully capture behavior in more complex, multi-token scenarios.",
        "Assumes a fixed attacker budget B, which may not reflect real-world conditions with varying attacker resources.",
        "Limited discussion on how the proposed attacks and defenses would scale to handle multi-token answers.",
        "Potential overemphasis on defense strategies without a comprehensive comparison of their relative strengths and weaknesses across all attack types."
      ],
      "questions": [
        "How do the proposed attacks and defenses scale to handle multi-token answer extraction scenarios?",
        "What are the relative strengths and weaknesses of the evaluated defense strategies across different attack types and model editing techniques?",
        "How do the findings generalize to more complex, real-world extraction scenarios beyond single-token answers?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7ERQPyR2eb",
    "title": "",
    "std_review": {
      "summary": "Real3D-Portrait presents a novel one-shot 3D talking face generation framework that reconstructs 3D faces from a single 2D image and animates them with audio. The method integrates a Head-Torso-Background super-resolution model to enhance realism, achieving high-quality results. While it advances the field by reducing data requirements and improving audio-driven animation, it still faces challenges in background and torso modeling, and computational efficiency. Overall, the paper is strong and recommended for acceptance.",
      "strengths": [
        "One-shot learning enables 3D talking face generation from a single 2D image.",
        "High-quality 3D reconstruction with the I2P model maintains geometric accuracy.",
        "Smooth and realistic audio-driven animation through the audio-to-motion model.",
        "Significant realism improvements via the HTB super-resolution model."
      ],
      "weaknesses": [
        "Background and torso modeling could be more sophisticated.",
        "Computationally intensive, potentially limiting real-time applications.",
        "Performance heavily reliant on input image quality."
      ],
      "questions": [
        "How can background and torso modeling be further improved for more realistic outputs?",
        "What strategies can be employed to enhance computational efficiency for real-time applications?",
        "How does the method handle variations in input image quality beyond ideal conditions?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7essnmWOK5",
    "title": "",
    "std_review": {
      "summary": "The paper introduces HSDGNN, a hierarchical spatial‑dynamic graph neural network for multivariate time‑series forecasting. It effectively models hierarchical dependencies among attributes and captures intra‑attribute relationships using an IDLM, outperforming baselines on five traffic datasets. The authors provide strong theoretical and empirical justification, though the model's complexity and lack of extensive cross‑domain validation are noted.",
      "strengths": [
        "Hierarchical structure effectively models complex attribute dependencies.",
        "Intra‑attribute dependency learning module (IDLM) improves performance on datasets with few attributes.",
        "Robustness across diverse traffic datasets demonstrates versatility.",
        "Provides both theoretical insights and empirical evidence supporting the architecture."
      ],
      "weaknesses": [
        "Model complexity may lead to longer training times and higher computational costs.",
        "Limited benchmarking on other domains could further validate generalizability.",
        "Lack of detailed hyperparameter tuning and ablation studies weakens the claim of superiority.",
        "Hierarchical nature may reduce interpretability compared to simpler models."
      ],
      "questions": [
        "How does HSDGNN perform on benchmarks from domains beyond traffic, such as social networks or sensor streams?",
        "What are the optimal hyperparameter settings for HSDGNN, and how do they impact performance?",
        "Could ablation studies on the IDLM and hierarchical structure further clarify their contributions?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7etoNfU9uF",
    "title": "",
    "std_review": {
      "summary": "SpikePoint introduces a method for event-based action recognition that transforms spiking neural events into point clouds with implicit timestamp encoding. It uses a sampling strategy similar to Condensation and dual feature extraction to capture spatial and temporal dynamics. The method is trained with surrogate gradients, achieving competitive results on benchmark datasets. While innovative, the approach has some limitations, such as the implicit temporal representation and lack of detailed comparisons with existing methods. Overall, the paper is well‑received and recommended for acceptance.",
      "strengths": [
        "Innovative implicit temporal encoding that preserves temporal dynamics without explicit temporal operations.",
        "Efficient sampling strategy similar to Condensation, enabling scalability to high-frequency event streams.",
        "Comprehensive dual feature extraction architecture that captures both fine-grained spatial details and broader temporal patterns.",
        "Training feasibility through surrogate gradients, bridging traditional deep learning and neuromorphic computing."
      ],
      "weaknesses": [
        "Implicit temporal representation may obscure precise temporal dynamics, potentially limiting the model's ability to capture subtle variations.",
        "Lack of detailed comparison with existing sampling methods like Condensation highlights SpikePoint's unique advantages.",
        "The choice of timestep is not thoroughly justified, and trade-offs between data granularity and computational efficiency are not fully explored.",
        "Appendix provides a brief mention of surrogate gradients without clear explanation of their application and effectiveness."
      ],
      "questions": [
        "How does the implicit encoding of timestamps affect the model's ability to capture subtle temporal variations compared to explicit temporal methods?",
        "What detailed comparisons are planned between SpikePoint's sampling strategy and established techniques like Condensation?",
        "Could a more thorough analysis of timestep selection provide insights into the balance between data granularity and computational efficiency?",
        "What specific aspects of surrogate gradients are used for training SNNs, and how do they compare to other backpropagation methods for spiking networks?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7eYmijcuqO",
    "title": "On the Dynamics of Learning",
    "std_review": {
      "summary": "The paper provides a novel dynamical‑systems analysis of RNN training, identifying three distinct phases (exploration, convergence, plateau) and demonstrating these phases across simple tasks and architectures. While offering valuable insights into learning dynamics, the findings are limited to toy datasets and basic RNNs, raising questions about broader applicability. The study suggests practical implications for model design but also notes challenges in interpretability and generalization.",
      "strengths": [
        "Introduces a fresh dynamical‑systems perspective on RNN learning.",
        "Leverages PCA and Jacobian eigenvectors for rigorous analysis.",
        "Empirically validates the three‑phase structure across multiple toy tasks."
      ],
      "weaknesses": [
        "Results are based on limited, simple datasets and architectures.",
        "Interpretability of dynamical insights may be challenging for practitioners.",
        "Focuses only on traditional RNNs, not modern variants like transformers."
      ],
      "questions": [
        "How do the identified learning phases manifest in more complex, real‑world RNN tasks?",
        "What visual or simplified models can be developed to make the dynamical insights more accessible?",
        "How might the findings differ when applied to contemporary RNN architectures such as transformers?",
        "What adjustments to the methodology are needed to analyze irregular or high‑dimensional time series data?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "7ezBaMwOqY",
    "title": "Trading-off Multiple Properties for Molecular Optimization",
    "std_review": {
      "summary": "The paper introduces PCI, a Pareto‑Constrained Integer framework that formulates multi‑objective molecular optimization as a linear programming problem, enabling efficient generation of diverse, high‑quality molecules while respecting scaffold hierarchies. PCI outperforms existing methods on benchmark datasets in terms of Pareto front coverage and computational efficiency. The reviewer finds the approach novel, theoretically sound, and practically effective, recommending acceptance.",
      "strengths": [
        "Novel LP formulation for multi‑objective molecular optimization",
        "Efficient Pareto generation via a single LP",
        "Flexibility to accommodate various molecular properties",
        "Strong theoretical guarantees and convergence properties"
      ],
      "weaknesses": [
        "Assumes convexity of objectives and constraints, which may limit applicability",
        "Scalability concerns for very large scaffold trees",
        "Lacks comprehensive comparisons with non‑LP based methods",
        "Empirical validation could be strengthened with diverse datasets"
      ],
      "questions": [
        "How does PCI handle non‑convex objective functions or constraints?",
        "What is the scalability of PCI for very large scaffold hierarchies?",
        "How does PCI compare to state‑of‑the‑art non‑LP based multi‑objective optimization methods?",
        "Can PCI be extended to other types of molecular optimization backbones beyond scaffold trees?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7F4ioiKQFT",
    "title": "ColCLIP: Enhancing Fine-Grained Image Retrieval with Pre-trained Embeddings",
    "std_review": {
      "summary": "ColCLIP introduces a MaxSim operator to align object-specific queries with image regions, improving fine-grained image retrieval across multiple datasets. The approach shows significant gains over standard CLIP and other baselines, while also reducing computational costs. Despite promising results, the paper lacks reproducibility due to missing code and data, and further validation on diverse datasets is needed to address potential overfitting.",
      "strengths": [
        "Innovative MaxSim layer effectively bridges object-specific queries with image regions, enhancing retrieval precision.",
        "Demonstrates cross-dataset generalization with improvements on Flickr30K and MS COCO beyond Visual Genome.",
        "Computational efficiency gains through dimensionality reduction techniques.",
        "Clear experimental validation with comprehensive ablations and comparisons against baselines."
      ],
      "weaknesses": [
        "Limited baselines for the MaxSim layer could be expanded to strengthen the argument.",
        "Potential overfitting to the Visual Genome dataset warrants further validation.",
        "Trade-off between retrieval accuracy and computational efficiency is not fully quantified.",
        "Absence of publicly available code and data hinders reproducibility."
      ],
      "questions": [
        "How does the model perform on additional, more diverse datasets beyond Visual Genome, Flickr30K, and MS COCO?",
        "What are the specific impacts of different aggregation functions in the MaxSim layer on retrieval accuracy?",
        "Can the reproducibility of the results be improved by providing code and data?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7FeIRqCedv",
    "title": "",
    "std_review": {
      "summary": "SLiMe introduces a novel few-shot image segmentation method that uses Stable Diffusion to generate text embeddings for guiding segmentation. The approach is flexible, achieving competitive results on benchmark datasets like horse/car/face, and offers some interpretability by linking embeddings to Stable Diffusion tokens. However, its performance on complex objects and less interpretable embeddings, along with limited benchmarking, prevent full acceptance.",
      "strengths": [
        "Innovative use of text embeddings from Stable Diffusion to guide segmentation.",
        "Flexibility in granularity through varying text prompts.",
        "Competitive performance on benchmark datasets."
      ],
      "weaknesses": [
        "Limited benchmark datasets evaluated, restricting comprehensive assessment.",
        "Interpretability of learned embeddings remains a challenge.",
        "Potential struggles with small or featureless objects."
      ],
      "questions": [
        "How does SLiMe perform on more complex datasets like ADE-Bedroom-30 and FSS-1000?",
        "Can the learned embeddings be mapped to more interpretable terms or concepts?",
        "What is the impact of the weighted accumulated self-attention (WAS) component on segmentation quality?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "7ffJo4vtTY",
    "title": "Robustness Signatures in CLIP Models",
    "std_review": {
      "summary": "The paper introduces a novel framework for assessing robustness in multimodal models by identifying outlier features and privileged directions. It provides a clear theoretical foundation and a comprehensive experimental setup comparing baseline and multimodal fine-tuned models. While the approach is insightful, the review highlights concerns about figure clarity and metric choice, suggesting these areas for improvement.",
      "strengths": [
        "Introduces a novel framework for assessing robustness in multimodal models through outlier features and privileged directions.",
        "Provides a clear theoretical foundation linking these concepts to model performance.",
        "Employs a comprehensive experimental setup, comparing baseline and multimodal fine-tuned models."
      ],
      "weaknesses": [
        "Figures, particularly Figure 2, are difficult to interpret and could benefit from clearer presentation.",
        "The use of kurtosis to determine outlier features may not be the most robust choice.",
        "The paper does not adequately address the differences in model complexity between its work and reference works."
      ],
      "questions": [
        "How can the figures be improved to better illustrate the concepts of outlier features and privileged directions?",
        "What alternative metrics could be used to identify outlier features more robustly?",
        "How do the identified privileged directions compare to those in other multimodal models?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7FHrZuKogW",
    "title": "Contractive Systems Improve Graph Neural Networks Against Adversarial Attacks",
    "std_review": {
      "summary": "The paper proposes a novel Graph Convolutional Neural Network (CSGN) that enhances GNN robustness against adversarial attacks by learning the dynamics of the adjacency matrix using neural ordinary differential equations (ODEs). Theoretical foundations and empirical results demonstrate superior performance compared to existing baselines like GNNGuard across various attack scenarios. While introducing computational overhead, the approach is competitive with other defense mechanisms and shows broad applicability to different adversarial attack types.",
      "strengths": [
        "Innovative approach to learning adjacency matrix dynamics using neural ODEs.",
        "Strong theoretical backing with Theorems 1 and 2.",
        "Empirical validation showing significant improvements in accuracy and robustness."
      ],
      "weaknesses": [
        "Computational complexity due to learning adjacency matrix dynamics.",
        "Potential scalability issues for very large graphs.",
        "Lack of comprehensive comparison with other state-of-the-art methods."
      ],
      "questions": [
        "How does the model perform on extremely large graphs or high-dimensional data?",
        "What are the specific conditions under which the contractive properties of the learned ODEs hold?",
        "How does the model compare to recent advancements in adversarial training for GNNs?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7fwzPsn1lJ",
    "title": "LLark : A Multimodal Model for Music",
    "std_review": {
      "summary": "LLark is a novel multimodal model for music that integrates audio and text modalities using a transformer architecture, achieving competitive performance on music understanding tasks. While it outperforms many existing models, its novelty does not always translate to superior results across all tasks, and there are concerns about text hallucinations and the need for more comprehensive ablation studies. The paper is recommended for weak acceptance.",
      "strengths": [
        "Innovative multimodal architecture combining audio and text.",
        "State-of-the-art performance on key music understanding tasks.",
        "End-to-end training simplifies development and potentially improves coherence."
      ],
      "weaknesses": [
        "Novelty may not surpass highly specialized models for specific tasks.",
        "Performance on certain tasks, like music captioning, could be improved.",
        "Potential for text hallucinations requiring better mitigation.",
        "Lack of extensive ablation studies to validate component contributions."
      ],
      "questions": [
        "Could more detailed ablation studies clarify the impact of each model component?",
        "What strategies are proposed to address text hallucinations?",
        "How does LLark's performance compare to other multimodal models under different noise conditions?",
        "What ethical considerations and safeguards are needed for real-world deployment?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "7fxzVTSgZC",
    "title": "Offline Imitation Learning without Auxiliary High-quality Behavior Data",
    "std_review": {
      "summary": "The paper presents BCDP, a method for offline reinforcement learning that effectively leverages both expert and low-quality behavior data. It introduces a distributional regularizer to mitigate the impact of non-random data, addressing a key limitation in offline RL. Empirically, BCDP outperforms several state-of-the-art methods on MuJoCo control tasks, demonstrating robustness to out-of-distribution samples. While the method shows promise, it relies on assumptions about data quality and may face scalability challenges due to increased computational complexity.",
      "strengths": [
        "Innovative approach combining expert and low-quality behavior data.",
        "Robustness to noisy data through a distributional regularizer.",
        "Introduces DRG metric for evaluating performance in unobserved states."
      ],
      "weaknesses": [
        "Effectiveness depends on assumptions about the quality of low-quality data.",
        "Computational complexity may limit scalability.",
        "Lack of extensive ablation studies.",
        "No comparison with model-based imitation learning methods."
      ],
      "questions": [
        "How does BCDP perform with highly biased or adversarial low-quality data?",
        "What is the impact of the distributional regularizer on the computational efficiency of BCDP?",
        "Could a more comprehensive ablation study provide deeper insights into the contributions of each component?",
        "How does BCDP compare to model-based imitation learning approaches in terms of robustness and generalization?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7GCRhebJEr",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a novel robustness improvement method using Bregman divergences and learned similarity metrics. It projects corrupted images back into a distribution of in-distribution images by iteratively projecting onto Bregman and L2 balls. The approach leverages a learned base function and shows improved robustness on CIFAR-10-C compared to baselines. While promising, the method has some theoretical and practical concerns.",
      "strengths": [
        "Innovative use of Bregman divergences to define a learned similarity metric.",
        "Practical and efficient iterative projection method.",
        "Solid theoretical foundation for the projection method.",
        "Empirical results demonstrating significant improvements in robustness.",
        "Forward-looking adversarial training approach."
      ],
      "weaknesses": [
        "Lack of thorough analysis on projection existence and uniqueness.",
        "Unclear justification for the convergence of the mirror descent algorithm.",
        "Arbitrary choice of distance d without clear guidance.",
        "Limited evaluation to CIFAR-10-C, with no indication of scalability."
      ],
      "questions": [
        "How do the authors ensure the existence and uniqueness of the projection under all conditions?",
        "What theoretical guarantees support the convergence of the mirror descent algorithm when the projection onto the learned base function is not available in closed form?",
        "Are there any prior works or guidelines for selecting appropriate values of d in the experiments?",
        "How does the proposed method scale to more complex datasets like ImageNet?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "7gDENzTzw1",
    "title": "Belief-Enriched Pessimistic Q-Learning against Adversarial State Perturbations",
    "std_review": {
      "summary": "The paper investigates the robustness of a reinforcement learning method against color perturbations in Atari games using the Continuous Gridworld environment. It evaluates three attack budgets and finds that the method maintains performance under significant color noise, suggesting robustness. However, the study's limited scope to two games and a simple environment raises questions about generalizability. Overall, the paper provides valuable insights but requires further exploration in more complex settings.",
      "strengths": [
        "Clear experimental setup focusing on color perturbations in a controlled Atari environment.",
        "Methodological rigor through the use of multiple attack budgets.",
        "Relevance to real-world applications where RL agents must handle varying environmental conditions."
      ],
      "weaknesses": [
        "Limited scope to a single environment and only two Atari games, potentially limiting generalizability.",
        "Use of 8-bit RGB color representation may not fully capture real-world complexity.",
        "Observed robustness might be due to color filtering rather than true robustness to perturbations.",
        "Lack of exploration in more complex environments like Mujoco or Mountain Car."
      ],
      "questions": [
        "How does the method perform in more complex environments with continuous state spaces?",
        "What is the extent to which the observed robustness is due to color filtering versus true robustness to perturbations?",
        "Could the method be adapted to handle higher-dimensional color representations beyond 8-bit RGB?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "7GkdjhupsV",
    "title": "InfoAug: Mutual Information Informed Augmentation for Representation Learning",
    "std_review": {
      "summary": "InfoAug presents a novel data augmentation technique grounded in information-theoretic principles, aiming to improve robustness and generalization of deep learning models. The method shows significant improvements over baseline techniques on benchmark image classification tasks, is computationally efficient, and can be easily integrated into existing pipelines. However, the paper lacks a detailed theoretical analysis of the augmentation technique and does not comprehensively compare it with state-of-the-art methods across various tasks and domains.",
      "strengths": [
        "Introduces a novel data augmentation method grounded in information-theoretic principles.",
        "Demonstrates consistent improvements over existing augmentation techniques on multiple benchmark datasets.",
        "Computational efficiency and ease of integration into existing deep learning pipelines."
      ],
      "weaknesses": [
        "Lacks a detailed theoretical analysis of the proposed augmentation technique.",
        "Does not provide a comprehensive comparison with state-of-the-art methods across a wide range of tasks and datasets.",
        "Evaluation limited to image classification tasks, with limited discussion on applicability to other domains."
      ],
      "questions": [
        "What is the theoretical analysis of the proposed augmentation technique?",
        "How does InfoAug perform on tasks beyond image classification, such as object detection or semantic segmentation?",
        "What are the potential limitations or drawbacks of InfoAug that practitioners should consider?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7gLfQT52Nn",
    "title": "",
    "std_review": {
      "summary": "The paper introduces ALLO, an adversarial learning framework that learns Laplacian representations for MDPs, aiming to stabilize learning and improve state representation quality. Theoretical guarantees and practical experiments on synthetic and real-world environments demonstrate benefits in exploration, reward shaping, and value estimation. However, the computational complexity of the optimization, limited empirical validation, and lack of detailed analysis in continuous settings prevent a strong recommendation.",
      "strengths": [
        "Introduces a novel adversarial learning framework (ALLO) with Laplacian regularization.",
        "Provides theoretical stability guarantees (Theorem 1) under specific conditions.",
        "Demonstrates practical utility through experiments on both synthetic and real-world environments."
      ],
      "weaknesses": [
        "Computational complexity of the proposed objective function is not fully analyzed.",
        "Theoretical stability guarantee relies on conditions that may not hold in all scenarios.",
        "Lack of extensive empirical evidence or comparison to state-of-the-art methods.",
        "Only briefly discusses the stability of the minimax game.",
        "Theoretical extension to continuous spaces lacks concrete examples or experiments."
      ],
      "questions": [
        "Can the computational complexity of the proposed optimization be quantified and mitigated for larger-scale problems?",
        "How robust are the theoretical stability guarantees in practical scenarios beyond the conditions specified?",
        "What additional empirical evidence is needed to fully assess the practical impact of the Laplacian representation?",
        "What methods can be used to analyze and ensure the stability of the minimax game in more complex environments?",
        "How can the framework be practically extended to continuous state spaces, and what challenges might arise?"
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "7gUrYE50Rb",
    "title": "EQA-MX: Embodied Question Answering using Multimodal Expression",
    "std_review": {
      "summary": "The paper presents EQA-MX, a multimodal grounding system that integrates non-verbal gestures (pointing and gaze) with visual inputs to improve object localization and counting. It introduces three tasks—object grounding, perspective-aware grounding, and perspective grounding—to evaluate the method's adaptability. While demonstrating effectiveness on a challenging dataset, the paper faces challenges in clearly defining tasks and handling ambiguities in real-world scenarios, such as multiple similar objects or varying gaze cues.",
      "strengths": [
        "Integrates non-verbal gestures with visual inputs for a more comprehensive understanding of user intent.",
        "Uses detailed 3D joint positions and gaze information to enhance object localization and counting.",
        "Introduces clear task definitions (OG, POG, PG) to showcase the method's adaptability."
      ],
      "weaknesses": [
        "Lacks clear differentiation between the tasks of object grounding, perspective-aware grounding, and perspective grounding.",
        "Does not thoroughly address ambiguity in the dataset, such as multiple similar objects or varying pointing gestures.",
        "Representation of gaze is not explicitly detailed, which may affect the method's accuracy."
      ],
      "questions": [
        "How does the method differentiate between the tasks of object grounding, perspective-aware grounding, and perspective grounding?",
        "What strategies are employed to handle ambiguity in the dataset, such as multiple similar objects or varying pointing gestures?",
        "Can you provide a detailed analysis of how the method performs in scenarios with multiple similar objects?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "7gVX2LxE7A",
    "title": "SpecAR-Net: Spectrogram Analysis and Representation Network for Time Series",
    "std_review": {
      "summary": "SpecAR-Net introduces a novel neural network architecture that combines spectral and autoregressive modeling to enhance time series prediction, achieving superior performance on complex datasets. The architecture leverages a time-frequency transform, multi-scale convolutions, and an order-preserving loss to capture frequency and temporal dependencies effectively. While innovative, the model's complexity and sensitivity to hyperparameters are noted as potential drawbacks. Overall, the paper is well-received for its strong performance and theoretical foundation.",
      "strengths": [
        "Innovative architecture that integrates spectral and autoregressive modeling.",
        "Significant performance improvements over existing methods on complex time series tasks.",
        "Robust handling of complex periodicities and trend patterns in real-world data."
      ],
      "weaknesses": [
        "Increased complexity may hinder implementation and maintenance.",
        "Potential sensitivity to hyperparameter tuning.",
        "Lack of comprehensive ablation study to quantify component contributions."
      ],
      "questions": [
        "Should an ablation study be conducted on all components of SpecAR-Net to better understand their individual contributions?",
        "What statistical tests can be used to confirm the significance of performance improvements?",
        "How does SpecAR-Net compare to other state-of-the-art methods beyond the cursory comparison provided?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7HdtLgsvys",
    "title": "Tube Loss: A Novel Approach for High Quality Prediction Interval Estimation",
    "std_review": {
      "raw_text": "{\n  \"summary\": \"The paper introduces a novel tube loss function for interval estimation in regression, offering statistically sound and computationally efficient prediction intervals. It outperforms existing methods like quantile regression and quantile depth loss across synthetic and real-world datasets, showing improved interval coverage and narrower intervals. The authors provide strong theoretical justification and empirical evidence, though tuning the parameter \\( r \\) and broader baseline comparisons could be improved. Overall, the paper is well‑received with a strong accept recommendation.\",\n  \"strengths\": [\n    \"Innovative loss function for interval estimation\",\n    \"Solid theoretical foundation with interval coverage guarantees\",\n    \"Empirical improvements over existing methods\"\n  ],\n  \"weaknesses\": [\n    \"Complexity of tuning parameter \\( r \\)\",\n    \"Computational considerations for large datasets\",\n    \"Limited baseline comparisons\"\n  ],\n  \"questions\": [\n    \"How can the optimal value of \\( r \\) be determined more systematically?\",\n    \"What are the computational trade-offs for different values of \\( r \\)?\",\n    \"How does the method perform on highly dynamic datasets?\"\n  ],\n  \"overall_score\": \"7: accept\",\n  \"confidence\": \"4: high\"\n}",
      "parse_error": true
    }
  },
  {
    "paper_id": "7HfliVAtCG",
    "title": "Detect Every Thing with Few Examples",
    "std_review": {
      "summary": "The paper introduces DE‑ViT, a novel approach that combines Vision Transformers with Region-based Convolutional Neural Networks to enhance few‑shot object detection. It leverages frozen DINOv2 features and a prototype‑based classification scheme, achieving competitive results on few‑shot, one‑shot, and open‑vocabulary benchmarks. While demonstrating strong performance, the paper notes implementation complexity, dependence on frozen features, and higher computational costs, which could limit real‑world deployment.",
      "strengths": [
        "Innovative architecture combining ViT and RCNN for robust few‑shot detection.",
        "Prototype learning simplifies classification in open‑set settings.",
        "Propagated localization improves object proposal accuracy for open‑vocabulary tasks."
      ],
      "weaknesses": [
        "Increased implementation complexity due to the integration of ViT and RCNN.",
        "Reliance on frozen DINOv2 features may limit adaptability to diverse datasets.",
        "Higher computational requirements compared to some baseline methods."
      ],
      "questions": [
        "How does DE‑ViT perform on real‑world datasets with varying image resolutions and backgrounds?",
        "What strategies can be employed to reduce the computational cost of DE‑ViT for real‑time applications?",
        "How does the model handle scenarios with high occlusion or cluttered images?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7hxoYxKDTV",
    "title": "",
    "std_review": {
      "summary": "PQDiff introduces a progressive quantization diffusion model for outpainting that can handle inputs of varying sizes and aspect ratios while producing outputs of a fixed size. The model demonstrates competitive performance on both in‑painting and out‑painting tasks, outperforming several state‑of‑the‑art baselines. However, the quantitative evaluation of outpainting quality in arbitrary positions is limited, and the model's scalability is not fully substantiated beyond a few tested multiples. Overall, the paper presents a promising approach with room for improvement in rigor and thoroughness.",
      "strengths": [
        "Versatile input handling: processes inputs of any size and aspect ratio while maintaining a fixed output size.",
        "State‑of‑the‑art performance: achieves competitive results on standard benchmarks in both in‑painting and out‑painting tasks.",
        "Innovative quantization diffusion: leverages progressive quantization to enhance efficiency and quality, especially for large‑scale outpainting."
      ],
      "weaknesses": [
        "Limited quantitative evaluation for arbitrary positions: relies primarily on qualitative analysis.",
        "Insufficient testing of scalability: only evaluates up to 2.5x, 5x, and 11.7x multiples.",
        "Lack of consistency analysis: does not thoroughly examine the impact of the one‑to‑many mapping on outpainting ratios.",
        "Visual comparisons could be clearer: supplementary figures lack side‑by‑side comparisons for intuitive understanding."
      ],
      "questions": [
        "Can you provide quantitative results for outpainting quality in arbitrary positions across a broader range of input multiples?",
        "What is the impact of the one‑to‑many mapping between anchor and target views on the consistency of outpainting ratios across all edges?",
        "Could side‑by‑side visual comparisons be included in the supplementary material to enhance clarity?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "7iCUSBlOgh",
    "title": "Toward Generalizability of Graph-based Imputation on Bio-Medical Missing Data",
    "std_review": {
      "summary": "The paper introduces GRASS, a graph-based imputation method that leverages feature gradients and k-NN graphs to improve accuracy on bio-medical and medical datasets. It outperforms traditional methods like Mean and GAIN, demonstrating strong performance and computational efficiency. The method is also promising for generalizing to other domains, though it has some computational demands and parameter sensitivity.",
      "strengths": [
        "Innovative approach using feature gradients in graph-based imputation.",
        "Superior performance on bio-medical and medical datasets compared to traditional methods.",
        "Computational efficiency with feature gradient computation and column-wise propagation."
      ],
      "weaknesses": [
        "Computational demands may limit applicability to very large datasets.",
        "Performance sensitive to the choice of the number of neighbors (k).",
        "Complexity of graph construction and feature gradient calculations."
      ],
      "questions": [
        "How does GRASS perform on datasets with extremely high sparsity levels?",
        "What are the specific strategies for handling categorical features beyond the clamping technique mentioned?",
        "Can GRASS be extended to handle streaming data or incremental updates efficiently?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7ipjMIHVJt",
    "title": "DASFormer: Self-supervised Pretraining for Earthquake Monitoring",
    "std_review": {
      "summary": "The paper introduces a self-supervised pretraining approach for anomaly detection in Distributed Acoustic Sensing (DAS) data, showing improved performance over traditional models. While it addresses a key gap in the field, the evaluation lacks comparison with broader state-of-the-art SSL methods and includes some concerns about baseline simplicity, loss function choice, and uncertainty analysis.",
      "strengths": [
        "Introduces a novel self-supervised pretraining method tailored for DAS data, enhancing anomaly detection performance.",
        "Provides a comprehensive evaluation across a range of baseline models, from simple aggregation to deep learning architectures.",
        "Demonstrates practical relevance with a real-time anomaly detection framework on DAS datasets."
      ],
      "weaknesses": [
        "Evaluation primarily focuses on the necessity of the proposed pretraining without a broader comparison with state-of-the-art SSL methods.",
        "Includes simple baseline models like aggregation-0 that perform comparably to deep learning, raising questions about the necessity of more complex architectures.",
        "The pointwise loss function, while applied uniformly, is noted for its drawbacks, suggesting potential benefits from alternative loss functions.",
        "Lacks uncertainty analysis, which is crucial given the stochastic nature of DAS data.",
        "The real-time prediction window of 1 second may be insufficient for timely detection of seismic events, though this is not fully explored."
      ],
      "questions": [
        "How does the proposed pretraining technique compare to other state-of-the-art SSL methods like MAE or Moco?",
        "Could simpler models such as Random Forest or ARIMA-family models achieve comparable performance with greater interpretability?",
        "What impact does the choice of loss function have on model performance, and are there alternative loss functions better suited for anomaly detection?",
        "How does the 1-second prediction window affect the model's ability to detect seismic events in real-time?",
        "What is the effect of uncertainty on the model's predictions, and how can it be quantified?"
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "7iuFxx9Ccx",
    "title": "Resource Efficient Test-Time Training with Slimmable Network",
    "std_review": {
      "summary": "SlimTTT presents a resource‑efficient test‑time training method that dynamically adapts a model's width during inference to improve robustness to distribution shifts. The authors introduce a slimmable network architecture combined with three consistency mechanisms—Width‑Enhanced Contrastive Learning, Logit Consistency Regularization, and Global Feature Alignment—to align sub‑networks. Empirical evaluations on ImageNet‑C and CIFAR10‑C show significant improvements over baseline TTT methods, especially under limited computational budgets. While the approach is innovative and effective, concerns about implementation complexity and the need for broader evaluation are noted.",
      "strengths": [
        "Resource Efficiency: Adaptive width reduces computational cost without sacrificing robustness.",
        "Robustness to Distribution Shifts: Consistency mechanisms effectively generalize under distribution shifts.",
        "Methodological Innovation: Introduces a slimmable network architecture and multi‑width adaptation strategy."
      ],
      "weaknesses": [
        "Complexity of Implementation: Multi‑width adaptation and ensemble approach may be challenging to implement.",
        "Limited Scope of Evaluation: Only tested on ImageNet‑C and CIFAR10‑C, limiting general applicability.",
        "Lack of Detailed Analysis: Insufficient analysis of how each consistency mechanism contributes to performance.",
        "Potential Overfitting: Multiple regularizations could lead to overfitting if not properly managed."
      ],
      "questions": [
        "How does the method perform on other benchmarks or datasets beyond ImageNet‑C and CIFAR10‑C?",
        "What is the impact of each consistency mechanism on robustness, and how can they be balanced?",
        "Are there specific guidelines or tools to mitigate the implementation complexity of the multi‑width adaptation?",
        "How does the method scale to larger models or more complex distribution shifts?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7jUQHmz4Tq",
    "title": "D3AD: Dynamic Denoising Diffusion Probabilistic Model for Anomaly Detection",
    "std_review": {
      "summary": "The paper introduces D3AD, a dynamic denoising diffusion probabilistic model for anomaly detection that enhances reconstruction quality and detection efficiency. It proposes a domain adaptation strategy using a dynamic perturbation mechanism to improve feature alignment across domains, addressing limitations of existing methods. Empirical results on the MVTec dataset show significant improvements in anomaly detection accuracy and efficiency, outperforming traditional methods. The DIC noise mechanism's adaptive perturbation selection effectively handles varying anomaly severities, providing robust segmentation and localization. Overall, the paper presents a strong, innovative approach with promising results.",
      "strengths": [
        "Introduces a novel DIC noise mechanism that adaptively adjusts noise levels to improve reconstruction quality and anomaly detection.",
        "Proposes a dynamic perturbation mechanism for domain adaptation, addressing limitations of static feature-based distance metrics.",
        "Demonstrates superior performance on complex datasets like MVTec, achieving higher accuracy and efficiency compared to existing methods.",
        "Provides strong empirical evidence supporting the effectiveness of the proposed approach across different anomaly severities.",
        "Balances computational efficiency with detection accuracy through reduced resolution latent diffusion modeling."
      ],
      "weaknesses": [
        "The dynamic nature of DIC noise and perturbation mechanism may introduce implementation complexity and require more computational resources.",
        "Evaluation primarily focuses on the MVTec dataset, which may limit the generalizability of the findings to other real-world scenarios.",
        "Lacks a detailed theoretical analysis to further strengthen the credibility of the proposed method.",
        "Potential risk of overfitting due to the adaptive noise and perturbation mechanisms, which could affect performance on unseen data."
      ],
      "questions": [
        "How does the proposed DIC noise mechanism perform on datasets with varying levels of noise and complexity beyond MVTec?",
        "What are the specific strategies employed to prevent overfitting in the dynamic perturbation mechanism?",
        "Could the theoretical justification for the improvement in reconstruction quality be further elaborated to enhance the method's credibility?",
        "How does the model's performance scale with increasing dataset size and diversity?",
        "Are there any specific scenarios or types of anomalies where the proposed method might underperform compared to other state-of-the-art techniques?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7jWiBAWG0b",
    "title": "Learning Guarantees for Non-convex Pairwise SGD with Heavy Tails",
    "std_review": {
      "summary": "The paper investigates SGD under sub-Weibull noise, deriving generalization bounds that improve with heavier tails. While it offers novel insights and a clear analysis, it has several issues, including ambiguous distributional assumptions and a lack of comparison with pointwise SGD. The overall contribution is valuable but needs clearer exposition and additional analyses.",
      "strengths": [
        "Novel analysis of SGD under sub-Weibull noise, a less explored regime.",
        "Clear derivation of generalization bounds that depend on the heavy-tail parameter θ.",
        "Mathematically rigorous with well-defined assumptions."
      ],
      "weaknesses": [
        "Ambiguity in distributional assumptions regarding sub-Weibull tails.",
        "Potential lack of novelty compared to existing work on finite-variance noise.",
        "Omission of comparison with pointwise SGD.",
        "Monotonic dependence on the heavy-tail parameter θ may oversimplify the analysis.",
        "Results presented in expectation rather than high-probability bounds."
      ],
      "questions": [
        "How do sub-Weibull tails provide additional informational content beyond second-moment assumptions?",
        "Should the paper compare results with pointwise SGD to broaden its impact?",
        "What are the potential non-monotonic dependencies on θ that could be explored?",
        "How can the expectation in Assumptions 3.8 and 3.9 be clarified to avoid ambiguity?",
        "Why is the Lipschitz condition with respect to the loss function excluded, and what are the implications?"
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "7Jwpw4qKkb",
    "title": "Generating Stealthy Jailbreak Prompts on Aligned Large Language Models",
    "std_review": {
      "summary": "The paper presents a novel method to enhance LLM robustness by generating specific tokens that indicate successful command execution, using a handcrafted DAN baseline. It evaluates the approach with a 'Recheck' metric and compares it across several models, including GPT‑4 and GPT‑3.5 Turbo. While the method shows promise, its evaluation is limited by the absence of comprehensive baseline comparisons and a full GPT‑4 assessment, and the transferability results are under‑explored.",
      "strengths": [
        "Clear objective definition of generating specific tokens for command execution.",
        "Innovative handcrafted DAN baseline for benchmarking LLM outputs.",
        "Comprehensive evaluation using both the Recheck metric and comparisons with state-of-the-art models."
      ],
      "weaknesses": [
        "Limited baseline comparisons could better highlight the novelty of the method.",
        "Omission of GPT‑4 evaluation weakens the claim of effectiveness across top-tier models.",
        "Lack of detailed transferability results for GPT‑3.5 Turbo hinders understanding of practical applicability."
      ],
      "questions": [
        "How does the proposed method compare to existing baselines not related to DAN?",
        "What are the detailed results of evaluating the method's transferability to GPT‑3.5 Turbo?",
        "Could the robustness of the method be further tested across a broader range of prompts and scenarios?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "7KDuQPrAF3",
    "title": "",
    "std_review": {
      "summary": "The paper introduces FECCT, a neural decoder for LDPC codes that uses self-attention to improve error correction. It demonstrates strong performance on short to moderate-length codes, outperforming classical belief propagation and other neural decoders. While promising, concerns about scalability to very long codes, interpretability of the self-attention mechanism, and computational complexity limit its immediate acceptance.",
      "strengths": [
        "Novel integration of self-attention in a neural decoder for LDPC codes.",
        "Federated learning setup enables generalization across diverse code families.",
        "Competitive performance on short to moderate-length codes."
      ],
      "weaknesses": [
        "Limited generalization to very long codes.",
        "Interpretability challenges due to complex self-attention mechanism.",
        "Higher computational complexity compared to state-of-the-art neural decoders."
      ],
      "questions": [
        "How does FECCT perform on significantly longer codes (e.g., hundreds of bits)?",
        "What strategies are proposed for deploying FECCT in resource-constrained environments?",
        "How does FECCT compare to specialized neural decoders fine-tuned for specific code families?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "7LZjuA4AB2",
    "title": "Ask Your Distribution Shift if Pre-Training is Right for You",
    "std_review": {
      "summary": "The paper proposes a method to improve model robustness against distribution shifts by distinguishing between in‑support and out‑of‑support examples using a probability density ratio. It introduces a pre‑training on a broad distribution followed by fine‑tuning on task‑specific data, evaluated with a new 'Effective Robustness' metric. Experiments show the method outperforms standard fine‑tuning, especially on biased datasets, though its generalizability and comparison with state‑of‑the‑art methods remain limited.",
      "strengths": [
        "Clear definition of support using a probability density ratio.",
        "Empirical validation demonstrating clear improvements over standard fine‑tuning.",
        "Intuitive 'Effective Robustness' metric for evaluating trade‑offs.",
        "Practical recommendations for dataset curation and model training."
      ],
      "weaknesses": [
        "Limited scope of out‑of‑support examples based on a simple density ratio.",
        "Assumes independent and identically distributed data, which may not hold in practice.",
        "Effectiveness evaluated primarily on synthetic datasets, raising generalizability concerns.",
        "Lacks comparison with state‑of‑the‑art methods for distribution shift robustness."
      ],
      "questions": [
        "How does the method perform on more complex distribution shifts beyond simple density ratios?",
        "What is the impact of real‑world data non‑IID assumptions on the proposed approach?",
        "How does the method generalize to other domains beyond synthetic datasets?",
        "How does the proposed method compare with recent state‑of‑the‑art techniques for distribution shift robustness?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7M0EzjugaN",
    "title": "Online Continual Learning for Interactive Instruction Following Agents",
    "std_review": {
      "summary": "The paper proposes Confidence-Aware Moving Average (CAMA), a method for continual learning in RL that dynamically adjusts the influence of new experiences based on confidence scores derived from model logits. Experiments show CAMA outperforms existing strategies in both performance and stability across various benchmarks. The innovative approach of using confidence scores to guide learning is a significant contribution, though it introduces implementation complexities and relies on model output quality.",
      "strengths": [
        "Introduces a novel confidence-based weighting scheme for continual learning.",
        "Demonstrates clear empirical improvements over existing methods.",
        "Provides thorough evaluations across multiple benchmark tasks."
      ],
      "weaknesses": [
        "Relies on a specific mathematical formulation for confidence scores, which may be complex to implement.",
        "Effectiveness is tied to model logits, which can be sensitive to hyperparameters.",
        "Does not explore a wide range of alternative approaches."
      ],
      "questions": [
        "How robust is CAMA to variations in confidence score thresholds across different environments?",
        "Can CAMA be integrated with other continual learning techniques to further enhance performance?",
        "What are the computational costs associated with calculating confidence scores during training?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7m5jhNXklB",
    "title": "VTruST : Controllable value function based subset selection for Data-Centric Trustworthy AI",
    "std_review": {
      "summary": "The paper introduces VTruST, a framework that simultaneously optimizes model accuracy and robustness through a novel value function formulation. It employs a single regularization weight λ to balance these objectives, using validation loss computed on both original and augmented data. The approach is demonstrated on image datasets, with a focus on fairness as a secondary robustness metric. While innovative, the framework's limitations in data type generalizability and lack of theoretical guarantees are significant concerns.",
      "strengths": [
        "Unified Value Function: Combines accuracy and robustness into a single objective, simplifying the optimization process.",
        "Parameter Efficiency: Uses a single λ to balance multiple objectives, reducing the need for extensive hyperparameter tuning.",
        "Clear Experimental Setup: Provides a transparent and reproducible methodology for evaluating the trade‑offs between trustworthiness and accuracy."
      ],
      "weaknesses": [
        "Limited Data Types: Focuses solely on image data, potentially limiting the generalizability of the findings to other domains like tabular data.",
        "Single Weight Parameterization: The use of a single λ may not capture complex trade‑offs between accuracy and robustness effectively.",
        "Lack of Theoretical Guarantees: Does not provide theoretical bounds on the trade‑off between trustworthiness and accuracy.",
        "Absence of Advanced Augmentations: Relies on heuristic augmentations, which might not be optimal for all datasets."
      ],
      "questions": [
        "How can the framework be extended to other data types, such as tabular data, where different augmentation strategies might be more effective?",
        "What theoretical guarantees can be provided regarding the trade‑off between trustworthiness and accuracy?",
        "Could more principled augmentation techniques improve the robustness of the models beyond the heuristic approaches used?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "7Mq096hr9Y",
    "title": "OpenMixup: A Comprehensive Mixup Benchmark for Visual Classification",
    "std_review": {
      "summary": "OpenMixup is a comprehensive benchmarking framework for evaluating mixup methods across various datasets and deep learning tasks. It provides a standardized environment with robust performance metrics and visualization tools, making it a valuable resource for researchers. The framework's strengths include comprehensive coverage, ease of use, and extensibility. However, it has limitations such as limited real-world applications and smaller community support. Overall, the paper is well-suited for research purposes and is recommended for acceptance.",
      "strengths": [
        "Comprehensive coverage of mixup methods and datasets",
        "Ease of use with clear documentation and integration",
        "Robust performance metrics beyond accuracy",
        "Powerful visualization and analysis tools",
        "Designed for extensibility"
      ],
      "weaknesses": [
        "Limited real-world applications",
        "Smaller community of contributors",
        "Potential documentation gaps",
        "Narrow scope of performance evaluation"
      ],
      "questions": [
        "How can OpenMixup be extended to include more real-world datasets?",
        "What additional performance metrics could be incorporated to enhance evaluation?",
        "How can the community be encouraged to contribute to OpenMixup?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7mR83Q12cJ",
    "title": "Counterfactual Data Augmentation with Contrastive Learning",
    "std_review": {
      "summary": "The paper introduces a novel contrastive learning framework for estimating the Conditional Average Treatment Effect (CATE), generating synthetic treated data that closely resembles the original treated data to reduce bias. Empirical evaluations show significant improvements over baselines, especially in limited data scenarios, highlighting its potential for handling heterogeneous treatment effects. While the method is theoretically justified and empirically validated, implementation challenges and reliance on strong assumptions limit its practical applicability.",
      "strengths": [
        "Innovative use of contrastive learning to generate high-quality synthetic treated data.",
        "Clear theoretical foundation linking contrastive loss to CATE consistency under unconfoundedness.",
        "Empirical validation demonstrating strong performance improvements over existing methods."
      ],
      "weaknesses": [
        "Complexity of implementation due to reliance on contrastive learning and specific hyperparameters.",
        "Theoretical justification heavily depends on the unconfoundedness assumption, which may not hold in practice.",
        "Limited comparison with other state-of-the-art methods could strengthen the claim of superiority."
      ],
      "questions": [
        "How can practitioners with limited expertise in contrastive learning effectively implement and tune the proposed method?",
        "What are the practical implications of the unconfoundedness assumption in real-world applications?",
        "How does the method compare to recent advancements in causal inference beyond the ReiszNet baseline?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7oYpj8BOLW",
    "title": "BackBench: Are Vision Language Models Resilient to Object-to-Background Context?",
    "std_review": {
      "summary": "The paper proposes a two-stage pipeline that conditions a diffusion model on background attributes extracted from textual descriptions, improving image quality and background consistency. It introduces a practical method for leveraging textual context in generative models and provides strong empirical evidence across multiple datasets. While the approach shows promise, it has limitations in capturing nuanced background details and introduces additional computational overhead.",
      "strengths": [
        "Innovative background conditioning method for diffusion models",
        "Clear and well-documented pipeline with a lightweight language model",
        "Empirical validation across multiple datasets and metrics"
      ],
      "weaknesses": [
        "Limited granularity of background attributes captured by the language model",
        "Increased computational cost for real-time or resource-constrained environments",
        "Lack of comparison with state-of-the-art baselines that specifically incorporate background information"
      ],
      "questions": [
        "How does the method handle more complex background scenarios with varying lighting or texture?",
        "What is the impact of background conditioning on the generation time of the diffusion model?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7Phicg0WAg",
    "title": "FlexCap: Generating Rich, Localized, and Flexible Captions in Images",
    "std_review": {
      "summary": "FlexCap introduces a novel approach to vision‑language models by generating localized, flexible‑length captions tied to specific image regions. The system, FlexCap‑LLM, leverages these localized captions to enhance downstream tasks like visual question answering (VQA) using a pre‑trained large language model (LLM). While demonstrating competitive performance on benchmarks, the method's novelty is modest, and its effectiveness hinges on dataset quality and LLM performance.",
      "strengths": [
        "Localized captions provide interpretable, granular descriptions of image content.",
        "Flexible caption length supports nuanced and context‑aware descriptions.",
        "Efficiently uses pre‑trained LLMs, reducing the need for end‑to‑end multimodal training."
      ],
      "weaknesses": [
        "The localized captioning idea is incremental compared to prior work.",
        "Performance is contingent on the quality of the training dataset and the LLM used.",
        "Risk of generating factually incorrect or misleading captions."
      ],
      "questions": [
        "How does FlexCap‑LLM compare to other localized captioning baselines in terms of novelty and effectiveness?",
        "What robustness checks have been performed on caption quality and hallucination across diverse datasets?",
        "Can ablation studies isolate the impact of localized captions on downstream task performance?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "7pVIFJW2Hp",
    "title": "FigCaps-HF: A Figure-to-Caption Generative Framework and Benchmark with Human Feedback",
    "std_review": {
      "summary": "The paper introduces CLIPCap, a figure-to-caption model that adapts CLIP to generate captions using reinforcement learning from human feedback. It demonstrates competitive performance on FigureQA, outperforming baselines like ViT+GPT2, and shows robustness to caption length. While innovative, the approach relies on an oracle model for feedback, which may introduce bias, and lacks a thorough comparison with recent related works. With minor revisions, the paper could more convincingly showcase its strengths.",
      "strengths": [
        "Innovative adaptation of CLIP to generate figure captions.",
        "Effective use of reinforcement learning from human feedback (RLHF) to improve caption quality.",
        "Modular architecture that can be easily integrated with different backbone models."
      ],
      "weaknesses": [
        "Reliance on an oracle model for generating 'good' or 'bad' tokens may introduce bias.",
        "Modest improvements over ViT+GPT2 suggest limited adaptability of CLIP.",
        "Lack of comprehensive discussion of related work, missing recent benchmarks like Matcha and Deplot."
      ],
      "questions": [
        "How does the performance of CLIPCap compare when using heuristic-based feedback instead of an oracle model?",
        "Could using CLIPCap itself as the backbone model yield better results for figure caption generation?",
        "What specific metrics beyond BLEU-4 should be reported to fully evaluate caption quality?",
        "How does the human feedback data (helpfulness, takeaway, visual, OCR) influence the RLHF process?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "7pWRLDBAtc",
    "title": "Heterogeneous Personalized Federated Learning by Local-Global Updates Mixing via Convergence Rate",
    "std_review": {
      "summary": "The paper introduces a novel federated learning framework that integrates local model updates with a global aggregation step using a last-layer latent feature for trace approximation. It effectively balances personalization across heterogeneous clients while maintaining privacy and efficiency, outperforming baselines on several benchmark datasets. The method shows promise but has limitations related to model architecture assumptions and scalability, which could be addressed in future work.",
      "strengths": [
        "Innovative trace approximation using a last-layer latent feature enhances personalization.",
        "Balances personalization and generalization across heterogeneous clients.",
        "Provides a clear theoretical foundation with rigorous derivations.",
        "Demonstrates robust empirical performance on multiple datasets."
      ],
      "weaknesses": [
        "Assumes identical model backbones across clients, limiting applicability.",
        "Computational cost, especially GPU memory usage, may be a concern.",
        "Performance may degrade with a large number of clients due to communication overhead.",
        "Lacks detailed analysis of model architecture complexity impact."
      ],
      "questions": [
        "How can the method be adapted for clients with diverse model architectures?",
        "What is the impact of model architecture complexity on the method's performance?",
        "How does the method scale with an increasing number of clients?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7q7s5fXEpP",
    "title": "Stealthy Imitation: Reward-guided Environment-Free Policy Stealing",
    "std_review": {
      "summary": "The paper proposes a defense mechanism against adversarial attacks by approximating the state space with a normal distribution and incorporating uncertainty quantification. It demonstrates effectiveness on image and lidar datasets against both white-box and black-box attacks, showing promise for real-world applications. However, the reliance on a normal distribution may limit applicability in high-dimensional or non-Gaussian scenarios, and the computational cost for scaling is not fully addressed. Adaptive attacks and distribution shifts are not adequately explored, which could impact long-term robustness.",
      "strengths": [
        "Introduces a novel defense leveraging uncertainty quantification through normal distribution approximation.",
        "Demonstrates strong performance across diverse datasets (image and lidar) and attack types.",
        "Provides clear experimental evidence of improved robustness against adversarial attacks."
      ],
      "weaknesses": [
        "Reliance on normal distribution may not be optimal for high-dimensional or non-Gaussian state spaces.",
        "Computational cost for scaling to larger inputs is not thoroughly addressed.",
        "Lack of analysis on defense performance against adaptive attacks."
      ],
      "questions": [
        "How does the defense scale to larger image or lidar inputs in terms of computational cost?",
        "What strategies can be employed to mitigate adaptive attacks that exploit out-of-range states?",
        "How does the method handle distribution shifts over time as attacker and victim distributions evolve?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "7QI7tVrh2c",
    "title": "Adversarial Adaptive Sampling: Unify PINN and Optimal Transport for the Approximation of PDEs",
    "std_review": {
      "summary": "The paper introduces Adversarial Adaptive Sampling (AAS), a novel method for solving PDEs using neural networks that combines adversarial training with adaptive sampling. AAS demonstrates superior convergence speed and accuracy over existing techniques, especially for high-dimensional problems, and provides theoretical convergence guarantees. While the method is innovative and theoretically sound, it faces challenges such as implementation complexity, training instability, and limited generalization to broader problem classes.",
      "strengths": [
        "Innovative combination of adversarial training and adaptive sampling for PDEs.",
        "Significant improvements in convergence speed and accuracy over traditional methods.",
        "Strong theoretical foundation with formal convergence proofs."
      ],
      "weaknesses": [
        "Complex implementation involving advanced neural network architectures and adversarial training.",
        "Potential training instability due to adversarial components.",
        "Limited testing on a broader range of PDEs, including singularly perturbed or nonlinear equations."
      ],
      "questions": [
        "How can the training instability of AAS be mitigated for broader applicability?",
        "What is the impact of the regularization term on the method's performance in highly irregular problem domains?",
        "How does AAS scale to very high-dimensional problems, and what computational cost implications arise?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7QlKLvfVge",
    "title": "Directional Rank Reduction for Backdoor Defense",
    "std_review": {
      "summary": "The paper introduces Directional Rank Reduction (DRR), a novel method for detecting and mitigating backdoors in deep neural networks by leveraging kurtosis. DRR identifies a direction vector that reduces kurtosis, exposing latent backdoor features. Empirical results show strong effectiveness against multiple backdoor attacks while maintaining model performance. Despite some limitations, the method is theoretically sound and empirically validated, leading to an acceptance.",
      "strengths": [
        "Innovative use of kurtosis as a backdoor detection metric.",
        "Directional pruning approach provides a flexible framework.",
        "Strong theoretical foundation and empirical validation."
      ],
      "weaknesses": [
        "Relies on assumptions about latent separability and isotropic covariance.",
        "Initialization of direction vector can affect performance.",
        "Computational overhead from optimizing vectors in each layer.",
        "Dependence on access to backdoored data for initialization."
      ],
      "questions": [
        "How robust is DRR to violations of the latent separability assumption?",
        "What are the practical implications of requiring backdoored data for initialization?",
        "Can DRR be extended to work with models that have limited access to backdoored data?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7QncaLObzi",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a binary hyperbolic embedding method that reduces storage and computational costs while maintaining retrieval performance. It leverages a Hamming distance approximation to hyperbolic distances, enabling efficient similarity search. The method is evaluated on various datasets and models, showing strong scalability and generalization across different hyperbolic geometries and backbones. Despite minor approximation errors, the approach offers significant efficiency gains with minimal loss in performance.",
      "strengths": [
        "Storage and computational efficiency through binary representation",
        "Scalability with large datasets and models",
        "Strong theoretical foundation for Hamming distance approximation",
        "Generalization across different hyperbolic models and backbones"
      ],
      "weaknesses": [
        "Practical impact of approximation error on retrieval accuracy is not fully quantified",
        "Limited exploration of quantization bit sensitivity in resource-constrained environments",
        "Evaluation focused on a subset of datasets and models"
      ],
      "questions": [
        "How does the method perform on highly imbalanced or sparse datasets?",
        "What is the impact of different quantization algorithms on retrieval accuracy?",
        "Can the method be further optimized for edge devices with extreme memory constraints?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7rex8lEZH2",
    "title": "Prompt Tuning with Diffusion for Few-Shot Pre-trained Policy Generalization",
    "std_review": {
      "summary": "The paper introduces Prompt Diffuser, a method for improving few-shot policy generalization in offline RL by generating and optimizing prompts using a diffusion model. It demonstrates significant improvements over baselines and shows strong generalization to unseen environments. While promising, the method's computational cost and sensitivity to prompt length are noted as areas for improvement.",
      "strengths": [
        "Introduces a novel prompt-based approach for few-shot RL generalization.",
        "Demonstrates substantial performance gains in few-shot scenarios.",
        "Shows robust generalization to unseen environments."
      ],
      "weaknesses": [
        "Computational overhead from diffusion model may limit scalability.",
        "Performance sensitive to prompt length, requiring careful tuning.",
        "Lack of direct comparison with expert-provided prompts.",
        "Potential reproducibility issues due to hyperparameter choices."
      ],
      "questions": [
        "How does the method perform when compared to expert-provided prompts?",
        "What is the optimal prompt length for different tasks?",
        "How robust is the method to variations in hyperparameters and training data?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7sASqAmGaO",
    "title": "Augmenting Negative Representations",
    "std_review": {
      "summary": "The paper introduces AugNeg, a contrastive learning approach that enhances domain-invariant learning by incorporating augmented negative examples. It proposes a new loss function and demonstrates improved performance on benchmark datasets, but has some concerns regarding hyperparameter choices, result consistency, and clarity in certain equations.",
      "strengths": [
        "Introduces a novel contrastive learning approach called AugNeg.",
        "Proposes a new loss function that leverages additional negative examples.",
        "Demonstrates superior performance on multiple benchmark datasets."
      ],
      "weaknesses": [
        "Lacks detailed justification for certain hyperparameters.",
        "Shows inconsistency in results compared to existing methods.",
        "Unclear relationship between key equations."
      ],
      "questions": [
        "Why are certain hyperparameters, like the batch size for Cassle, not justified?",
        "What explains the discrepancy between AugNeg and SyCON scores for Domain-IL?",
        "Were MoCo and CaSSLe models run with an extended queue size?",
        "Why does the gradient of the AugNeg loss remain nearly the same direction despite additional negative examples?",
        "How do Equation 5 and Equation 4 relate, and why might they appear offsetting?"
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "7Scc7Nl7lg",
    "title": "Revealing Vision-Language Integration in the Brain with Multimodal Networks",
    "std_review": {
      "summary": "The paper introduces a novel framework for aligning multimodal neural networks with brain activity, using fMRI and machine learning to decode brain regions involved in vision-language integration. It demonstrates significant overlap between predicted multimodal regions and known language-related areas, advancing neuro-AI. While innovative, the study has limitations such as limited brain region coverage and potential model bias, which could affect generalizability.",
      "strengths": [
        "Innovative multimodal approach combining fMRI and machine learning.",
        "Robust experimental design with precise brain activity mapping.",
        "Clear contribution to neuro-AI by identifying key brain regions for vision-language integration."
      ],
      "weaknesses": [
        "Limited coverage of brain regions involved in vision-language integration.",
        "Choice of multimodal models may influence results and limit generalizability.",
        "Statistical controls could be further explored for robustness."
      ],
      "questions": [
        "How comprehensive is the coverage of brain regions involved in vision-language integration?",
        "What are the implications of the choice of multimodal models on the generalizability of the findings?",
        "How robust are the statistical controls used to ensure the significance of the identified brain regions?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7sMR09VNKU",
    "title": "Learning System Dynamics from Sensory",
    "std_review": {
      "summary": "The paper introduces a Koopman‑based learning framework for nonlinear dynamical systems, leveraging optimal trajectories to learn a linear representation. While it demonstrates high accuracy on simple systems like a pendulum and cart‑pole, the method's broader applicability, theoretical foundations, and practical deployment remain underexplored. The reviewer finds the approach promising but flags significant limitations in scope, reproducibility, and theoretical guarantees.",
      "strengths": [
        "Novel integration of Koopman theory with deep learning for nonlinear system modeling.",
        "Demonstrated high accuracy in learning dynamics for simple systems.",
        "Use of proximal regularization to handle non‑convex optimization challenges."
      ],
      "weaknesses": [
        "Limited scope of system demonstrations, only tested on simple systems.",
        "Reliance on optimal trajectories for training, restricting real‑world applicability.",
        "Lack of extensive comparisons with established control techniques.",
        "Absence of publicly available code and detailed reproducibility information.",
        "No theoretical analyses provided for convergence or approximation error."
      ],
      "questions": [
        "How does the method generalize to more complex or high‑dimensional systems beyond simple pendulums and cart‑poles?",
        "What are the theoretical conditions under which the Koopman embedding is guaranteed, and how does the control‑affine form of the system meet these conditions?",
        "Can the method be adapted to learn from raw sensory data instead of requiring optimal trajectories?",
        "What are the stability guarantees of the proposed approach compared to other Koopman‑based methods?",
        "How does the method perform in terms of computational cost and robustness on nonlinear systems beyond the simple examples provided?"
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "7suavRDxe8",
    "title": "Plausibly Deniable Encryption",
    "std_review": {
      "summary": "The paper introduces a novel approach to plausible deniability using a stochastic language model, achieving a formal security model and empirical evaluation. While innovative, it faces practical challenges such as deterministic/lossless encoding, key choice implications, prompting effects, and statistical test limitations. The authors' overall contribution is promising but requires addressing these concerns for broader applicability.",
      "strengths": [
        "Innovative use of stochastic models for plausible deniability",
        "Clear formal security model and theoretical foundation",
        "Empirical evaluation through frequency and correlation tests"
      ],
      "weaknesses": [
        "Challenges in ensuring deterministic and lossless encoding/decoding with stochastic models",
        "Insufficient exploration of key choice implications on security and correctness",
        "Lack of comprehensive analysis on prompting effects and trade-offs",
        "Reliance on frequency and correlation tests may not be sufficient for cryptographic security",
        "Unclear guidelines on the required level of randomness for encoded messages",
        "Practical feasibility concerns regarding computational overhead and shared model requirements"
      ],
      "questions": [
        "How does varying the quantization granularity (k) impact the security and correctness of the encoding/decoding process?",
        "What is the comprehensive analysis of prompting effects on deniability and trade-offs?",
        "What additional formal criteria are needed to ensure that encoded strings are indistinguishable from white noise?",
        "How can the computational overhead and shared model requirements be addressed for practical implementation?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "7TOs9gjAg1",
    "title": "Removing Biases from Molecular Representations via Information Maximization",
    "std_review": {
      "summary": "The paper introduces InfoCORE, a self-supervised learning framework that enhances representation learning in the presence of batch effects by balancing intra-cluster and inter-cluster similarity through a hyperparameter λ. It demonstrates superior performance over existing methods on simulation data, providing strong empirical evidence. While the evaluation is limited to simulation data and lacks comprehensive hyperparameter analysis, the insights into λ's impact and the framework's adaptability are valuable.",
      "strengths": [
        "Introduces a novel self-supervised learning framework specifically addressing batch effects.",
        "Incorporates a hyperparameter λ to flexibly balance intra-cluster and inter-cluster similarity.",
        "Demonstrates superior performance over existing methods through rigorous simulation experiments."
      ],
      "weaknesses": [
        "Evaluation is limited to simulation data, potentially not capturing real-world complexity.",
        "Lacks comprehensive analysis of λ's impact across a wide range of values.",
        "Qualitative evaluation is limited to examining only the first two principal components."
      ],
      "questions": [
        "How does InfoCORE perform on real-world datasets with diverse batch effects?",
        "What are the optimal λ values for different types of high-throughput data?",
        "How does InfoCORE compare to other state-of-the-art methods in terms of computational efficiency?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7Ttk3RzDeu",
    "title": "BoooookScore:",
    "std_review": {
      "summary": "The paper introduces BOOOOKSCORE, a novel coherence metric for text summaries inspired by book chapter coherence. It evaluates the metric on a book‑summary dataset, exploring model parameters and summary length effects. While showing promise, the study has several methodological and technical limitations, such as the choice of precision/recall evaluation, specific coherence error examples, and the exclusion of LLaMA2 due to reproducibility issues.",
      "strengths": [
        "Introduces a novel coherence metric inspired by book chapter coherence.",
        "Provides a comprehensive evaluation against human annotations.",
        "Explores the impact of model parameters like nucleus sampling and temperature on summary quality."
      ],
      "weaknesses": [
        "Evaluates BOOOOKSCORE on precision versus recall, which may not fully capture coherence nuances.",
        "Includes specific coherence error examples that may not generalize well.",
        "Uses a nucleus probability of 1, leading to overly deterministic outputs.",
        "Sets a high temperature, potentially resulting in less focused summaries.",
        "Excludes LLaMA2 from incremental updating experiments, raising reproducibility concerns.",
        "Sentence‑level scoring may favor summaries with many short sentences.",
        "Fails to evaluate faithfulness alongside coherence.",
        "Lacks thorough reproducibility analysis for incremental updating."
      ],
      "questions": [
        "How does the choice of precision/recall evaluation impact the interpretation of coherence scores?",
        "Could the specific coherence error examples be generalized to other types of coherence issues?",
        "What are the long‑term reproducibility implications of excluding LLaMA2 from experiments?",
        "How does the sentence‑level scoring approach affect the overall coherence assessment?",
        "What additional metrics (e.g., faithfulness) could complement the current evaluation framework?"
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "7U5QE9T4hI",
    "title": "Learning to Extrapolate and Adjust:",
    "std_review": {
      "summary": "The paper introduces LEAF, a framework for online time series forecasting that addresses concept drift by separating macro-drift (long-term trends) and micro-drift (short-term fluctuations) through dedicated modules. The approach shows strong performance on multiple datasets and balances efficiency and accuracy, making it suitable for real-world applications. While the framework is well‑designed and effective, its complexity may hinder adoption by practitioners unfamiliar with drift concepts, and the evaluation is limited to a few datasets. Computational complexity of the adjustment module could also be a concern for latency‑sensitive applications.",
      "strengths": [
        "Introduces a novel LEAF framework specifically designed to tackle concept drift in online time series forecasting.",
        "Effectively separates and addresses macro-drift and micro-drift, providing a clear and structured approach.",
        "Demonstrates strong performance compared to existing baselines across multiple datasets.",
        "Balances model efficiency and accuracy, making it practical for real-world use.",
        "Provides a clear and interpretable framework, aiding practitioners."
      ],
      "weaknesses": [
        "The complexity of the framework may pose a challenge for practitioners unfamiliar with macro-drift and micro-drift concepts.",
        "Evaluation is limited to a few datasets, potentially underestimating robustness and generalizability.",
        "Computational complexity of the relation network and embedding function in the adjustment module could be problematic for real-time applications.",
        "Lacks detailed analysis of trade-offs between model efficiency and accuracy."
      ],
      "questions": [
        "How does the framework handle scenarios where both macro- and micro-drift occur simultaneously?",
        "What are the computational requirements for deploying LEAF in real-time systems with strict latency constraints?",
        "Could you provide more detailed ablations or experiments to evaluate the impact of different components on performance?",
        "How does LEAF perform on datasets with high-frequency concept drift or abrupt changes?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7UhxsmbdaQ",
    "title": "",
    "std_review": {
      "summary": "The paper presents a novel generative model for molecular design that combines an autoregressive language model with an augmented memory mechanism to improve the diversity and quality of generated molecules. Experiments show significant improvements over existing baselines, particularly when combined with beam enumeration. While the approach is innovative, the review highlights several areas for improvement, such as clearer description of the self-conditioning scheme and more detailed ablation studies. Overall, the paper is well‑structured, with a clear experimental setup and strong empirical results, leading to an acceptance recommendation.",
      "strengths": [
        "Introduces an innovative augmented memory mechanism that enhances the generation of chemically valid and diverse molecules.",
        "Demonstrates superior performance over existing baselines, both in terms of diversity and quality.",
        "Provides comprehensive evaluation through ablation studies and quantitative metrics, supporting the method's effectiveness.",
        "Clearly documents the experimental setup, making the results reproducible and comparable."
      ],
      "weaknesses": [
        "The description of the self-conditioning scheme is somewhat vague, lacking concrete details.",
        "Ablation studies do not explicitly quantify the standalone contribution of the augmented memory component.",
        "Comparison with state-of-the-art methods is cursory, and could be more detailed.",
        "The paper does not explore potential optimizations or alternative configurations for the combined approach."
      ],
      "questions": [
        "Could you provide a more detailed explanation of how the self-conditioning scheme guides the generation process?",
        "What are the specific ablation studies conducted on the standalone impact of the augmented memory component?",
        "How does the proposed method compare to the latest advancements in molecular generation models?",
        "Are there any potential optimizations or alternative configurations for the combination of beam enumeration with other generative models that could further enhance performance?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7v3tkQmtpE",
    "title": "Rethinking Decision Transformer via Hierarchical Reinforcement Learning",
    "std_review": {
      "summary": "The paper introduces V-ADT, a hierarchical RL framework that combines Inverse Q-Learning with a transformer-based high-level policy to improve planning efficiency. It demonstrates significant gains in sample efficiency and task completion rates on benchmark tasks, supported by a solid theoretical foundation. While the approach shows promise, it has limitations such as reliance on current state conditioning and dependence on the quality of learned Q and V functions, and it primarily focuses on single-task learning.",
      "strengths": [
        "Innovative integration of value functions using Inverse Q-Learning to enhance decision-making.",
        "Adoption of a transformer-based high-level policy for flexible and efficient learning of complex action sequences.",
        "Demonstrated improvements in sample efficiency, making the method more practical for real-world applications."
      ],
      "weaknesses": [
        "Reliance on current state conditioning may limit the model's ability to capture long-term dependencies.",
        "Performance heavily dependent on the accuracy of learned Q and V functions.",
        "Primarily evaluated on single-task learning scenarios, with limited analysis on multi-task or hierarchical learning.",
        "Lack of detailed analysis comparing performance with alternative function approximators."
      ],
      "questions": [
        "How could the method be extended to handle multi-task or hierarchical learning scenarios?",
        "What impact would alternative function approximators have on the robustness and generalizability of the approach?",
        "How does conditioning on the current state affect the model's ability to capture long-term dependencies in complex environments?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7vKWg2Vdrs",
    "title": "LeBD: A Run-time Defense Against Backdoor Attack in YOLO",
    "std_review": {
      "summary": "The paper introduces CA-LeBD, a defense mechanism that integrates digital and physical constraints to detect backdoor attacks in YOLO models. While demonstrating strong performance in experiments, the method suffers from a performance gap compared to state-of-the-art benchmarks and scalability issues. The authors should address these concerns to enhance its practical applicability.",
      "strengths": [
        "Innovative integration of digital and physical backdoor attack defenses.",
        "Robust detection of backdoor triggers in both digital and physical settings.",
        "Strong theoretical foundation supporting its effectiveness."
      ],
      "weaknesses": [
        "Significant performance gap relative to existing benchmarks.",
        "Scalability concerns may limit its use in large-scale applications.",
        "Limited generalizability across different domains and physical triggers."
      ],
      "questions": [
        "How can the computational overhead of CA-LeBD be reduced to improve its scalability?",
        "What guidelines can be provided for determining the optimal number of classes to protect?",
        "How can CA-LeBD be extended to other model architectures, such as vision transformers?"
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "7VPTUWkiDQ",
    "title": "Provable Compositional Generalization for Object-Centric Learning",
    "std_review": {
      "summary": "The paper introduces a novel consistency loss for slot-based latent variable models, aiming to improve object representation across multiple views. It shows strong empirical results on synthetic datasets, particularly in handling occlusions and complex interactions, suggesting potential for real-world applications. However, the method's real-world validation is limited, and the decoder's additivity constraint may restrict its ability to capture highly complex interactions. Overall, the approach is promising but requires more rigorous testing and a more principled regularization strategy.",
      "strengths": [
        "Innovative consistency loss that enforces uniformity across latent slots.",
        "Clear theoretical motivation for maintaining slot consistency.",
        "Empirical success on synthetic datasets, especially in challenging scenarios."
      ],
      "weaknesses": [
        "Limited real-world validation; performance evaluated primarily on synthetic data.",
        "Decoder additivity constraint may limit expressivity for complex interactions.",
        "Lack of a more principled regularization approach, such as learning a prior over latent slots."
      ],
      "questions": [
        "How does the method perform on real-world datasets with diverse and complex scenes?",
        "What are the computational implications of the additional regularization terms?",
        "Could learning a prior over latent slots improve the model's robustness and interpretability?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "7VVGO0kuuY",
    "title": "Learning Causal Dynamics Models in Object-Oriented Environments",
    "std_review": {
      "summary": "The paper introduces the Object-Oriented Causal Dynamics Model (OOCDM), which effectively scales to large object-oriented environments and improves causal graph accuracy through object-oriented representations and symmetry assumptions. It demonstrates strong generalization to out-of-distribution data and performs well on benchmark tasks, outperforming existing baselines. The OOCDM is a valuable contribution to causal discovery in complex environments, though some practical implementation challenges remain.",
      "strengths": [
        "The OOCDM scales well with the number of objects and attributes, maintaining computational efficiency.",
        "It achieves high causal graph accuracy, outperforming baselines in various scenarios.",
        "The model's object-oriented representation captures complex interactions robustly.",
        "Causation and result symmetries enhance the model's ability to learn accurate causal dynamics.",
        "The OOCDM demonstrates strong generalization capabilities, performing well on out-of-distribution data."
      ],
      "weaknesses": [
        "Computational efficiency gains may be less pronounced in extremely large-scale environments.",
        "Performance in causal graph accuracy could be further improved with more sophisticated handling of symmetries.",
        "Generalization to out-of-distribution data may be limited by training environment characteristics.",
        "Practical implementation may face challenges in managing model architecture and parameters.",
        "Robustness to overfitting, especially with limited data, requires further investigation."
      ],
      "questions": [
        "How does the OOCDM handle extremely large-scale environments with high computational efficiency?",
        "What further improvements can be made to leverage causation and result symmetries in complex scenarios?",
        "How does the model's generalization to out-of-distribution data vary across different types of environments?",
        "What techniques can be employed to address potential overfitting, particularly with limited data?",
        "How can the model's architecture and parameterization be optimized for practical implementation in large-scale settings?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7vVWiCrFnd",
    "title": "Rethinking and Extending the Probabilistic Inference Capacity of GNNs",
    "std_review": {
      "summary": "The paper proposes PE, a method that augments GNNs with phantom nodes/edges to improve higher-order inference. It provides a theoretical framework linking GNN expressivity to higher-order MRF marginals via the k‑WL hierarchy. While innovative, the method faces scalability challenges and limited experimental validation, leading to a weak accept recommendation.",
      "strengths": [
        "Introduces a novel augmentation technique for GNNs to enhance higher-order inference.",
        "Offers a rigorous theoretical foundation linking GNN expressivity to higher-order MRF marginals.",
        "Clearly distinguishes the method's novelty and theoretical underpinnings."
      ],
      "weaknesses": [
        "Computational complexity can become super‑quadratic for dense graphs due to phantom node/edge addition.",
        "Scalability is limited by the need for maximum clique detection, which is computationally expensive.",
        "Experimental evaluation is restricted to small datasets and lacks comprehensive comparisons with state‑of‑the‑art baselines."
      ],
      "questions": [
        "How can the computational complexity of adding phantom nodes/edges be mitigated for larger graphs?",
        "What are the practical implications of the k‑WL hierarchy choice, and could alternative metrics be explored?",
        "How can the scalability of the method be improved, and what heuristics can be employed to reduce computational burden?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "7vzyqs8UbA",
    "title": "",
    "std_review": {
      "summary": "The paper introduces LMCC-MBC, a novel clustering algorithm that combines local metric correlation clustering with a modified beta-clustering approach, using a Wasserstein-2 distance framework to enhance intra-cluster cohesion and inter-cluster separation. The method is evaluated on synthetic datasets and compared against several state-of-the-art algorithms, showing competitive performance. The reviewer finds the theoretical foundation strong and the empirical validation robust, though some areas for improvement are noted.",
      "strengths": [
        "Innovative integration of local metric correlation clustering with beta-clustering.",
        "Strong theoretical foundation using Wasserstein-2 distance for locally monotonic continuity.",
        "Robust empirical validation on synthetic datasets."
      ],
      "weaknesses": [
        "Complexity of theoretical analysis may be challenging for some readers.",
        "Limited real-world validation could affect generalizability.",
        "Lack of detailed guidance on parameter tuning.",
        "Comparison with baselines could be enhanced with more metrics."
      ],
      "questions": [
        "How does the method perform on real-world datasets beyond synthetic examples?",
        "What are the practical guidelines for tuning the shift parameter δ and the number of neighbors?",
        "Could additional benchmarking metrics be provided to highlight LMCC-MBC's relative advantages?",
        "How does the method scale to higher-dimensional spaces beyond the tested 3D and 4D examples?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7W3GLNImfS",
    "title": "Human Feedback is not Gold Standard",
    "std_review": {
      "summary": "The paper investigates how human annotators misjudge the factual accuracy of AI-generated responses, particularly when those responses are assertive or complex. It introduces a taxonomy of ten error types and uses Lasso regression to identify which features most strongly predict each error type. The authors find that annotators are biased toward labeling assertive, complex responses as factual, even when they are false, and that this bias persists across different model sizes and domains. Overall, the study provides valuable insights into human bias in AI evaluation with strong empirical backing and practical implications for model development.",
      "strengths": [
        "Comprehensive Error Taxonomy: The ten error types cover a wide range of potential issues in AI-generated text, providing a solid theoretical foundation for the study.",
        "Empirical Validation: The use of Lasso regression to quantify feature importance offers a clear, data-driven method for understanding annotator behavior.",
        "Large-Scale Experiments: Testing across models ranging from 13 B to 52 B demonstrates the robustness and scalability of the observed bias."
      ],
      "weaknesses": [
        "Limited Scope of Error Types: While ten error types are comprehensive, the choice may still miss nuanced issues relevant to specific domains.",
        "Potential Overfitting in Regression: The reliance on a single regression model could lead to overfitting, especially with the large number of features considered.",
        "Annotator Consistency: The study does not fully address how annotator variability (e.g., training, experience) might influence the results.",
        "Lack of Longitudinal Study: The findings are based on a single evaluation phase, and the persistence of bias over time is not explored."
      ],
      "questions": [
        "How might the error taxonomy be refined to capture domain-specific nuances?",
        "What are the implications of annotator variability on the observed bias, and how can it be mitigated?",
        "Could a more robust statistical approach be employed to reduce the risk of overfitting in the regression analysis?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7W4boWjb3Q",
    "title": "Partitioned Learned Count-Min Sketch",
    "std_review": {
      "raw_text": "{\n  \"summary\": \"The paper introduces PL‑CMS, a probabilistic Count‑Min Sketch algorithm that integrates learned models to improve frequency estimation accuracy. It partitions the input space into regions, each with a CMS and a learned model, and combines outputs using thresholds. Experiments show lower error rates compared to traditional CMS and other learned methods, with reproducible code provided. However, the lack of detailed threshold selection, model size reporting, and robust analysis of noisy predictions weakens the overall impact.\",\n  \"strengths\": [\n    \"Innovative integration of traditional CMS with learned models to enhance accuracy.\",\n    \"Scalable partitioned architecture with minimal memory overhead.\",\n    \"Empirical validation across multiple datasets demonstrating effectiveness.\"\n  ],\n  \"weaknesses\": [\n    \"Threshold selection process is not detailed, affecting reproducibility and generalizability.\",\n    \"Model size for LCMS and PL‑CMS is not clearly reported, hindering resource usage assessment.\",\n    \"Comparison with other methods is complicated by differences in model types and training approaches.\",\n    \"Limited analysis of robustness to noisy predictions.\"\n  ],\n  \"questions\": [\n    \"How are the thresholds \\(t_i\\) chosen, and what is the impact of this choice on the final estimates?\",\n    \"What are the specific model sizes (in parameters and memory) for LCMS and PL‑CMS across the datasets?\",\n    \"Could you provide more details on the reproducibility setup, including any dependencies or setup instructions for the code?\",\n    \"How does PL‑CMS perform under noisy or inaccurate frequency predictions, and what trade-offs are involved?\"\n  ],\n  \"overall_score\": \"5: borderline\",\n  \"confidence\": \"3: medium\"\n}",
      "parse_error": true
    }
  },
  {
    "paper_id": "7W4rbphLht",
    "title": "",
    "std_review": {
      "summary": "The paper introduces S5N, a novel optimization algorithm combining semi-smooth Newton methods with block coordinate descent, offering theoretical convergence guarantees and empirical results on image datasets. While innovative and promising, several concerns regarding assumptions, reproducibility, and detailed analysis prevent a strong acceptance.",
      "strengths": [
        "Innovative combination of semi-smooth Newton methods with block coordinate descent.",
        "Provides rigorous theoretical convergence guarantees.",
        "Demonstrates practical effectiveness on benchmark image datasets."
      ],
      "weaknesses": [
        "Relies on specific step size assumptions that may limit practical applicability.",
        "Unclear method for solving the linear system in the algorithm.",
        "Lacks detailed convergence rate information.",
        "Experiments show convergence issues with the BCD component.",
        "Dataset choice may limit generalizability."
      ],
      "questions": [
        "What are the specific assumptions and bounds on the step size used in the convergence analysis?",
        "How is the linear system in Equation (2) solved, and what tolerance or iteration details are used?",
        "What is the specific global convergence rate of the S5N algorithm compared to existing methods?",
        "What conditions or settings ensure the convergence of the BCD algorithm in the experiments?",
        "Why were MNIST and Fashion-MNIST selected, and how do they affect the algorithm's generalizability?",
        "How do implementation details impact the reported timing results, especially for runs under one second?",
        "What criteria were used to select and compare against other algorithms?",
        "What additional steps are needed to ensure reproducibility of the experiments?",
        "How do theoretical convergence rates align with empirical observations?"
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "7W9zRGhLq7",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a heterogeneity‑driven Lipschitz assumption for Federated Averaging, providing tighter convergence bounds by accounting for data variability across clients. Empirical experiments validate the theoretical claims, showing improved convergence rates. While the approach is novel and theoretically significant, practical challenges in estimating the required Lipschitz constants and its applicability to non‑convex settings remain. Overall, the work advances federated learning analysis and is recommended for acceptance.",
      "strengths": [
        "Introduces a realistic heterogeneity‑driven Lipschitz assumption that better captures real‑world variability.",
        "Provides a framework for deriving tighter convergence bounds by explicitly modeling data heterogeneity.",
        "Empirically validates the theoretical claims through concrete experiments estimating Lipschitz constants."
      ],
      "weaknesses": [
        "Estimating the heterogeneity‑driven Lipschitz constants in practice may be challenging.",
        "The assumption still imposes a Lipschitz condition that may not hold for all non‑convex objective functions.",
        "Analysis is limited to the convergence properties of FedAvg and does not cover other algorithms or settings."
      ],
      "questions": [
        "How robust is the heterogeneity‑driven assumption in highly dynamic or large‑scale federated environments?",
        "What are the theoretical implications of the assumption for non‑convex objective functions?",
        "Can the proposed analysis be extended to other federated learning algorithms beyond FedAvg?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7WsivwyHrS",
    "title": "You Only Query Once: An Efficient Label-Only Membership Inference Attack",
    "std_review": {
      "summary": "The paper introduces a membership inference attack that selects the most challenging samples near the decision boundary to evaluate worst-case performance. It demonstrates robustness across various training settings and query budgets, achieving high inference accuracy with limited queries. While the approach is theoretically sound and experimentally validated, concerns about dataset size, overfitting, and the lack of detailed analysis in some areas limit its overall impact.",
      "strengths": [
        "Robust evaluation metric using distance from decision boundary",
        "Adaptive query strategy that maintains accuracy with limited queries",
        "Cross-training setting robustness across different optimizers, batch sizes, and learning rates"
      ],
      "weaknesses": [
        "Limited dataset size for the target model may reduce generalizability",
        "No overfitting mitigation experiments with larger datasets or pretrained models",
        "Potential overfitting in shadow models used for the attack",
        "Lack of detailed analysis on how query budget impacts attack strategy"
      ],
      "questions": [
        "How does the attack perform on larger datasets or models pretrained on ImageNet?",
        "What is the detailed impact of increasing the query budget beyond 10 queries?",
        "How does the transferability of crafted queries change when using different training algorithms?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "7wY67ZDQTE",
    "title": "Cauchy-Schwarz Divergence Information Bottleneck for Regression",
    "std_review": {
      "summary": "The paper introduces a novel approach to mutual information estimation using Conditional Symmetry (CS) divergence and a Gaussian variational lower bound. It demonstrates strong empirical performance across various datasets, suggesting a robust alternative to existing methods. While the theoretical analysis is not fully detailed, the method shows significant promise and is recommended for acceptance.",
      "strengths": [
        "Introduces Conditional Symmetry (CS) divergence for potentially more accurate MI estimation.",
        "Leverages a Gaussian variational lower bound to enhance practical applicability.",
        "Empirical results validate the effectiveness of the proposed method across datasets."
      ],
      "weaknesses": [
        "Lacks detailed theoretical analysis of convergence properties.",
        "Experimental setup primarily uses synthetic datasets, limiting generalizability.",
        "Limited comparison with existing methods beyond performance metrics.",
        "Could benefit from a deeper discussion of inductive biases."
      ],
      "questions": [
        "What are the convergence properties of the proposed CS divergence?",
        "How do the inductive biases of CS+Gaussian compare to those of KL+Gaussian?",
        "What is the impact of the Gaussian variational lower bound on the method's performance in real-world scenarios?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7YEXo5qUmN",
    "title": "Organ-DETR: 3D Organ Detection Transformer with Multiscale Attention and Dense Query Matching",
    "std_review": {
      "summary": "Organ-DETR introduces a transformer-based approach for organ detection in medical imaging, combining MultiScale Attention and Dense Query Matching to improve performance. The method shows competitive results on benchmark datasets, suggesting potential clinical benefits through accurate and efficient localization. However, the experimental evaluation lacks thorough clinical scenarios and does not compare against established medical detection frameworks. Additional metrics and a more comprehensive experimental setup could strengthen the work.",
      "strengths": [
        "Innovative integration of MultiScale Attention and Dense Query Matching enhances feature extraction and query matching.",
        "End-to-end detection framework simplifies the pipeline and may reduce post-processing requirements.",
        "Competitive performance on benchmark datasets demonstrates effectiveness in real-world scenarios."
      ],
      "weaknesses": [
        "Limited experimental evaluation does not adequately address clinical scenarios.",
        "Omission of comparative analyses with established medical detection frameworks.",
        "One-to-many label assignment may not align well with typical one-instance-per-organ tasks.",
        "Insufficient localization metrics may not fully capture localization accuracy."
      ],
      "questions": [
        "How does the model perform in complex clinical scenarios involving multiple organs or rare conditions?",
        "What are the specific clinical benefits of the end-to-end detection framework compared to existing solutions?",
        "How does the one-to-many label assignment strategy affect performance on typical organ detection tasks?",
        "What additional localization metrics should be included to better evaluate the model's performance?"
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "7Zbg38nA0J",
    "title": "Explaining Grokking through circuit efficiency",
    "std_review": {
      "summary": "The paper introduces a novel framework for understanding learning dynamics in deep neural networks by identifying 'generalizing' and 'memorizing' circuits and proposing a metric for circuit efficiency. It provides theoretical insights and empirical evidence linking these circuits to the grokking phenomenon observed in large language models. While the findings are compelling, they are primarily based on transformer models, which limits generalizability. The study also relies on assumptions about a critical dataset size and could benefit from exploring alternative regularization mechanisms.",
      "strengths": [
        "Clear identification of circuit types and a novel efficiency metric.",
        "Theoretical framework linking circuit efficiency to model complexity.",
        "Empirical validation of theoretical predictions with robust experiments."
      ],
      "weaknesses": [
        "Limited scope to transformer models, potentially limiting generalizability.",
        "Assumptions in determining the critical dataset size (Dcrit).",
        "Potential for overfitting in experiments, especially with input encoding changes."
      ],
      "questions": [
        "How do the identified circuit dynamics generalize to other neural network architectures beyond transformers?",
        "What is the impact of alternative regularization mechanisms on circuit dynamics and grokking?",
        "Can the proposed metric be applied to evaluate learning efficiency in non‑transformer models?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7zxGHwe7Vw",
    "title": "FedAnchor: Enhancing Federated",
    "std_review": {
      "summary": "FedAnchor introduces a federated semi-supervised learning framework that uses a label-contrastive loss during server updates to improve convergence and accuracy. The method shows strong empirical results on CIFAR100 and ImageNet, especially with limited labeled data, but has concerns about communication overhead and experimental reproducibility.",
      "strengths": [
        "Introduces a novel label-contrastive loss that effectively bridges labeled and unlabeled data.",
        "Demonstrates significant improvements over existing federated semi-supervised methods.",
        "Scales well across multiple clients, reducing reliance on centralized data."
      ],
      "weaknesses": [
        "Incurring additional communication costs due to server embeddings.",
        "Hyper-parameter sensitivity not thoroughly explored.",
        "Baseline comparison may not be fair due to the use of a supervised baseline with abundant labeled data."
      ],
      "questions": [
        "How will the impact of the contrastive loss be quantified through ablation studies?",
        "What sensitivity analysis will be conducted on hyper-parameters such as threshold value and augmentation strength?",
        "Will a more robust supervised baseline be used for fair comparison?",
        "What steps will be taken to ensure reproducibility of the experiments?",
        "How will notational consistency be maintained throughout the paper?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "83w0LPowHz",
    "title": "On Reconstructability of Graph Neural Networks",
    "std_review": {
      "summary": "The paper introduces a novel framework for graph reconstructability based on inner‑product conditions of node embeddings, proposing a sufficient and necessary condition for models to recover original graph topology. It defines contextual features that combine label information with noise and demonstrates that the Graph Isomorphism Network (GIN) preserves node identity through a parameter ε. The framework is evaluated on synthetic datasets, with insightful discussion of real‑world challenges. Overall, the paper makes a valuable contribution with clear mathematical definitions and theoretical insights, though some aspects require further clarification.",
      "strengths": [
        "Provides a clear and mathematically rigorous definition of graph reconstructability using inner‑product conditions.",
        "Introduces contextual features that combine label information with noise, highlighting the importance of signal in reconstruction.",
        "Demonstrates that GIN preserves node identity through parameter ε, contributing to the theoretical understanding of message‑passing networks.",
        "Evaluates the framework on synthetic datasets, providing concrete evidence of effectiveness."
      ],
      "weaknesses": [
        "The necessity and sufficiency of the inner‑product condition are not fully substantiated; theoretical justification could be more detailed.",
        "Notation for τl and τu in Propositions 2 and 3 is ambiguous, potentially leading to misinterpretation of probability bounds.",
        "The definition of contextual features assumes availability of node labels for both training and testing, which may not always be realistic.",
        "The term 'signal' in contextual features is not clearly defined, and it is unclear whether it specifically refers to node labels.",
        "The discussion of GIN's role in preserving node identity lacks detailed analysis of how ε influences the balance between preserving structural information and node identity."
      ],
      "questions": [
        "Can the inner‑product condition be generalized to other types of graph neural networks beyond GIN?",
        "How can the framework be adapted to scenarios where node labels are unavailable or noisy?",
        "What are the specific values of ε that optimize the trade‑off between preserving structural information and node identity?",
        "How can the framework be evaluated on real‑world graphs where multiple instances are not available?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "84fOBZlOiV",
    "title": "Estimating uncertainty from feed-forward network based sensing using quasi-linear approximation",
    "std_review": {
      "summary": "The paper presents a method for approximating the output of deep neural networks using Gaussian distributions, focusing on MLPs with tanh activations. It demonstrates effectiveness in approximating MLP output distributions but has several limitations, including assumptions about Gaussian noise, potential error accumulation in deep networks, and lack of comparison with existing methods. Overall, the work is promising but requires further refinement.",
      "strengths": [
        "Introduces a novel approach to approximate deep network outputs with Gaussian distributions.",
        "Provides clear insights into noise distribution and error accumulation in MLPs.",
        "Validates effectiveness through experimental results."
      ],
      "weaknesses": [
        "Assumes input noise is always Gaussian, which may not hold in practice.",
        "Error accumulation in deep networks could lead to significant inaccuracies.",
        "Does not explore adaptation to modern architectures like ResNet.",
        "Lacks quantification of approximation errors from each source.",
        "Fails to compare with existing methods, limiting context."
      ],
      "questions": [
        "How does the method handle non-Gaussian input noise?",
        "What strategies can mitigate error accumulation in deep networks?",
        "How can the method be adapted to modern architectures such as ResNet?",
        "What are the quantified approximation errors from each source?",
        "How does the proposed method compare with existing approaches like GELU and Wang et al. (2016)?"
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "84Hk01tFKq",
    "title": "HyperFields: Towards Zero-Shot Generation of NeRFs from Text",
    "std_review": {
      "summary": "HyperFields presents a novel framework for generating 3D scenes from text using a dynamic hypernetwork integrated with NeRFs. The approach effectively disentangles and combines attributes like colors and shapes from text embeddings, leading to highly detailed and coherent scene generation. Compared to existing methods such as ATT3D and Shap-E, HyperFields shows significant improvements in text conditioning and out-of-distribution prompt handling. The paper is well-structured, with clear contributions and thorough experimental evaluation, making it a strong candidate for acceptance.",
      "strengths": [
        "Dynamic hypernetwork integration for effective attribute disentanglement from text embeddings.",
        "Improved text conditioning and handling of complex, ambiguous prompts.",
        "NeRF distillation process enhances scene detail preservation and robustness."
      ],
      "weaknesses": [
        "Training complexity of the dynamic hypernetwork may require significant computational resources.",
        "Potential issues with generating coherent scenes from highly complex or ambiguous textual descriptions.",
        "Scalability to complex scenes with multiple objects or intricate spatial arrangements remains an area for further exploration."
      ],
      "questions": [
        "How does the model perform on benchmarks with highly creative or ambiguous textual descriptions beyond the provided examples?",
        "What are the specific training strategies employed to address the complexity of the dynamic hypernetwork?",
        "How can the model's performance in generating scenes with multiple interacting objects be further improved?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "84n3UwkH7b",
    "title": "Detecting, Explaining, and Mitigating Memo-RIZATION in Diffusion Models",
    "std_review": {
      "summary": "The paper introduces a method to detect memorized prompts in diffusion models and proposes mitigation strategies. The detection method is novel and effective, and the mitigation strategies are evaluated for their impact on model performance and robustness against adversarial attacks. While the proposed methods show promise, the lack of a more interpretable detection method, insufficient evaluation of performance impact, and the absence of adversarial testing and user-friendly features limit their overall acceptability.",
      "strengths": [
        "Introduces a novel and effective method for detecting memorized prompts in diffusion models.",
        "Proposes mitigation strategies that are tested for their impact on model performance and robustness.",
        "Provides a taxonomy of trigger tokens and user-friendly prompt modification features."
      ],
      "weaknesses": [
        "Detection method relies on an empirical threshold for false positives without confidence scores.",
        "Impact of mitigation strategies on overall model performance is not fully explored.",
        "Prompt modification process is not user-friendly and lacks features to assist users.",
        "No adversarial testing conducted to evaluate robustness against potential attacks."
      ],
      "questions": [
        "How can the detection method be made more interpretable by producing confidence scores or p-values?",
        "What is the extent of the impact of the proposed mitigation strategies on the overall performance of the diffusion model, particularly the trade-off between mitigating memorization and maintaining high-quality image generation?",
        "Could a taxonomy or classification of trigger tokens be provided to help develop more targeted mitigation strategies?",
        "What additional adversarial tests should be conducted to evaluate the robustness of the mitigation strategies against potential attacks?"
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "85Af6AcMo5",
    "title": "",
    "std_review": {
      "summary": "The paper introduces the Recursive Difference (RD) method for estimating higher-order derivatives, which improves upon conventional finite-difference techniques. The authors propose a SciRE‑Solver that leverages the RD method to accelerate convergence and enhance numerical stability. Empirical results demonstrate that the RD approach yields more accurate gradient estimates for score functions compared to traditional methods. The paper provides strong theoretical and empirical evidence supporting the method's superiority, though it notes implementation complexity and parameter sensitivity.",
      "strengths": [
        "Improved accuracy for higher-order derivatives compared to conventional finite-difference methods.",
        "Enhanced convergence and numerical stability through the SciRE‑Solver.",
        "Strong theoretical and empirical validation of the method's effectiveness."
      ],
      "weaknesses": [
        "Potential additional computational overhead due to the RD method's complexity.",
        "Sensitivity of performance to the choice of the coefficient C6.",
        "Limited scope to score function gradients, with a need for broader applicability research."
      ],
      "questions": [
        "How can the RD method be extended to other types of derivative estimation beyond score functions?",
        "What are the practical guidelines for tuning the C6 coefficient in real-world applications?",
        "How does the RD method perform on larger-scale problems compared to existing high-order derivative estimation techniques?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "85gNpcUhmx",
    "title": "Unsupervised Domain Adaptive Lane Detection via Contextual Contrast and Aggregation",
    "std_review": {
      "summary": "The paper presents a novel unsupervised domain‑adaptive lane detection framework that leverages a cross‑domain contrastive loss and a domain‑level feature aggregation module. It effectively improves lane detection performance on target domains without requiring labeled data from those domains, as demonstrated by substantial gains on several benchmark datasets. The approach is theoretically grounded in contrastive learning and feature alignment, and it shows strong empirical results. However, its computational cost and sensitivity to hyperparameters may limit its practicality in resource‑constrained settings. Overall, the paper makes significant contributions to unsupervised domain adaptation for lane detection.",
      "strengths": [
        "Introduces a novel cross‑domain contrastive loss that aligns feature distributions between source and target domains.",
        "Proposes a domain‑level feature aggregation module that enhances feature discrimination and facilitates cross‑domain knowledge transfer.",
        "Provides a clear theoretical foundation based on established principles of contrastive learning and feature alignment.",
        "Demonstrates strong empirical improvements on multiple benchmark datasets, outperforming existing state‑of‑the‑art methods."
      ],
      "weaknesses": [
        "The method may incur higher computational overhead due to the additional contrastive loss and DFA module.",
        "Effectiveness is sensitive to the choice of hyperparameters, which may require extensive tuning.",
        "Generalizability to other domain adaptation tasks or object detection problems has not been fully explored."
      ],
      "questions": [
        "How can the computational cost of the proposed method be reduced for deployment in resource‑constrained environments?",
        "What are the long‑term implications of the hyperparameter sensitivity on the practical applicability of the approach?",
        "Could the DFA module be adapted or extended to improve performance on other types of domain adaptation tasks beyond lane detection?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "86NGO8qeWs",
    "title": "CompA: Addressing the Gap in Compositional Reasoning in Audio-Language Models",
    "std_review": {
      "summary": "The paper introduces CompA, a novel approach to audio classification that leverages ChatGPT for extensive dataset curation and employs manipulation techniques like replacing sounding objects and swapping orders to improve model robustness. It achieves state-of-the-art results on several benchmarks, demonstrating significant improvements over existing models. While innovative, the approach has limitations such as potential overfitting and a lack of comprehensive baseline comparisons, which could affect generalizability.",
      "strengths": [
        "Innovative data curation using ChatGPT significantly expands dataset size and diversity.",
        "Robust manipulation techniques enhance model generalization across different scenarios.",
        "Comprehensive evaluation with quantitative and qualitative metrics strengthens the claim of effectiveness."
      ],
      "weaknesses": [
        "Limited dataset diversity may restrict model generalizability in certain audio contexts.",
        "Complexity of manipulation techniques hinders reproducibility.",
        "Absence of thorough baseline comparisons could weaken the argument for method superiority.",
        "Potential for overfitting due to extensive data manipulation without proper regularization."
      ],
      "questions": [
        "How does the model perform on out-of-distribution audio samples not present in the curated datasets?",
        "What specific strategies are employed to mitigate overfitting in the extensive manipulation process?",
        "Could the proposed manipulation techniques be generalized to other audio classification tasks beyond the evaluated benchmarks?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "86w3LbTNI1",
    "title": "Preventing Reward Hacking with Occupancy Measure Regularization",
    "std_review": {
      "summary": "The paper introduces ORPO, a method that regularizes action distributions to encourage exploration by optimizing an optimistic objective and using a discriminator to separate safe from unsafe actions. Empirical results on MuJoCo and Atari show improved sample efficiency and safety, but the method's complexity, tuning difficulty, and limited theoretical guarantees are noted. Overall, ORPO is promising yet requires careful consideration.",
      "strengths": [
        "Novel regularization approach that encourages exploration",
        "Safety mechanism via discriminator separating safe and unsafe actions",
        "Empirical improvements in sample efficiency and safety across benchmarks"
      ],
      "weaknesses": [
        "Complexity introduced by the discriminator",
        "Challenges in tuning the regularization strength (λ)",
        "Limited theoretical underpinnings compared to established methods"
      ],
      "questions": [
        "How can the stability of the discriminator be improved in high-dimensional domains?",
        "What are the long-term safety guarantees provided by the safe policy?",
        "How does ORPO compare to other regularization techniques in terms of computational efficiency?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "86zAUE80pP",
    "title": "CPPO: Continual Learning for Reinforcement Learning with Human Feedback",
    "std_review": {
      "summary": "The paper proposes a novel RLHF method that optimizes a specific formulation (Equation 4) by focusing on a subset of data, aiming to improve efficiency and effectiveness. The approach introduces a hard cutoff (k) to balance optimization and computational constraints, showing statistically significant improvements over existing methods across multiple random seeds. However, the theoretical motivation behind Equation 4, the rationale for discarding data, and the justification for the hard cutoff are not clearly explained.",
      "strengths": [
        "Introduces a novel formulation (Equation 4) that selectively optimizes a subset of data for RLHF.",
        "Provides a clear mechanism for balancing optimization and computational constraints using a hyperparameter (k).",
        "Demonstrates statistically significant improvements over existing RLHF techniques."
      ],
      "weaknesses": [
        "Lacks a clear theoretical motivation for Equation 4 and the specific optimization terms.",
        "Does not adequately explain why discarding data (optimizing over a subset) is beneficial.",
        "The hard cutoff based on hyperparameter k is introduced without a well-defined optimization target.",
        "The claim that Equation 6 makes Equation 5 easier to optimize is not convincingly justified."
      ],
      "questions": [
        "Can you clarify the theoretical motivation behind Equation 4 and the specific optimization terms?",
        "What is the rationale for discarding data and how does this approach address computational constraints?",
        "How was the hyperparameter k chosen and what is its optimal value?",
        "Could you provide a more detailed analysis of the statistical significance of the results across random seeds?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "87XbxDnPqj",
    "title": "Gradient Descent Provably Solves Nonlinear Tomographic Reconstruction",
    "std_review": {
      "raw_text": "{\n  \"summary\": \"The paper introduces a deep learning framework for non-linear X-ray tomographic reconstruction, addressing limitations of traditional linear methods. It demonstrates improved image quality and reduced artefacts, especially in the presence of beam hardening, making it relevant for medical imaging. However, the approach has methodological limitations, including unclear figure quality, limited comparative analysis, and ambiguous variable selection processes.\",\n  \"strengths\": [\n    \"Innovative deep learning approach for non-linear tomographic reconstruction.\",\n    \"Effective handling of beam hardening artefacts.\",\n    \"Empirical validation with quantitative and qualitative metrics.\"\n  ],\n  \"weaknesses\": [\n    \"Unclear and low-resolution figures hinder interpretation.\",\n    \"Lack of comparison with other state-of-the-art non-linear methods.\",\n    \"Transition from regularization term to inequality constraint raises questions about solution space.\"\n  ],\n  \"questions\": [\n    \"How can the clarity of Figure 2 be improved to better illustrate the reconstruction results?\",\n    \"What are the specific steps for selecting or constructing the variable \\(x\\) in equation (4.1)?\",\n    \"How does the proposed method compare with other non-linear tomographic reconstruction techniques?\"\n  ],\n  \"overall_score\": \"5: borderline\",\n  \"confidence\": \"3: medium\"\n}",
      "parse_error": true
    }
  },
  {
    "paper_id": "87YOFayjcG",
    "title": "JudgeLM : Fine-tuned Large Language Models are Scalable Judges",
    "std_review": {
      "summary": "JudgeLM presents a novel method for evaluating language models by using external reference answers to mitigate position, knowledge, and format biases. The approach employs a score-first generation strategy and reference augmentation, achieving significant performance improvements over baselines in bias mitigation and efficiency. The paper demonstrates strong results across multiple metrics and highlights the method's potential for multimodal generalization, though it also notes limitations related to reference quality and scalability.",
      "strengths": [
        "Effectively addresses position, knowledge, and format biases through innovative use of external references.",
        "Shows superior performance across multiple bias metrics, achieving higher consistency and agreement compared to existing methods.",
        "Introduces a score-first generation approach that reduces inference time while maintaining high-quality evaluations."
      ],
      "weaknesses": [
        "Performance heavily relies on the quality and relevance of the external references.",
        "The process of integrating references may introduce additional complexity and computational overhead.",
        "Scalability concerns are not fully addressed, which may limit real-world applicability."
      ],
      "questions": [
        "How robust is JudgeLM to scenarios where high-quality references are scarce or unavailable?",
        "What are the computational costs associated with integrating references in both retrieved form and well-organized paragraphs?",
        "How can the approach be scaled to handle very large datasets or models without compromising performance?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "88FcNOwNvM",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a novel conditional diffusion model for unsupervised image decomposition, separating images into local and global factors. It leverages latent variable conditioning to enforce disentanglement, enabling controlled generation and manipulation of image components. While demonstrating strong performance qualitatively and quantitatively, the method's computational expense and lack of explicit factor labeling are noted as limitations. Overall, the approach is innovative and valuable, warranting acceptance.",
      "strengths": [
        "Innovative decomposition framework combining conditional diffusion models with latent variable conditioning.",
        "Achieves meaningful factorization without labeled data, advancing unsupervised learning in image processing.",
        "Enforces disentanglement effectively, allowing clear separation of distinct image factors."
      ],
      "weaknesses": [
        "Computational expense increases both training and inference time, potentially limiting real-time applications.",
        "Lack of explicit labeling for inferred factors requires visual inspection for interpretation.",
        "Evaluation metrics could be expanded beyond MSE and LPIPS to include FID or KID for better cross-dataset quality assessment."
      ],
      "questions": [
        "How can the computational cost be reduced while maintaining the model's performance?",
        "What strategies can be employed to provide explicit labels for inferred image factors?",
        "Could additional evaluation metrics improve the robustness of the model's performance across diverse datasets?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "88MalncLgU",
    "title": "GInX-Eval: Towards In-Distribution Evaluation of Graph Neural Network Explanations",
    "std_review": {
      "summary": "GInX-Eval introduces a novel framework for evaluating GNN explainability by retraining the model on modified training data, addressing the out-of-distribution problem. The approach improves explanation robustness and fidelity on unseen data distributions, with strong theoretical foundations and practical implications. While the method is innovative and impactful, concerns about implementation complexity, hyper-parameter sensitivity, and limited benchmark datasets are noted.",
      "strengths": [
        "Introduces a novel evaluation framework for GNN explainability by retraining the model.",
        "Addresses the out-of-distribution problem, a critical issue in explainability research.",
        "Provides a solid theoretical foundation for understanding edge removal strategies.",
        "Demonstrates significant improvements in explanation fidelity and robustness on unseen data."
      ],
      "weaknesses": [
        "Implementation complexity due to the retraining process and edge removal strategy adjustments.",
        "Limited exploration of hyper-parameter sensitivity, affecting reproducibility.",
        "Evaluation based on a limited set of benchmark datasets may not capture real-world diversity.",
        "Comparison with baselines is not comprehensive across datasets and metrics."
      ],
      "questions": [
        "How can the retraining process be made more accessible to practitioners with limited resources?",
        "What are the long-term effects of hyper-parameter choices on the generalizability of GInX-Eval?",
        "Could the framework be extended to handle a wider variety of graph structures and data distributions?",
        "How does GInX-Eval perform when evaluated on more diverse benchmark datasets?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "89A5c6enfc",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a semi-supervised learning framework that uses a graph-based approach to estimate true label proportion and optimize seed selection for label propagation, aiming to improve clustering in noisy label scenarios. Theoretical analysis provides provable bounds under specific conditions, and empirical experiments show effectiveness compared to baselines. While innovative and theoretically grounded, the method's practical applicability is limited by parameter sensitivity, strong assumptions on label noise, and graph density requirements, and it lacks robustness and comprehensive comparison analyses.",
      "strengths": [
        "Innovative approach to estimating label noise and optimizing seed selection.",
        "Provides theoretical guarantees under specific conditions.",
        "Demonstrates practical improvements in clustering performance with noisy labels."
      ],
      "weaknesses": [
        "High sensitivity to the choice of ϵ, which may require extensive tuning.",
        "Assumes known label noise parameters a₀ and a₁, which may not be realistic.",
        "Theoretical results rely on a dense graph assumption that may not hold for all datasets.",
        "Lacks analysis of robustness to variations in seed source mass (Δs).",
        "Experimental evaluation does not compare against non-flow-based methods."
      ],
      "questions": [
        "How can the method be adapted for sparser clusters beyond the current p = ω(log k/k) assumption?",
        "What is the robustness of the method to variations in the seed source mass (Δs)?",
        "How does the method compare to non-flow-based semi-supervised learning approaches?",
        "What are the practical guidelines for estimating ϵ in real-world datasets?"
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "89AOrk05uy",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a regularization technique for deep neural networks by modifying the Neural Tangent Kernel (NTK) Gram matrix to scale its eigenvalues, aiming to reduce spurious correlations and improve subgroup robustness. While the approach shows promise in theory and empirically outperforms standard methods on minority subgroups, its practical applicability is limited by computational overhead and sensitivity to initialization and regularization strength. Overall, the method is promising but requires further refinement.",
      "strengths": [
        "Innovative regularization technique by directly manipulating the NTK.",
        "Strong theoretical foundation linking eigenvalue scaling to reduced spurious correlations.",
        "Empirical evidence demonstrating improved subgroup robustness across multiple datasets."
      ],
      "weaknesses": [
        "High computational cost due to recalculating and scaling the NTK Gram matrix.",
        "Limited generalization to other kernel methods or architectures.",
        "High sensitivity to the choice of scaling factor, requiring careful tuning.",
        "Lack of analysis on robustness to different network initializations."
      ],
      "questions": [
        "How can the computational cost of applying the NTK modification be reduced for large-scale models?",
        "What are the theoretical guarantees for extending the method to other kernel methods?",
        "How does the method perform under varying network initializations and depths?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "89bUur0Q4J",
    "title": "Vision-Language Subspace Prompting",
    "std_review": {
      "summary": "The paper presents a novel approach to zero-shot image classification using subspace-based prompt learning combined with hard-prompt regularization and ensemble techniques. It shows competitive performance across several datasets but exhibits inconsistent results, lacks detailed ablation studies, and has interpretability gaps. The innovative aspects include hard-prompt regularization and ensembling, but the manuscript suffers from rushed sections and unclear explanations.",
      "strengths": [
        "Innovative subspace modeling that captures intra-class variability effectively.",
        "Introduces hard-prompt regularization to potentially improve classification robustness.",
        "Utilizes ensemble learning to aggregate predictions from multiple models, likely enhancing overall performance."
      ],
      "weaknesses": [
        "Performance inconsistency across datasets, with some showing superior results while others do not.",
        "Lack of detailed ablation studies to isolate the contribution of each component.",
        "Interpretability gaps due to unclear explanations or visualizations of learned subspaces.",
        "Does not comprehensively address computational cost.",
        "Fails to compare against state-of-the-art methods, potentially overlooking significant advancements."
      ],
      "questions": [
        "Can detailed ablation studies be conducted to isolate the contribution of each component?",
        "What methods can be used to improve the interpretability of the learned subspaces?",
        "How does the computational cost of the proposed method compare to existing approaches?",
        "Should the manuscript include a re‑implementation of state‑of‑the‑art methods like LASP for fair comparison?",
        "What theoretical motivations support the division of soft prompts into subgroups and the application of hard regularization?"
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "89l6VLPrin",
    "title": "Graph layouts and graph contrastive learning via neighbour embeddings",
    "std_review": {
      "summary": "The paper introduces Graph Contrastive Node Embedding (graph CNE), a method for learning node embeddings in graphs using contrastive learning. It aims to improve embedding quality by maximizing agreement between positive node pairs and minimizing it between negatives. While the experimental setup is well-defined and the method shows competitive performance on several datasets, concerns about metric choice, data splitting, and baseline comparisons suggest that the robustness of the claims needs further validation. Overall, the paper is innovative but requires addressing several methodological and evaluation issues.",
      "strengths": [
        "Innovative contrastive learning framework for graph node embeddings",
        "Clear and reproducible experimental setup with consistent data splits",
        "Comprehensive evaluation across multiple benchmark datasets"
      ],
      "weaknesses": [
        "Use of k-NN classification accuracy as a layout quality metric may be inappropriate",
        "Uniform 2/3 : 1/3  training-test split may not be optimal for all datasets",
        "Some baselines outperform the proposed method, weakening comparability claims"
      ],
      "questions": [
        "How robust are the results to different evaluation metrics for graph layouts?",
        "Could a more nuanced data splitting strategy improve the robustness of the findings?",
        "What statistical evidence supports the claim of comparability with state-of-the-art methods?",
        "How does the method perform when using GNN architectures for both baselines and the proposed approach?",
        "Is the code for reproducing experiments publicly available?"
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "8dN7gApKm3",
    "title": "Uncertainty-aware Graph-based Hyperspectral Image Classification",
    "std_review": {
      "summary": "The paper presents a novel uncertainty quantification framework (UCE) that combines uncertainty regularization (UR) and total variation (TV) regularization to improve out-of-distribution detection and misclassification detection. Evaluated on several benchmark datasets, UCE shows strong performance in OOD detection while maintaining competitive misclassification detection. However, the paper lacks clarity on the limitations of existing methods and the specific role of UR, and the proposed methods do not reach state-of-the-art levels on misclassification detection for some variants. Overall, the work is promising but requires further clarification and exploration of computational efficiency and generalizability.",
      "strengths": [
        "Introduces a novel approach to uncertainty quantification by combining UR and TV regularization.",
        "Demonstrates strong performance in OOD detection on multiple benchmark datasets.",
        "Provides a thorough analysis of computational efficiency, offering insights into practical applicability."
      ],
      "weaknesses": [
        "Does not clearly delineate the limitations of existing uncertainty quantification methods and the role of UR.",
        "Proposed methods do not achieve state-of-the-art performance on misclassification detection for some variants.",
        "Computational efficiency on OOD and misclassification detection tasks is not fully explored.",
        "Generalizability of the model to other classes in different datasets is unclear.",
        "Performance on specific classes (e.g., class-10 and class-7) is below baseline, indicating potential limitations."
      ],
      "questions": [
        "How do the limitations of existing uncertainty quantification methods and the specific role of UR compare to prior work?",
        "What is the computational efficiency of the proposed methods on OOD and misclassification detection tasks?",
        "Is the proposed model equally applicable to OOD detection for other classes in different datasets?",
        "Why does the performance on specific classes (e.g., class-10, class-7) fall below the baseline?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "8euJaTveKw",
    "title": "Prometheus: Inducing Fine-grained Evaluation Capability in Language Models",
    "std_review": {
      "summary": "The paper introduces Prometheus, a system that generates language feedback using a dataset created with GPT‑4 and 20,000 instructions. It evaluates feedback quality, consistency, generalization to unseen domains, and performance against GPT‑4, demonstrating strong results. The innovative feedback collection method and robust evaluation framework are highlighted, though some concerns about dataset construction and human evaluation remain.",
      "strengths": [
        "Innovative feedback collection method leveraging GPT‑4 to expand and diversify the dataset.",
        "Comprehensive evaluation framework using multiple metrics (semantic consistency, relevance) and human annotation.",
        "Demonstrated strong generalization to unseen domains with well‑chosen benchmarks."
      ],
      "weaknesses": [
        "Reliance on GPT‑4 for dataset expansion may introduce biases or inconsistencies.",
        "Human evaluation dependency could introduce variability in feedback quality assessment.",
        "Benchmark selection for generalization testing may not fully capture all unseen domains.",
        "Performance comparison with GPT‑4 lacks clear quantification of specific differences."
      ],
      "questions": [
        "How robust is Prometheus' feedback generation when evaluated on datasets with different linguistic styles or cultural contexts?",
        "What are the long‑term implications of using GPT‑4 for dataset creation, particularly regarding bias and fairness?",
        "Could the evaluation metrics be further refined to better capture the nuances of feedback quality beyond semantic consistency and relevance?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "8EyRkd3Qj2",
    "title": "CLAP: Collaborative Adaptation for Checkerboard Learning",
    "std_review": {
      "summary": "The paper proposes a novel federated learning framework for handling missing modalities using a Conditional Autoencoder Variational Autoencoder (CA‑VAE) and a vertical Pareto min-max optimization. It effectively addresses statistical heterogeneity and improves performance over baselines, especially on complex datasets. While the method shows promise, it lacks direct experimental validation of the CA‑VAE component and could benefit from clearer algorithm presentation.",
      "strengths": [
        "Introduces a CA‑VAE component tailored for modality dependencies in federated learning.",
        "Uses vertical Pareto min-max optimization to mitigate statistical heterogeneity, offering a novel approach compared to traditional averaging.",
        "Provides comprehensive experimental evaluation across various datasets, demonstrating effectiveness and robustness.",
        "Clearly explains the assumptions underlying the method, with practical justifications."
      ],
      "weaknesses": [
        "Performance evaluation is limited to datasets with moderate complexity; behavior in highly complex or high-dimensional settings is not thoroughly explored.",
        "Assumptions (Assumption 1 and Assumption 2) are theoretically justified but may not hold in all practical scenarios, potentially limiting applicability.",
        "Lacks direct experimental results demonstrating the specific contribution of the CA‑VAE component, relying instead on qualitative discussions.",
        "Algorithm presentation could be more accessible with clearer steps and visual aids like flowcharts or diagrams."
      ],
      "questions": [
        "How does the method perform with a large number of missing modalities, and what are the mitigation strategies?",
        "Can the effectiveness of the CA‑VAE be isolated and experimentally verified?",
        "What are the theoretical implications of Assumptions 1 and 2 in practical federated learning scenarios?",
        "How can the algorithm be presented more clearly to aid understanding and reproducibility?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "8F6bws5JBy",
    "title": "Language-Interfaced Tabular Oversampling",
    "std_review": {
      "summary": "The paper introduces LITO, a method that uses language models to generate synthetic minority samples in tabular data, addressing class imbalance with a self‑authentication component and importance‑aware imputation. It outperforms traditional oversampling techniques across multiple language models and datasets, though it faces challenges with numeric features, computational cost, and real‑world validation. Overall, the method is promising with clear strengths in innovation and performance.",
      "strengths": [
        "Innovative use of language models to generate synthetic samples.",
        "Self‑authentication component ensures high-quality minority class data.",
        "Importance‑aware imputation preserves minority feature distribution.",
        "Demonstrated effectiveness across various language model backbones and datasets."
      ],
      "weaknesses": [
        "Semantic challenges in applying language models to numeric features.",
        "Higher computational cost compared to traditional oversampling methods.",
        "Limited real‑world validation and potential for overfitting."
      ],
      "questions": [
        "What specific strategies are employed to mitigate semantic challenges with numeric features?",
        "How does LITO perform on real‑world datasets with complex data distributions?",
        "What is the impact of model size on the trade‑off between sample quality and computational cost?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "8FhwHJGUPZ",
    "title": "Dual-Balancing for Multi-Task Learning",
    "std_review": {
      "summary": "The paper introduces DB‑MTL, a novel multi‑task learning framework that uses a maximum‑norm strategy to adaptively scale task contributions, aiming to improve generalization. Experiments show it outperforms standard baselines and the state‑of‑the‑art STL method on most datasets, supported by theoretical insights and visual analyses. However, the paper lacks detailed justification for baseline performance, experimental evidence for the maximum‑norm strategy, and a clear method for adaptive scale estimation. These gaps reduce confidence in the method's robustness and theoretical foundation.",
      "strengths": [
        "Introduces a unique maximum‑norm strategy for adaptive task scaling in MTL.",
        "Demonstrates superior performance over existing baselines and STL on multiple datasets.",
        "Provides theoretical insights and visual analyses to support the approach."
      ],
      "weaknesses": [
        "Lacks thorough justification for why baseline methods underperform STL.",
        "Experimental support for the maximum‑norm strategy is insufficient.",
        "No clear method described for adaptively estimating the scale of the logarithm transformation.",
        "Theoretical analysis is limited and could be strengthened."
      ],
      "questions": [
        "Why do the baseline methods underperform STL on most datasets?",
        "What experimental evidence supports the effectiveness of the maximum‑norm strategy?",
        "How is the scale for the logarithm transformation adaptively estimated?",
        "Could a more comprehensive theoretical analysis enhance the credibility of DB‑MTL?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "8FHWkY0SwF",
    "title": "Learning Personalized Causally Invariant Representations for Heterogeneous Federated Clients",
    "std_review": {
      "summary": "The paper introduces FedSDR, a federated learning framework that uses causal modeling to mitigate shortcut learning while preserving client personalization. It demonstrates improved robustness across multiple datasets, but experimental results are mixed, with some unexpected lower accuracies on baseline methods. The method is innovative and addresses a key challenge in federated learning, yet its strong theoretical assumptions and lack of comprehensive comparison limit full acceptance.",
      "strengths": [
        "Innovative causal modeling approach to address shortcut learning in federated learning.",
        "Strong theoretical foundation with clear assumptions and implications.",
        "Comprehensive experimental evaluation across multiple datasets."
      ],
      "weaknesses": [
        "Algorithmic choice of Algorithm 1 is not clearly justified.",
        "Unexpected experimental results on CMNIST and CFMNIST datasets.",
        "Strong theoretical assumptions that may not hold in practice.",
        "Lack of comparison with robust federated learning and federated domain generalization methods."
      ],
      "questions": [
        "Why was Algorithm 1 chosen over conventional client selection methods?",
        "How do the unexpected lower accuracies on CMNIST and CFMNIST datasets affect the robustness of the findings?",
        "What are the detailed configurations of the models used in the experiments?",
        "How can the strong assumptions in the theoretical analysis be relaxed for practical use?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "8FP6eJsVCv",
    "title": "Explanation Shift: How Did the Distribution Shift Impact the Model?",
    "std_review": {
      "summary": "The paper introduces a novel method for detecting distribution shifts in machine learning models by analyzing explanation shifts using Shapley values. It effectively captures how model behavior changes under distribution shifts and compares favorably to baseline approaches. While the approach is theoretically sound and demonstrates good sensitivity, it could benefit from broader evaluation and deeper exploration of theoretical properties and alternative methods.",
      "strengths": [
        "Introduces a novel perspective on distribution shift detection by focusing on explanations.",
        "Leverages Shapley values to provide a theoretically sound foundation for the method.",
        "Comprehensive evaluation setup demonstrates the method's sensitivity and effectiveness compared to baselines."
      ],
      "weaknesses": [
        "Evaluation could be strengthened with more diverse datasets and real-world scenarios.",
        "Limited analysis of trade-offs between different feature attribution methods.",
        "Runtime comparison does not fully account for potential optimizations.",
        "Alternative tests or methods for distinguishing explanation distributions are underexplored."
      ],
      "questions": [
        "How does the method perform on more diverse datasets and real-world scenarios?",
        "What are the trade-offs between different feature attribution methods beyond Shapley values?",
        "Are there potential optimizations or parallelization techniques to improve runtime performance?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "8fQlGQkj0S",
    "title": "A Theoretical Analysis of In-context",
    "std_review": {
      "summary": "The paper presents a novel theoretical analysis of in-context learning using a Gaussian mixture model (GMM) to derive risk bounds for retrieval‑based tasks, identifying U‑shaped and flipped‑U risk patterns. While the analysis is mathematically rigorous and offers valuable insights into the trade‑off between retrieval accuracy and label noise, its reliance on synthetic data and simplified assumptions limits the generalizability of the findings. The authors propose several directions for future work, including real‑world validation and exploration of alternative loss functions.",
      "strengths": [
        "Clear theoretical framework with explicit risk bounds grounded in probabilistic models.",
        "Insightful identification of U‑shaped and flipped‑U risk patterns, linking them to practical challenges in language models.",
        "Contributes to the literature by reconciling zero‑shot and few‑shot performance observations."
      ],
      "weaknesses": [
        "Simplification of real data through a linear GMM may not capture the complexity of real‑world data distributions.",
        "Limited empirical validation confined to synthetic data, potentially limiting the generality of the results.",
        "Assumptions on retrieval quality (fixed threshold) may not align with dynamic retrieval processes.",
        "Focus on retrieval risk bounds without exploring alternative loss functions."
      ],
      "questions": [
        "How do the derived risk bounds generalize to real‑world NLP tasks beyond synthetic data?",
        "What are the implications of the optimal retrieval threshold identified for practical in‑context learning pipelines?",
        "How do alternative loss functions (e.g., cross‑entropy) affect the observed risk patterns and practical implications?",
        "What empirical studies are needed to validate the generality of the U‑shaped and flipped‑U risk patterns across diverse settings?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "8g26Yv1EOu",
    "title": "Amortized Network Intervention to Steer the Excitatory Point Processes",
    "std_review": {
      "summary": "The paper introduces a novel framework for learning and optimizing interventions in large-scale networks, treating discrete events as dynamic processes. It leverages amortized policy learning and node embeddings to capture both global and local network patterns, and introduces an intensity cost metric for evaluating intervention effectiveness. While innovative, the framework's complexity and limited experimental validation are noted as areas for improvement.",
      "strengths": [
        "Innovative modeling of discrete events as dynamic processes.",
        "Amortized policy learning that efficiently constructs policies from sub-network updates.",
        "Node embedding component capturing both global and local network patterns."
      ],
      "weaknesses": [
        "Complexity of implementation may be challenging for practitioners.",
        "Limited experimental validation across diverse network types.",
        "Assumptions of network homogeneity may limit applicability."
      ],
      "questions": [
        "How does the framework handle networks with highly heterogeneous node properties?",
        "What are the computational costs associated with amortized policy learning in large-scale systems?",
        "How does the intensity cost metric compare to traditional evaluation metrics in terms of predictive power?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "8GCcSXlkZN",
    "title": "Dense Representation Learning for a Joint-Embedding Predictive Architecture",
    "std_review": {
      "summary": "Dense-JEPA extends I-JEPA by adding a Masked Semantic Neighboring (MSN) mechanism and a Local Aggregation Target (LAT) module, which improve target representations and performance across image classification, semantic segmentation, object detection, and video object segmentation. The approach is theoretically justified and outperforms I-JEPA and other state-of-the-art methods, though it introduces computational overhead and potential overfitting. Overall, the paper is strongly recommended.",
      "strengths": [
        "Introduces innovative MSN mechanism for selecting semantically similar target patches.",
        "Leverages cross-attention in LAT module for effective local feature aggregation.",
        "Demonstrates strong performance across multiple downstream tasks."
      ],
      "weaknesses": [
        "Increased computational complexity may lead to longer training times and higher memory usage.",
        "Potential overfitting, especially with limited or non-diverse training data.",
        "Lacks comprehensive robustness analysis under adversarial conditions."
      ],
      "questions": [
        "How does the approach scale to extremely large or small model sizes?",
        "What are the specific strategies to mitigate overfitting in Dense-JEPA?",
        "Can the robustness of Dense-JEPA be evaluated under more adversarial scenarios?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "8giiPtg6rw",
    "title": "DataFreeShield: Defending Adversarial Attacks without Training Data",
    "std_review": {
      "summary": "DataFreeShield presents a novel, data-free defense mechanism that enhances adversarial robustness by generating synthetic images from a pretrained teacher model. The approach improves robustness against both weak and strong adversarial attacks, as shown in experimental results. The method is theoretically grounded with a loss formulation (Eq (8)) that effectively incorporates synthetic data. Overall, the paper makes a valuable contribution to adversarial defense.",
      "strengths": [
        "Data-Free Constraint: Uses only a pretrained teacher model to generate synthetic data, avoiding reliance on original training samples.",
        "Generative Model Flexibility: Leverages a pretrained teacher model to produce diverse and realistic synthetic images.",
        "Robustness Gains: Demonstrates substantial improvements in adversarial robustness compared to baselines.",
        "Theoretical Foundation: Provides a clear, theoretically grounded loss formulation (Eq (8)) for incorporating synthetic data."
      ],
      "weaknesses": [
        "Synthetic Data Quality: Effectiveness depends on the quality of the pretrained teacher model; poor or limited diversity can limit robustness gains.",
        "Computational Cost: Generating high-quality synthetic images can be computationally intensive.",
        "Limited Generalization: Relies on a single pretrained teacher model, which may not match the target data distribution.",
        "Potential Overfitting: The student model may overfit to synthetic data if not properly regularized."
      ],
      "questions": [
        "How robust is the method to variations in the pretrained teacher model's quality or diversity?",
        "What are the practical implications of the computational cost for large-scale applications?",
        "Can the method be adapted to scenarios where the teacher model does not closely match the target data distribution?",
        "What strategies can be employed to prevent overfitting to synthetic data?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "8GmPLkO0oR",
    "title": "DNAct: Diffusion Guided Multi-Task",
    "std_review": {
      "summary": "The paper presents NeRFuser/DNAct, a novel approach for learning 3D representations and policies using diffusion training, addressing limitations of previous methods. It introduces a unique pre-training phase for the 3D encoder and joint training of the policy, enabling robust multi-modal representation without requiring complete scene observation. The method shows improved stability and flexibility in neural rendering across diverse datasets, enhancing generalization to new environments and objects. Overall, the paper makes significant technical contributions to 3D learning and is recommended for acceptance.",
      "strengths": [
        "Innovative pre-training and joint training approach",
        "Leverages diffusion training for robust multi-modal representation",
        "Addresses voxel-based limitations, improving scalability and applicability",
        "Demonstrates enhanced stability and flexibility in neural rendering"
      ],
      "weaknesses": [
        "Increased implementation complexity due to diffusion training",
        "Potential for overfitting with flexible dataset usage",
        "Performance on highly dynamic scenes remains untested"
      ],
      "questions": [
        "How does the method handle scenes with rapidly changing lighting conditions?",
        "What are the specific ablations performed to evaluate the impact of the neural rendering objective?",
        "Can the method be extended to handle real-time or interactive applications?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "8gZtt8nrpI",
    "title": "Diffusion Models With Learned Adaptive Noise",
    "std_review": {
      "summary": "The paper introduces MuLAN, a method that augments the VDM framework with auxiliary latent variables to learn a dynamic, instance-specific noise schedule. This approach aims to improve the variational posterior by allowing the noise level to adapt during training, potentially leading to better sample quality and training stability. Empirical results on image generation tasks demonstrate that MuLAN achieves comparable or improved performance over the standard VDM baseline while maintaining competitive training efficiency. The reviewer finds the method compelling, with a solid theoretical framework and strong empirical benefits, though some concerns about complexity and scalability remain.",
      "strengths": [
        "Innovative Noise Schedule Learning: Introduces a novel mechanism for learning a non‑identical, instance‑dependent noise schedule, which can adaptively adjust the noise level during training.",
        "Theoretical Justification: Provides a clear theoretical rationale for why a dynamic noise schedule can improve the variational posterior, leveraging insights from stochastic variational inference.",
        "Empirical Validation: Demonstrates strong empirical performance on image generation tasks, showing that MuLAN can produce higher quality samples and stabilize training compared to VDM.",
        "Interpretability of Auxiliary Variables: Analyzes the auxiliary latent variables to uncover interpretable patterns, offering insights into how the noise schedule influences the learning process."
      ],
      "weaknesses": [
        "Complexity vs. Benefit: The added complexity of incorporating auxiliary latent variables may not always justify the performance gains, especially for simpler tasks or datasets.",
        "Training Time Overhead: While the paper shows improved training speed, the additional computational cost of managing auxiliary variables could be a concern for large-scale applications.",
        "Scalability Concerns: The effectiveness of the dynamic noise schedule may vary across different types of data and model architectures, limiting the generalizability of the approach.",
        "Lack of Baseline Comparison: The paper could benefit from a more comprehensive comparison with other state‑of‑the‑art methods, particularly those that also address dynamic noise schedules or variational posterior improvements."
      ],
      "questions": [
        "How does the added complexity of auxiliary latent variables impact performance on simpler tasks or smaller datasets?",
        "What is the exact computational overhead introduced by the auxiliary variables, and how does it affect training time for large-scale applications?",
        "How does the learned adaptive noise schedule perform across different data types and model architectures beyond the image generation tasks evaluated?",
        "Could a more detailed comparison with other state‑of‑the‑art methods that address dynamic noise schedules or variational posterior improvements provide additional insights?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "8jKuUHsndT",
    "title": "Re-evaluating Retrosynthesis Algorithms with Syntheseus",
    "std_review": {
      "summary": "The paper introduces Pistachio, a framework that enhances molecule generation using the USPTO‑FULL dataset with a multi‑step planning method called FusionRetro and a novel set‑wise exact match metric. It demonstrates superior performance over the USPTO‑FULL baseline and provides a comprehensive library (SYNTHESEUS) for reproducible research. While innovative, the approach has concerns about computational complexity, metric specificity, and limited external validation.",
      "strengths": [
        "Introduces FusionRetro, a systematic multi‑step planning method for flexible and chemically plausible molecule generation.",
        "Proposes the set‑wise exact match metric, offering a more nuanced evaluation of generated molecules.",
        "Delivers a well‑documented SYNTHESEUS library that promotes reproducibility and ease of use."
      ],
      "weaknesses": [
        "FusionRetro may introduce significant computational overhead and complexity.",
        "The set‑wise exact match metric may not capture all aspects of molecule quality.",
        "Evaluation is limited to internal benchmarks from the USPTO‑FULL dataset.",
        "Potential overfitting to the USPTO‑FULL data could reduce generalizability."
      ],
      "questions": [
        "How does the approach handle scalability and resource constraints in real‑world settings?",
        "What are the implications of the set‑wise exact match metric on synthetic feasibility and biological activity?",
        "How can the framework be validated on external benchmarks beyond the USPTO‑FULL dataset?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "8JKZZxJAZ3",
    "title": "Nonnegative Matrix Factorization through Canonical Edges",
    "std_review": {
      "summary": "The paper introduces nonnegative canonical edges (NCEs) as a novel approach within nonnegative matrix factorization (NMF) for enhanced feature extraction. It provides a solid theoretical foundation and highlights potential applications in fields like image processing and bioinformatics. However, the lack of experimental validation and comparative analysis with existing NMF algorithms limits the paper's impact and applicability.",
      "strengths": [
        "Introduces NCEs as a new perspective within NMF, offering a fresh approach to handling nonnegative data.",
        "Provides a solid theoretical basis for the proposed method, detailing the mathematical formulation and properties of NCEs.",
        "Highlights potential applications in areas such as image processing, bioinformatics, and social network analysis, where nonnegative data is common."
      ],
      "weaknesses": [
        "Absence of experimental evaluations on real datasets raises concerns about the method's practical applicability and effectiveness.",
        "Lack of comparative analysis with existing NMF algorithms makes it difficult to assess the method's relative performance.",
        "Limited scope of discussion on the coverage of NCEs for subspaces in general position lacks concrete evidence or quantitative results."
      ],
      "questions": [
        "What are the key challenges in adapting the proposed method to real-world data, and how can they be addressed?",
        "How should the proposed method be compared with existing NMF algorithms in terms of reconstruction error, computational efficiency, and feature quality?",
        "What experimental settings, datasets, and evaluation metrics should be used to provide concrete evidence for the coverage of NCEs for subspaces in general position?"
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "8Ju0VmvMCW",
    "title": "",
    "std_review": {
      "summary": "The paper introduces labeled pseudo-NTK (lpNTK), a framework that extends the standard NTK to better capture training dynamics by categorizing example interactions. It provides theoretical justification and practical tools for data pruning and selective prediction, with empirical results showing improved model performance and interpretability. While the method offers significant insights, it faces challenges in computational complexity and scalability, and its broader applicability remains limited.",
      "strengths": [
        "Theoretical Foundation: Rigorously defines lpNTK and justifies its use.",
        "Practical Tools: Introduces data pruning and selective prediction tools.",
        "Empirical Validation: Demonstrates improvements on multiple datasets."
      ],
      "weaknesses": [
        "Computational Complexity: May introduce significant overhead.",
        "Scalability: Interaction analysis could limit scalability.",
        "Assumptions: Relies on specific conditions that may not hold in all scenarios."
      ],
      "questions": [
        "How can lpNTK be extended to handle noisy or mislabeled data?",
        "What are the computational costs for very large models or datasets?",
        "How does lpNTK perform in few-shot or zero-shot learning scenarios?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "8LBS1nixTJ",
    "title": "HashOrder: Accelerating Graph Processing Through Hashing-based Reordering",
    "std_review": {
      "summary": "HashOrder introduces a novel graph reordering technique that uses a hash function to map nodes to a low-dimensional space, followed by a greedy ordering to minimize fill-in during sparse matrix factorization. Theoretically grounded by Theorem 1, which bounds fill-in based on the graph's spectral gap, the method outperforms existing techniques like GOrder and RCM across synthetic and real-world datasets. While demonstrating strong empirical results and scalability, the paper notes limitations for large-diameter graphs and the need for robustness analysis.",
      "strengths": [
        "Novel hash‑based mapping offers a fresh perspective on graph reordering.",
        "Theorem 1 provides a rigorous theoretical guarantee linking hash properties to fill‑in.",
        "Empirical superiority across diverse datasets with lower fill‑in and faster factorization."
      ],
      "weaknesses": [
        "Assumptions on graph structure may limit applicability to graphs with large diameters or non‑small‑world properties.",
        "Performance sensitive to hash function choice and parameters, requiring careful tuning.",
        "Lack of analysis on robustness to noisy or adversarial inputs.",
        "Comparisons with newer reordering techniques are not provided."
      ],
      "questions": [
        "How does HashOrder perform on graphs with very large diameters or non‑small‑world structures?",
        "What is the impact of hash function choice and parameter tuning on practical performance?",
        "Could a more comprehensive robustness analysis be provided for noisy or adversarial graphs?",
        "How does HashOrder compare to recent or specialized reordering methods?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "8nxy1bQWTG",
    "title": "DiffEnc: Variational Diffusion",
    "std_review": {
      "summary": "The paper introduces DiffEnc, a learnable encoder integrated into a diffusion model to enhance its generative capabilities. It achieves significant improvements in likelihood (BPD) on CIFAR‑10, with a theoretical analysis guiding the encoder's design. While the approach shows promise, concerns about complexity, interpretability, and limited evaluation on other datasets remain.",
      "strengths": [
        "Significantly improves generative performance with a 2.63 BPD on CIFAR‑10.",
        "Provides a strong theoretical foundation with variance ratio and infinite depth limits.",
        "Enhances interpretability of the encoded space, offering insights into model behavior."
      ],
      "weaknesses": [
        "The added complexity of the learnable encoder may not justify benefits for simpler datasets.",
        "Potential challenges in training stability due to the new learnable component.",
        "Performance is primarily evaluated on CIFAR‑10, with limited validation on other datasets."
      ],
      "questions": [
        "How does the approach scale to more complex datasets or tasks?",
        "What is the interpretability of the encoded space for high-dimensional data?",
        "How does the conditioning on time versus direct data conditioning affect performance in different scenarios?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "8nz6xYntfJ",
    "title": "AlignDiff: Aligning Diffusion Models for General Few-Shot Segmentation",
    "std_review": {
      "summary": "The paper presents AlignDiff, a novel approach to few-shot image segmentation using text-conditioned diffusion models. It addresses instance misalignment and object-centric bias through normalized masked textual inversion and semi-supervised mask generation. Experiments show strong performance on standard benchmarks, though computational cost and OOD class handling remain limitations.",
      "strengths": [
        "Introduces a unique method for aligning text and image representations in few-shot segmentation.",
        "Effectively mitigates instance misalignment and reduces object-centric bias.",
        "Demonstrates strong experimental validation across multiple datasets and settings."
      ],
      "weaknesses": [
        "Requires substantial computational resources, limiting accessibility.",
        "Does not adequately address performance on out-of-distribution classes.",
        "Lacks detailed analysis of robustness to input variations."
      ],
      "questions": [
        "How can the method be made more computationally efficient?",
        "What strategies can be employed to improve performance on out-of-distribution classes?",
        "Could additional experiments on diverse datasets and resolutions provide further insights?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "8OBuqbLb8h",
    "title": "Fast-ELECTRA for Efficient Pre-training",
    "std_review": {
      "summary": "Fast-ELECTRA introduces a novel approach to ELECTRA-style pretraining by decoupling the generator from the discriminator, allowing the generator to be trained separately and reused. This method achieves comparable or better performance than existing ELECTRA models while significantly reducing computational cost and memory usage. The paper highlights the broader implications for large-scale language model training, particularly in overcoming memory constraints. Overall, the approach is promising and well-received for its efficiency and scalability.",
      "strengths": [
        "Introduces a unique method of decoupling the generator from the discriminator, offering a fresh perspective on improving training efficiency.",
        "Achieves results that are on par with or better than existing ELECTRA-style models, demonstrating the effectiveness of the proposed method.",
        "Significantly reduces memory consumption during pretraining, addressing a critical limitation for large-scale language models."
      ],
      "weaknesses": [
        "There is a noticeable gap in performance compared to some recent methods, which could be a concern for applications requiring the highest possible performance.",
        "The authors acknowledge the potential to reduce the performance gap while maintaining efficiency, suggesting that this is an area for future research."
      ],
      "questions": [
        "How can the performance gap with recent methods be further reduced while maintaining efficiency?",
        "What are the optimal strategies for designing a learning curriculum to bridge the performance gap?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "8ohamFnX14",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a novel framework for modeling metabeliefs using a colimit of probability spaces under the final topology. It establishes strong topological properties for the limiting space and demonstrates its application through a rock-paper-scissors game example. The authors highlight potential applications in machine learning, particularly in hierarchical learning and social inference. Overall, the paper is well‑structured, mathematically rigorous, and makes a significant contribution to the field.",
      "strengths": [
        "Provides a coherent mathematical framework for modeling metabeliefs.",
        "Establishes strong topological properties (metrizability, paracompactness, Hausdorffness) for the limiting space.",
        "Extends the model to index-dependent cases, increasing its applicability.",
        "Illustrates the model with a clear and intuitive rock-paper-scissors game example."
      ],
      "weaknesses": [
        "The mathematical formalism may be challenging for readers without a strong background in topology and measure theory.",
        "Practical computational implementations of the colimit model could face challenges, especially in high-dimensional spaces.",
        "The paper could benefit from a more detailed comparison with existing approaches."
      ],
      "questions": [
        "How can the colimit model be extended to handle non‑stationary or dynamic belief systems?",
        "What are the computational complexities involved in implementing the colimit model for large‑scale applications?",
        "How does the model perform in scenarios where beliefs are not perfectly rational or where noise is introduced?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "8oNzf7u5lT",
    "title": "Pylic: Leveraging Source Code for Planning in Structured Environments",
    "std_review": {
      "summary": "The paper presents Pylic, a planning framework that uses structured source code to define 'meaningful events' for pathfinding within simulations. It dynamically generates event sequences, reducing the need for extensive domain knowledge upfront. Empirical experiments show improved performance over baselines, though the approach assumes well‑structured code and relies on local search, which may struggle in complex environments. Overall, the framework is innovative and promising, with some practical considerations.",
      "strengths": [
        "Introduces a novel definition of meaningful events that is flexible and context‑specific.",
        "Leverages source code structure to dynamically generate event sequences, enhancing adaptability.",
        "Provides strong empirical validation through experiments demonstrating improved performance."
      ],
      "weaknesses": [
        "Relies on assumptions about the structure of the source code, which may limit applicability.",
        "Lack of a universally accepted definition of meaningful events could affect reproducibility.",
        "Performance depends on the reliability of the local search process in complex environments."
      ],
      "questions": [
        "How robust is the framework to variations in source code structure beyond what is assumed?",
        "What are the theoretical guarantees for the local search process in highly dynamic environments?",
        "How can the definition of meaningful events be standardized across different domains?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "8oUF3uGIVo",
    "title": "Exploring High-Order Message-Passing in Graph Transformers",
    "std_review": {
      "summary": "The paper introduces HOtrans, a framework that combines hypergraph neural networks with graph transformers to better model complex graph structures. It proposes a three-step message-passing framework that unifies hypergraph message passing with graph transformer attention, achieving competitive or superior performance on graph-level tasks compared to state-of-the-art models. The use of random walks for community sampling enhances scalability, making the model suitable for large-scale graphs. While the framework is theoretically justified, it could benefit from more rigorous mathematical proofs and a broader evaluation across different applications.",
      "strengths": [
        "Innovative integration of hypergraph neural networks with graph transformers.",
        "Unified three-step message-passing framework that leverages strengths of both approaches.",
        "Competitive or superior empirical performance on graph-level tasks.",
        "Scalability improvements through random walk community sampling."
      ],
      "weaknesses": [
        "Potential additional computational complexity from the three-step framework.",
        "Lack of more rigorous theoretical justification.",
        "Limited evaluation scope focusing primarily on graph-level tasks.",
        "Comparison with existing models is somewhat narrow."
      ],
      "questions": [
        "Could the authors provide more detailed theoretical analysis and proofs for the framework's properties?",
        "How does HOtrans perform on non-graph-level tasks or in dynamic graph settings?",
        "What are the computational costs and scalability limits of the proposed community-sampling strategies compared to other methods?",
        "Could the authors explore additional sampling techniques or compare with other advanced transformer-based models?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "8OxL034uEr",
    "title": "MgNO: Efficient Parameterization of",
    "std_review": {
      "summary": "The paper introduces MgNO, a neural operator framework that uses a multigrid-based parameterization to improve computational efficiency and expressivity. It presents a universal approximation theorem and demonstrates scalability across input resolutions. While showing promise, the approach faces implementation complexity and limited benchmarking against existing methods.",
      "strengths": [
        "Efficient parameterization using multigrid reduces trainable parameters while maintaining expressivity.",
        "Theoretical foundation with a universal approximation theorem (Theorem 3.1).",
        "Demonstrates effective scaling with input resolution, suitable for high-fidelity simulations."
      ],
      "weaknesses": [
        "Implementation complexity due to the multigrid-based approach.",
        "Lack of extensive benchmarking against other neural operator architectures.",
        "Potential computational overhead from managing multiple grid resolutions.",
        "Limited empirical evidence on scalability to very high resolutions."
      ],
      "questions": [
        "How does MgNO compare to other state-of-the-art neural operator methods in terms of both efficiency and accuracy?",
        "What are the practical steps to implement the multigrid-based parameterization in real-world applications?",
        "Could the computational overhead be mitigated, and if so, how?",
        "What further benchmarking studies are needed to establish MgNO's competitive advantage?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "8oYjW8QxuC",
    "title": "Pi-DUAL: Using privileged information to distinguish clean from noisy labels",
    "std_review": {
      "summary": "Pi-DUAL introduces a novel semi-supervised learning framework that dynamically adapts to per-instance label noise and leverages privileged information (PI) to improve performance, especially on large datasets like ImageNet-PI. The method shows significant gains over existing label-noise and semi-supervised techniques, demonstrating strong robustness and scalability. While implementation complexity and sensitivity to PI quality are noted, these can be mitigated with better PI acquisition strategies. Overall, Pi-DUAL is a promising approach that advances semi-supervised learning by effectively handling noisy labels and integrating PI.",
      "strengths": [
        "Dynamic label noise adaptation enhances robustness.",
        "Effective use of privileged information improves semi-supervised results.",
        "Scalable design suitable for large datasets."
      ],
      "weaknesses": [
        "Implementation complexity due to dynamic adaptation and PI integration.",
        "Reliance on high-quality privileged information.",
        "Limited ablation studies on model architecture."
      ],
      "questions": [
        "How can the method be adapted to scenarios with low-quality or randomly generated privileged information?",
        "What are the computational costs associated with training on very large datasets, and how can they be optimized?",
        "Could more extensive ablation studies on model architecture and hyperparameters provide additional insights?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "8oZf2SlXEY",
    "title": "Distribution Calibration For Few-Shot Learning by Bayesian Relation Inference",
    "std_review": {
      "summary": "The paper presents a novel graph-based method for integrating heterogeneous information in machine learning tasks by constructing a relation graph and learning node embeddings that combine local and global structural information. While the approach shows promise with strong empirical results on graph-based tasks, it relies on a known relation graph and has limited experimental evaluation. The notation is inconsistent, and the splicing mechanism is not well-documented, making the method less clear.",
      "strengths": [
        "Introduces a novel relation graph framework for integrating heterogeneous information.",
        "Proposes a novel splicing mechanism for combining local and global information.",
        "Demonstrates strong empirical performance on graph-based tasks.",
        "Provides clear theoretical analysis and convergence guarantees."
      ],
      "weaknesses": [
        "Relies on the assumption that the relation graph is known a priori, which may not always be the case in real-world applications.",
        "The splicing mechanism is not well-documented, making it difficult to understand how the embeddings are combined.",
        "Experimental evaluation is limited to a few benchmark datasets without extensive ablation studies or sensitivity analysis.",
        "Notation used in the paper is inconsistent and can be confusing at times."
      ],
      "questions": [
        "How can the method be adapted to scenarios where the relation graph is not known a priori?",
        "Can you provide a more detailed explanation of the splicing mechanism and how local and global information are combined?",
        "What are the implications of the limited experimental evaluation on the robustness of the proposed method?",
        "How can the notation be standardized to improve clarity for readers?"
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "8p3fu56lKc",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a novel linear self-attention layer and analyzes its training dynamics through a least-squares formulation. It establishes conditions under which the model achieves a unique global minimizer despite being under-parameterized. Theoretical results are complemented by empirical insights, positioning the work within the broader context of self-attention mechanisms and optimization theory. The reviewer finds the paper innovative, theoretically rigorous, and well-connected to related work, with some minor concerns about notation and generality.",
      "strengths": [
        "Innovative linear self-attention framework that is computationally tractable while preserving essential properties.",
        "Strong theoretical foundation, including conditions for a unique global minimizer and a learning rate schedule based on the Hessian's largest eigenvalue.",
        "Comprehensive analysis of the impact of data covariance on the weight vector and its implications for model training and convergence.",
        "Clear connections to related work, situating contributions within self-attention and optimization literature."
      ],
      "weaknesses": [
        "Complex notation and indexing conventions that may require additional clarification.",
        "Assumptions on data covariance structure that could limit the generality of the results.",
        "Lack of explicit proof for the quantitative relationship between the learning rate and the largest eigenvalue of the Hessian.",
        "Potential for further empirical validation to strengthen the theoretical insights."
      ],
      "questions": [
        "Can the learning rate relationship be made more explicit or derived more rigorously?",
        "How robust are the theoretical results to variations in data covariance?",
        "What additional empirical studies could be conducted to further validate the theoretical insights?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "8pYNdmwGAO",
    "title": "EvolMPNN: Predicting Mutational Effect on Homologous Proteins by Evolution Encoding",
    "std_review": {
      "summary": "The paper introduces EvolMPNN, a graph neural network that integrates evolutionary information into protein representation learning. It leverages anchor proteins and a protein language model for residue embeddings, showing improved performance on protein engineering tasks. While innovative, the method has several concerns regarding anchor selection, lack of direct comparisons with related methods, and insufficient empirical justification for chosen aggregation strategies.",
      "strengths": [
        "Innovative integration of evolutionary information with modern GNN techniques.",
        "Effective use of anchor proteins to capture evolutionary context.",
        "Utilization of state-of-the-art protein language models for residue embeddings."
      ],
      "weaknesses": [
        "Ambiguity in the definition of anchor proteins and their selection process.",
        "Absence of direct comparison with comparable methods like EvolMPNN.",
        "Potential overfitting to specific benchmark datasets.",
        "Lack of empirical justification for the chosen aggregation method (mean pooling).",
        "Limited baseline comparison with the state of the art."
      ],
      "questions": [
        "How should the anchor proteins be defined and selected to ensure reproducibility and generalization?",
        "What is the optimal number of anchor proteins (M) relative to the total number of proteins (N)?",
        "Why was mean pooling chosen over other aggregation strategies, and what empirical evidence supports this choice?",
        "How does the method perform on broader benchmark datasets beyond those used in the evaluation?",
        "What empirical evidence demonstrates the superiority of the most parsimonious phylogenetic tree over alternative tree construction methods?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "8Q4uVOJ5bX",
    "title": "R&B: Region and Boundary Aware Zero-shot Grounded Text-to-image Generation",
    "std_review": {
      "summary": "The paper presents R&B, a training-free method for grounded text-to-image generation that improves spatial accuracy and attribute-noun binding. It introduces a two-module system (refinement and binding) and demonstrates significant improvements over existing approaches on multiple datasets. While the method shows promise, it has limitations in handling complex spatial arrangements and may struggle with generating complete objects in certain cases.",
      "strengths": [
        "Introduces a novel training-free approach to text-to-image generation focusing on spatial accuracy and attribute-noun binding.",
        "Proposes a two-module system (refinement and binding) that effectively addresses key challenges in grounded text-to-image synthesis.",
        "Demonstrates substantial improvements in spatial accuracy compared to previous methods through extensive experiments."
      ],
      "weaknesses": [
        "Limited evaluation on datasets with complex spatial arrangements involving multiple objects.",
        "Effectiveness in handling intricate prompts with multiple attributes or objects is not thoroughly explored.",
        "Struggles with generating complete or accurate objects in certain cases, such as the 'bundle of' example."
      ],
      "questions": [
        "How does the R&B method perform on datasets with complex spatial arrangements involving multiple objects?",
        "What design choices or modifications could improve the method's performance in handling intricate prompts with multiple attributes or objects?",
        "How does the refinement module iteratively refine the generated image to better align with spatial descriptions in the text?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "8QfK9Dq4q0",
    "title": "Class Incremental Learning via Likelihood Ratio Based Task Prediction",
    "std_review": {
      "summary": "The paper presents TPLR, a novel Continual Learning framework that estimates the probability of encountering a new task using likelihood‑ratio scores from task embeddings. It shows strong empirical performance on benchmark datasets while being more memory‑efficient than many existing methods. Despite its theoretical and practical strengths, the method's implementation complexity and limited baseline comparisons are noted.",
      "strengths": [
        "Introduces a unique task identification mechanism based on likelihood‑ratio scores.",
        "Provides a memory‑efficient approach without requiring explicit replay buffers.",
        "Grounded in a clear probabilistic framework with strong theoretical backing.",
        "Demonstrates competitive empirical results against state‑of‑the‑art baselines."
      ],
      "weaknesses": [
        "Implementation complexity due to likelihood‑ratio scores and task embeddings.",
        "Potential computational cost for large datasets or real‑time applications.",
        "Limited baseline comparison, missing recent memory‑free methods.",
        "Absence of ablation studies on task‑ID prediction robustness."
      ],
      "questions": [
        "How does TPLR perform when tasks have highly similar or dissimilar class distributions?",
        "What is the impact of class similarity on task‑ID prediction accuracy?",
        "Could additional ablation studies provide deeper insights into the method's robustness?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "8rhHI6C8iC",
    "title": "",
    "std_review": {
      "summary": "The paper introduces HPFL, a modular federated learning framework that enables selective adaptation to test-time data distribution shifts, improving accuracy and efficiency. While demonstrating strong potential, the framework has some limitations, such as limited real-world evaluation and the need for further optimization of module selection criteria. Overall, the HPFL framework is well-positioned for acceptance.",
      "strengths": [
        "Introduces a novel approach to handling test-time data distribution shifts in federated learning.",
        "Modular architecture allows for selective adaptation, improving model performance on diverse test samples.",
        "Demonstrates scalability and privacy-preserving capabilities, making it suitable for large-scale federated learning settings."
      ],
      "weaknesses": [
        "Limited evaluation on real-world datasets and scenarios may not fully capture the framework's performance in practical applications.",
        "The selection criteria for plug-in modules could be further explored and optimized for better adaptability.",
        "Potential computational overhead associated with dynamic module selection and application needs to be considered."
      ],
      "questions": [
        "How does HPFL perform on real-world datasets and scenarios beyond the ones evaluated?",
        "What are the specific criteria used to select plug-in modules, and how can they be further optimized?",
        "How does the computational overhead of dynamic module selection and application impact the overall performance and scalability of HPFL?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "8S14xeFQAY",
    "title": "Segmenting the Unknown: Discrete Diffusion Models for Non-Deterministic Segmentation",
    "std_review": {
      "summary": "The paper presents a novel approach to uncertainty quantification in medical image segmentation, specifically for distinguishing between two anatomical structures in brain MRI scans. It introduces a deep learning model that outputs both deterministic segmentations and aleatoric uncertainty estimates, improving segmentation accuracy and uncertainty estimation compared to baseline models. The method shows strong potential for clinical applications where understanding segmentation confidence is crucial, though it faces challenges in computational complexity and evaluation on complex datasets.",
      "strengths": [
        "Captures aleatoric uncertainty and provides probabilistic segmentations.",
        "Improves segmentation accuracy over baseline deterministic models.",
        "Facilitates informed decision-making in clinical settings with probabilistic outputs."
      ],
      "weaknesses": [
        "Computational complexity may limit real-time applicability in clinical environments.",
        "Performance on complex medical imaging datasets has not been fully evaluated.",
        "Does not explicitly model epistemic uncertainty (model uncertainty)."
      ],
      "questions": [
        "How does the method scale to larger datasets or more complex models?",
        "What is the impact of the method on real-time clinical workflows?",
        "How does the approach handle epistemic uncertainty in addition to aleatoric uncertainty?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "8S7eGD15b6",
    "title": "",
    "std_review": {
      "summary": "The paper introduces GridSweepPerturbationsL2, a deterministic defense mechanism that systematically sweeps over a grid of perturbations in an orthonormal basis to identify robust model configurations. It demonstrates significant improvements in robustness across multiple datasets and attack types, providing both theoretical guarantees and strong empirical results. Despite computational costs and basis selection challenges, the deterministic nature offers practical advantages. Overall, the paper is well‑received, with a clear contribution and promising results.",
      "strengths": [
        "Introduces a structured, novel approach to perturbation analysis for model robustness.",
        "Provides a clear theoretical framework and robustness guarantees.",
        "Shows substantial empirical improvements across various datasets and attack scenarios.",
        "Offers a deterministic defense, which can be more predictable and easier to implement than stochastic methods."
      ],
      "weaknesses": [
        "Computational expense due to sweeping over a grid of perturbations.",
        "Effectiveness heavily depends on the choice of orthonormal basis, which may require domain expertise.",
        "Limited evaluation to a few datasets and attack types may not fully capture general performance.",
        "Deterministic defenses may be less effective against sophisticated, adaptive adversaries."
      ],
      "questions": [
        "How can the computational cost be reduced while maintaining robustness gains?",
        "What strategies can be employed to optimize the choice of orthonormal basis for different model architectures?",
        "How does the method perform under more diverse and challenging adversarial scenarios not covered in the current evaluation?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "8sKcAWOf2D",
    "title": "Fine-Tuning Enhances Existing Mechanisms:",
    "std_review": {
      "summary": "The paper investigates how fine-tuning affects attention circuits in large language models, specifically comparing Llama-7B with its fine-tuned versions Vicuna-7B and Goat-7B. By dividing attention heads into four groups, the authors identify a circuit in the base model that is preserved across fine-tuned models and assess its impact on entity tracking tasks. The study provides valuable insights into the generalizability of identified circuits and the effects of fine-tuning, though it is limited by its focus on a single model and dataset.",
      "strengths": [
        "Introduces a novel approach to analyzing attention circuits by dividing them into four groups.",
        "Investigates the generalizability of identified circuits across different model variants.",
        "Conducts thorough experiments with quantitative and qualitative analyses.",
        "Addresses critical aspects of large language models, such as the impact of fine-tuning on model interpretability."
      ],
      "weaknesses": [
        "Relies on a single foundational model and dataset, limiting generalizability.",
        "Lacks comprehensive analysis of potential limitations of the approach.",
        "Focuses on entity tracking tasks, which may not capture all model capabilities.",
        "Could provide more detailed information on the path patching and circuit identification techniques."
      ],
      "questions": [
        "How do the findings generalize to other model architectures and sizes?",
        "What is the impact of different training datasets on the identified circuits?",
        "How robust is the identified circuit to variations in fine-tuning objectives?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "8SPSIfR2e0",
    "title": "Dissecting Language Models:",
    "std_review": {
      "summary": "The paper investigates neuron specialization in large language models and demonstrates that selective pruning of specific neurons can effectively remove task-specific capabilities. It compares this approach to contextual sparsity, showing finer control over capability removal. The study highlights practical benefits for model deployment, such as reduced computational costs and tailored architectures, but notes limitations in domain generalization and the need for more detailed baseline comparisons.",
      "strengths": [
        "Clear demonstration of neuron specialization within LLMs.",
        "Comparison with prior work on contextual sparsity provides nuanced insights.",
        "Practical implications for efficient model deployment."
      ],
      "weaknesses": [
        "Limited domain generalization due to focus on code-related tasks.",
        "Lack of detailed baseline comparison with other pruning methods.",
        "Scope of capability removal is not fully explored across all tasks."
      ],
      "questions": [
        "How does the observed neuron specialization generalize to other domains beyond code?",
        "What are the broader implications of selectively removing specific capabilities on overall model performance?",
        "How does the method compare to other fine-grained pruning techniques in terms of efficiency and effectiveness?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "8T7m27VC3S",
    "title": "3D Dense Captioning beyond Nouns: A Middleware for Autonomous Driving",
    "std_review": {
      "summary": "The paper introduces DESIGN, a middleware that enhances 3D dense captioning for autonomous driving by using a transformer-based architecture. It proposes a scalable labeling pipeline and demonstrates improved safety and intelligence in an end-to-end driving model. While effective, the approach has limitations in evaluation metrics, scalability, and handling uncertain intents, leading to a weak accept recommendation.",
      "strengths": [
        "Effectively bridges dense captioning and autonomous driving with detailed semantic annotations.",
        "Transformer-based architecture captures complex spatial-temporal relationships crucial for dynamic driving scenarios.",
        "Proposes a scalable automatic labeling pipeline addressing challenges of annotating open-set entities."
      ],
      "weaknesses": [
        "Evaluation metrics (collision rates, L2 distance) may not fully capture qualitative aspects of human-like reasoning.",
        "Scalability of the labeling pipeline is limited by the complexity of annotating open-set entities.",
        "Performance of the end-to-end driving model is not compared against state-of-the-art baselines.",
        "Uncertain object intents and forecasting in dynamic environments are not thoroughly addressed."
      ],
      "questions": [
        "How does the model handle scenarios with highly uncertain object intents or unexpected behaviors?",
        "What is the impact of the labeling pipeline's scalability on the overall efficiency of the approach in real-world applications?",
        "How does the end-to-end driving model's performance compare to other state-of-the-art baselines in terms of safety and intelligence?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "8TAGx549Ns",
    "title": "REX: Rapid Exploration and EXploitation",
    "std_review": {
      "summary": "The paper introduces REX, a reinforcement learning framework that balances exploration and exploitation through a structured reward validation approach. It shows strong performance on benchmarks like Blocksworld and GSM8K, but faces challenges with non-binary rewards and large action spaces. Overall, REX is a promising approach with notable strengths but some limitations that prevent full acceptance.",
      "strengths": [
        "Innovative reward validation mechanism",
        "Strong performance on standard benchmarks",
        "Clear and detailed algorithmic description",
        "Theoretical justification of exploration-exploitation trade-off"
      ],
      "weaknesses": [
        "Limited handling of non-binary rewards",
        "Performance variability with large action spaces",
        "Lack of comprehensive comparison with Tree-of-Thoughts (ToT)"
      ],
      "questions": [
        "How does REX perform on tasks with continuous or complex reward structures?",
        "What heuristic methods can be employed to improve REX's handling of large action spaces?",
        "How does REX compare to other state-of-the-art methods in terms of computational efficiency?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "8tWOUmBHRv",
    "title": "Offline Tracking with Object Permanence",
    "std_review": {
      "summary": "The paper presents an offline tracking framework that integrates object permanence to improve tracking in dynamic environments. It introduces a track completion module to handle occlusions and re‑identification, achieving superior performance on the nuScenes dataset. While innovative, the framework lacks detailed reproducibility information and may overfit to the training data, limiting its generalizability.",
      "strengths": [
        "Innovative integration of object permanence for enhanced tracking.",
        "Effective track completion module improves continuity during occlusions.",
        "Strong performance gains on the nuScenes dataset."
      ],
      "weaknesses": [
        "Lack of detailed reproducibility information for training and evaluation.",
        "Potential overfitting to the nuScenes dataset.",
        "Absence of richer appearance features for robustness."
      ],
      "questions": [
        "Could you provide more details on the training hyper‑parameters and experimental setup to improve reproducibility?",
        "How does the framework perform on more diverse datasets beyond nuScenes?",
        "What additional appearance features could be incorporated to further enhance robustness?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "8Ur2xmuw7w",
    "title": "Revisiting Link Prediction: a data perspective",
    "std_review": {
      "raw_text": "{\n  \"summary\": \"The paper introduces a novel graph embedding method that integrates feature proximity with structural proximity to improve node representation in heterogeneous graphs. It proposes a theoretical model that accounts for heterophily by adjusting proximity measures based on feature similarity and structural context. Experimental results demonstrate superior performance on link prediction and node classification tasks across several benchmark datasets, highlighting the method's effectiveness in diverse graph domains. While the paper makes a significant contribution to addressing heterophily in graph embedding, it could improve readability and self-contained presentation.\",\n  \"strengths\": [\n    \"Innovative Integration of Proximity Measures: The paper effectively combines feature proximity with local and global structural proximity, providing a nuanced approach to graph embedding that respects both feature and structural information.\",\n    \"Theoretical Foundation: The development of a theoretical model that explicitly incorporates heterophily is a significant contribution, offering insights into how different proximity measures can conflict and why adjustments are necessary.\",\n    \"Empirical Validation: The experimental results across multiple datasets and tasks provide strong evidence of the method's effectiveness, showcasing its broad applicability and robustness.\",\n    \"Clear Problem Statement: The paper clearly defines the challenges posed by heterophily in graph embedding, setting a clear context for the proposed solution.\"\n  ],\n  \"weaknesses\": [\n    \"Complexity and Readability: The paper is dense and may be challenging to follow without prior knowledge of graph theory and embedding techniques, potentially limiting its accessibility to a broader audience.\",\n    \"Placement of Technical Details: Important parameters and details, such as the role of the parameter \\( r \\), are relegated to appendices, which can hinder the paper's self-contained nature.\",\n    \"Limited Discussion of Limitations: The limitations, broader impacts, and future work are discussed in appendices rather than the main text, which may not meet the conference's 9-page limit for a self-contained paper.\",\n    \"Connection to Theory and Experiments: There is a lack of explicit linkage between the theoretical model and the experimental results, making it less clear how the theoretical insights guide the empirical findings and model design.\"\n  ],\n  \"questions\": [\n    \"How can the paper improve its readability and self-contained presentation to better fit the 9-page limit?\",\n    \"Can you provide a clearer link between the theoretical model and the experimental results to enhance the coherence between theory and practice?\",\n    \"Should the parameter \\( r \\) and other technical details be integrated into the main text to improve accessibility?\"\n  ],\n  \"overall_score\": \"6: weak accept\",\n  \"confidence\": \"3: medium\"\n}",
      "parse_error": true
    }
  },
  {
    "paper_id": "93LoCyww8o",
    "title": "The HIM Solution for Legged Locomotion:",
    "std_review": {
      "summary": "The paper introduces a Hybrid Internal Model (HIM) for legged locomotion, combining dynamics-aware representations with contrastive learning to improve performance in unstructured environments. The approach is evaluated through comprehensive ablations and experiments across various terrains and command ranges, showing competitive tracking error and success rates compared to baseline methods. The reviewer finds the method promising and robust, with clear strengths in its innovative approach and robust evaluation framework, while noting concerns about implementation complexity and limited real-world validation.",
      "strengths": [
        "Innovative Hybrid Approach: Combines dynamics-aware representations with contrastive learning for unstructured environments.",
        "Robustness Across Terrains: Demonstrates effective generalization across diverse terrain types and command ranges.",
        "Clear Evaluation Framework: Provides thorough ablation studies and comparisons with state-of-the-art methods."
      ],
      "weaknesses": [
        "Complexity of Implementation: Integrating multiple components may increase implementation complexity.",
        "Limited Real-World Validation: Real-world experiments are limited, potentially affecting generalizability.",
        "Performance Trade-offs: Ablations suggest potential trade-offs between prototype number and performance."
      ],
      "questions": [
        "How can the implementation complexity be addressed to make HIM more accessible to other researchers?",
        "What further real-world validation experiments are planned to enhance the generalizability of the findings?",
        "Are there additional ablations or optimizations that could further improve the balance between prototype number and performance?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "94FKDbtTqO",
    "title": "Rethinking the BERT-like Pretraining for DNA Sequences",
    "std_review": {
      "summary": "The paper introduces RandomMask, a novel tokenization technique for DNA sequences that masks random token sequences during pre‑training, potentially uncovering more nuanced patterns. It shows improvements in downstream tasks like Biotype Embeddings and competitive benchmark performance, but lacks a comprehensive comparison with existing methods and evidence of generalization to unseen data. The method's effectiveness is promising yet not fully substantiated.",
      "strengths": [
        "Innovative tokenization strategy that masks random sequences, potentially uncovering more nuanced patterns in DNA sequences.",
        "Demonstrates improvements in downstream tasks such as Biotype Embeddings, indicating enhanced embedding quality.",
        "Competitive performance on standard benchmark datasets, suggesting robustness across different evaluation metrics."
      ],
      "weaknesses": [
        "Lacks a comprehensive comparative analysis with established tokenization strategies like BPE.",
        "Insufficient evidence of how RandomMask generalizes to unseen data or different DNA‑based tasks.",
        "Potential for overfitting due to reliance on random masking, especially if pre‑training data is not sufficiently diverse."
      ],
      "questions": [
        "How does RandomMask compare to other tokenization methods like BPE in terms of performance and robustness?",
        "What is the impact of RandomMask on model convergence and generalization to unseen data?",
        "What is the optimal configuration of masking parameters (e.g., number of consecutive masked tokens, pre‑training stages) for different scenarios?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "9528xxcT7h",
    "title": "Two Heads are Better than One:",
    "std_review": {
      "summary": "The paper introduces a novel transductive defense mechanism that combines rejection and transduction to enhance adversarial robustness. It proposes a theoretical framework with a tighter bound for error-abstention trade‑offs, validated empirically on MNIST and CIFAR‑10. The method shows significant improvements over existing approaches, especially in limited or streaming data scenarios, but has limitations related to test data dependency and scalability.",
      "strengths": [
        "Novel combination of rejection and transductive learning for adversarial robustness",
        "Theoretical contribution: tighter bound (Theorem 4.1) for error-abstention trade‑offs",
        "Empirical validation on MNIST and CIFAR‑10 demonstrating practical benefits"
      ],
      "weaknesses": [
        "Theoretical results depend on access to test data",
        "Additional computational complexity in the transductive setting",
        "Assumes equivalence between robust classification and selective classification",
        "Empirical focus on image classification tasks"
      ],
      "questions": [
        "How can the method be extended to scenarios where test data is not available?",
        "What is the impact of the equivalence assumption on robustness in more complex adversarial settings?",
        "Can the framework be applied to non‑image model types or other adversarial scenarios?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "95joD3Yc5t",
    "title": "Generative Semantic Communication:",
    "std_review": {
      "summary": "The paper presents a novel semantic diffusion framework for communication that effectively regenerates high-quality semantic maps from noisy transmissions. It introduces a Fast Denoising Semantic (FDS) block to efficiently handle channel noise while preserving semantic information, demonstrated through robust performance across various noise conditions. The evaluation uses comprehensive metrics like mIoU, LPIPS, and FID, indicating strong real-world applicability. Despite promising results, the framework's generalizability is limited by the narrow dataset scope and lack of clean input performance metrics, suggesting areas for future improvement.",
      "strengths": [
        "Introduces a semantic diffusion model tailored for semantic image synthesis, advancing beyond traditional pixel-level diffusion models.",
        "Features an efficient Fast Denoising Semantic (FDS) block that significantly reduces computational cost while maintaining high performance.",
        "Provides a thorough evaluation using multiple metrics (mIoU, LPIPS, FID) to assess both perceptual quality and fidelity of regenerated images.",
        "Demonstrates practical relevance through real-world communication scenarios, including tasks like object detection and depth estimation."
      ],
      "weaknesses": [
        "Evaluation is limited to the Cityscapes and COCO-Stuff datasets, potentially restricting the framework's applicability to other domains.",
        "Lacks quantitative results for clean input performance, which is crucial for understanding the framework's core capability.",
        "The computational cost of the FDS block is not fully quantified compared to a full denoising network, which could be a concern for resource-constrained environments.",
        "Baseline comparisons are not exhaustive, possibly overlooking other state-of-the-art methods."
      ],
      "questions": [
        "How does the framework perform on more diverse datasets beyond Cityscapes and COCO-Stuff?",
        "What is the exact computational cost of the FDS block relative to a full denoising network?",
        "Could you provide quantitative results for the framework's performance on clean semantic maps?",
        "How does the proposed method compare to other recent state-of-the-art semantic communication models?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "95ObXevgHx",
    "title": "",
    "std_review": {
      "summary": "The paper presents a novel approach to converting electrocorticography (ECoG) signals into speech using a transformer-based language model (GPT-2). It introduces a preprocessing pipeline for ECoG data and demonstrates that the model can generate intelligible speech, suggesting potential for real-time speech generation from brain activity. While the study makes a significant contribution to neuroprosthetics, it lacks detailed preprocessing steps, optimization details, and comparison with other models, which limits its robustness and generalizability. The exploration of underlying biophysical mechanisms is also missing.",
      "strengths": [
        "Introduces a novel approach to converting brain signals into speech using advanced transformer models.",
        "Uses ECoG, a less invasive alternative to intracranial EEG, making the method more feasible for clinical applications.",
        "Provides a detailed preprocessing pipeline for ECoG data, crucial for reproducibility and further research."
      ],
      "weaknesses": [
        "Preprocessing pipeline lacks detailed descriptions of specific steps, affecting reproducibility.",
        "No mention of optimizing encoding model parameters or architectures, which could improve performance.",
        "Only compares the model to GPT-2, without evaluating other neural language models.",
        "Does not explore the biophysical mechanisms underlying the observed layer-timing relationships."
      ],
      "questions": [
        "Could you provide more details on the specific preprocessing steps, such as filtering, normalization, and feature extraction?",
        "Were any optimization techniques applied to the encoding model parameters or architectures?",
        "How does the model's performance compare to other neural language models like BERT or T5?",
        "What are the biophysical mechanisms that could explain the observed layer-timing relationships between ECoG signals and generated speech?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "96nX9xIIx2",
    "title": "Visual Prompting Upgrades Neural Network Sparsification: A Data-Model Perspective",
    "std_review": {
      "summary": "The paper introduces a novel visual prompting pruning method for vision models that leverages a data-model co-design paradigm to enhance sparsification. It demonstrates improved performance across various sparsity levels compared to existing pruning techniques and shows competitive results on multiple datasets. While the method is effective, it has limitations such as limited evaluation on non-image tasks and insufficient exploration of computational and latency implications. Overall, the paper makes a significant contribution to the field.",
      "strengths": [
        "Introduces a novel visual prompting pruning method that effectively combines data and model design principles to enhance sparsification.",
        "Demonstrates strong performance across a range of sparsity levels, outperforming several existing pruning techniques.",
        "Provides comprehensive experimental evaluations on multiple datasets, showcasing the method's versatility and robustness."
      ],
      "weaknesses": [
        "Limited evaluation on non-image tasks such as object detection or segmentation, which may restrict the method's applicability to broader domains.",
        "The computational and latency implications of the proposed method are not thoroughly explored, potentially impacting its practicality in real-world scenarios.",
        "The method's performance compared to other recent pruning techniques, such as BiP or other structured/unstructured pruning methods, is not fully addressed.",
        "The impact of visual prompting on model generalization is not quantitatively evaluated, leaving open questions about the method's ability to generalize to unseen data."
      ],
      "questions": [
        "How does the proposed method perform on non-image tasks such as object detection or segmentation?",
        "What are the computational and latency implications of the proposed method, and how does it compare to other pruning techniques?",
        "How does visual prompting affect the model's generalization to unseen data, and what are the quantitative evaluations for this impact?",
        "How does the performance of the proposed method compare to other recent pruning techniques like BiP or other structured/unstructured pruning methods?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "97Dl82avFs",
    "title": "Alt-Text with Context:",
    "std_review": {
      "summary": "The paper proposes using user-generated Twitter captions as a benchmark for evaluating image captioning models, offering a more realistic and diverse set of references. It includes a user study to qualitatively assess caption relevance and quality, addressing limitations of existing datasets. However, concerns about noise in user captions, lack of clarity on BLEU@4 score modifications, and insufficient details on the user study design and ethical considerations weaken the overall impact.",
      "strengths": [
        "Introduces a novel approach to benchmarking image captioning models using user-generated captions.",
        "Adds depth to analysis with a user study to qualitatively evaluate generated captions.",
        "Addresses limitations of traditional benchmark datasets by leveraging a large, diverse social media dataset."
      ],
      "weaknesses": [
        "User-generated captions may introduce noise and inaccuracies, affecting results and generalizability.",
        "Lacks clarity on whether a modified BLEU@4 score is used, impacting evaluation metrics.",
        "User study details are insufficient, including recruitment, participant background, and ethical oversight.",
        "Ethical concerns about exposing participants to potentially harmful social media content are not adequately addressed."
      ],
      "questions": [
        "Could you clarify whether a modified version of the BLEU@4 score was used and how it differs from the standard version?",
        "What steps were taken to ensure participants were not exposed to harmful content during the user study?",
        "How were the qualitative assessment samples selected, and how representative are they of the broader population?",
        "Did an Institutional Review Board (IRB) approve the study design, and if so, what measures were taken to protect participant well-being?"
      ],
      "overall_score": "5: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "98g9NdJPxm",
    "title": "Theoretically Understanding Data Reconstruction Leakage in Federated Learning",
    "std_review": {
      "summary": "The paper introduces a novel theoretical framework for bounding the performance of gradient leakage attacks in federated learning, providing a rigorous mathematical formulation and empirical validation across various attack strategies. While the theoretical contributions are strong, practical limitations such as sensitivity to model initialization and computational cost are noted. Overall, the work is well‑received with clear insights and potential for future research.",
      "strengths": [
        "Novel theoretical contribution with a rigorous bound for gradient leakage attacks.",
        "Clear and mathematically sound derivation of the bound.",
        "Extensive empirical validation across multiple attack strategies and model complexities."
      ],
      "weaknesses": [
        "Theoretical bound based on optimal model parameters may not align with practical intermediate iterates.",
        "Reliance on assumptions like model smoothness that may not hold for complex non‑convex models.",
        "Computational expense in estimating the bound, especially for large models."
      ],
      "questions": [
        "How can the bound be adapted for non‑convex, real‑world models?",
        "What is the impact of hyperparameter tuning on the bound's reliability?",
        "Can the bound be computed more efficiently to improve practical applicability?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "992eLydH8G",
    "title": "Do pretrained Transformers Really",
    "std_review": {
      "summary": "The paper rigorously analyzes the functional equivalence between in-context learning (ICL) and gradient descent (GD) in linear regression models, arguing that they are not equivalent due to differences in objective functions, model architectures, and emergent behaviors. It provides a formal mathematical proof of non-equivalence under specific conditions and supports its claims with empirical evidence from Llama‑7b fine-tuning. While the model setup is contrived, the findings offer valuable insights into the nature of ICL in transformers versus linear models.",
      "strengths": [
        "Clear theoretical framework with a formal proof of non-equivalence.",
        "Empirical validation using Llama‑7b fine-tuning that robustly supports the theoretical claims.",
        "Insightful analysis of objective differences and model architecture contrasts."
      ],
      "weaknesses": [
        "The linear regression model with explicit weight construction may not generalize to more complex transformer models.",
        "The focus on linear models could limit the broader implications for ICL in pre-trained transformers.",
        "Empirical evidence is specific to the Llama‑7b setup and may not capture nuances across different architectures or training paradigms."
      ],
      "questions": [
        "How do the findings generalize to more complex transformer models beyond the linear regression setup?",
        "What are the implications of the specific objective functions used in the analysis for broader ICL-GD comparisons?",
        "Could additional empirical studies with different architectures or training paradigms further validate the conclusions?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "99hq9VMkbg",
    "title": "Fisher-aware Quantization for DETR Detectors with Critical-category Objectives",
    "std_review": {
      "summary": "The paper presents a novel Fisher‑aware quantization scheme for DETR‑based object detectors, leveraging the Fisher information matrix to guide quantization and preserve critical objectives. Experiments across various precisions, architectures, and datasets, including COCO‑Panoptic, demonstrate significant performance gains. While the method is innovative and effective, it introduces additional complexity and computational overhead, and its applicability beyond DETR needs further exploration.",
      "strengths": [
        "Innovative Fisher‑aware quantization scheme that addresses disparate quantization impacts on different objectives.",
        "Demonstrated significant performance improvements, especially in challenging scenarios with many object categories.",
        "Robustness is enhanced through Fisher‑trace regularization, leading to stable performance during quantization‑aware training."
      ],
      "weaknesses": [
        "Increased method complexity due to Fisher information matrix and Fisher‑trace regularization, requiring careful tuning.",
        "Potential computational overhead from mixed‑precision quantization and Fisher‑aware approach, impacting training time and resources.",
        "Limited scope of validation to DETR‑based models; applicability to other object detection models and real‑world scenarios remains unexplored."
      ],
      "questions": [
        "How can the proposed method be adapted for other object detection frameworks beyond DETR?",
        "What are the long‑term computational and memory implications of the Fisher‑aware quantization scheme?",
        "Can the method be extended to handle dynamic or real‑time inference scenarios with varying quantization requirements?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "99tKiMVJhY",
    "title": "Learning Decentralized Partially Observable Mean Field Control for Artificial Collective Behavior",
    "std_review": {
      "summary": "The paper introduces a decentralized Partially Observable Markov Decision Process (Dec-POMFC) framework for multi-agent reinforcement learning in environments with incomplete information. It leverages reinforcement learning to enable agents to learn optimal strategies locally, overcoming centralized training limitations. The approach shows significant improvements in convergence and policy quality on benchmark problems, with strong theoretical guarantees. Overall, it is a valuable contribution to multi-agent systems research.",
      "strengths": [
        "Addresses a critical challenge in multi-agent systems by focusing on decentralized POMC problems.",
        "Provides strong theoretical guarantees on convergence and optimality.",
        "Demonstrates significant improvements in convergence speed and policy quality on benchmark problems."
      ],
      "weaknesses": [
        "Assumes each agent has access to a limited set of observations, which may not always be realistic.",
        "The high generality of the framework may lead to increased computational complexity.",
        "Empirical validation is limited to a few benchmark problems."
      ],
      "questions": [
        "How does the method perform in environments with highly dynamic or sparse observations?",
        "What are the scalability limits of the proposed framework in large-scale multi-agent systems?",
        "Can the theoretical optimality guarantees be extended to non-stationary or more complex POMC scenarios?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "9BERij4Gbv",
    "title": "Guided Evolution with Binary Discriminators",
    "std_review": {
      "summary": "The paper presents an AutoML framework that integrates online training of a binary discriminator with evolutionary algorithms to evolve neural network architectures and hyperparameters. This approach reduces computational costs compared to traditional batch training, making it particularly effective for computationally intensive tasks like Hero and AutoRL. The method is evaluated across various AutoML tasks, showing competitive performance and highlighting its potential to accelerate model discovery. Overall, the paper demonstrates significant promise in improving AutoML efficiency, though further exploration on a broader range of challenges is warranted.",
      "strengths": [
        "Innovative integration of online discriminator training with evolutionary search.",
        "Efficient for computationally expensive tasks due to reduced computational burden.",
        "Comprehensive evaluation across multiple AutoML tasks."
      ],
      "weaknesses": [
        "Limited benchmark scope may not fully capture method's performance across all AutoML challenges.",
        "Potential for overfitting with the binary discriminator.",
        "Complexity in tuning hyperparameters remains a challenge."
      ],
      "questions": [
        "How does the method perform on a broader range of AutoML tasks beyond the current benchmark suite?",
        "What strategies can be employed to mitigate overfitting with the binary discriminator?",
        "How does the choice of mutation operator impact the exploration of the solution space?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "9bmTbVaA2A",
    "title": "",
    "std_review": {
      "summary": "The paper introduces Concept-QA, a vision-language model that generates interpretable query chains for zero-shot classification tasks. By combining GPT-CLIP for pseudo-labels and a QA model for refinement, Concept-QA improves interpretability and performance on benchmark datasets. The authors demonstrate strong results in accuracy and explanation quality, outperforming baselines. Overall, the paper makes a valuable contribution to the field.",
      "strengths": [
        "Interpretability of pseudo-labels generated by GPT-CLIP",
        "Efficient use of unlabeled data",
        "Improved query chains with high accuracy and readability",
        "Strong performance compared to existing vision-language models"
      ],
      "weaknesses": [
        "Potential biases in pseudo-labels from GPT-CLIP",
        "Performance variability depending on zero-shot capabilities",
        "Computational cost of using a QA model",
        "Limited generalization to datasets with vastly different visual characteristics"
      ],
      "questions": [
        "How robust are the generated query chains in scenarios with ambiguous visual cues?",
        "What is the impact of the QA model choice on the interpretability of the results?",
        "Can Concept-QA be adapted for real-time applications with limited computational resources?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "9ceadCJY4B",
    "title": "",
    "std_review": {
      "summary": "The paper proposes a novel FOLLOW-UP QUESTIONING MECHANISM to mitigate sycophancy and bias in large language models (LLMs) by generating follow-up questions to probe response consistency and fairness. Evaluation using a Modification Rate metric shows improved judgement consistency in both synthetic and real-world scenarios, suggesting practical applications. While the approach offers a complementary strategy to existing methods, it has limitations such as potential oversimplification of judgement consistency, reliance on specific scenarios, and significant computational requirements for scaling.",
      "strengths": [
        "Introduces a novel approach to address sycophancy and bias in LLMs.",
        "Provides a clear and quantifiable evaluation metric (Modification Rate).",
        "Demonstrates effectiveness across synthetic and real-world scenarios.",
        "Highlights potential applications in critical decision-making tasks."
      ],
      "weaknesses": [
        "Modification Rate may not fully capture nuances of judgement consistency.",
        "Evaluation limited to synthetic and real-world scenarios, potentially missing edge cases.",
        "Computational demands could hinder practical deployment in resource-constrained environments.",
        "Lack of exploration of long-term effects on model performance and user trust."
      ],
      "questions": [
        "How does the proposed mechanism handle context-dependent biases not captured by the Modification Rate metric?",
        "What are the computational costs associated with scaling the follow-up questioning approach in real-time applications?",
        "How can the framework be adapted to evaluate and improve judgement consistency across diverse domains?",
        "What are the long-term implications of applying this mitigation method on model performance and user trust?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "9cQtXpRshE",
    "title": "AGILE3D: Attention Guided Interactive Multi-object 3D Segmentation",
    "std_review": {
      "summary": "The paper introduces AGILE3D, a method for interactive 3D object instance segmentation that uses user clicks to refine segmentation masks. It employs click-to-click, click-to-point, and point-to-click attention mechanisms, along with temporal encoding, to improve model performance, especially in limited data scenarios. The iterative click sampling strategy enhances results by focusing on error regions, aligning training with testing conditions. Overall, the approach is innovative and empirically effective, though it relies on user input and has some implementation complexity.",
      "strengths": [
        "User-assisted refinement through interactive clicks improves segmentation quality.",
        "Dynamic update mechanism adapts predictions in real-time based on user feedback.",
        "Effective attention mechanisms (C2C, C2S/S2C) and temporal encoding enhance generalization across datasets.",
        "Iterative click sampling strategy aligns training with testing conditions, improving performance."
      ],
      "weaknesses": [
        "Model effectiveness depends on the quality and accuracy of user-provided clicks.",
        "Complex implementation with attention mechanisms and iterative sampling may increase computational cost.",
        "Evaluation limited to specific datasets (ScanNet40, KITTI-360), potentially overlooking broader applicability.",
        "Risk of overfitting to user interaction patterns, reducing robustness."
      ],
      "questions": [
        "How does the model handle scenarios where user clicks are sparse or noisy?",
        "What is the impact of varying the number of clicks on segmentation accuracy?",
        "Can the model be adapted for real-time applications with limited computational resources?",
        "How does the model generalize to unseen object categories or environments?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "9Cu8MRmhq2",
    "title": "Multi-granularity Correspondence Learning from Noisy Instructional Videos",
    "std_review": {
      "summary": "The paper introduces the Norton method, a novel approach to address multi-granularity noisy correspondence (MNC) in video-language studies by leveraging optimal transport (OT) to handle both coarse-grained and fine-grained misalignments. The method introduces an alignable prompt bucket and a soft-maximum operator to improve video-text learning tasks such as video-paragraph retrieval, videoQA, and action segmentation. The proposed approach outperforms existing state-of-the-art methods like VideoCLIP and TempCLR, demonstrating significant improvements in handling noisy correspondence.",
      "strengths": [
        "Innovative Use of Optimal Transport (OT): The paper effectively utilizes OT to manage both coarse and fine-grained misalignments, a novel approach in video-text learning.",
        "Alignment of Video and Text: The introduction of an alignable prompt bucket and a soft-maximum operator enhances the alignment between video and text, addressing a critical challenge in MNC.",
        "Improved Performance: The Norton method shows superior performance compared to baselines like VideoCLIP and TempCLR across various downstream tasks, including video-paragraph retrieval, videoQA, and action segmentation."
      ],
      "weaknesses": [
        "Computational Complexity: The method may introduce significant computational costs, especially when dealing with long videos, potentially limiting its scalability.",
        "Limited Scope: The paper primarily focuses on video-text learning and does not explore applications in multi-modal noisy correspondence beyond this domain.",
        "Baseline Comparison: While the paper demonstrates improvements over existing methods, a more comprehensive comparison with a broader range of state-of-the-art techniques could strengthen the argument for its effectiveness."
      ],
      "questions": [
        "How can the computational complexity be further reduced to improve scalability?",
        "Could the method be adapted for multi-modal noisy correspondence beyond video-text learning?",
        "What is the impact of the method on other downstream tasks not evaluated in the paper?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "9cumTvvlHG",
    "title": "Implicit Chain of Thought Reasoning",
    "std_review": {
      "summary": "The paper introduces Implicit Chain‑of‑Thought (implicit CoT) reasoning, which extracts diagonal elements from a teacher model's hidden‑state matrix to capture key reasoning steps, allowing an emulator model to predict these states efficiently. This approach achieves comparable accuracy to explicit CoT while reducing computational cost, making it attractive for resource‑constrained settings. Despite promising results, the method's reliance on specific model architectures and potential overfitting to the extracted hidden states are noted concerns.",
      "strengths": [
        "Novel approach to implicitly capture reasoning steps without explicit prompting.",
        "Demonstrates significant efficiency gains with comparable performance.",
        "Provides a clear theoretical rationale for selecting diagonal hidden states."
      ],
      "weaknesses": [
        "Dependence on the specific teacher model architecture may limit applicability.",
        "Risk of overfitting to the fixed subset of hidden states.",
        "Lack of evaluation on out‑of‑distribution examples or complex reasoning tasks."
      ],
      "questions": [
        "How robust is implicit CoT to variations in model architecture beyond the tested teacher model?",
        "What strategies can be employed to mitigate overfitting when extracting a fixed subset of hidden states?",
        "How does implicit CoT perform on tasks requiring multi‑step reasoning with complex dependencies?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "9DvDRTTdlu",
    "title": "ED-Nerf: Efficient Text-Guided Editing of 3D Scene using Latent Space NeRF",
    "std_review": {
      "summary": "The paper presents ED-Nerf, a NeRF editing framework that uses a 4-channel latent representation to efficiently edit neural radiance fields, reducing training time and GPU memory usage while maintaining high editing accuracy. It effectively handles partially occluded objects and maintains view consistency across viewpoints, making it a valuable contribution to the field. The reviewer finds the method promising and recommends acceptance.",
      "strengths": [
        "Significantly reduces computational requirements, making the method more practical for real-time applications.",
        "Effectively handles partially occluded objects, a common challenge in NeRF editing, by leveraging the latent space for more robust editing.",
        "Achieves competitive editing accuracy with fewer training samples, demonstrating efficiency without compromising quality.",
        "Maintains view consistency across different viewpoints, addressing a key limitation in previous NeRF editing techniques."
      ],
      "weaknesses": [
        "Relies on object masks for segmentation, which can affect final editing results if masks are not precise.",
        "Performance may vary depending on the quality and accuracy of object masks, especially in complex scenes.",
        "4-channel latent representation may introduce limitations in capturing fine details compared to using original RGB images.",
        "Lacks detailed analysis on the impact of different mask generation techniques on editing results."
      ],
      "questions": [
        "How does the method perform when applied to scenes with highly detailed objects or fine textures?",
        "What is the impact of different mask generation techniques on the final editing results, and how can these be optimized?",
        "Can the method be extended to handle more complex scenarios, such as editing multiple objects simultaneously or dealing with highly dynamic scenes?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "9jmUwjZi7j",
    "title": "DreamFuser: Value-guided Diffusion Policy for Offline Reinforcement Learning",
    "std_review": {
      "summary": "The paper introduces GNMDP, a reinforcement learning framework that extends MDPs with a generative network to improve sample efficiency and generalization. It demonstrates competitive performance on Gym tasks and includes a multi-action prediction mechanism. However, it does not address partial observability, introduces computational overhead, and lacks comparison with POMDP methods.",
      "strengths": [
        "Combines MDP simplicity with generative model expressiveness for efficient learning.",
        "Multi-action prediction leverages temporal information to enhance decision-making.",
        "Clear experimental setup on Gym tasks provides a reproducible benchmark."
      ],
      "weaknesses": [
        "Does not explicitly handle partial observability, limiting real-world applicability.",
        "Generative network adds complexity and computational cost.",
        "Lacks detailed comparison with state-of-the-art POMDP methods.",
        "Multi-action prediction may lead to overfitting in limited data scenarios."
      ],
      "questions": [
        "How does GNMDP perform in environments with partial observability?",
        "What are the scalability implications of the generative network?",
        "How does multi-action prediction compare to other multi-step planning approaches?",
        "Can GNMDP be integrated with existing POMDP frameworks?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "9JQtrumvg8",
    "title": "A Real-World WebAgent with Planning,",
    "std_review": {
      "summary": "The paper introduces WebAgent, a system that enables open-ended web search and navigation through a unified action space. It defines 'open-ended actions' as flexible user intents and contrasts them with a 'pre-defined action space' of fixed actions. WebAgent uses a few canonical examples for program generation, where a Flan‑U‑PaLM model interprets HTML snippets via HTML‑T5 to execute actions. The system is evaluated on real‑world website navigation and simulated environments, demonstrating its ability to handle diverse tasks. While innovative, the paper lacks clarity in some key areas, leading to a weak accept recommendation.",
      "strengths": [
        "Innovative action space for open-ended web navigation",
        "Effective few-shot learning for program generation",
        "Unified model combining HTML‑T5 and Flan‑U‑PaLM"
      ],
      "weaknesses": [
        "Ambiguity in the definition of open-ended actions vs. pre-defined action space",
        "Vague description of few-shot prompting in Figure 3",
        "Insufficient explanation of differences between real-world and simulation tasks",
        "Unclear definition of 'planning'",
        "Incomplete description of the end-to-end workflow",
        "Lack of details on the curated dataset for WebAgent",
        "Unclear whether the same interface is used in real-world evaluations"
      ],
      "questions": [
        "How are the canonical examples for few-shot prompting selected and curated?",
        "What is the exact definition of 'planning' in the context of WebAgent?",
        "Could you provide more details on the curated dataset used for training/finetuning WebAgent?",
        "How does the system handle variations in user interface across different real-world websites?",
        "What are the specific metrics used to evaluate the planning process in WebAgent?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "9JRsAj3ymy",
    "title": "Time-Sensitive Replay for Continual Learning",
    "std_review": {
      "summary": "The paper proposes a continual learning framework for evolving data streams, using a confidence metric to retain information from past tasks and mitigate catastrophic forgetting. It demonstrates improved performance on evolving datasets compared to standard baselines, but has some clarity and completeness issues.",
      "strengths": [
        "Clear problem definition of evolving data streams",
        "Innovative confidence metric for selective memory retention",
        "Practical evaluation on realistic evolving datasets"
      ],
      "weaknesses": [
        "Ambiguity in the definition of 'evolving' tasks",
        "Lack of explicit assumptions about task relationships",
        "Unclear explanation of the confidence metric",
        "Reproducibility concerns due to unclear notation and poor figure quality"
      ],
      "questions": [
        "How should the size of the validation memory be specified and evaluated?",
        "What specific characteristics define an 'evolving' task?",
        "Are there any assumptions about the distributional changes between consecutive tasks?",
        "How does the confidence metric precisely quantify information retention?",
        "How does discarding the oldest logit enforce a temporal bias?",
        "Could the method be compared with regularization-based continual learning approaches?",
        "How can the presentation of equations and notation be improved for clarity?"
      ],
      "overall_score": "6: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "9JxQyat11M",
    "title": "Zero-Shot Visual Classification with Guided Cropping",
    "std_review": {
      "summary": "The paper introduces GC-CLIP, a method that dynamically crops images using object localization cues before zero-shot classification with CLIP. It shows significant performance improvements on standard benchmarks and zero-shot tasks, especially on datasets with diverse object sizes and out-of-distribution samples. The approach is flexible, benefiting from various object detectors and potentially extending to other multimodal tasks. Despite introducing computational overhead, the method's adaptability and robustness make it a strong candidate for acceptance.",
      "strengths": [
        "Improved zero-shot performance through dynamic cropping.",
        "Flexibility with different object detection models.",
        "Strong performance on datasets with large and varied object sizes.",
        "Clear theoretical justification linking cropping to optimal object-context balance.",
        "Potential for extension to other multimodal tasks."
      ],
      "weaknesses": [
        "Additional computational cost due to object detection.",
        "Dependence on the accuracy of the object detection model.",
        "Limited evaluation on a broader range of datasets.",
        "Potential for overfitting to specific detectors.",
        "Lack of detailed analysis on out-of-distribution samples."
      ],
      "questions": [
        "How does GC-CLIP perform on a wider variety of datasets beyond those evaluated?",
        "What strategies can mitigate the impact of object detection errors on GC-CLIP's performance?",
        "How does the method compare to static cropping strategies in terms of robustness?",
        "What are the computational costs associated with GC-CLIP in practical deployment scenarios?",
        "How can GC-CLIP be adapted for zero-shot retrieval and image-text retrieval tasks?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "9k0krNzvlV",
    "title": "On the Learnability of Watermarks",
    "std_review": {
      "summary": "The paper presents a novel open‑model watermarking framework for LLM‑generated text, leveraging teacher‑student distillation to embed imperceptible watermarks. It evaluates the framework's robustness against spoofing attacks, showing that the watermark is effective with a few hundred to a few thousand samples, and proposes mitigation strategies for fine‑tuning. While the approach is innovative and theoretically sound, it is limited to a narrow set of LLMs and assumes adversary knowledge of the watermark key, which may not hold in practice.",
      "strengths": [
        "Introduces a novel method for embedding imperceptible watermarks in LLM‑generated text.",
        "Provides a solid theoretical foundation for understanding trade‑offs between imperceptibility, robustness, and sample efficiency.",
        "Conducts extensive experiments across multiple LLMs and watermark configurations, offering valuable insights.",
        "Proposes practical mitigation strategies to enhance watermark robustness against model fine‑tuning."
      ],
      "weaknesses": [
        "Evaluation focuses on a limited set of LLMs, potentially limiting generalizability.",
        "Assumes the adversary knows the watermark key, which may not be realistic in all scenarios.",
        "Does not precisely quantify the minimum number of samples required for effective spoofing.",
        "Effectiveness of distinguishing between spoofed and genuine watermarked text is not fully quantified."
      ],
      "questions": [
        "How does the proposed method perform on a broader range of LLM architectures beyond those evaluated?",
        "What is the exact minimum number of samples needed for successful spoofing attacks?",
        "Can the detection mechanism be quantified more precisely to better assess watermark robustness?",
        "How does the method handle scenarios where the adversary does not know the watermark key?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  }
]