[
  {
    "paper_id": "014CgNPAGy",
    "title": "On the Role of Momentum in the Implicit Bias of Gradient Descent for Diagonal Linear Networks",
    "std_review": {
      "summary": "The paper investigates the implicit bias of momentum-based optimizers (Heavy Ball and Nesterov Accelerated Gradient) in diagonal linear networks, showing they converge to wider minima associated with better generalization compared to Gradient Descent. Theoretical and empirical analyses provide insights into how these optimizers bias the optimization landscape, with implications for practical applications where generalization is crucial. While the findings are significant, they are specific to diagonal linear networks and rely on idealized conditions.",
      "strengths": [
        "Novel theoretical analysis of momentum-based optimizers in diagonal linear networks.",
        "Derives explicit conditions for convergence to lower error solutions.",
        "Comprehensive empirical evaluation supporting theoretical findings."
      ],
      "weaknesses": [
        "Results are limited to diagonal linear networks, reducing generalizability.",
        "Assumes idealized conditions that may not hold in real-world scenarios.",
        "Empirical evaluation is limited to specific hyperparameters and datasets.",
        "Does not explore trade-offs between convergence speed and generalization."
      ],
      "questions": [
        "How do the findings generalize to more complex network architectures?",
        "What are the effects of non-ideal initialization on the implicit bias?",
        "Can the theoretical conditions be relaxed to broader settings?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "01ep65umEr",
    "title": "TeLLMe what you see: Using LLMs to Explain Neurons in Vision Models",
    "std_review": {
      "summary": "The paper proposes using large language models to generate natural language explanations for neuron activations, offering a novel approach to model interpretability. While it shows promise in providing more intuitive and context-aware explanations compared to traditional visualization techniques, it faces challenges such as high computational cost and potential biases in the LLM. The method demonstrates improved interpretability on several datasets but may be limited by scalability and the complexity of evaluating explanation quality.",
      "strengths": [
        "Enhanced interpretability through LLM-generated natural language explanations.",
        "Potential scalability to larger models and datasets.",
        "Captures semantic relationships and context, providing richer explanations."
      ],
      "weaknesses": [
        "Significant computational cost and resource demands compared to traditional visualization methods.",
        "Potential biases in explanations due to training data.",
        "Complexity in evaluating the quality of generated explanations."
      ],
      "questions": [
        "How can the computational cost be mitigated to improve scalability?",
        "What metrics can be used to more effectively evaluate the quality of LLM-generated explanations?",
        "How can the method address and mitigate biases introduced by the LLM?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "02f3mUtqnM",
    "title": "Hybrid LLM: Cost-Efficient and Quality-Aware Query Routing",
    "std_review": {
      "summary": "The paper presents a router system that dynamically selects between small and large language models based on query difficulty, using three designs: deterministic, probabilistic, and probabilistic with data transformation. It demonstrates that routing to smaller models can maintain acceptable quality, offering a practical solution for resource-constrained environments. The approach is empirically validated, though it has scalability concerns and limited generalizability.",
      "strengths": [
        "Innovative routing mechanism for dynamic model selection",
        "Comprehensive analysis of multiple router designs",
        "Empirical validation of cost-quality trade-offs"
      ],
      "weaknesses": [
        "Assumptions in deterministic model selection",
        "Scalability concerns for training routers per LLM pair",
        "Limited generalizability to other models or domains"
      ],
      "questions": [
        "How does the router handle queries with ambiguous difficulty levels?",
        "What are the computational costs associated with training routers for each LLM pair?",
        "How does the proposed approach perform when scaling to multiple LLMs?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "02Ug9N8DCI",
    "title": "GateLoop: Fully Data-Controlled Linear Recurrence for Sequence Modeling",
    "std_review": {
      "summary": "GateLoop introduces a novel linear recurrence mechanism for sequence modeling that retains memory indefinitely without fixed decay, leveraging a surrogate attention mechanism to dynamically adjust state transitions based on input data. Empirical results show competitive performance on language modeling tasks, outperforming traditional fixed-decay models like S4 and S5. The paper highlights the model's infinite memory capacity, data-controlled transitions, and efficient O(l log l) complexity, though it also notes challenges in parameter tuning and potential overhead from the attention mechanism.",
      "strengths": [
        "Infinite memory capacity without fixed decay.",
        "Data-controlled state transitions enable dynamic adjustment based on input.",
        "Scalable computational complexity of O(l log l) through parallelized associative scan."
      ],
      "weaknesses": [
        "Complexity of tuning data-dependent parameters (α, β).",
        "Potential overhead from surrogate attention mechanism implementation.",
        "Expressivity may still be limited compared to full attention models."
      ],
      "questions": [
        "How robust are the performance gains across diverse language modeling tasks?",
        "What is the impact of the surrogate attention mechanism on model interpretability?",
        "Can the model be further optimized to reduce computational overhead while maintaining expressivity?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "030cjlZm4a",
    "title": "Learning predictive checklists with",
    "std_review": {
      "summary": "The paper presents a novel method for generating interpretable checklists from machine learning models, particularly useful in medical settings. It introduces a fairness regularizer to ensure balanced treatment across sensitive groups, enhancing transparency and trust. Experiments show the method improves interpretability without significant performance loss, suggesting its potential for clinical use. However, challenges remain in scalability and interpretability for complex models.",
      "strengths": [
        "Introduces a unique approach to generating interpretable checklists from complex models.",
        "Ensures fairness in checklist generation, addressing equitable treatment across demographic groups.",
        "Demonstrates empirical effectiveness in improving interpretability without compromising model performance."
      ],
      "weaknesses": [
        "Interpretability may be limited for highly complex or non-linear models.",
        "Exponential memory complexity could restrict applicability to large-scale datasets.",
        "Effectiveness may be domain-specific, raising questions about generalizability."
      ],
      "questions": [
        "How does the method handle interpretability for models with a very large number of features?",
        "What techniques are used to mitigate the impact of the exponential memory complexity?",
        "How can the method be adapted for use in other domains beyond healthcare?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "04UvXg4CvW",
    "title": "EPIC: Compressing Deep GNNs via Expressive Power Gap-Induced Knowledge Distillation",
    "std_review": {
      "summary": "The paper introduces EPIC, a novel loss function for compressing deep GNNs into shallow MLPs by capturing both epistemic and entropic uncertainties. EPIC significantly outperforms existing distillation techniques, especially in inductive settings, while reducing computational costs. Despite some practical concerns, the innovative approach and strong empirical results justify its acceptance.",
      "strengths": [
        "Introduces a unique loss function combining epistemic and entropic consistency.",
        "Demonstrates superior performance over existing distillation methods, particularly in inductive scenarios.",
        "Provides a solid theoretical foundation and practical evidence of its effectiveness."
      ],
      "weaknesses": [
        "Hyperparameter tuning issues may lead to suboptimal results.",
        "Comparisons to GNN-to-MLP frameworks may be unfair due to unsuitable baseline architectures.",
        "Computational overhead from estimating EPIC bounds could limit practical applicability."
      ],
      "questions": [
        "How can the computational cost of estimating EPIC bounds be further reduced?",
        "What are the empirical bounds' tightness and reliability across different datasets and GNN architectures?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "06lrITXVAx",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a novel dropout method tailored for bilevel optimization, aiming to mitigate overfitting. Theoretical and empirical analyses demonstrate its effectiveness and practical benefits, though the complexity of bilevel optimization and limited scope of evaluation are noted as potential concerns.",
      "strengths": [
        "Introduces a dropout method specifically designed for bilevel optimization, addressing a gap in existing literature.",
        "Provides a solid theoretical foundation linking dropout regularization to the bilevel objective function.",
        "Empirical validation shows competitive performance against traditional early stopping methods."
      ],
      "weaknesses": [
        "The bilevel optimization framework may introduce additional complexity, potentially making analysis and implementation more challenging.",
        "Empirical evaluation is focused on a single task, which may limit generalizability.",
        "Theoretical assumptions may not hold in all practical scenarios, limiting broad applicability."
      ],
      "questions": [
        "How does the proposed dropout method scale to more complex bilevel optimization problems?",
        "What are the theoretical guarantees for convergence when the assumptions in the analysis are relaxed?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "06mzMua9Rw",
    "title": "A Trust Region Approach for Few-Shot Sim-to-Real Reinforcement Learning",
    "std_review": {
      "summary": "The paper introduces FOOD, an offline RL algorithm that tackles sim-to-real transfer by formulating a trust-region objective to align learned behavior with target policies. Empirical results across multiple simulation-to-real robotic tasks show significant improvements in sample efficiency and performance compared to state-of-the-art baselines. The theoretical contribution is a novel guarantee for dynamics mismatch, and the approach is robust, though it may face scalability issues and sensitivity to regularization choices.",
      "strengths": [
        "Novel trust-region objective for sim-to-real transfer",
        "Robust regularization strategy using learned value function",
        "Strong theoretical foundation with a novel guarantee for dynamics mismatch"
      ],
      "weaknesses": [
        "Potential computational complexity in high-dimensional spaces",
        "Sensitivity to the choice of performance metric for regularization",
        "Limited real-world dataset coverage",
        "Lack of detailed ablation studies on regularization"
      ],
      "questions": [
        "How does the method scale to high-dimensional state spaces?",
        "What is the impact of different performance metrics on generalization?",
        "Could you provide more ablation studies on the regularization strategy?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "070DFUdNh7",
    "title": "GraphGPT: Graph Learning with Generative Pre-trained Transformers",
    "std_review": {
      "summary": "GraphGPT is a large language model specialized for graph-structured data, achieving strong edge- and graph-level performance but underperforming on node-level tasks. The model leverages a transformer architecture with graph-aware attention, trained on diverse datasets. While promising, its computational demands and need for domain-specific retraining are significant drawbacks.",
      "strengths": [
        "Versatile graph representation capable of excelling at edge-, node-, and graph-level tasks.",
        "Scalable transformer-based architecture with graph-aware attention for large datasets.",
        "Diverse dataset coverage enhances generalizability across domains."
      ],
      "weaknesses": [
        "Limited node-level performance compared to state-of-the-art benchmarks.",
        "Requires domain-specific retraining, limiting practical deployment.",
        "High computational intensity for pre-training large models."
      ],
      "questions": [
        "Can the model's performance on node-level tasks be improved with architectural modifications?",
        "What strategies can mitigate over‑fitting on smaller datasets?",
        "How can the model be made more computationally efficient for broader use?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "07xuZw59uB",
    "title": "Bridging the Fairness Divide: Achieving Group and Individual Fairness in Graph Neural Networks",
    "std_review": {
      "summary": "The paper introduces FairGI, a framework that balances group fairness (Equal Opportunity and Statistical Parity) with individual fairness within groups for GNNs. It proposes a novel fairness loss function combining adversarial loss for group fairness and a similarity-matrix loss for individual fairness. Empirical evaluations on several graph datasets show improved fairness metrics without significant loss in accuracy, validating the approach's practical utility.",
      "strengths": [
        "Introduces a unique 'individual fairness within groups' metric that refines traditional individual fairness.",
        "Effectively balances group and individual fairness, addressing a critical gap in existing literature.",
        "Provides strong theoretical justifications and empirical validation across multiple datasets."
      ],
      "weaknesses": [
        "Implementation complexity due to novel fairness metric and combined loss functions.",
        "Hyperparameter sensitivity may be a barrier for practitioners.",
        "Limited dataset evaluation may not fully capture framework performance.",
        "Lack of robustness analysis to adversarial attacks or data variations."
      ],
      "questions": [
        "How does FairGI perform on datasets with highly imbalanced group sizes?",
        "What is the impact of the fairness loss weights on model robustness to adversarial attacks?",
        "Can the framework be extended to non-graph neural network architectures?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "09iOdaeOzp",
    "title": "Sheared LLAMA: Accelerating Language Model Pre-training via Structured Pruning",
    "std_review": {
      "summary": "Sheared-LLaMA presents a novel structured pruning technique for LLMs that combines targeted pruning with dynamic batch loading, achieving significant performance gains while preserving accuracy. The method outperforms existing baselines across various models and sparsity levels, and demonstrates the impact of domain-specific data on pruning and fine-tuning. However, concerns about baseline comparison and lack of generalization to other models limit its acceptance.",
      "strengths": [
        "Innovative pruning technique with significant performance gains",
        "Comprehensive experiments across multiple models and sparsity levels",
        "Insights into the impact of domain-specific data on pruning and fine-tuning"
      ],
      "weaknesses": [
        "Limited generalization to other open-source foundation models",
        "Potential bias in baseline comparison due to differences in training techniques",
        "Absence of detailed analysis on the impact of target architecture"
      ],
      "questions": [
        "How does the method perform on other open-source foundation models like Mistral-7B or DeepSeek-Coder?",
        "What is the computational cost of calculating reference losses for each domain?",
        "How does the choice of target architecture (uniform vs. non-uniform) affect inference speed and performance?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "09xFexjhqE",
    "title": "AutoLoRa: An Automated Robust Fine-Tuning Framework",
    "std_review": {
      "summary": "AutoLoRa presents an innovative framework for training robust deep learning models by dynamically adjusting hyperparameters during training. It combines a standard LoRA branch with an auxiliary branch and employs automated scheduling for learning rate and a scalar regularization term. Evaluated on multiple image classification tasks, AutoLoRa demonstrates significant improvements in robustness against adversarial attacks while maintaining competitive standard accuracy. The authors introduce a novel gradient similarity metric to guide hyperparameter adjustments, aiming to align adversarial and natural objectives more closely. Overall, the paper makes a strong contribution to the field of adversarial robustness.",
      "strengths": [
        "Innovative hyperparameter scheduling based on gradient similarity.",
        "Layer‑wise gradient aggregation for fine‑grained control.",
        "Substantial quantitative gains in robust accuracy across datasets.",
        "Clear and thorough experimental evaluation."
      ],
      "weaknesses": [
        "Increased implementation complexity and potential for overfitting.",
        "Limited generalizability to other domains or architectures.",
        "Lack of detailed description of the gradient similarity metric.",
        "Potential sensitivity to the choice of regularization parameters."
      ],
      "questions": [
        "How does the framework perform on non‑image tasks such as natural language processing?",
        "What is the theoretical justification for the gradient similarity metric used?",
        "How robust is the framework to variations in the auxiliary LoRA branch's hyperparameters?",
        "Can the automated scheduling be adapted to other types of adversarial attacks?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0A5o6dCKeK",
    "title": "Next-Gpt: Any-to-Any Multimodal LLM",
    "std_review": {
      "summary": "The paper presents NExT‑GPT, an end‑to‑end unified multimodal language model that can handle any‑to‑any modalities, including text and images. It introduces an alignment learning technique that jointly optimizes a unified model on diverse multimodal tasks, achieving strong performance across benchmark datasets. The authors demonstrate that NExT‑GPT outperforms existing models like InstructBLIP, LLaVA, and mPLUG‑Owl in terms of flexibility and cross‑modal understanding, though some concerns about computational complexity and dataset diversity remain.",
      "strengths": [
        "Introduces a novel end‑to‑end unified MM‑LLM that seamlessly integrates multiple modalities.",
        "Proposes an alignment learning technique that effectively balances performance across different modalities.",
        "Conducts thorough experiments on benchmark datasets, providing robust qualitative and quantitative comparisons."
      ],
      "weaknesses": [
        "The alignment learning technique may introduce additional computational complexity.",
        "The diversity of modalities in the training dataset could be further expanded.",
        "Qualitative comparisons could benefit from a broader range of tasks and models.",
        "Scalability concerns may limit future performance gains."
      ],
      "questions": [
        "How does the alignment learning technique scale with increasing model size or dataset diversity?",
        "What are the computational trade‑offs of the joint optimization approach compared to pipeline models?",
        "How does NExT‑GPT perform on emerging multimodal tasks beyond text and images?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0aEUd9UtiA",
    "title": "DiffCPS: Diffusion-based Constrained Policy Search for Offline Reinforcement Learning",
    "std_review": {
      "summary": "DiffCPS presents a novel offline RL algorithm that uses diffusion models to address multimodal policy challenges by reformulating the problem as a constrained optimization. The approach leverages a strong duality framework for efficient gradient-based optimization, achieving competitive performance on D4RL benchmarks. While innovative, the method's computational complexity and reliance on specific theoretical conditions are noted.",
      "strengths": [
        "Innovative use of diffusion models for capturing complex, multimodal policies in offline RL.",
        "Strong theoretical foundation via a strong duality framework enabling efficient gradient-based optimization.",
        "Empirical validation showing competitive performance on standard benchmarks."
      ],
      "weaknesses": [
        "Higher computational costs due to the use of diffusion models compared to simpler policy representations.",
        "Theoretical results depend on Slater’s condition, which may not always hold in practice.",
        "Limited generalization to other policy representations without significant modifications."
      ],
      "questions": [
        "How can the computational complexity of diffusion models be mitigated for larger-scale offline RL tasks?",
        "What are the practical implications of the reliance on Slater’s condition for the duality framework?",
        "Could the approach be extended to other types of policy representations, such as flow models, and what modifications would be required?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0akLDTFR9x",
    "title": "Contrastive Difference Predictive Coding",
    "std_review": {
      "summary": "The paper introduces TD InfoNCE, a method that combines temporal difference learning with contrastive information maximization to improve sample efficiency in reinforcement learning. It proposes a novel goal distribution and a sampling strategy for the next state, leveraging geometric distributions similar to those used in contrastive RL. Evaluated on several maze tasks, TD InfoNCE shows competitive performance, achieving high success rates with fewer samples. The paper's strengths lie in its innovative approach and clear experimental results, though some aspects, such as the novelty of the goal distribution and the clarity of mathematical derivations, could be further addressed.",
      "strengths": [
        "Introduces a novel goal distribution tailored to enhance sample efficiency in RL.",
        "Proposes an innovative sampling strategy for the next state, potentially offering a more efficient exploration of the state space.",
        "Demonstrates effectiveness and robustness through thorough experimental evaluation across multiple maze tasks."
      ],
      "weaknesses": [
        "The novelty of the goal distribution and sampling strategy may require additional validation.",
        "The experimental setup could benefit from a more diverse set of environments.",
        "Mathematical derivations and equations could be clearer."
      ],
      "questions": [
        "How does the proposed goal distribution compare to other goal distributions in terms of theoretical guarantees?",
        "Could the sampling strategy be generalized to other types of tasks beyond maze environments?",
        "What are the theoretical implications of sampling the next state randomly from a replay buffer instead of using a geometric distribution?"
      ],
      "overall_score": "Accept",
      "confidence": "High"
    }
  },
  {
    "paper_id": "0aR1s9YxoL",
    "title": "Revisiting Plasticity in Visual Reinforcement Learning: Data, Modules and Training Stages",
    "std_review": {
      "summary": "The paper introduces the Adaptive Replay Ratio (ARR) method to mitigate catastrophic plasticity loss in visual reinforcement learning (VRL) by dynamically adjusting the replay ratio based on the critic's plasticity. Experiments across DMC and Atari environments show ARR improves VRL performance and outperforms existing techniques like Reset DEA. While the paper is strong, it could benefit from theoretical analysis, broader experiments, and a detailed computational complexity discussion.",
      "strengths": [
        "Introduces a novel Adaptive Replay Ratio (ARR) method that dynamically adjusts the replay ratio based on the critic's plasticity, addressing catastrophic plasticity loss in VRL.",
        "Conducts comprehensive experiments across multiple environments (DMC and Atari) to evaluate the generalizability of the findings.",
        "Provides a thorough analysis of the relationship between plasticity metrics and VRL agent performance."
      ],
      "weaknesses": [
        "The paper could benefit from a more detailed discussion of the theoretical underpinnings of the proposed ARR method and its relationship to existing plasticity mitigation techniques.",
        "The experiments primarily focus on two environments (DMC and Atari), which may limit the generalizability of the findings to other domains.",
        "The paper does not provide a comprehensive analysis of the computational complexity and resource requirements of the ARR method compared to other approaches.",
        "The authors could have included more ablation studies to further validate the contribution of the ARR method and its components."
      ],
      "questions": [
        "How does the ARR method compare to other adaptive replay strategies in terms of computational efficiency and scalability?",
        "What is the theoretical basis for dynamically adjusting the replay ratio based on the critic's plasticity?",
        "How robust is the ARR method to variations in the environment dynamics and reward structures?",
        "Could the proposed method be combined with other regularization techniques to further improve VRL performance?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0AYosSFETw",
    "title": "Towards human-like spoken dialogue generation between AI agents from written dialogue",
    "std_review": {
      "summary": "The CHATS system introduces a novel Multi-Stream Dialogue Transformer Language Model (MS-DLM) that explicitly models backchannels, laughter, and turn-taking, significantly improving the naturalness and coherence of generated spoken dialogues. By preprocessing written dialogue to remove these elements and reintroducing them during generation, the system effectively addresses the limitations of existing models. Experiments show strong performance, especially in handling complex conversational structures, though language specificity and potential overfitting are noted.",
      "strengths": [
        "Effectively addresses limitations of existing spoken dialogue generation models by incorporating explicit streams for backchannels, laughter, and turn-taking.",
        "Significantly improves naturalness and coherence of generated dialogues, as demonstrated by experimental results.",
        "Demonstrates robust handling of complex conversational structures, making it a strong solution for realistic dialogue generation."
      ],
      "weaknesses": [
        "Increased complexity of implementation and computational requirements due to additional streams and preprocessing steps.",
        "Language specificity, primarily validated for Japanese, may limit applicability to other languages without further adaptation.",
        "Potential for overfitting due to increased model complexity, especially if training data is not sufficiently diverse.",
        "Lack of extensive validation across a wider range of languages and conversational contexts may limit generalizability."
      ],
      "questions": [
        "How does the system perform when applied to languages other than Japanese, and what adaptations are needed for broader language support?",
        "What strategies can be employed to mitigate the risk of overfitting, particularly with limited or non-diverse training data?",
        "Could the system be extended to handle additional conversational elements or styles beyond those explicitly modeled?"
      ],
      "overall_score": "Accept",
      "confidence": "High"
    }
  },
  {
    "paper_id": "0b328CMwn1",
    "title": "",
    "std_review": {
      "summary": "The paper introduces Activation Prompt (AP), a novel visual prompting technique that selectively prompts specific layers of a pre-trained vision model to enhance performance. AP outperforms traditional methods and other parameter-efficient fine-tuning techniques across multiple benchmarks, offering theoretical insights and practical guidelines. However, it lacks comprehensive theoretical analysis, a thorough comparison with state-of-the-art methods, and discussion of practical considerations, leading to a borderline recommendation.",
      "strengths": [
        "Introduces a novel and innovative approach to visual prompting.",
        "Demonstrates superior performance compared to existing methods.",
        "Provides theoretical insights into the connection with normalization tuning."
      ],
      "weaknesses": [
        "Lacks a comprehensive theoretical analysis or proofs.",
        "Benchmark datasets may not fully capture real-world diversity.",
        "Does not compare with state-of-the-art visual prompting methods.",
        "Practical considerations and limitations are not thoroughly explored.",
        "Reproducibility of results is not explicitly addressed."
      ],
      "questions": [
        "Could you provide a more detailed theoretical analysis supporting the effectiveness of AP?",
        "How does AP perform on a broader set of real-world datasets?",
        "What are the practical considerations and limitations of applying AP in industry settings?",
        "Could you compare AP with other recent state-of-the-art methods in visual prompting?"
      ],
      "overall_score": "Borderline",
      "confidence": "Medium"
    }
  },
  {
    "paper_id": "0bjIoHD45G",
    "title": "Closing the gap on tabular data with Fourier and Implicit Categorical Features",
    "std_review": {
      "summary": "The paper presents a novel method for tabular data modeling that combines implicit categorical feature identification, Fourier encoding, and a 1D convolutional ResNet. It shows strong empirical results on several datasets, outperforming traditional models like XGBoost and MLP. However, the approach lacks clear justification for many design choices, such as thresholds for low cardinality features and Fourier component selection, which could affect reproducibility and generalization.",
      "strengths": [
        "Innovative feature identification for low-cardinality categorical features.",
        "Novel Fourier encoding tailored for tabular data to capture periodic patterns.",
        "Creative adaptation of convolutional neural networks for tabular inputs."
      ],
      "weaknesses": [
        "Unclear justification for thresholds used to determine low-cardinality features.",
        "No rationale provided for selecting statistical tests or interpreting p-values.",
        "Rationale for Fourier feature selection is missing.",
        "Model architecture details (layer numbers, kernel sizes, activation functions) are not fully specified.",
        "Hyperparameter selection lacks clear justification.",
        "Evaluation metric 'p-range' is not standard and lacks justification.",
        "Baseline comparisons are limited to XGBoost and MLP.",
        "Robustness testing on unseen data or with different seeds is insufficient.",
        "Computational resources for training and hyperparameter search are not detailed."
      ],
      "questions": [
        "What is the rationale behind the thresholds used to identify low-cardinality features?",
        "How were the frequencies or periods for Fourier encoding selected, and why?",
        "Could you provide more details on the specific architecture of the 1D convolutional ResNet, including layer numbers and kernel sizes?",
        "What criteria were used for selecting hyperparameters such as learning rate, batch size, and optimizer?",
        "How was the 'p-range' metric chosen and justified for evaluation?",
        "What additional baselines or models were compared to assess broader performance?",
        "How was model robustness evaluated, particularly with respect to unseen data or different random seeds?",
        "What computational resources were allocated for training and hyperparameter search?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "0bMmZ3fkCk",
    "title": "NEFTune: Noisy Embeddings Improve Instruction Finetuning",
    "std_review": {
      "summary": "NEFTune introduces a novel regularization technique that adds noise to embedding vectors during finetuning, enhancing model generalization across diverse instruction datasets. The method shows strong empirical results, with varying optimal noise levels for different models and datasets. While the paper provides valuable insights and practical improvements, it lacks a detailed theoretical analysis and explores only a limited range of noise distributions and domains.",
      "strengths": [
        "Introduces a novel regularization technique that leverages noise addition to embedding vectors.",
        "Demonstrates strong empirical results across multiple instruction datasets and model sizes.",
        "Provides a clear theoretical motivation for why noise addition can act as a regularizer."
      ],
      "weaknesses": [
        "Lacks detailed theoretical analysis on the mechanism of noise as a regularizer.",
        "Limited exploration of different noise distributions and their impact.",
        "Evaluation focused primarily on instruction-following tasks, with limited domain generalization.",
        "Computational costs of applying NEFTune are not thoroughly analyzed."
      ],
      "questions": [
        "What is the theoretical basis for why adding noise to embeddings improves model generalization?",
        "How does the choice of noise distribution (e.g., Gaussian vs. Uniform) affect model performance?",
        "Can NEFTune be applied to other domains beyond instruction-following tasks?",
        "What are the computational costs of applying NEFTune, and how does it scale with model size?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0BqyZSWfzo",
    "title": "One-shot Empirical Privacy Estimation",
    "std_review": {
      "summary": "The paper introduces a method for estimating user-level differential privacy in federated learning using canary clients, which provides tighter privacy bounds compared to existing methods. Empirical validation shows its effectiveness, but the approach is limited to the Gaussian mechanism in DP-FedAvg and sensitive to canary parameters. Overall, it is a valuable contribution with strong empirical results and theoretical insights.",
      "strengths": [
        "Practical approach using canary clients for realistic DP estimation.",
        "Empirical validation through extensive experiments.",
        "Theoretical insights into the impact of canary parameters."
      ],
      "weaknesses": [
        "Interpretation of privacy estimate may vary with client choice.",
        "Analytical bound may not fully capture real-world complexity.",
        "Method is tailored for Gaussian mechanism in DP-FedAvg."
      ],
      "questions": [
        "How do the privacy estimates differ when using synthetic canary examples versus real clients?",
        "What are the theoretical guarantees for the analytical upper bound used as a reference?",
        "How can the method be generalized to other privacy mechanisms or federated learning settings?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0Ce3c9l7G1",
    "title": "Learning Multi-Agent Communication using Regularized Attention Messages",
    "std_review": {
      "summary": "ARCOMM presents a novel communication protocol for multi-agent reinforcement learning that combines attention mechanisms and DCT compression to produce concise yet informative messages. Empirical evaluations show that ARCOMM outperforms existing methods like TARMAC and achieves competitive results with QMIX + ARCOMM across various environments, highlighting its robustness and efficiency. The paper is well‑motivated theoretically and includes extensive experiments, though it could benefit from more comprehensive comparisons and deeper theoretical analysis.",
      "strengths": [
        "Innovative use of attention and DCT for efficient multi-agent communication.",
        "Introduces a message regularizer to maintain informativeness while reducing message size.",
        "Demonstrates strong empirical performance across multiple environments."
      ],
      "weaknesses": [
        "Limited comparison with recent state‑of‑the‑art communication protocols.",
        "Lacks detailed theoretical analysis and formal proofs.",
        "Ablation studies may need additional experiments to rule out overfitting."
      ],
      "questions": [
        "How does ARCOMM compare to the latest advancements in communication protocols for MARL?",
        "What is the theoretical relationship between message entropy and cooperation, and how is it formally analyzed?",
        "Could the impact of the DCT compression be isolated by applying it to different dimensions of the message vectors?",
        "How does varying the number of observations predicted (k) affect the balance between message richness and communication cost?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0cJ8ERfnrM",
    "title": "Antibody DomainBed: Out-of-Distribution Generalization in Therapeutic Protein Design",
    "std_review": {
      "summary": "The paper introduces a synthetic benchmark for evaluating domain‑generalization in antibody design, presenting a dataset of synthetic ΔΔG labels and assessing several domain‑generalization methods against standard empirical risk minimization. While highlighting the challenges of transferring knowledge across synthetic environments, the study also points out the relative performance of DG approaches compared to ERM. The reviewer finds the benchmark valuable but notes several limitations regarding realism, completeness, and the need for additional validation and community engagement.",
      "strengths": [
        "Comprehensive synthetic benchmark with realistic antigen‑antibody interactions.",
        "Clear evaluation of multiple domain‑generalization methods.",
        "Use of saliency maps to enhance interpretability of model behavior."
      ],
      "weaknesses": [
        "Synthetic ΔΔG labels may not fully capture real binding affinities.",
        "Dataset construction criteria may not fully represent real antibody design variability.",
        "Limited testing on model size impact suggests a need for broader experiments."
      ],
      "questions": [
        "Should experiments be included to validate synthetic ΔΔG labels against wet‑lab measurements?",
        "How can the selection criteria for antigens and seed sequences be refined to better reflect realistic antibody design scenarios?",
        "What additional experiments are needed to assess model selection's utility beyond synthetic benchmarks?",
        "How can the benchmark's completeness and reproducibility be improved?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "0d1gQI114C",
    "title": "LiDAR-PTQ: Post-Training Quantization for Point Cloud 3D Object Detection",
    "std_review": {
      "summary": "The paper presents LiDAR-PTQ, a method for post-training quantization of point cloud 3D object detection models using a sparsity-aware calibration and task-guided loss. It improves sparse model accuracy by adjusting calibration to the sparsity pattern and incorporating task-specific loss guidance. Empirical results show significant performance gains over existing techniques on sparse detection tasks, though the method's complexity and limited generalization are noted.",
      "strengths": [
        "Introduces a novel sparsity-aware calibration technique.",
        "Leverages task-guided loss to enhance performance on sparse detection tasks.",
        "Demonstrates strong empirical improvements over baseline methods."
      ],
      "weaknesses": [
        "Adds complexity to the calibration process.",
        "Effectiveness evaluated primarily on sparse object detection tasks.",
        "Lacks comprehensive comparison with other sparse model training techniques."
      ],
      "questions": [
        "How does the calibration complexity impact real-world deployment?",
        "Can the proposed method be generalized to other sparse tasks beyond object detection?",
        "What is the exact data usage for the sparsity-based calibration step?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0D6mUZTWoF",
    "title": "A Topology-aware Graph Coarsening Framework for Continual Graph Learning",
    "std_review": {
      "summary": "TACO introduces a novel continual learning framework that dynamically adjusts task importance based on correlations between old and new tasks, addressing catastrophic forgetting. It shows significant improvements in time and memory efficiency compared to existing rehearsal-based methods, while also enhancing generalization across tasks. The paper is well‑structured, with clear contributions and strong empirical results, making it a strong candidate for acceptance.",
      "strengths": [
        "Dynamic task importance adjustment based on correlation",
        "Efficient memory usage by focusing on relevant tasks",
        "Improved generalization across tasks",
        "Empirical performance surpassing traditional methods"
      ],
      "weaknesses": [
        "Computational complexity in estimating task correlations",
        "Potential overfitting due to dynamic importance adjustments",
        "Lack of robustness to noisy or mislabeled data",
        "Scalability concerns for very large datasets"
      ],
      "questions": [
        "How does TACO handle scenarios with rapidly changing task distributions?",
        "What are the specific metrics used for estimating task correlations, and how do they impact performance?",
        "Can TACO be integrated with other continual learning techniques to further improve robustness?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0ez68a5UqI",
    "title": "Reinforcement Learning for Node Selection in Branch-and-Bound",
    "std_review": {
      "summary": "The paper introduces a reinforcement learning framework for optimizing node selection in branch-and-bound algorithms, leveraging a graph neural network to encode the search tree structure. It demonstrates strong performance on combinatorial optimization problems like TSP, UFLP, and MILP instances, outperforming traditional heuristics. The approach is versatile across different problem domains, though it may face challenges in generalizing to other domains and requires careful hyperparameter tuning.",
      "strengths": [
        "Novel integration of RL with branch-and-bound for dynamic node selection.",
        "Effective use of GNNs to capture global search tree structure.",
        "Empirical validation across multiple benchmark datasets showing robustness."
      ],
      "weaknesses": [
        "Limited generalization to domains beyond combinatorial optimization.",
        "Potential overfitting due to training primarily on TSP problems.",
        "Additional computational complexity from GNNs may limit scalability."
      ],
      "questions": [
        "How does the method perform on non‑combinatorial optimization problems?",
        "What is the impact of hyperparameter choices on model performance?",
        "Could the approach be extended to real‑time or online settings?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0fpLLsAynh",
    "title": "Sporadicity in Decentralized Federated Learning: Theory and Algorithm",
    "std_review": {
      "summary": "The paper introduces DSpodFL, a decentralized federated learning algorithm that incorporates sporadic local updates and communications to improve convergence efficiency. The authors provide theoretical analysis showing improved convergence bounds under sporadic conditions compared to standard DSGD, and extend these results to non-convex settings. While the theoretical contributions are significant, the paper lacks extensive empirical validation and a comprehensive comparison with existing methods.",
      "strengths": [
        "Innovative approach to handling sporadic updates in decentralized federated learning.",
        "Rigorous theoretical analysis demonstrating improved convergence bounds.",
        "Broader applicability to non-convex settings."
      ],
      "weaknesses": [
        "Limited empirical validation of the theoretical results.",
        "Reliance on specific assumptions about sporadicity that may limit generalizability.",
        "Lack of comprehensive comparison with existing decentralized federated learning methods."
      ],
      "questions": [
        "Could you provide more empirical evidence to validate the theoretical claims?",
        "How do the results generalize to more realistic network conditions with varying sporadicity?",
        "What are the practical implications of the assumptions made about device processing capabilities and communication bandwidth?"
      ],
      "overall_score": "6: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0fSNU64FV7",
    "title": "Sorting Out Quantum Monte Carlo",
    "std_review": {
      "summary": "The paper introduces the sortlet ansatz, a neural network wavefunction for quantum chemistry that uses a discrete, piecewise-linear representation of the spatial wavefunction. It aims to capture strong localization and reduce computational demands compared to full determinant methods, achieving competitive results on small molecules. However, concerns remain about its theoretical foundations, scalability, and ability to reach chemical accuracy.",
      "strengths": [
        "Computational Efficiency: Significantly reduces trainable parameters and speeds up training and evaluation.",
        "Expressiveness for Localization: Naturally promotes localization through a discontinuous mixing parameter.",
        "Theoretical Motivation: Grounded in a clear variational principle ensuring well-defined kinetic energy."
      ],
      "weaknesses": [
        "Discontinuity Challenges: Potential complications with kinetic energy well-definedness due to discontinuous α.",
        "Limited Scalability: Performance on larger systems is unexplored, raising questions about scalability.",
        "Comparison with Determinants: Inferior to full determinant methods, suggesting fundamental limitations.",
        "Lack of Hartree-Fock Recovery: No demonstration of efficient recovery of the Hartree-Fock limit."
      ],
      "questions": [
        "How does the discontinuous α function affect the well-definedness of the kinetic energy term?",
        "What is the expected growth of the expansion parameter K with system size, and how does it impact scalability?",
        "How does the sortlet ansatz perform on larger systems beyond the small molecules tested?",
        "Can the sortlet ansatz efficiently recover the Hartree-Fock limit?"
      ],
      "overall_score": "4: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "0gDQgwjoX0",
    "title": "Stochastic Gradient Discrete Langevin Dynamics",
    "std_review": {
      "summary": "The paper introduces a novel discrete Langevin dynamics method for sampling from high-dimensional discrete spaces, leveraging a caching technique to reduce computational overhead. Theoretical guarantees for convergence are provided under certain conditions, and empirical comparisons show potential efficiency gains. However, practical performance on complex domains remains to be fully evaluated.",
      "strengths": [
        "Innovative caching technique that reduces memory usage for high-dimensional discrete spaces.",
        "Clear theoretical foundation with convergence guarantees under specific conditions.",
        "Empirical advantages demonstrated over existing techniques, particularly in efficiency and bias reduction."
      ],
      "weaknesses": [
        "Initial memory overhead for storing intermediate quantities despite caching.",
        "Limited scalability demonstrated only on small-scale problems.",
        "Unclear role of the step-size parameter N in controlling Monte Carlo error.",
        "Lack of adaptive mechanisms for step-size updates or hierarchical caching."
      ],
      "questions": [
        "How does the choice of N in equations (9) and (10) influence the asymptotic bias and convergence rate?",
        "What are the theoretical guarantees for different choices of N, and how do they compare to existing methods?",
        "How does the method scale to larger or more complex discrete domains beyond the toy examples provided?",
        "Could adaptive step-size updates or hierarchical caching strategies further optimize performance?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0gTW5JUFTW",
    "title": "TopoMLP: An Simple yet Strong Pipeline",
    "std_review": {
      "summary": "TopoMLP presents a simple yet effective pipeline for 3D road topology reasoning, combining YOLOv8 object detection with a Multi‑Layer Perceptron (MLP) to predict lane geometry and topology. The method achieves competitive performance on the Road Topology Benchmark, especially when evaluated with an adjusted TOP metric that accounts for detection errors. While the initial detection stage shows room for improvement, the MLP's simplicity and effectiveness are highlighted as key strengths. The paper is recommended for acceptance.",
      "strengths": [
        "Innovative detection‑reasoning pipeline using YOLOv8 and MLP.",
        "Adaptive evaluation metric (adjusted TOP) that better reflects topology reasoning.",
        "Demonstrates that a simple MLP can achieve strong results, challenging the need for complex architectures."
      ],
      "weaknesses": [
        "Initial detection performance is a bottleneck for low TOP_ll scores.",
        "Assumes perfect detection in the adjusted TOP metric, which may not be realistic.",
        "Bezier curve representation may limit handling of complex lane shapes."
      ],
      "questions": [
        "How can the detection stage be improved to reduce false positives and improve TOP_ll scores?",
        "What are the practical implications of the assumption of perfect detection in the adjusted TOP metric?",
        "How can the model be extended to better handle highly irregular lane geometries beyond Bezier curves?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0GZ1Bq4Tfr",
    "title": "",
    "std_review": {
      "summary": "The paper introduces Real-Time Weight Decay (RWD), a modification to standard weight decay that applies the decay term during gradient updates, addressing the 'delay defect' that distorts feature distributions. Empirical results on CIFAR datasets show RWD improves convergence speed and robustness, and combined with layer‑wise pre‑weight decay (LPWD) enhances training stability and performance, especially for larger models. While innovative and theoretically justified, the study is limited to image classification tasks and lacks comprehensive statistical analysis and comparison with state‑of‑the‑art methods.",
      "strengths": [
        "Introduces a novel approach to weight decay that addresses known issues with traditional decoupled weight decay.",
        "Provides comprehensive empirical evidence across multiple datasets and model architectures, demonstrating clear improvements in convergence speed and robustness.",
        "Offers a solid theoretical explanation for why the delay defect of weight decay and non‑linear activation distortions lead to performance degradation."
      ],
      "weaknesses": [
        "Empirical evaluation is primarily focused on image classification tasks using CIFAR datasets, which may not fully generalize to other domains.",
        "Lacks statistical rigor, with no error bars or additional runs with different random seeds to assess significance.",
        "Potential overfitting is not fully addressed, especially with larger models.",
        "Does not compare against the latest state‑of‑the‑art methods or more advanced regularization techniques."
      ],
      "questions": [
        "How does RWD perform on non‑image datasets such as natural language processing or reinforcement learning tasks?",
        "What are the long‑term effects of applying RWD to very large models beyond ConvNext and Swin‑Transformer?",
        "Could additional statistical analyses (e.g., error bars, multiple random seeds) strengthen the empirical claims?",
        "How does RWD interact with other regularization techniques or advanced optimizers?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0H6DFoZZXZ",
    "title": "Language Control Diffusion: Efficiently Scaling through Space, Time, and Tasks",
    "std_review": {
      "summary": "The paper introduces LCD, a method for text-to-video generation that combines a well-trained HULC baseline with a diffusion-based low-level policy. It leverages a large textual encoder like T5-XXXL to capture complex textual information, aiming for high-quality video generation. The CALVIN benchmark is used for evaluation, showing competitive results but with notable limitations in generalizability and computational efficiency.",
      "strengths": [
        "Integrates a well-trained HULC baseline with a diffusion-based LLP for high-quality video generation.",
        "Uses a large textual encoder (T5-XXXL) to enhance video generation accuracy.",
        "Provides a controlled evaluation environment with the CALVIN benchmark."
      ],
      "weaknesses": [
        "Relies heavily on a well-trained HULC baseline, which may not be easily transferable.",
        "Performance is benchmark-specific, limiting generalizability.",
        "Computational cost is high due to the large textual encoder."
      ],
      "questions": [
        "How does LCD perform on more diverse or real-world benchmarks beyond CALVIN?",
        "What is the impact of using large textual encoders on the scalability of LCD?",
        "Could alternative encoders reduce computational costs while maintaining performance?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "0i6Z9N5MLY",
    "title": "Variance Reduced Halpern Iteration",
    "std_review": {
      "summary": "The paper introduces two novel algorithms for solving monotone operator problems, offering theoretical improvements in oracle complexity. While the convergence analysis is strong, the unconventional choice of the PAGE optimizer for convex problems and the lack of detailed explanations for some theoretical aspects raise concerns. The practical relevance of the algorithms, particularly in deep learning, remains underexplored.",
      "strengths": [
        "Innovative use of the PAGE optimizer for monotone problems.",
        "Provides new convergence bounds and analyses for variance-reduced methods.",
        "Introduces an anchoring mechanism for handling non-monotone operators."
      ],
      "weaknesses": [
        "Unconventional choice of PAGE for convex problems may be less efficient.",
        "Lack of clear explanation of Lipschitz constant relationships.",
        "Presence of logarithmic factors in convergence bounds without full justification.",
        "Inner-loop stopping criteria are not well justified.",
        "Limited practical examples demonstrating generality."
      ],
      "questions": [
        "Clarify the choice of the base estimator in Algorithm 1.",
        "Provide a detailed explanation of the relationship between Lipschitz constants.",
        "Explain the source of logarithmic factors in the convergence bounds.",
        "Justify the stopping criteria for the inner loop in Algorithm 2.",
        "Provide concrete examples of non-monotone but co-monotone operators.",
        "Interpret the observed oscillations in the empirical results."
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "0IaTFNJner",
    "title": "On the Embedding Collapse When Scaling up Recommendation Models",
    "std_review": {
      "summary": "The paper introduces a novel multi-embedding approach to tackle the information abundance problem in multi-embedding learning for text classification. It combines multiple embeddings into a single representation to capture more diverse information, achieving state-of-the-art results on benchmark datasets. However, the approach relies on a heuristic method, lacks a detailed theoretical foundation, and does not fully address computational complexity, leading to a weak accept recommendation.",
      "strengths": [
        "Introduces a novel multi-embedding approach that effectively addresses the information abundance problem in ME.",
        "Demonstrates superior performance on multiple benchmark datasets.",
        "Provides a comprehensive analysis of results compared to existing ME methods."
      ],
      "weaknesses": [
        "Relies on a heuristic method for combining embeddings, which may not always yield optimal results.",
        "Limited experiments on a few benchmark datasets may restrict generalizability.",
        "Lacks thorough analysis of computational complexity for large-scale applications.",
        "Insufficient discussion of the theoretical foundations and relationship to existing ME methods."
      ],
      "questions": [
        "How is information abundance formally defined and quantified in the context of multi-embedding learning?",
        "What is the computational complexity of the proposed approach, and how does it scale with larger datasets?",
        "How does the proposed method compare to existing ME methods in terms of theoretical underpinnings?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "0j9ZDzMPqr",
    "title": "UNR-Explainer: Counterfactual Explanations for Unsupervised Node Representation Learning Models",
    "std_review": {
      "summary": "UNR-Explainer introduces a Monte Carlo Tree Search (MCTS) method for generating interpretable subgraph explanations of GNN predictions. The approach is innovative and provides domain-specific insights, but its performance varies across datasets and is sensitive to parameter choices. While it demonstrates robustness on real-world data, its computational cost and suboptimal results in synthetic settings limit its overall impact.",
      "strengths": [
        "Introduces a novel MCTS-based method for generating interpretable subgraph explanations.",
        "Provides domain-relevant insights through graph-specific explanations.",
        "Offers flexibility in perturbation levels to tailor explanations to application contexts."
      ],
      "weaknesses": [
        "High computational cost due to MCTS, especially for large graphs.",
        "Performance is sensitive to parameter choices like subgraph size and perturbation level.",
        "Lacks comprehensive comparison with state-of-the-art methods.",
        "Underperforms in synthetic settings, raising questions about generalizability."
      ],
      "questions": [
        "How can the computational efficiency of UNR-Explainer be improved for very large graphs?",
        "What strategies can be employed to better balance interpretability and explanation quality across different datasets?",
        "How does UNR-Explainer compare to other graph-specific explanation methods in terms of recall and fidelity?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "0jHkUDyEO9",
    "title": "Magic123: One Image to High-Quality 3D Object Generation Using Both 2D and 3D Diffusion Priors",
    "std_review": {
      "summary": "The paper presents Magic123, a method that integrates textual inversion with a 2D Stable Diffusion model to generate high-quality images from textual descriptions. It demonstrates significant improvements in image quality and alignment with textual inputs compared to existing methods. The approach also shows robustness in handling scenes without explicit object segmentation, maintaining fidelity to complex backgrounds. While the paper provides a strong baseline comparison and highlights the method's effectiveness, it could benefit from further analysis of computational efficiency and a more detailed exploration of the trade-offs between textual inversion and DreamBooth.",
      "strengths": [
        "Introduces a novel integration of textual inversion with 2D Stable Diffusion, enhancing image generation fidelity.",
        "Demonstrates superior performance in generating high-quality images aligned with textual descriptions.",
        "Explores robustness in handling scenes without explicit object segmentation, showcasing versatility."
      ],
      "weaknesses": [
        "Lacks detailed analysis of computational efficiency compared to existing methods.",
        "Does not thoroughly examine trade-offs between textual inversion and DreamBooth for conditioning.",
        "Performance on complex, unsegmented scenes could be further validated with additional experiments."
      ],
      "questions": [
        "How does the method's performance scale with computational resources for large-scale image generation?",
        "What are the optimal conditions for using textual inversion versus DreamBooth in different scenarios?",
        "Can the method be extended to generate 3D objects from textual descriptions, as suggested by the title?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0JnaN0Crlz",
    "title": "Enhancing Adversarial Robustness on Categorical Data via Attribution Smoothing",
    "std_review": {
      "summary": "The paper introduces IGSG, a novel method to enhance adversarial robustness on categorical data by leveraging attribution smoothing. It provides a theoretical framework and demonstrates empirical effectiveness on multiple datasets. The reviewer finds the approach promising but suggests improvements in theoretical depth and real-world evaluation.",
      "strengths": [
        "Introduces a novel approach to improve adversarial robustness on categorical data, addressing a significant gap in existing literature.",
        "Provides a theoretical foundation for the proposed IGSG regularization technique, relating it to adversarial risk bounds.",
        "Demonstrates empirical effectiveness of IGSG through extensive experiments on multiple datasets.",
        "Offers a clear and concise explanation of the method, making it accessible to a broad audience."
      ],
      "weaknesses": [
        "The paper lacks a detailed discussion of the theoretical underpinnings of IGSG, which could be more convincing to readers.",
        "The evaluation section could benefit from a more comprehensive analysis of the limitations and challenges of applying IGSG to real-world scenarios.",
        "The paper does not provide a thorough comparison with state-of-the-art methods in the field of adversarial robustness for categorical data."
      ],
      "questions": [
        "Could you provide a more detailed theoretical analysis of the IGSG regularization technique?",
        "What are the potential limitations and challenges of applying IGSG to real-world scenarios?",
        "How does IGSG compare to the latest state-of-the-art methods in adversarial robustness for categorical data?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0jsfesDZDq",
    "title": "Sparse Spiking Neural Network: Exploiting Heterogeneity in Timescales for Pruning Recurrent SNN",
    "std_review": {
      "summary": "The paper presents Lyapunov Noise Pruning (LNP), a task-agnostic pruning method for recurrent spiking neural networks (RSNNs) that leverages Lyapunov noise to achieve efficient pruning. The authors demonstrate that LNP improves sparsity, accuracy, and computational efficiency compared to existing methods, with promising implications for neuromorphic computing. However, the paper lacks detailed explanations of Lyapunov noise and its application, and the experimental evaluation is limited. Overall, the work is promising but requires further clarification and broader testing.",
      "strengths": [
        "Introduces a novel task-agnostic pruning method for RSNNs.",
        "Proposes Lyapunov Noise Pruning (LNP) that leverages a unique noise concept.",
        "Demonstrates effectiveness through experiments on various datasets."
      ],
      "weaknesses": [
        "Lacks detailed explanation of Lyapunov noise and its application.",
        "Experimental evaluation is limited to a few datasets and tasks.",
        "Does not provide a comprehensive comparison with other pruning approaches.",
        "Limited discussion on potential limitations and real-world implementation challenges."
      ],
      "questions": [
        "Can you provide a detailed explanation of Lyapunov noise and its role in the pruning process?",
        "How does LNP compare to other pruning methods across a broader range of RSNN applications?",
        "What are the key challenges in implementing LNP in real-world scenarios?"
      ],
      "overall_score": "6: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0JsRZEGZ7L",
    "title": "From Latent graph to Latent Topology Inference: Differentiable Cell Complex Module",
    "std_review": {
      "summary": "The paper introduces Directed Community Matching (DCM), a GNN architecture that enhances community detection in graphs, especially in heterophilic settings. DCM leverages directed edges and a novel similarity measure with community-based attention to improve node representation and community separation. Experimental results show significant improvements over existing baselines across various datasets, demonstrating robustness and versatility. However, the paper could benefit from ablation studies and a more detailed discussion on adapting DCM for directed complexes.",
      "strengths": [
        "Innovative community detection approach using directed edges.",
        "Parameter-efficient architecture suitable for large-scale graphs.",
        "Strong theoretical foundation with clear mathematical formulations."
      ],
      "weaknesses": [
        "Complex mathematical formulations may be difficult for some readers.",
        "Lack of ablation studies to evaluate key hyperparameters.",
        "Limited discussion on adapting DCM for directed complexes."
      ],
      "questions": [
        "Could you provide ablation studies for the impact of edge assignment threshold and parameter α?",
        "What are the steps to adapt DCM for directed complexes?",
        "How does DCM's performance compare to recent advancements in community detection?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0JTwZ30qPH",
    "title": "Task-Oriented Multi-View Representation Learning",
    "std_review": {
      "summary": "The paper introduces TOMRL, a novel few-shot learning approach that combines meta-learning with multi-view learning to generate task-specific biases and fuse them, improving performance on benchmark datasets. The method effectively addresses overfitting with limited data and demonstrates strong results compared to existing techniques. However, its generalizability could be better assessed across more diverse datasets, and the implementation complexity and hyperparameter sensitivity warrant further exploration.",
      "strengths": [
        "Introduces a novel approach to few-shot learning by combining meta-learning with multi-view learning.",
        "Effectively addresses the challenge of overfitting in limited sample scenarios.",
        "Demonstrates improved performance on benchmark datasets compared to existing methods."
      ],
      "weaknesses": [
        "Limited evaluation on a diverse set of datasets may not fully capture the method's generalizability.",
        "The complexity of the proposed method could make it challenging to implement and optimize in practice.",
        "Lack of detailed analysis on the impact of different hyperparameters on the model's performance."
      ],
      "questions": [
        "How does TOMRL perform on a broader range of datasets beyond the current benchmarks?",
        "What are the practical considerations for implementing and optimizing TOMRL in real-world scenarios?",
        "Could a more detailed analysis of hyperparameter sensitivity provide insights into model performance?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0JWVWUlobv",
    "title": "4D Tensor Multi-task Continual Learning for Disease Dynamic Prediction",
    "std_review": {
      "summary": "The paper introduces a 4D tensor representation of MRI biomarkers for Alzheimer's disease progression, integrated into a continual learning framework. Experiments on the ADNI dataset show significant improvements over baselines, with clear results and biomarker analysis. The approach is promising but could benefit from more theoretical discussion and comparison with state-of-the-art methods.",
      "strengths": [
        "Novel 4D tensor representation captures spatio-temporal MRI information.",
        "Effective continual learning framework for sequential AD data.",
        "Well-designed model for incremental learning and real-world applicability.",
        "Comprehensive experimental setup and clear evaluation metrics.",
        "Detailed biomarker analysis provides valuable insights."
      ],
      "weaknesses": [
        "Lacks detailed discussion on biomarker relevance.",
        "Theoretical underpinnings of continual learning approach are not fully explained.",
        "Experimental setup could include more discussion on data preprocessing and biases.",
        "Evaluation results are presented qualitatively; quantitative comparison with state-of-the-art methods would strengthen the paper.",
        "Generalization to other datasets is not fully addressed."
      ],
      "questions": [
        "What is the specific rationale for selecting the biomarkers used in the study and their relevance to AD progression?",
        "How does the proposed continual learning approach differ from other methods, and what is its theoretical foundation?",
        "Could you provide more details on the data preprocessing steps and potential biases in the ADNI dataset?",
        "What are the quantitative evaluation results compared to state-of-the-art methods?",
        "How does the model generalize to other datasets or tasks beyond the ADNI dataset?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0KVkTDB6KZ",
    "title": "EFFL: Egalitarian Fairness in Federated Learning for Mitigating Matthew Effect",
    "std_review": {
      "raw_text": "{\n  \"summary\": \"EFFL introduces a framework that integrates fairness constraints directly into federated learning, balancing accuracy and fairness through a novel objective. The approach is validated empirically across synthetic and real datasets, showing improved fairness without significant loss in performance. While addressing a critical gap in FL research, the paper acknowledges challenges such as parameter sensitivity and assumptions on smoothness and convexity.\",\n  \"strengths\": [\n    \"Innovative integration of fairness constraints into federated learning.\",\n    \"Strong theoretical foundation with a rigorous mathematical formulation.\",\n    \"Empirical validation demonstrating practical effectiveness across diverse datasets.\"\n  ],\n  \"weaknesses\": [\n    \"Parameter sensitivity to fairness parameters may require extensive tuning.\",\n    \"Assumptions of smoothness and convexity may limit generalizability.\",\n    \"Lack of detailed analysis on communication overhead introduced by fairness constraints.\"\n  ],\n  \"questions\": [\n    \"How can the optimal values of $\\epsilon_b$, $\\epsilon_{ub}$, and $\\epsilon_{ul}$ be determined in practice?\",\n    \"What are the implications of the smoothness and convexity assumptions on the applicability of the results?\",\n    \"How does the approach scale with a large number of clients, and what is the communication overhead compared to non-fair FL?\"\n  ],\n  \"overall_score\": \"7: accept\",\n  \"confidence\": \"4: high\"\n}",
      "parse_error": true
    }
  },
  {
    "paper_id": "0kvrymILfy",
    "title": "Making Predictors More Reliable with Selective Recalibration",
    "std_review": {
      "summary": "The paper presents a method to improve deep neural networks' robustness against out‑of‑distribution samples by combining confidence‑based rejection with a recalibration step. It introduces the R‑ECE metric to evaluate the approach and demonstrates its effectiveness on ImageNet and Camelyon17 datasets. The method is innovative and empirically shown to reduce OOD errors, though some details in the implementation and evaluation are unclear.",
      "strengths": [
        "Innovative combination of confidence‑based rejection with recalibration.",
        "Clear definition of the R‑ECE metric for evaluating the method.",
        "Empirical results on challenging datasets showing significant OOD robustness gains."
      ],
      "weaknesses": [
        "Ambiguity in Figure 1 regarding the interpretation of the blue and green curves.",
        "Multiple curves for non‑selected cases in Figure 1 are confusing.",
        "R‑ECE metric definition is not fully detailed in the main text.",
        "Lack of detailed explanation of the ECE calculations in the appendix."
      ],
      "questions": [
        "Could you clarify the exact groups represented by the blue and green curves in Figure 1?",
        "Why are multiple curves shown for non‑selected cases instead of a single baseline curve?",
        "Please provide a detailed definition and computation of the R‑ECE metric in the main text.",
        "Could you elaborate on the spacing, notation, and assumptions used in the ECE calculations in the appendix?"
      ],
      "overall_score": "Accept",
      "confidence": "High"
    }
  },
  {
    "paper_id": "0kWd8SJq8d",
    "title": "MInde: Mutual Information Neural Diffusion Estimation",
    "std_review": {
      "summary": "The paper introduces MINDE, a novel generative model that effectively estimates probability distributions using neural networks. It compares MINDE's performance to classic estimators like DoE and GM, as well as a related work, demonstrating its high-quality sample generation and competitive accuracy. While noting training and computational costs, the paper highlights its practical applicability and provides valuable insights for future research.",
      "strengths": [
        "Introduces a novel generative model (MINDE) that effectively estimates probability distributions using neural networks.",
        "Provides a thorough comparison of MINDE's performance against classic generative estimators and a related work.",
        "Demonstrates the ability of MINDE to generate high-quality samples, showcasing its practical applicability."
      ],
      "weaknesses": [
        "Lacks detailed explanation of specific differences between MINDE and the work in [3].",
        "Training process for MINDE may be computationally expensive, limiting applicability in resource-constrained environments.",
        "Does not provide a comprehensive analysis of memory requirements for training and inference."
      ],
      "questions": [
        "Can you elaborate on the unique aspects of MINDE's architecture and training process that distinguish it from the work in [3]?",
        "What are the specific memory and computing requirements for training and inference, and how do they compare to other methods?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0Lqyut1y7M",
    "title": "On the Optimality of Activations in Implicit Neural Representations",
    "std_review": {
      "summary": "The paper investigates the use of sinc activation functions in integral neural representations (INRs) and demonstrates that a 2-layer network with sinc activation can form a Riesz basis under mild conditions, which is crucial for stable and accurate signal reconstruction. It also explores the interaction between sinc activations and sinusoidal positional encodings, showing potential performance benefits. However, the paper's claim of sinc's optimality among INR activations is not fully substantiated, and its theoretical analysis is limited to shallow networks. Overall, the work makes a novel contribution but has several limitations that need addressing.",
      "strengths": [
        "Provides a rigorous theoretical analysis of sinc activation properties in INRs.",
        "Introduces a promising interaction between sinc activations and sinusoidal positional encodings.",
        "Validates theoretical claims with experiments demonstrating practical utility."
      ],
      "weaknesses": [
        "Theoretical analysis limited to 2-layer networks; unclear extension to deeper architectures.",
        "Claim of sinc optimality lacks a clear definition and formal proof.",
        "Does not explore potential failure modes of sinc activation.",
        "Interaction with other positional encodings is not thoroughly investigated."
      ],
      "questions": [
        "How do the theoretical guarantees of sinc activations extend to deeper INR architectures?",
        "What is the formal definition of optimality for sinc activations in the context of INRs?",
        "Are there specific failure modes or scenarios where sinc activations underperform?",
        "How do sinc activations interact with other types of positional encodings beyond sinusoidal ones?"
      ],
      "overall_score": "Borderline",
      "confidence": "Medium"
    }
  },
  {
    "paper_id": "0lW9cDUtf8",
    "title": "",
    "std_review": {
      "summary": "The paper introduces FairReweighing, a method that enhances fairness in regression by ensuring separation fairness (Y ⟂ A|Y) through kernel density estimation or radius-neighbor density estimation in preprocessing. Empirical evaluations show improved separation metrics and competitive performance, bridging theory and practice. While innovative, the method faces challenges in parameter selection, theoretical guarantees, and limited baseline comparisons.",
      "strengths": [
        "Innovative integration of KDE/RND with reweighting for fairness.",
        "Clear theoretical foundation ensuring separation fairness.",
        "Empirical validation on real-world datasets with strong performance."
      ],
      "weaknesses": [
        "Complexity in selecting optimal bandwidth or radius.",
        "Lack of detailed theoretical guarantees on convergence.",
        "Limited baseline comparisons may overlook other methods."
      ],
      "questions": [
        "How does FairReweighing handle low-frequency protected groups?",
        "What is the method's performance under noisy or adversarial data?",
        "How does parameter tuning affect fairness vs. model accuracy trade-offs?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0NruoU6s5Z",
    "title": "CompoDiff: Versatile Composed",
    "std_review": {
      "summary": "CompoDiff introduces a novel approach to image retrieval by dynamically generating text prompts with CLIP to better match query images, especially in complex scenes with multiple objects. The method shows significant improvements over baselines and introduces learnable text prompts that adapt to specific query images, potentially enhancing performance. However, implementation complexity and limited dataset evaluation are noted as areas for improvement.",
      "strengths": [
        "Innovative use of CLIP to generate dynamic text prompts.",
        "Improved retrieval accuracy, particularly in complex scenes.",
        "Exploration of learnable text prompts for flexible retrieval."
      ],
      "weaknesses": [
        "Potential computational complexity for real-time applications.",
        "Lack of detailed analysis of trade-offs between accuracy and efficiency.",
        "Limited evaluation on diverse datasets."
      ],
      "questions": [
        "How does the method handle queries with multiple target objects or conditions simultaneously?",
        "What is the effect of using learnable text prompts in the CLIP‑text branch on retrieval performance?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0Nui91LBQS",
    "title": "",
    "std_review": {
      "summary": "The paper introduces SEED, a tokenizer that integrates visual information into large language models (LLMs) by converting images into discrete visual tokens. SEED leverages a pre-trained CLIP-ViT encoder, a Causal Q‑Former for token optimization, and a VQ codebook, trained with contrastive and causal losses. It demonstrates strong performance on image-text retrieval benchmarks and scales well with larger LLMs, though it faces challenges in training complexity and handling video data.",
      "strengths": [
        "Innovative tokenization approach for seamless visual‑text integration.",
        "Effective training objectives that balance contrastive and causal learning.",
        "Competitive multimodal performance and scalability across model sizes."
      ],
      "weaknesses": [
        "Complex training pipeline requiring significant computational resources.",
        "Evaluation using CLIP similarity may not fully capture image generation nuances.",
        "Scalability concerns with discrete visual tokens compared to continuous embeddings.",
        "Limited discussion on handling video data."
      ],
      "questions": [
        "How does SEED's performance compare to continuous visual embeddings in terms of expressiveness and scalability?",
        "What are the specific challenges in scaling SEED to very large model sizes, and how can they be mitigated?",
        "How does SEED's tokenization approach affect its ability to handle video data compared to static images?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0oIkKERYhH",
    "title": "DOG: Discriminator-only Generation",
    "std_review": {
      "summary": "The paper introduces DOG, a discriminator‑only method for generating graph data that iteratively refines graph structures using a discriminator network. DOG outperforms existing models like SPECTRE and diffusion approaches on several benchmarks, showing improved sample quality and faster training times. The authors provide both intuitive and theoretical justifications for DOG's effectiveness, particularly in handling the discrete nature of graph data. Overall, the paper is well‑structured, clearly presented, and makes a significant contribution to graph generation.",
      "strengths": [
        "Simplicity and Efficiency: DOG simplifies the generation process by using only a discriminator, eliminating the need for a generator and associated complexities.",
        "Improved Sample Quality: The iterative refinement process allows DOG to produce higher quality graph samples, as demonstrated on benchmark datasets.",
        "Faster Training: By focusing on discriminator updates, DOG achieves significantly faster training times compared to traditional GANs and other graph generation models."
      ],
      "weaknesses": [
        "Limited Generalization: The method's reliance on a discriminator may limit its ability to capture certain graph properties or structures that a generator could more naturally model.",
        "Training Instability: Iterative processes can sometimes lead to training instability, especially if the discriminator becomes too strong or too weak.",
        "Lack of Flexibility: DOG's approach may not easily adapt to diverse graph types or specific application requirements without significant modifications."
      ],
      "questions": [
        "How does DOG perform on very large or sparse graph datasets, and what modifications might be needed for such cases?",
        "Can DOG be extended to generate graphs with specific structural constraints or properties beyond general graph generation?",
        "What are the long‑term stability and generalization capabilities of DOG when applied to real‑world graph generation tasks?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0Pu0H7y3gg",
    "title": "Understanding the Initial Condensation of Convolutional Neural Networks",
    "std_review": {
      "summary": "The paper introduces a novel theoretical framework explaining the initial condensation of convolutional neural network parameters along specific eigendirections of the Fisher information matrix. It derives a time estimate for when this condensation occurs and validates the findings with experiments on networks with suboptimal performance. While the theoretical insights are valuable, the practical relevance is limited by the use of suboptimal networks and the reliance on specific assumptions.",
      "strengths": [
        "Novel theoretical framework that relaxes Assumption 4 to provide a more nuanced understanding of condensation.",
        "Clear and rigorous mathematical derivation of the time estimate for condensation.",
        "Empirical validation of theoretical predictions, despite using networks with suboptimal performance."
      ],
      "weaknesses": [
        "Limited network performance in experiments may reduce the practical relevance of the findings.",
        "Theoretical results depend on specific assumptions that are not fully explored for robustness.",
        "The role of activation functions in parameter dynamics is not fully addressed.",
        "The necessity of a supremum in Theorem 1 raises questions about the completeness of the condensation analysis."
      ],
      "questions": [
        "How robust are the theoretical results to variations in network architecture and training conditions?",
        "What is the impact of the activation function on the time derivatives of the parameters and the condensation phenomenon?",
        "Can the theoretical framework be extended to adaptive optimizers like Adam?",
        "How does the initialization of the last layer (e.g., zero weights) influence the occurrence of condensation?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0Q1mBvUgmt",
    "title": "VIPER: Vibrant Period Representation for Robust and Efficient Time Series Forecasting",
    "std_review": {
      "summary": "The paper proposes TimesNet, a novel architecture for time series representation learning that captures both intraperiod-variation and interperiod-variation using convolutional and attention mechanisms. While the model shows competitive performance on benchmark datasets, the review highlights several issues, including unclear explanations of key equations and inconsistent results compared to the original paper. The overall verdict leans towards a weak acceptance.",
      "strengths": [
        "Introduces a novel architecture that explicitly models both intraperiod-variation and interperiod-variation in time series data.",
        "Combines convolutional and attention mechanisms to capture local and global patterns in the data.",
        "Provides a clear and interpretable framework for understanding how the model processes time series data."
      ],
      "weaknesses": [
        "The purpose of the 'Avg' in Equation (1) is not clearly explained.",
        "The representation of Equation (3) lacks clarity regarding which axis the attention operation is performed on.",
        "The paper does not provide a clear explanation of how the proposed representation block captures intraperiod-variation and interperiod-variation separately.",
        "The results presented in Table 2 are inconsistent with the original paper.",
        "The reported Avg results in Table 3 are incorrect, and the proposed block only yields a slight 2.9% improvement in MSE."
      ],
      "questions": [
        "Could you clarify the role of the 'Avg' in Equation (1) and how it contributes to the model?",
        "Please provide a detailed explanation of the attention operation in Equation (3), including the specific axis on which it is performed.",
        "How does the proposed representation block explicitly separate intraperiod-variation and interperiod-variation?",
        "Could you investigate the inconsistencies in the results presented in Table 2 compared to the original paper?",
        "Please verify the reported Avg results in Table 3 and provide a more accurate comparison."
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "0QAzIMq32X",
    "title": "Inner Classifier-Free Guidance and Its Taylor Expansion for Diffusion Models",
    "std_review": {
      "summary": "The paper introduces a second-order inference guidance framework for diffusion models, enhancing consistency and image quality on the COCO dataset. It provides a rigorous theoretical foundation and demonstrates computational efficiency by selectively applying the method. However, it lacks broader empirical validation, detailed hyperparameter analysis, and a comprehensive comparison with first-order methods.",
      "strengths": [
        "Introduces a novel second-order inference guidance method.",
        "Provides a strong theoretical analysis with necessary and sufficient conditions.",
        "Demonstrates significant improvements in image quality and consistency on COCO."
      ],
      "weaknesses": [
        "Theoretical analysis is complex and may be hard for some readers to follow.",
        "Empirical validation is limited to the COCO dataset.",
        "Does not extensively address hyperparameter sensitivity.",
        "Lacks a detailed computational cost comparison with first-order methods."
      ],
      "questions": [
        "Can the method be validated on additional datasets beyond COCO?",
        "What is the impact of hyperparameter choices on reproducibility?",
        "How does the computational cost of selective second-order ICFG application compare to first-order methods?",
        "Can the theoretical proof be extended to show both necessary and sufficient conditions?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "0Qyxw0cCuu",
    "title": "Control: A Contrastive Learning Framework",
    "std_review": {
      "summary": "CONTROL presents a novel framework for open-world semi-supervised learning (OWSSL) by leveraging three contrastive learning objectives to separate seen and unseen class features. The approach optimizes at the feature level, providing theoretical justification and outperforming existing OWSSL methods and even traditional semi-supervised algorithms like FixMatch. While showing strong empirical results, the paper notes high hyperparameter sensitivity and a lack of comprehensive theoretical guarantees.",
      "strengths": [
        "Introduces three distinct contrastive learning objectives to effectively address the seen-unseen class problem in OWSSL.",
        "Optimizes at the feature level, offering a theoretically justified approach that improves performance.",
        "Demonstrates superior empirical results across various benchmarks compared to state-of-the-art methods."
      ],
      "weaknesses": [
        "High sensitivity to hyperparameter choices may limit practical deployment.",
        "Theoretical underpinnings are not as comprehensive as those in some other recent works.",
        "Comparison with a broader range of baselines could strengthen the argument for generality."
      ],
      "questions": [
        "How robust is CONTROL to variations in hyperparameter settings across different datasets?",
        "What are the theoretical guarantees for feature-level optimization beyond the arguments provided in the paper?",
        "How does CONTROL compare to other OWSSL methods not specifically mentioned in the experiments?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0S0CgZEYxR",
    "title": "Examining the Achilles' Heel of CLIP Models: The Worst-Performing Categories",
    "std_review": {
      "summary": "The paper introduces a method to improve zero-shot image classification by dynamically generating enriched prompts for the worst‑performing categories, identified using a Class‑wise Matching Margin metric. It fine‑tunes a CLIP model with these prompts and shows significant accuracy gains on the targeted categories. While promising, the method's robustness and general applicability are limited by the lack of labeled validation data, unclear prompt application, and limited comparison to other models.",
      "strengths": [
        "Innovative prompt enrichment approach for zero-shot classification.",
        "Clear and reproducible evaluation framework using Class‑wise Matching Margin.",
        "Empirical results demonstrate substantial gains on problematic categories."
      ],
      "weaknesses": [
        "Relies on pseudo‑labeling without labeled validation data, raising reliability concerns.",
        "Enriched prompts are applied uniformly across worst categories, limiting flexibility.",
        "Limited comparison to other zero‑shot/few‑shot approaches.",
        "No evidence of impact beyond the worst‑10 categories.",
        "Potential applicability to other visual‑language tasks is underexplored."
      ],
      "questions": [
        "How can the method be validated without labeled validation data for pseudo‑labels?",
        "Are the enriched prompts tailored to each category or applied uniformly?",
        "How does the method compare to other zero‑shot or few‑shot models?",
        "What is the impact of enriched prompts on categories beyond the worst‑10?",
        "Can the enriched prompt approach be generalized to other visual‑language tasks?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "0sbIEkIutN",
    "title": "From Interpolation to Extrapolation: Complete Length Generalization for Arithmetic Transformers",
    "std_review": {
      "summary": "The paper introduces Attention Bias Calibration (ABC), a technique that enforces diagonal attention patterns in transformers to improve arithmetic reasoning. Experiments show strong performance on standard arithmetic benchmarks, outperforming baselines without this calibration. While ABC is effective for linear tasks, it may struggle with more complex or non‑monotonic reasoning due to its strong inductive bias. The method is theoretically motivated and flexible, but its limited generalization and potential overfitting are concerns.",
      "strengths": [
        "Targeted improvement on arithmetic tasks by aligning attention with sequential reasoning.",
        "Clear theoretical motivation for using diagonal attention in linear problems.",
        "Empirical success on benchmark arithmetic datasets.",
        "Flexibility to apply to both self-attention and cross-attention heads."
      ],
      "weaknesses": [
        "Limited generalization to non‑linear or complex reasoning tasks.",
        "Potential overfitting due to strict diagonal attention enforcement.",
        "Increased implementation complexity may affect computational efficiency.",
        "Lack of extensive comparison with state-of-the-art methods."
      ],
      "questions": [
        "How does ABC perform on non‑monotonic reasoning tasks beyond arithmetic?",
        "What is the impact of the strong inductive bias on the model's ability to generalize to natural language tasks?",
        "Could relaxing the diagonal bias improve performance on tasks requiring flexible attention patterns?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "0sO2euxhUQ",
    "title": "Learning Latent Structural Causal Models",
    "std_review": {
      "summary": "The paper introduces a method for learning latent structural causal models (SCMs) by inferring latent weight matrices and estimating latent Gaussian noises using interventions. Experiments on synthetic and image datasets show the method's effectiveness, outperforming existing approaches in causal accuracy and noise estimation. While promising, the method lacks comprehensive theoretical guarantees and scalability analysis, and its practical applicability in complex scenarios is not fully explored.",
      "strengths": [
        "Provides a systematic approach to learning latent SCMs, addressing key identifiability issues.",
        "Leverages interventions to infer latent structures, enhancing robustness.",
        "Demonstrates practical applicability through experiments on synthetic and image datasets."
      ],
      "weaknesses": [
        "Lacks comprehensive theoretical guarantees for learning latent SCMs.",
        "Scalability with respect to nodes and interventions is not thoroughly addressed.",
        "Practical challenges in applying the method to real-world scenarios are not fully explored."
      ],
      "questions": [
        "What are the theoretical guarantees for learning latent SCMs?",
        "How does the method scale with the number of nodes and interventions?",
        "What are the practical challenges in applying the method to real-world scenarios?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0SOhDO7xI0",
    "title": "DeepDRK: Deep Dependency Regularized Knockoff for Feature Selection",
    "std_review": {
      "summary": "DeepDRK introduces a novel method that combines SWC dependency regularization with a perturbation technique to control false discovery rate (FDR) and enhance power in high-dimensional settings. The approach integrates a multi‑swapper adversarial training procedure to enforce the swap property, aiming to improve both FDR control and statistical power. Empirical results demonstrate that DeepDRK achieves better performance compared to existing methods, particularly in high-dimensional contexts. However, the paper also highlights trade‑offs between FDR control and power improvement, especially influenced by the row‑permuted (DRP) term.",
      "strengths": [
        "Innovative combination of SWC dependency regularization with perturbation techniques offers a novel approach to FDR control in high-dimensional data.",
        "Adversarial training procedure effectively enforces the swap property, enhancing the robustness of the method.",
        "Comprehensive theoretical analysis clearly outlines how the proposed method affects FDR and power guarantees in high-dimensional settings."
      ],
      "weaknesses": [
        "Lack of high-dimensional simulations limits validation of the method's effectiveness in realistic high-dimensional settings.",
        "Complexity of the multi‑swapper adversarial training procedure could benefit from more in-depth explanation and validation.",
        "Trade‑offs between FDR control and power improvement are discussed but not fully explored."
      ],
      "questions": [
        "Could additional high-dimensional simulations be conducted to validate the method's performance in realistic settings?",
        "What are the detailed design and role of the multi‑swapper adversarial training procedure?",
        "Would ablation studies help clarify the balance between FDR control and power improvement in DeepDRK?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "0t1O8ziRZp",
    "title": "Retrieval-Guided Reinforcement Learning for Boolean Circuit Minimization",
    "std_review": {
      "summary": "The paper introduces ABC-RL, a retrieval-guided reinforcement learning approach for optimizing digital circuits using a graph convolutional network (GCN) to compute similarity between circuit graphs. It leverages cosine similarity for retrieval, allowing the agent to prioritize structurally similar but functionally distinct circuits during exploration. Experiments on the ISPD benchmark show improved performance over baseline RL methods, especially for functionally diverse yet structurally similar circuits. The method is innovative, scalable, and effective for the target problem, though it has some limitations that need addressing.",
      "strengths": [
        "Innovative retrieval mechanism using GCN for similarity-based circuit optimization.",
        "Improved performance on circuits that are structurally similar but functionally different.",
        "Scalable architecture suitable for large benchmark datasets."
      ],
      "weaknesses": [
        "Limited evaluation on larger datasets may affect generalizability.",
        "Computational trade-offs introduced by GCN depth and retrieval process.",
        "Potential for overfitting due to reliance on cosine similarity."
      ],
      "questions": [
        "How does the method scale with larger benchmark datasets?",
        "What alternative similarity metrics could improve retrieval quality beyond cosine similarity?",
        "What are the computational trade-offs for very large circuits, and how can they be mitigated?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0tsJ7Nv5hk",
    "title": "Harnessing Orthogonality to Train Low-Rank Neural Networks",
    "std_review": {
      "summary": "The paper introduces OIALR, a novel iterative low-rank training method that enhances stability and efficiency. It begins with full-rank training, then progressively reduces the weight matrix rank while maintaining performance. Empirical results show improvements over traditional low-rank techniques and full-rank training across various models. The method is scalable, reducing memory usage and training time, but its implementation complexity and reliance on initial full-rank training are noted.",
      "strengths": [
        "Introduces a novel stability metric specific to low-rank training.",
        "Iterative refinement provides smoother convergence and improved stability.",
        "Demonstrates empirical superiority over baseline methods on multiple datasets.",
        "Shows significant reductions in memory usage and training time."
      ],
      "weaknesses": [
        "Implementation complexity due to iterative refinement process.",
        "Dependence on the quality of the initial full-rank training phase.",
        "Limited analysis for non-transformer models."
      ],
      "questions": [
        "How does OIALR compare to adaptive low-rank methods in terms of computational efficiency?",
        "Can the method be extended to other model architectures beyond transformers?",
        "What are the theoretical guarantees for the stability metric defined in the paper?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0tWTxYYPnW",
    "title": "Understanding Hidden Context in Preference Learning: Consequences for RLHF",
    "std_review": {
      "summary": "The paper introduces Distributional Preference Learning (DPL), a method that models hidden context in preference data by assuming a single underlying utility function. DPL incorporates a regularization term to ensure the uniqueness of this utility function, allowing it to uncover hidden context such as population diversity or competing objectives. The method is demonstrated through case studies on competing objectives and risk‑sensitive optimization, showing effective identification of hidden context. While innovative, the approach relies on simplifying assumptions and lacks comprehensive comparison with existing methods, raising questions about its scalability and robustness.",
      "strengths": [
        "Clear theoretical foundation with a rigorous mathematical framework.",
        "Practical relevance demonstrated through case studies on competing objectives and risk‑sensitive optimization.",
        "Innovative approach to modeling hidden context as a single underlying utility function."
      ],
      "weaknesses": [
        "Simplistic assumption of a single underlying utility function may not capture real‑world preference complexity.",
        "Limited quantile sensitivity analysis for the risk‑sensitive optimization.",
        "Lack of comprehensive comparison with other state‑of‑the‑art methods.",
        "Scalability concerns due to experiments on small datasets."
      ],
      "questions": [
        "How does the method handle preferences influenced by multiple, competing objectives or irrational behavior?",
        "What is the sensitivity of the 0.01 quantile choice in risk‑sensitive optimization to the specific results?",
        "How does DPL compare to other methods such as clustering or annotator identity modeling in terms of performance and scalability?",
        "What is the impact of the assumption of a single underlying utility function on the interpretability of the learned preferences?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "0TZs6WOs16",
    "title": "Hyperbolic Embeddings in Sequential Self-Attention for Improved Next-Item Recommendations",
    "std_review": {
      "summary": "The paper introduces Hyperbolic Sequential Self-Attention (HSASRec), a model that leverages hyperbolic embeddings to enhance sequential recommendation systems. It demonstrates superior performance over existing models like SASRec and BERT4Rec on several benchmark datasets, highlighting the practical benefits of hyperbolic embeddings. The study provides a solid theoretical foundation and extensive experiments, though it also notes challenges related to implementation complexity, parameter sensitivity, and scalability.",
      "strengths": [
        "Innovative use of hyperbolic geometry for sequential recommendation.",
        "Demonstrated superior performance compared to state-of-the-art models.",
        "Provides a solid theoretical foundation and comprehensive experiments."
      ],
      "weaknesses": [
        "Complexity of hyperbolic embedding and self-attention mechanism.",
        "Sensitivity to hyperbolic space parameters.",
        "Potential scalability issues in large-scale systems."
      ],
      "questions": [
        "How can the model's computational cost be reduced for large-scale applications?",
        "What strategies can be employed to improve the robustness of hyperbolic models to non-hierarchical datasets?",
        "Are there specific loss functions or training techniques that could further enhance performance?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0u9uvPdRgV",
    "title": "Semi-supervised Diffusion Solver for Travel-Ling Salesman Problem",
    "std_review": {
      "summary": "The paper presents a semi-supervised diffusion model for solving the Traveling Salesman Problem (TSP), leveraging a small set of labeled tours to guide the generation of high-quality tours from an unlabeled distribution. It combines supervised and unsupervised losses to balance exploration and exploitation, showing significant improvements over both unsupervised and supervised baselines on benchmark TSP instances. While the approach is theoretically motivated and empirically demonstrated, some aspects such as the clarity of the transition matrix interpretation and the lack of reproducibility details need improvement.",
      "strengths": [
        "Novel integration of semi-supervised learning with an unsupervised diffusion process.",
        "Clear theoretical motivation for the semi-supervised loss formulation.",
        "Empirical evidence demonstrating effectiveness and scalability through ablation studies and scalability experiments."
      ],
      "weaknesses": [
        "Ambiguity in the interpretation of the transition matrix used to guide the diffusion process.",
        "Lack of detailed comparison with other unsupervised methods.",
        "Absence of reproducibility details that could affect the verification of results."
      ],
      "questions": [
        "Can the transition matrix be interpreted more clearly to better guide the diffusion process?",
        "How does the model perform when compared to other state-of-the-art unsupervised TSP solvers?",
        "What are the specific conditions under which the model can directly output a feasible solution without a search step?"
      ],
      "overall_score": "Accept",
      "confidence": "High"
    }
  },
  {
    "paper_id": "0uI5415ry7",
    "title": "Linear attention is (maybe) all you need",
    "std_review": {
      "summary": "The paper introduces a linearized Transformer as a simplified model to study the optimization dynamics of full attention Transformers. It provides a detailed empirical analysis of stochastic‑gradient noise distributions, showing that the linear model reproduces heavy‑tailed behavior similar to full Transformers, while also offering theoretical insights into implicit regularization. However, the study is limited by the lack of a rigorous theoretical foundation for the observed behaviors and does not fully explore non‑linear tasks or alternative data distributions. Overall, the work is valuable but should be considered a promising proxy model rather than a definitive explanation.",
      "strengths": [
        "Introduces a linear Transformer as a useful proxy for full attention Transformers.",
        "Provides a comprehensive empirical analysis of stochastic‑gradient noise distributions.",
        "Offers theoretical insights into why the linear model might exhibit similar optimization characteristics."
      ],
      "weaknesses": [
        "Lacks a rigorous theoretical explanation for the observed optimization behaviors.",
        "Limited exploration of non‑linear tasks and their impact on optimization dynamics.",
        "Focuses primarily on heavy‑tailed and Gaussian distributions, potentially missing broader applicability."
      ],
      "questions": [
        "What theoretical framework could explain the observed similarity in optimization dynamics between the linear and full attention models?",
        "How do the optimization dynamics of the linear Transformer generalize to non‑linear tasks?",
        "What are the implications of the model's sensitivity to data distribution choices for its broader applicability?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "0upMDCx8AA",
    "title": "Post-Training Recovery from Injected Bias",
    "std_review": {
      "summary": "The paper introduces Bias-Conditioned Self-Influence (BCSI), a method that adapts the self-influence technique to detect and mitigate spurious correlations in biased datasets. BCSI modifies self-influence by conditioning influence scores on bias scores, improving bias detection and correction. Empirical evaluations show that BCSI outperforms standard self-influence and other baselines across various bias ratios, including extreme cases, and demonstrates robustness in post-training recovery. The authors provide a solid theoretical foundation and comprehensive empirical evidence, though real-world dataset evaluation is limited.",
      "strengths": [
        "Innovative adaptation of self-influence to address bias.",
        "Clear theoretical justification for effectiveness.",
        "Comprehensive empirical validation across different bias scenarios."
      ],
      "weaknesses": [
        "Implementation complexity due to bias conditioning.",
        "Assumes availability of reliable bias scores.",
        "Limited evaluation on real-world datasets."
      ],
      "questions": [
        "How does BCSI perform on datasets with non-uniform or unknown bias distributions?",
        "What is the impact of the pivotal set size on BCSI's bias reduction and model performance?",
        "How does BCSI compare to other post-training debiasing techniques in terms of computational cost?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0uUASYeXav",
    "title": "Relational Object-Centric Actor-Critic",
    "std_review": {
      "summary": "The paper presents GOCA, a multi-agent reinforcement learning framework that extends the SLATE architecture to handle continuous action spaces using Soft Actor-Critic with message passing. It demonstrates strong performance on the GOCA benchmark, showcasing scalability and adaptability to various object attributes. While addressing key challenges in multi-agent RL, the approach has notable computational costs and hyperparameter sensitivity, which could impact practical deployment.",
      "strengths": [
        "Introduces a novel architecture extending SLATE to continuous action spaces, addressing a significant gap in multi-agent RL literature.",
        "Demonstrates robust performance on a challenging benchmark involving complex manipulation tasks with dynamic objects.",
        "Provides comprehensive evaluation through ablations on embedding dimensions, entropy tuning, and generalization to new object attributes."
      ],
      "weaknesses": [
        "Computational cost increases with the number of slots due to treating the slot set as a complete graph.",
        "Hyperparameter sensitivity, particularly in embedding dimensions and entropy tuning, may require extensive tuning.",
        "Limited evaluation of model generalization to changes in object attributes beyond the original color schema."
      ],
      "questions": [
        "How does the model's performance scale in environments with a very large number of slots?",
        "What strategies could be employed to reduce hyperparameter sensitivity and improve practical deployment?",
        "Could additional ablations explore the model's generalization to more diverse visual features or object attribute changes?"
      ],
      "overall_score": "6: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0V311Uh8q1",
    "title": "Algorithmic Stability Unleashed: Generalization Bounds with Unbounded Losses",
    "std_review": {
      "summary": "The paper presents a novel concentration inequality for sub-Weibull random variables, extending classical results to handle unbounded losses. It derives a generalization bound for learning algorithms with Lipschitz continuous losses, offering tighter error guarantees for algorithms with heavy-tailed losses. The work is technically innovative, broadly applicable, and impactful, though it may be challenging for readers unfamiliar with sub-Weibull theory and lacks empirical validation.",
      "strengths": [
        "Technical novelty: leverages a reduction to a sum of independent sub-Weibull variables for handling unbounded losses.",
        "Generalization bound: provides tighter error guarantees compared to existing results for heavy-tailed losses.",
        "Broader impact: opens avenues for analysis in online learning, streaming algorithms, and robust statistics."
      ],
      "weaknesses": [
        "Complexity of proofs: may obscure intuition for readers unfamiliar with sub-Weibull theory.",
        "Empirical validation: lacks empirical studies to assess practical relevance.",
        "Verification for specific algorithms: additional verification for other algorithms would strengthen applicability."
      ],
      "questions": [
        "Can the bound be further tightened by relaxing assumptions on the loss function or stability parameter?",
        "What are the empirical performance implications of the derived bounds in real-world settings?",
        "How can the Lipschitz condition be verified for a wider range of algorithms beyond ridge regression?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0V5TVt9bk0",
    "title": "Q-Bench: A Benchmark for General-Purpose Foundation Models on Low-level Vision",
    "std_review": {
      "summary": "The paper presents LLVisionQA, a benchmark for evaluating large multimodal language models on perception, description, and image quality assessment tasks. It compares GPT‑4V against state‑of‑the‑art open‑source models and human benchmarks, highlighting strengths in perception accuracy but noting limitations in metric scope and potential human bias. The review concludes with a strong recommendation to accept the paper.",
      "strengths": [
        "Comprehensive benchmark design covering perception, description, and image quality assessment.",
        "Incorporation of both proprietary and open-source models for a broad evaluation perspective.",
        "Establishment of human baselines to assess practical utility and accuracy."
      ],
      "weaknesses": [
        "Limited evaluation metrics focusing primarily on accuracy.",
        "Potential bias introduced by human benchmarking.",
        "Rapid advancements in LLMs may render some comparisons outdated."
      ],
      "questions": [
        "How can the benchmark address interpretability and efficiency alongside accuracy?",
        "What strategies will be employed to keep the benchmark current with rapid LLM advancements?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0VBsoluxR2",
    "title": "MoFDiff: Coarse-grained Diffusion for Metal-Organic Framework Design",
    "std_review": {
      "summary": "The paper presents MoFDiff, a novel coarse-grained diffusion model for predicting metal-organic framework (MOF) assembly from building blocks. It combines autoencoder embeddings with contrastive learning using ECFP4 fingerprints, achieving improved accuracy over baselines. While innovative, the approach has limitations such as limited orientation exploration, lack of ablation studies, and insufficient technical detail. Overall, the method shows promise but requires further validation and refinement.",
      "strengths": [
        "Innovative integration of autoencoder embeddings and contrastive learning for MOF assembly.",
        "Comprehensive benchmarking using a diverse dataset of known MOF structures.",
        "Clear and detailed description of the MOFid algorithms and ECFP4 fingerprint approach."
      ],
      "weaknesses": [
        "Limited exploration of orientation beyond global rotation and translation.",
        "Absence of ablation studies to assess sensitivity to modeling choices.",
        "Technical detail gaps that could affect reproducibility."
      ],
      "questions": [
        "How does incorporating orientation beyond global rotation and translation impact MOF assembly predictions?",
        "Could ablation studies or comparative analyses provide insights into the sensitivity of the method to different modeling components?",
        "What additional technical details could be provided to enhance the clarity and reproducibility of the proposed approach?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "0VKEJKKLvr",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a graph-based neural network (GCN) for stratifying cancer risk using genomic data, where nodes represent individuals and edges encode SNP similarity via Hamming distance. The GCN model learns node embeddings that capture SNP interactions and outperforms traditional baselines like FCNs, XGBoost, and SVM on simulated and real datasets. While innovative, the approach could benefit from more detailed graph construction explanations, integration of clinical features, and a broader comparison with recent GNN models.",
      "strengths": [
        "Innovative graph construction that captures complex SNP interactions beyond pairwise analysis.",
        "Demonstrated superior accuracy over traditional baselines, highlighting the added value of graph-based learning for genomic data.",
        "Provides clear evaluation with detailed error bars and statistical significance, enhancing credibility."
      ],
      "weaknesses": [
        "Lacks a comprehensive comparison with state-of-the-art GNN models from recent literature.",
        "Graph construction details, especially the role of Hamming distance, could be more detailed for reproducibility.",
        "Does not integrate clinical information, which may limit real-world applicability."
      ],
      "questions": [
        "How does the model's performance compare with recent GNN approaches in the literature?",
        "What are the specific steps for defining nodes and edges, particularly the role of Hamming distance?",
        "Could the model's predictive power be improved by integrating additional clinical features?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0VZP2Dr9KX",
    "title": "Baseline Defenses for Adversarial Attacks Against Aligned Language Models",
    "std_review": {
      "summary": "The paper proposes a perplexity‑based filtering defense against targeted adversarial attacks on large language models, evaluating it on 7‑B models. While the defense shows promise in reducing attack success, its effectiveness is limited to the specific attack studied, and it may not generalize well to other adversarial techniques. The approach also faces challenges in adaptive settings and lacks comprehensive evaluation on larger models, raising questions about its broader applicability.",
      "strengths": [
        "Introduces a novel perplexity filtering approach that effectively reduces the success rate of targeted attacks.",
        "Provides a systematic evaluation framework that includes both static and adaptive attack scenarios.",
        "Grounds the defense in the well‑established metric of perplexity, offering a strong theoretical foundation."
      ],
      "weaknesses": [
        "Effectiveness is primarily validated against the Zou et al. (2023) attack, raising concerns about generalizability.",
        "The windowed perplexity filter may not remain robust in adaptive attack settings.",
        "Impact of the preprocessing paraphrasing step is not thoroughly investigated.",
        "Evaluation focuses only on smaller 7‑B models, leaving open questions for larger models.",
        "Adversarial training is approximated via data augmentation, which may limit true robustness."
      ],
      "questions": [
        "How does the defense perform against a broader range of adversarial attack methods?",
        "What is the defense's robustness in adaptive attack scenarios where suffixes can be dynamically adjusted?",
        "How does the paraphrasing preprocessing step affect the attack's success, and is this interaction fully explored?",
        "What are the implications of the defense on larger, state‑of‑the‑art LLMs beyond the evaluated 7‑B models?",
        "How does the data‑augmentation approach in adversarial training compare to true adversarial training in terms of model robustness?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "0w42S2Gp70",
    "title": "LipSim: A Provably Robust Perceptual Similarity Metric",
    "std_review": {
      "summary": "LipSim introduces a neural‑network‑based perceptual similarity metric designed to be robust against adversarial perturbations, crucial for lip‑reading and facial analysis. It leverages contrastive learning to align lip movements and achieves certified robustness guarantees up to 72/255 perturbations. The metric aligns well with human perception and demonstrates strong robustness on NIGHT and BAPPS datasets, though it may be computationally intensive and requires further evaluation across more datasets.",
      "strengths": [
        "Provides certified robustness guarantees against adversarial attacks.",
        "Aligns perceptual similarity with human perception, enhancing reliability.",
        "Demonstrates strong performance across multiple datasets, indicating robustness."
      ],
      "weaknesses": [
        "Higher computational complexity compared to non‑neural‑network metrics.",
        "Limited evaluation scope; further testing on additional datasets is needed.",
        "Focus on certified robustness may overlook practical computational overhead."
      ],
      "questions": [
        "How does LipSim perform on a broader range of datasets beyond NIGHT and BAPPS?",
        "What is the computational cost of LipSim compared to traditional low‑level metrics?",
        "How does the trade‑off between perceptual similarity and robustness manifest in real‑world applications?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0xLWPdObG1",
    "title": "Subject-specific Deep Neural Networks",
    "std_review": {
      "summary": "The paper introduces a novel approach to integrate deep neural networks with mixed models using a Poisson DNN and Gamma random effects, leveraging the h-likelihood for efficient joint estimation. It demonstrates improved estimation accuracy and computational efficiency over traditional methods, with a strong theoretical foundation. While innovative, the method's complexity and certain assumptions warrant further validation.",
      "strengths": [
        "Innovative integration of DNNs with mixed models.",
        "Theoretical foundation using the h-likelihood for global optimality.",
        "Computational efficiency by avoiding Hessian computation."
      ],
      "weaknesses": [
        "Complexity of the adjustment process described in Theorem 1.",
        "Assumption of Gamma random effects may not be suitable for all data.",
        "Empirical validation could be more comprehensive.",
        "Potential identifiability issues with derived random-slope features."
      ],
      "questions": [
        "Clarify the adjustment process and its impact on model identifiability.",
        "Provide more detailed discussion on the assumptions of Gamma random effects.",
        "Conduct additional sensitivity analyses to strengthen empirical claims.",
        "Address potential identifiability concerns when random-slope features are derived from fixed-effect features."
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0xT87opqKV",
    "title": "",
    "std_review": {
      "summary": "The paper presents ProteinAdapter, a lightweight adapter architecture for fine-tuning large protein language models efficiently. It addresses long sequence lengths using a pyramid architecture and adapter modules that can be inserted without modifying the original model. The approach shows comparable performance to full fine-tuning while significantly reducing computational costs and memory usage, outperforming existing methods on multiple protein tasks. However, the adapter's design is tailored to protein models, limiting its generalizability, and lacks comprehensive ablation studies and quantitative efficiency analysis.",
      "strengths": [
        "Introduces a novel adapter design tailored for protein sequences, addressing the challenge of long sequence lengths.",
        "Demonstrates substantial speedup and reduced memory footprint compared to full model fine-tuning, making it practical for resource-constrained environments.",
        "Shows comparable or better performance than existing state-of-the-art methods, highlighting its effectiveness."
      ],
      "weaknesses": [
        "The adapter architecture's design is heavily optimized for protein models, which may limit its applicability to other domains without further adaptation.",
        "Lacks detailed ablation studies on the integration mechanism and the impact of different adapter configurations.",
        "Does not include comparisons with other relevant baselines like ESM‑GearNet.",
        "Efficiency gains are qualitatively discussed but not quantitatively analyzed."
      ],
      "questions": [
        "Could the adapter architecture be adapted for other domains beyond protein models?",
        "What is the quantitative analysis of efficiency gains compared to full model fine-tuning?",
        "How does the Intra‑Level Self‑Attention mechanism compare to a unified approach in terms of information flow?",
        "Could additional ablation studies provide deeper insights into the adapter's effectiveness?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "0y0yOpI4wx",
    "title": "General-Purpose In-Context Learning",
    "std_review": {
      "summary": "The paper introduces a novel framework for General-Purpose In-Context Learning (GPICL) in large language models, defining GPICL as the ability to perform a wide range of tasks without task-specific fine-tuning. It proposes a methodology that leverages in-context learning to enable the model to transition between memorization, task identification, and general learning-to-learn states. Empirical experiments on diverse datasets demonstrate significant improvements over standard baselines, highlighting the importance of state/memory size. The paper is well-structured, with clear definitions, innovative methodology, and thorough empirical validation, though it has some limitations in dataset scope and theoretical analysis.",
      "strengths": [
        "Clear definition of GPICL",
        "Innovative meta-training methodology",
        "Empirical validation with diverse datasets",
        "Insightful analysis of state/memory size",
        "Practical interventions and actionable insights"
      ],
      "weaknesses": [
        "Limited scope of datasets",
        "Complexity of methodology with new hyperparameters",
        "Lack of detailed theoretical analysis",
        "Potential for overfitting",
        "Code availability without detailed documentation"
      ],
      "questions": [
        "How does the proposed methodology scale to larger model sizes or more complex tasks?",
        "What is the theoretical justification for the observed improvements in GPICL?",
        "How robust are the results to variations in dataset distribution or task complexity?",
        "Can the proposed interventions be generalized to other types of models beyond transformers?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0Y26tFG3WF",
    "title": "Inducing Precision in Lagrangian Neural Networks: Proof of concept application on Chaotic systems",
    "std_review": {
      "summary": "The paper introduces a precision‑aware modification to Lagrangian Neural Networks (LNNs) to better handle chaotic systems, where numerical precision is critical. The authors propose a regularization method that conditions the network on each significant bit of the output, addressing the challenge of precision loss in chaotic dynamics. Experiments on the double pendulum and Hénon–Heiles systems demonstrate improved performance compared to standard LNNs. The approach offers a novel way to integrate precision considerations into neural network training for dynamical systems.",
      "strengths": [
        "Innovative Approach: Introduces a novel way to incorporate precision into neural network training for dynamical systems, addressing a significant challenge in modeling chaotic behavior.",
        "Practical Relevance: The proposed method is directly applicable to real-world problems involving chaotic systems, such as physics simulations and control systems.",
        "Clear Experimental Evaluation: Provides comprehensive experiments on well-known chaotic systems, demonstrating the effectiveness of the precision‑aware LNN."
      ],
      "weaknesses": [
        "Complexity of Implementation: The precision‑aware regularization may add complexity to the implementation and training process, potentially requiring more computational resources.",
        "Limited Scope: The evaluation is limited to two specific chaotic systems, which may not fully capture the robustness and generalizability of the approach across a wide range of problems.",
        "Lack of Detailed Analysis: The paper could benefit from a more detailed analysis of how the regularization term interacts with the original loss function and its impact on convergence."
      ],
      "questions": [
        "How does the proposed regularization method scale to larger and more complex chaotic systems?",
        "What is the impact of the regularization strength on the model's ability to generalize to unseen data?",
        "Could the approach be extended to other types of neural networks beyond Lagrangian Neural Networks?"
      ],
      "overall_score": "Accept",
      "confidence": "High"
    }
  },
  {
    "paper_id": "0ypXhS83Lh",
    "title": "Robust Reinforcement Learning with Structured Adversarial Ensemble",
    "std_review": {
      "summary": "The paper introduces an adversarial ensemble training method for reinforcement learning that aims to mitigate over‑optimism and over‑pessimism by training against the worst‑k adversaries and averaging their losses. Empirical results on MuJoCo environments show improved sample efficiency and robustness compared to baselines like RARL, ADR, and domain randomization. Theoretical analysis provides bounds on approximation error, supporting the method's effectiveness. While computationally expensive and requiring careful tuning of the adversary set size, the approach offers a novel and robust solution to inner‑optimization problems.",
      "strengths": [
        "Novel adversarial ensemble approach that combines multiple adversary samples for robust training.",
        "Strong theoretical backing with formal guarantees linking the ensemble to improved robustness.",
        "Empirical validation demonstrating clear performance gains across multiple benchmark tasks."
      ],
      "weaknesses": [
        "Increased computational cost due to training against multiple adversaries.",
        "Limited scope of empirical comparisons; broader evaluation across tasks would strengthen claims.",
        "Theoretical guarantees assume known adversary sets; robustness to novel attacks is not fully explored.",
        "Parameter sensitivity to the number of adversaries (k) without systematic analysis."
      ],
      "questions": [
        "How does the method perform under novel, unseen attack scenarios beyond the ones used in the experiments?",
        "What is the systematic analysis of the impact of the adversary set size (k) on the trade‑off between robustness and computational cost?",
        "Can the approach be extended to continuous‑action spaces or high‑dimensional environments without significant modifications?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0Z6lN4GYrO",
    "title": "",
    "std_review": {
      "summary": "The paper introduces S4G, a graph neural network that effectively balances long-range modeling with graph inductive bias through hierarchical neighborhood aggregation. It outperforms existing models on long-range graph benchmarks while maintaining computational efficiency. The theoretical analysis provides strong support for the model's design, though some practical concerns remain.",
      "strengths": [
        "Balances long-range modeling and inductive bias effectively.",
        "Hierarchical neighborhood representation enhances expressivity without losing efficiency.",
        "Strong performance on long-range graph benchmarks."
      ],
      "weaknesses": [
        "Pre-processing for hierarchical neighborhoods adds computational overhead.",
        "Theoretical analysis relies on assumptions about bounded derivatives.",
        "Lacks detailed comparison with the latest advancements."
      ],
      "questions": [
        "How does the model perform on extremely large graphs with billions of nodes?",
        "What is the impact of the bounded derivative assumption on practical applications?",
        "How does S4G compare to recent models like those by Di Giovanni et al. (2023)?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0zIKlb0prF",
    "title": "MPPN: Multi-Resolution Periodic Pattern Network For Long-Term Time Series Forecasting",
    "std_review": {
      "summary": "The paper introduces MPPN, a novel architecture for extracting multi-resolution and periodic patterns from time series data. It leverages a channel adaptive module to enhance pattern capture and shows strong performance on noisy and irregular datasets. The model is scalable and interpretable, though its long-term forecasting capabilities are limited. Overall, the paper makes a valuable contribution with promising results.",
      "strengths": [
        "Effective pattern extraction at multiple resolutions.",
        "Adaptive channel modulation improves performance on diverse data.",
        "Robustness to noise and scalability to large datasets."
      ],
      "weaknesses": [
        "Performance may be sensitive to hyperparameter settings.",
        "Limited long-term forecasting capabilities.",
        "Potential need for domain-specific adaptations."
      ],
      "questions": [
        "How can the model's long-term forecasting be improved?",
        "What are the specific domain adaptations needed for optimal performance?",
        "How does the model handle extreme noise or outliers in time series data?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "0ZUKLCxwBo",
    "title": "",
    "std_review": {
      "summary": "The paper introduces an analytic solution for weights in a two-layer MLP trained on periodic data, linking periodic feature structures to grokking behavior. It derives trigonometric solutions that capture the sudden jump in generalization performance and introduces phase variables to distinguish memorization from generalization phases. While the approach provides deep insights and practical implications, its reliance on a simple MLP limits generalizability to more complex architectures, and empirical validation across diverse settings is lacking.",
      "strengths": [
        "Provides a novel analytic solution that offers deep insights into grokking behavior.",
        "Uses trigonometric functions to intuitively model periodic feature structures.",
        "Introduces phase variables that clarify the transition from memorization to generalization."
      ],
      "weaknesses": [
        "Findings may not generalize to more complex architectures like Transformers.",
        "Analytic solution is derived under specific assumptions about data and model.",
        "Lacks empirical validation across a wide range of datasets and configurations."
      ],
      "questions": [
        "How can the analytic solution be extended to more complex architectures?",
        "What empirical evidence supports the generalizability of the findings?",
        "How do phase variables influence learning dynamics in non‑periodic data scenarios?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "10BTKkFfhl",
    "title": "Efficient Backdoor Mitigation in Federated Learning with Contrastive Loss",
    "std_review": {
      "summary": "The paper presents a novel contrastive loss function for efficient backdoor detection in federated learning, leveraging a clean model to guide trigger image generation. It shows improved efficiency and effectiveness over existing methods, though its reliance on a clean model and limited empirical validation are concerns.",
      "strengths": [
        "Introduces a novel contrastive loss function tailored for backdoor detection in federated learning.",
        "Utilizes a clean model to enhance detection accuracy and provides a clear theoretical framework.",
        "Demonstrates improved efficiency and effectiveness compared to existing techniques."
      ],
      "weaknesses": [
        "Relies on a clean model which may not always be available in real-world scenarios.",
        "Performance may vary depending on the specific federated learning setup.",
        "Lacks extensive empirical validation across a wide range of datasets and models."
      ],
      "questions": [
        "How does the method perform when a clean model is not available?",
        "What is the impact of the specific contrastive loss function on the detection accuracy?",
        "How robust is the method across different federated learning scenarios and datasets?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "10eQ4Cfh8p",
    "title": "Simultaneous Generation and Improvement: A Unified RL Paradigm for FJSP Optimization",
    "std_review": {
      "raw_text": "{\n  \"summary\": \"The paper proposes a novel reinforcement learning framework that simultaneously generates and improves solutions using a Dueling DQN as an improvement network. It shows improved convergence and solution quality on grid-based instances compared to baseline methods, but lacks scalability evaluation and detailed training comparisons. The innovative approach is promising but requires addressing scalability and component contribution questions.\",\n  \"strengths\": [\n    \"Introduces a unique simultaneous generation and improvement paradigm using Dueling DQN.\",\n    \"Demonstrates significant improvements in convergence speed and solution quality.\",\n    \"Provides a clear and reproducible experimental setup.\"\n  ],\n  \"weaknesses\": [\n    \"Uses Dueling DQN instead of more advanced actor-critic methods, potentially limiting scalability.\",\n    \"Does not compare the generator alone versus the combined setup.\",\n    \"Does not evaluate performance on larger instances, raising concerns about practical scalability.\"\n  ],\n  \"questions\": [\n    \"Why was Dueling DQN chosen over more advanced actor-critic methods like PPO?\",\n    \"How does the generator perform when trained alone versus the combined generator-improvement setup?\",\n    \"What is the rationale behind selecting the number of improvement iterations \\(n_t\\)?\",\n    \"How does the method scale to larger instances, such as the 100 × 60 instances studied in [29]?\"\n  ],\n  \"overall_score\": \"6: borderline\",\n  \"confidence\": \"3: medium\"\n}",
      "parse_error": true
    }
  },
  {
    "paper_id": "10fsmnw6aD",
    "title": "How Out-of-Distribution Important is",
    "std_review": {
      "summary": "The paper introduces a novel Continual Learning framework that integrates Out-of-Distribution (OOD) detection to address catastrophic forgetting and data drift. It proposes a dynamic model architecture that adapts to new tasks without forgetting previous knowledge while monitoring and mitigating OOD data impact. Experiments show significant improvements over existing methods on several benchmarks, highlighting its potential for real-world applications. The reviewer finds the approach innovative and effective, though implementation and evaluation considerations are noted.",
      "strengths": [
        "Innovative integration of continual learning with OOD detection.",
        "Dynamic model architecture that adapts to new tasks without forgetting.",
        "Strong empirical validation demonstrating superior performance."
      ],
      "weaknesses": [
        "Increased complexity and computational overhead due to three separate models.",
        "Potential training time and resource requirements.",
        "Lack of detailed analysis of trade-offs and hyperparameter impact."
      ],
      "questions": [
        "How does the method scale to very large datasets or high-dimensional data?",
        "What are the long-term stability and generalization properties of the dynamic model architecture?",
        "How robust is the OOD detection component to adversarial or unseen distribution shifts?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "11oqo92x2Z",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a novel NAS-based approach for solar-farm segmentation, integrating high-performing architectures into a modified AutoDeepLab model. It evaluates the models on a newly curated 'solis-dataset' and demonstrates competitive performance, particularly in terms of mIoU. While the study shows promise, it is limited by reliance on a single dataset and potential overfitting, and lacks detailed hyper-parameter optimization and additional dataset evaluations.",
      "strengths": [
        "Innovative NAS integration for solar-farm segmentation.",
        "Customized model adaptation with AutoDeepLab for domain-specific needs.",
        "Comprehensive evaluation on a held-out test set with strong performance metrics."
      ],
      "weaknesses": [
        "Reliance on a single dataset may limit generalizability.",
        "Potential overfitting not fully addressed.",
        "Lack of evaluation on additional datasets or diverse conditions."
      ],
      "questions": [
        "How does the model perform on datasets with different environmental conditions?",
        "What specific NAS search space components contributed most to improved segmentation?",
        "Could you provide more details on the hyper-parameter optimization process?"
      ],
      "overall_score": "6: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "11WAKGH8uv",
    "title": "FedAIoT: A Federated Learning Benchmark for Artificial Intelligence of Things",
    "std_review": {
      "summary": "The paper presents a novel similarity matrix method for estimating noisy labels in machine learning, particularly useful for speech recognition. It demonstrates improved performance on benchmark datasets, showing the method's effectiveness. While the approach is innovative, it requires recalculating the similarity matrix when the learning algorithm changes, and the conversion to the frequency domain may lose important information. Overall, the paper is recommended for acceptance.",
      "strengths": [
        "Introduces a novel similarity matrix method for estimating noisy labels, applicable to various centralized learning algorithms.",
        "Provides a practical solution to a common problem in machine learning, especially in speech recognition tasks.",
        "Demonstrates improved performance on benchmark datasets, showcasing the effectiveness of the proposed approach."
      ],
      "weaknesses": [
        "The similarity matrix may need to be recalculated when the learning algorithm changes, which could be computationally expensive.",
        "The conversion of raw audio to the frequency domain may lead to loss of important information.",
        "The purpose of Section 4 is unclear regarding the intent to enable correct ranking of optimizers."
      ],
      "questions": [
        "How can the computational expense of recalculating the similarity matrix be mitigated when the learning algorithm changes?",
        "Could preserving the raw audio format in the frequency domain analysis help retain more original data?",
        "Is the primary goal of Section 4 to enable correct ranking of optimizers, and if not, what other aspects of model performance should be considered?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "12Acp6ZcRa",
    "title": "Evaluating the Robustness of Text-to-image Diffusion Models against Real-world Attacks",
    "std_review": {
      "summary": "The paper investigates the robustness of text-to-image diffusion models against adversarial perturbations, introducing a suite of perturbations (typos, glyphs, phonetics) and evaluating the models' ability to generate semantically consistent images. It reveals significant vulnerabilities, especially with maximum mean discrepancy and KL divergence as attack objectives, highlighting potential real-world risks. The study is well-structured, with a comprehensive evaluation framework and clear success metrics, though it could benefit from broader baseline comparisons and more detailed human evaluation methods.",
      "strengths": [
        "Comprehensive Evaluation Framework",
        "Diverse Perturbation Set",
        "Clear Success Metrics",
        "Real-World Implications"
      ],
      "weaknesses": [
        "Limited Baseline Models",
        "Scope of Human Evaluation",
        "Potential for Further Attacks",
        "Scalability of Results"
      ],
      "questions": [
        "How do the identified vulnerabilities scale with other types of perturbations?",
        "What are the implications of the attack objectives on the robustness of the models?",
        "Could the evaluation framework be extended to include more diverse baseline models?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "12zKEh2APn",
    "title": "PROSE: Predicting Operators and Symbolic Expressions using Multimodal Transformers",
    "std_review": {
      "summary": "PROSE introduces a dual-decoder transformer model for predicting trajectories and reconstructing symbolic expressions in dynamical systems. It shows strong performance on extrapolation and symbolic regression tasks across various ODEs, but lacks evaluation on out-of-distribution parameters and detailed training specifics. The model's architecture is innovative, yet its robustness and generalization remain underexplored.",
      "strengths": [
        "Innovative dual-decoder architecture enabling simultaneous temporal prediction and symbolic reconstruction.",
        "Demonstrates robust extrapolation beyond training data ranges.",
        "Achieves high accuracy in symbolic regression tasks."
      ],
      "weaknesses": [
        "Limited evaluation on out-of-distribution parameters raises concerns about generalization.",
        "Lack of detailed training procedure details affecting reproducibility.",
        "Absence of ablation studies to assess component contributions.",
        "Potential overfitting due to large transformer for feature fusion."
      ],
      "questions": [
        "How does the model perform on out-of-distribution parameters beyond the training range?",
        "What specific training loss functions and hyperparameters were used?",
        "Could ablation studies be conducted to isolate the impact of individual components?",
        "What evaluation metrics beyond relative L2 error are recommended for a comprehensive assessment?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "13D1zn0mpd",
    "title": "Effective and Parameter-Efficient Reusing Fine-Tuned Models",
    "std_review": {
      "summary": "The paper introduces PERU-LoRA, a method for merging multiple task-specific fine-tuned models into a single multi-task model using singular value decomposition (SVD) to approximate the product of the transpose of the parameter matrices. The authors demonstrate that their approach reduces parameter count while maintaining performance, comparing it favorably with existing model merging techniques. However, the novelty of the method is constrained as it primarily combines existing techniques, and the performance gain is marginal. The paper is recommended for weak acceptance.",
      "strengths": [
        "Introduces a novel approach to model merging using SVD, which is a well-established technique in linear algebra.",
        "Demonstrates the effectiveness of the proposed method in reducing parameter count while maintaining performance.",
        "Provides a clear comparison with existing model merging methods, highlighting the advantages of PERU-LoRA."
      ],
      "weaknesses": [
        "The novelty of the proposed method is constrained, as it primarily combines existing techniques without introducing fundamentally new concepts.",
        "The performance gain from the proposed method is marginal, with only a slight reduction in parameter count compared to existing methods.",
        "The comparison with LoRA is not as clear-cut, as LoRA is primarily a fine-tuning technique, while PERU-LoRA focuses on merging existing fine-tuned models."
      ],
      "questions": [
        "Can the authors provide insights into why singular value decomposition (SVD) was chosen over direct rank reduction of matrices At and Bt?",
        "How does PERU-LoRA compare with other model merging methods like Fisher-Merging, RegMean, and TIES-Merging?",
        "What are the specific advantages of PERU-LoRA over existing merging methods in terms of parameter efficiency and performance?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "14rn7HpKVk",
    "title": "SALMONN: Towards Generic Hearing Abilities for Large Language Models",
    "std_review": {
      "summary": "The paper introduces Q-Former, a two-stage instruction tuning method for QA using monotonic alignment, achieving competitive results on some benchmarks but underperforming on others. While innovative, the complexity and limited analysis of its performance on challenging tasks raise concerns about its generalizability and acceptance.",
      "strengths": [
        "Introduces monotonic alignment, a novel technique for ensuring consistent output generation.",
        "Demonstrates broad applicability across multiple QA domains.",
        "Provides a clear and comprehensive evaluation framework."
      ],
      "weaknesses": [
        "The two-stage tuning process is computationally intensive and complex to implement.",
        "Performance variability on tasks like PR and OSR with limited analysis.",
        "Lack of detailed data generation and verification processes may affect reproducibility.",
        "Limited generalization to open-ended or ambiguous tasks."
      ],
      "questions": [
        "What is the detailed process for generating prompted QA samples and verifying their correctness?",
        "How can the performance drops on tasks like PR and OSR be better understood and mitigated?",
        "What additional analyses could be performed to assess the method's generalizability?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "17BA0Tl2Id",
    "title": "Meta-Referential Games to Learn Compositional Learning Behaviours",
    "std_review": {
      "summary": "The paper introduces a novel benchmark and evaluation methodology for studying compositional learning behaviors (CLBs) in AI systems. The authors propose tasks that assess how AI agents compose learned concepts to solve novel problems, evaluating the benchmark across various AI models. The results highlight the importance of CLBs for developing flexible and adaptable AI systems, though the novelty and practical significance of the benchmark are somewhat limited.",
      "strengths": [
        "Introduces a novel benchmark focused on compositional learning behaviors.",
        "Provides a clear and well-defined evaluation methodology.",
        "Uses diverse tasks to comprehensively assess CLBs."
      ],
      "weaknesses": [
        "The specific set of tasks may limit the benchmark's scope.",
        "The evaluation methodology could benefit from more detailed examples.",
        "The practical significance is limited to a specific type of AI model."
      ],
      "questions": [
        "How can the benchmark be expanded to cover a wider range of compositional learning scenarios?",
        "What additional examples or explanations can improve the clarity of the evaluation methodology?",
        "How can the generalizability of the results to other AI systems be demonstrated?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "17pVDnpwwl",
    "title": "Feature Learning in Infinite Depth Neural Networks",
    "std_review": {
      "summary": "The paper introduces Depth-μP, a novel parametrization that maximizes feature diversity at each depth, enabling effective hyperparameter transfer across network depths. The authors provide theoretical justification and empirical evidence supporting the importance of feature diversity for stable training dynamics and performance. While the work is well‑structured and makes significant contributions, it could benefit from more rigorous proofs and a broader exploration of feature diversity metrics.",
      "strengths": [
        "Introduces a novel Depth-μP parametrization emphasizing feature diversity.",
        "Provides a clear theoretical justification for hyperparameter transfer under the proposed limit.",
        "Employs mean-centering of residual blocks to enhance gradient flow and feature diversity."
      ],
      "weaknesses": [
        "Theoretical justification for hyperparameter transfer could be strengthened with more rigorous proofs.",
        "Empirical validation may not fully address all edge cases or network architectures.",
        "Assumes a specific form of feature diversity without exploring alternative metrics.",
        "Discussion of the infinite depth limit lacks detailed analysis on training dynamics and convergence."
      ],
      "questions": [
        "Could the theoretical justification be further supported by additional mathematical proofs or simulations?",
        "How does the proposed approach generalize to different network architectures beyond those tested?",
        "What alternative metrics or methods could be used to quantify feature diversity more comprehensively?",
        "What are the detailed implications of the infinite depth limit on training dynamics and convergence?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "17ZbByq95E",
    "title": "Memory-Efficient Backpropagation through Large Linear Layers",
    "std_review": {
      "summary": "The paper introduces Randomized Matrix Multiplication (RMM) to compress activations in large linear layers of GNNs and transformers, using random projections to estimate gradients. It shows competitive performance and potential stability improvements, but its novelty is limited and its applicability to other architectures is underexplored. Overall, the work is innovative yet requires further validation.",
      "strengths": [
        "Introduces a novel gradient estimation technique using random projections.",
        "Demonstrates significant memory savings and potential stability improvements.",
        "Provides thorough empirical evaluations across various benchmarks."
      ],
      "weaknesses": [
        "The core idea of random projection for gradient estimation is not entirely novel.",
        "Averaging multiple samples introduces additional computational overhead.",
        "Performance may vary significantly with network depth.",
        "Limited exploration of applicability to other architectures like convolutional networks."
      ],
      "questions": [
        "How does the choice of sample size S impact performance across different network depths?",
        "What are the theoretical guarantees for convergence when using RMM in very deep networks?",
        "How does RMM compare to activation compression methods in terms of training stability?",
        "What is the potential impact of RMM on convolutional architectures and vision tasks?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "1Akd36hG9z",
    "title": "Enhancing Offline Reinforcement Learning with an Optimal Supported Dataset",
    "std_review": {
      "summary": "The paper introduces OSD-RL, an offline RL algorithm that improves upon OptiDICE by adding a strong-convexity regularization term and a single-transition estimator. It achieves competitive performance on D4RL benchmarks, outperforming several state-of-the-art methods. The theoretical foundation and practical estimator are highlighted as key contributions, though concerns about estimator bias and sample complexity remain.",
      "strengths": [
        "Improved performance on D4RL benchmarks compared to several state-of-the-art offline RL methods.",
        "Strong theoretical foundation provided by the strong-convexity regularization term, addressing bias and variance in non-deterministic environments.",
        "Introduces a computationally efficient and robust single-transition estimator suitable for complex domains."
      ],
      "weaknesses": [
        "The single-transition estimator introduces bias in complex, non-deterministic domains, potentially limiting applicability.",
        "Sample complexity of O(ϵ⁻⁴) is theoretically appealing but may have significant practical trade-offs in computational resources and data efficiency.",
        "Lack of detailed implementation guidelines or code releases could hinder reproducibility and adoption.",
        "Comparison with a broader range of state-of-the-art methods, including both online and other offline RL algorithms, would strengthen the contextualization of performance gains."
      ],
      "questions": [
        "How does the algorithm perform in highly stochastic environments beyond the D4RL benchmarks?",
        "What are the practical trade-offs of the sample complexity O(ϵ⁻⁴) in very large or complex domains?",
        "Could the inclusion of more detailed implementation guidelines or code releases improve reproducibility?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1armpjgh8L",
    "title": "Adaptive Hierarchical Certification for Segmentation using Randomized Smoothing",
    "std_review": {
      "summary": "The paper presents AdaptCertify, a method that enhances semantic segmentation model certification through a hierarchical class structure and adaptive sampling. It shows significant improvements over the baseline SegCertify method on Cityscapes and ACDC datasets, particularly in certified accuracy and class-specific performance. The approach balances class granularity and certified accuracy using a custom evaluation metric, and while it demonstrates strong performance, its evaluation is limited to specific datasets and lacks visual examples and comparisons with other state-of-the-art methods.",
      "strengths": [
        "Hierarchical class structure allows nuanced and granular certification.",
        "Adaptive sampling strategy improves robustness and efficiency.",
        "Custom evaluation metric balances class granularity and certified accuracy."
      ],
      "weaknesses": [
        "Limited dataset evaluation may not fully capture method's performance.",
        "Lack of visual examples hinders understanding of practical implications.",
        "No comparison with additional baselines limits assessment of relative performance."
      ],
      "questions": [
        "How does AdaptCertify perform on a broader range of datasets beyond Cityscapes and ACDC?",
        "What are the practical implications of the certification results, and could visual examples aid in understanding?",
        "How does AdaptCertify compare to other state-of-the-art methods in terms of certification robustness and accuracy?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1AXvGjfF0V",
    "title": "Evaluating Hallucinations in Chinese Large Language Models",
    "std_review": {
      "summary": "The paper introduces HalluQA, a benchmark for evaluating hallucinations in Chinese large language models, addressing a gap in current methods by categorizing hallucinations into imitative falsehoods and factual errors. It uses GPT-4 as a reference and finds varying hallucination rates among Chinese LLMs, with GPT-4 performing best. While highlighting strengths such as a comprehensive benchmark and clear categorization, the review notes weaknesses like reliance on GPT-4 and limited scope to Chinese LLMs.",
      "strengths": [
        "Comprehensive benchmark creation for Chinese LLMs",
        "Clear categorization of hallucinations",
        "Unique question patterns distinct from existing benchmarks"
      ],
      "weaknesses": [
        "Dependence on GPT-4 for evaluation",
        "Limited scope to Chinese LLMs",
        "Potential for overfitting to the HalluQA dataset"
      ],
      "questions": [
        "How can the benchmark be extended to evaluate hallucinations in other languages?",
        "What alternative evaluation methods could mitigate the reliance on GPT-4?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1bAUywYJTU",
    "title": "DreamTime: An Improved Optimization Strategy for Diffusion-Guided 3D Generation",
    "std_review": {
      "summary": "The paper introduces a Gaussian-weighted timestep annealing schedule for 3D representation learning, enhancing both geometric and textural fidelity in models like NeRF. It outperforms existing methods in perceptual quality metrics such as FID and Inception Score, and shows broad applicability to complex 3D representations. While promising, the method's general applicability and computational cost need further validation.",
      "strengths": [
        "Introduces a novel Gaussian-weighted timestep annealing schedule that improves perceptual quality.",
        "Demonstrates broad applicability across complex 3D representations beyond NeRF.",
        "Provides a theoretically justified approach to optimizing the annealing process."
      ],
      "weaknesses": [
        "Lacks comprehensive quantitative comparisons across diverse prompts and datasets.",
        "Does not quantify the computational cost compared to baseline methods.",
        "Theoretical analysis of the Gaussian weight function is limited."
      ],
      "questions": [
        "How does the method perform on a wider range of prompts and 3D datasets?",
        "What is the computational cost of the proposed method relative to baseline approaches?",
        "Can the theoretical impact of the Gaussian weight function be further quantified?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1bbPQShCT2",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a novel reinforcement learning approach for robotic manipulation that integrates a learned policy with symbolic planning. It demonstrates improved sample efficiency and robustness in a 2‑D simulation environment compared to a purely learned baseline. While the results are promising, the 2‑D setting may limit real‑world applicability, and the hyper‑parameters for the combined strategy are not fully tuned. Overall, the work is well‑structured and provides valuable insights into leveraging symbolic reasoning in RL.",
      "strengths": [
        "Integrates symbolic planning with RL to leverage prior knowledge in robotic tasks.",
        "Uses a 2‑D environment that facilitates clear analysis and comparison.",
        "Conducts thorough ablation studies to highlight the contribution of each component.",
        "Provides a well‑documented experimental setup with reproducible metrics."
      ],
      "weaknesses": [
        "The 2‑D environment may not fully capture real‑world 3‑D manipulation complexities.",
        "Hyper‑parameters for the combined strategy baseline are not exhaustively tuned.",
        "Lacks detailed analysis of trade‑offs between sample efficiency and planning accuracy.",
        "Training regime (fewer than 100 k steps) raises questions about scalability."
      ],
      "questions": [
        "How does the approach generalize to more complex 3‑D manipulation tasks?",
        "What are the detailed hyper‑parameters used for the RL training of the combined strategy baseline?",
        "Could a detailed analysis of the trade‑offs between sample efficiency and planning accuracy be provided?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1BmveEMNbG",
    "title": "Rethinking Complex Queries on Knowledge Graphs with Neural Link Predictors",
    "std_review": {
      "summary": "The paper introduces FIT, a novel fuzzy logic-based approach for embedding complex queries in knowledge graphs, extending beyond tree structures to handle cycles, multigraphs, and existential leaves. FIT leverages fuzzy inference to improve query expressiveness and performance, particularly for EFO₁ queries, while providing strong theoretical guarantees of completeness and soundness. The authors demonstrate significant empirical improvements over existing methods, though implementation complexity and scalability for very large graphs remain concerns.",
      "strengths": [
        "Enhanced query expressiveness by handling non-tree structures",
        "Fuzzy logic integration provides nuanced matching and uncertainty handling",
        "Strong theoretical foundations with completeness and soundness guarantees",
        "Empirical validation showing superior performance on large-scale datasets"
      ],
      "weaknesses": [
        "Increased implementation complexity due to fuzzy logic and complex graph handling",
        "Scalability concerns not fully addressed for extremely large knowledge graphs",
        "Limited comparison with the latest advancements in query embedding"
      ],
      "questions": [
        "How does FIT scale to extremely large knowledge graphs in practice?",
        "What is the runtime complexity of FIT compared to other embedding methods for large graphs?",
        "How does FIT compare to recent state-of-the-art methods beyond ConE and BetaE?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1BuWv9poWz",
    "title": "",
    "std_review": {
      "summary": "The paper presents Gradient Normalization and Scaling (GNS) and High Frequency Adaptation (HFA) as a novel method to generate more transferable adversarial examples for deep neural networks. By attenuating mild gradients and emphasizing high-frequency components, the authors achieve higher evasion success rates across various models. The approach is theoretically motivated, empirically validated, and practical to integrate into existing pipelines. Despite some limitations, the paper is recommended for acceptance.",
      "strengths": [
        "Innovative combination of GNS and HFA to improve adversarial example transferability.",
        "Clear theoretical motivation for attenuating mild gradients and leveraging high-frequency components.",
        "Empirical validation across multiple models and attack methods demonstrates effectiveness.",
        "Practical integration into adversarial training pipelines with straightforward impact."
      ],
      "weaknesses": [
        "Lack of detailed theoretical analysis to fully support the proposed methods.",
        "Limited generalization to a broader range of architectures and tasks.",
        "Potential for overfitting due to focus on high-frequency components.",
        "Increased computational complexity from frequency-domain exploration."
      ],
      "questions": [
        "What is the precise threshold used to distinguish between strong and mild gradients?",
        "How does the method generalize to non-Transformer architectures?",
        "What strategies are employed to prevent overfitting when focusing on high-frequency components?",
        "How does the computational cost of HFA compare to existing adversarial generation techniques?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1CK45cqkEh",
    "title": "Unsupervised Order Learning",
    "std_review": {
      "summary": "The paper introduces an ordered k‑means algorithm that learns an order embedding to define 'previous' and 'next' clusters in high‑dimensional spaces, using a single tunable parameter α. It demonstrates effectiveness on MORPH II and RetinaMNIST datasets, advancing unsupervised order learning for ordinal classification. While innovative, the method's limited dataset scope, reliance on a single parameter, and lack of comprehensive comparative analysis are notable concerns.",
      "strengths": [
        "Innovative handling of high-dimensional order by learning an order embedding.",
        "Parameter efficiency with a single tunable parameter α.",
        "Clear ablation studies on MORPH II and RetinaMNIST datasets."
      ],
      "weaknesses": [
        "Limited dataset scope may not generalize across diverse applications.",
        "Sensitivity to the single parameter α could lead to suboptimal clustering.",
        "Lack of comparative analysis with a broader range of traditional clustering algorithms."
      ],
      "questions": [
        "How does the method perform on a wider variety of datasets beyond MORPH II and RetinaMNIST?",
        "What strategies can be employed to mitigate the sensitivity of α to dataset characteristics?",
        "How does the proposed method compare to clustering algorithms specifically designed for ordinal data?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "1CPta0bfN2",
    "title": "Adaptive Retrieval and Scalable Indexing for \\(k\\)-NN Search with Cross-Encoders",
    "std_review": {
      "summary": "The paper presents AXN, an adaptive retrieval framework that dynamically adjusts the number of retrieved items per query using a dual-encoder model to improve recall efficiency. It shows competitive or superior recall on several benchmarks while maintaining comparable inference costs. The innovative adaptive mechanism is well-motivated theoretically and empirically validated across multiple datasets, suggesting scalability. However, the paper lacks clear comparisons of inference time, detailed discussion of the dual-encoder choice, comprehensive analysis of scaling behavior, and guidance on parameter tuning.",
      "strengths": [
        "Introduces a novel adaptive retrieval mechanism that balances recall and computational efficiency.",
        "Provides strong theoretical motivation for the adaptive approach.",
        "Demonstrates empirical superiority over traditional methods on multiple benchmarks."
      ],
      "weaknesses": [
        "Does not clearly compare inference time with DE+kNN approaches.",
        "Ambiguity around the choice and relevance of the dual-encoder.",
        "Scaling properties are only hinted at without thorough analysis.",
        "Lacks guidance on optimal parameter tuning (CE call budget distribution, λ, number of rounds)."
      ],
      "questions": [
        "Can you provide a clear comparison of inference time between AXN and DE+kNN approaches?",
        "What are the specific reasons for choosing the dual-encoder, and how does it compare to state-of-the-art encoders?",
        "How does AXN scale with larger datasets, and what is the impact on recall and inference cost?",
        "What is the recommended approach for distributing the CE call budget and choosing λ and R for new datasets?"
      ],
      "overall_score": "5: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "1d2cLKeNgY",
    "title": "",
    "std_review": {
      "summary": "The paper presents a novel pipeline that integrates 3D mesh reconstruction, domain adaptation, and LiDAR simulation to bridge domain gaps in autonomous driving. It effectively reduces the domain gap, as shown by improvements in mesh fidelity and domain adaptation metrics on benchmark datasets. The method is scalable and robust to sensor variations, making it suitable for real-world applications. However, computational requirements and limited evaluation scope are noted as potential limitations.",
      "strengths": [
        "Integrates 3D mesh reconstruction, domain adaptation, and LiDAR simulation into a cohesive pipeline.",
        "Demonstrates significant improvements in mesh fidelity and domain adaptation effectiveness.",
        "Shows scalability and robustness to sensor variations, making it practical for real-world use."
      ],
      "weaknesses": [
        "High computational requirements may limit applicability in resource-constrained environments.",
        "Effectiveness evaluated on a limited set of benchmark datasets.",
        "Relies on high-quality point cloud data, which may be a limitation in noisy or sparse environments.",
        "Scalability with respect to LiDAR sensors and target domain complexity is not thoroughly explored."
      ],
      "questions": [
        "How does the method perform on datasets with highly variable sensor configurations and limited labeled data?",
        "What is the computational cost of the pipeline, and how can it be optimized for real-time applications?",
        "How does the method handle scenarios with highly sparse or noisy point cloud data?"
      ],
      "overall_score": "Accept",
      "confidence": "High"
    }
  },
  {
    "paper_id": "1djnGJnaiy",
    "title": "",
    "std_review": {
      "summary": "The BrainMixer model introduces a novel approach to neuroimaging representation learning by jointly learning representations of voxel activity and functional connectivity networks using a graph neural network framework. It demonstrates strong performance across various datasets, modalities, and tasks, outperforming existing baselines. The model's ability to effectively capture complex brain connectivity patterns is a significant advancement, though it has limitations such as potential overfitting on smaller datasets and limited interpretability.",
      "strengths": [
        "Effectively combines voxel activity and functional connectivity data.",
        "Leverages a graph neural network to model complex brain connectivity patterns.",
        "Demonstrates strong performance across multiple datasets and tasks."
      ],
      "weaknesses": [
        "Performance on smaller datasets is not as strong, indicating potential overfitting.",
        "Computational complexity may pose challenges for real-time applications.",
        "Model's interpretability is limited due to non-human readable learned representations."
      ],
      "questions": [
        "How can the model's performance on smaller datasets be improved?",
        "What techniques can be used to enhance the interpretability of the learned representations?",
        "Are there potential methods to reduce the computational complexity for real-time applications?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1dY11GyZdp",
    "title": "Signed Binarization : Unlocking Efficiency",
    "std_review": {
      "summary": "The paper introduces Signed Binarization, a novel quantization technique that extends binary quantization to include signed values (±1), enhancing representational capacity while maintaining low computational overhead. It demonstrates significant improvements over existing binary and ternary quantization methods across multiple metrics, including accuracy, latency, energy consumption, throughput, and density. The authors apply the technique to convolutional neural networks and achieve competitive performance with reduced memory footprint and computational cost.",
      "strengths": [
        "Introduces Signed Binarization, expanding beyond traditional binary quantization by incorporating signed values.",
        "Efficiently maps a wide range of activations to a limited set of quantized values, reducing bits required for storage and computation.",
        "Demonstrates comprehensive performance gains across multiple metrics, providing a thorough assessment of the method's effectiveness."
      ],
      "weaknesses": [
        "Adds complexity to the quantization process, potentially requiring more sophisticated handling during training and inference.",
        "Potential for increased quantization error due to the use of signed values.",
        "Limited benchmarking scope may not fully capture the method's performance across all use cases."
      ],
      "questions": [
        "How does the method handle the increased complexity introduced by signed values during inference?",
        "Could the quantization error be further reduced with additional optimization techniques?",
        "Would extending the benchmarking to more diverse datasets provide a more comprehensive evaluation?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1FWDEIGm33",
    "title": "Large Language Models as Superpositions of Cultural Perspectives",
    "std_review": {
      "summary": "The paper introduces the metaphor of large language models (LLMs) as a superposition of cultural perspectives, arguing that their context‑sensitive behavior reflects a blend of multiple value or personality dimensions. Using a systematic experimental design with varied prompts, the authors develop a novel metric (Equation (1)) to quantify perspective shifts, finding that LLMs exhibit unexpected shifts that are not fully captured by simple instruction following. While innovative and empirically rigorous, the study has limitations in context generalizability, metric validation, and model diversity, suggesting further research to refine these aspects.",
      "strengths": [
        "Innovative metaphor of LLMs as a superposition of cultural perspectives.",
        "Empirical rigor with systematic experimental design and clear metric definition.",
        "Cross‑disciplinary relevance linking NLP and psychological theories."
      ],
      "weaknesses": [
        "Limited scope of contexts may restrict generalizability.",
        "Metric reliability not fully established.",
        "Analysis focused on a narrow set of model architectures.",
        "Direct comparability to human behavior lacks rigorous justification."
      ],
      "questions": [
        "How can the metric be validated against established psychological measures of personality and values?",
        "What are the implications of the observed perspective shifts for real‑world applications of LLMs?",
        "How might future work extend the analysis to a broader range of contexts and model families?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1gkePTsAWf",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a novel approach to recursive self‑improvement for large language models by using carefully crafted prompts to guide iterative refinement across a wide range of tasks and datasets. Empirical results show significant performance gains, indicating that prompt engineering can substantially advance recursive self‑improvement techniques. While the study provides valuable insights and a clear framework, it lacks a comprehensive ablation study, detailed evaluation metrics, and discussion of potential limitations. The repository for the code and data is not yet available, which affects reproducibility.",
      "strengths": [
        "Introduces a novel methodology that integrates diverse tasks and datasets.",
        "Provides a clear and replicable framework for evaluating prompt engineering.",
        "Demonstrates compelling empirical improvements in model performance."
      ],
      "weaknesses": [
        "Lacks a comprehensive ablation study to isolate prompt component effects.",
        "Evaluation metrics are not fully detailed.",
        "Does not discuss potential limitations such as computational cost or overfitting.",
        "Repository link for code and data is not yet available."
      ],
      "questions": [
        "Could a more detailed ablation study strengthen the argument for specific prompt features?",
        "What are the computational costs and potential overfitting risks of the proposed approach?",
        "How robust are the results across different types of tasks or models?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1GUTzm2a4v",
    "title": "Greedy PIG: Adaptive Integrated Gradients",
    "std_review": {
      "raw_text": "{\n  \"summary\": \"The paper introduces Greedy PIG, a gradient‑based feature attribution method that iteratively selects features to maximize a non‑submodular objective, improving attribution quality while controlling cost. Experiments show it outperforms Integrated Gradients, especially with correlated features. While theoretically sound and empirically superior, the method's sensitivity to the parameter \\(z\\) and the non‑strict submodularity of its objective function are noted as areas for improvement.\",\n  \"strengths\": [\n    \"Adaptive gradient utilization effectively captures feature interactions.\",\n    \"Handles feature correlations by isolating marginal gains.\",\n    \"Provides a rigorous theoretical analysis and guarantees.\"\n  ],\n  \"weaknesses\": [\n    \"Performance is sensitive to the choice of the parameter \\(z\\).\",\n    \"The objective function is not strictly submodular, affecting theoretical guarantees.\",\n    \"The sequential gradient definition is somewhat abstract.\",\n    \"Experimental details, such as the point game methodology, lack full transparency.\"\n  ],\n  \"questions\": [\n    \"What is the optimal choice of \\(z\\) and how does it vary across different datasets?\",\n    \"How robust are the theoretical guarantees when the objective deviates from strict submodularity?\",\n    \"Could the sequential gradient be defined more concretely to aid practical implementation?\",\n    \"What are the exact image selection criteria and network architecture used in the point game experiments?\"\n  ],\n  \"overall_score\": \"7: accept\",\n  \"confidence\": \"4: high\"\n}",
      "parse_error": true
    }
  },
  {
    "paper_id": "1hhja8ZxcP",
    "title": "Turbulent Flow Simulation using Autoregressive Conditional Diffusion Models",
    "std_review": {
      "summary": "The paper introduces an Autoregressive Conditional Diffusion Model (ACDM) for simulating turbulent flows, addressing high-dimensional, complex, and stochastic challenges. ACDM leverages autoregressive properties to enhance diffusion process conditioning, improving accuracy and stability. Experimental results show ACDM outperforms traditional baselines across various datasets, highlighting its potential for practical fluid dynamics applications.",
      "strengths": [
        "Innovative model architecture combining autoregressive modeling with conditional diffusion.",
        "Improved accuracy and stability in turbulent flow simulations compared to existing methods.",
        "Ability to generate posterior samples for enhanced uncertainty quantification."
      ],
      "weaknesses": [
        "High computational complexity may limit applicability in real-time or resource-constrained environments.",
        "Novelty may not fully translate to practical utility due to complexity and hyperparameter tuning requirements.",
        "Performance evaluation based on a limited set of datasets may not fully capture generalization across diverse turbulent flow scenarios."
      ],
      "questions": [
        "How can the computational complexity of ACDM be reduced for real-time applications?",
        "What strategies can be employed to improve the practical utility of ACDM in engineering and scientific workflows?",
        "How does ACDM perform on a broader range of turbulent flow datasets beyond those evaluated in the paper?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1hLFLNu4uy",
    "title": "Split and Merge: Aligning Position Biases in Large Language Model based Evaluators",
    "std_review": {
      "summary": "The paper proposes a method to mitigate position bias in LLM-based evaluators for open-ended questions by merging candidate answers based on semantic similarity. It effectively addresses the issue of answer position influencing evaluation scores while maintaining high evaluation quality. The approach is generalizable across different types of open-ended questions and leverages advanced semantic similarity metrics. However, it may struggle with responses that have significantly different lengths or semantic content, potentially leading to loss of important information. The method's effectiveness in maintaining coherence and meaning during merging is not fully quantified, leaving room for potential improvements.",
      "strengths": [
        "Effectively addresses position bias by integrating responses based on semantic content.",
        "Leverages advanced semantic similarity metrics to retain original meaning and coherence.",
        "Generalizable across different types of open-ended questions."
      ],
      "weaknesses": [
        "May struggle with responses that have significantly different lengths or semantic content.",
        "Risk of over-merging dissimilar responses, potentially diluting distinctiveness.",
        "Effectiveness in maintaining coherence and meaning during merging is not fully quantified."
      ],
      "questions": [
        "How does the method handle responses with varying lengths or semantic content?",
        "What is the impact of the method on evaluation accuracy when responses lack clear semantic overlap?",
        "How does the merging process ensure coherence and meaning are preserved?",
        "What is the trade-off between reducing position bias and maintaining evaluation quality?",
        "How does the proposed method compare to existing solutions for mitigating position bias in LLM-based evaluators?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1hsVvgW0rU",
    "title": "Sample-Efficient Learning of POMDPs",
    "std_review": {
      "summary": "The paper extends POMDP theory to k‑MO revealing POMDPs, where an agent can obtain k distinct observations at the end of an episode. It provides clear definitions, rigorous theoretical analysis of learnability and sample efficiency, and highlights practical benefits of multiple retrospective observations. While addressing some accessibility and applicability concerns, the work remains a valuable contribution with notable strengths and minor weaknesses.",
      "strengths": [
        "Introduces a meaningful extension of the MO POMDP framework to multiple observations.",
        "Provides precise definitions and conditions for k‑MO POMDPs, facilitating further research.",
        "Offers rigorous theoretical analysis of learnability and sample efficiency.",
        "Highlights practical implications of using multiple retrospective observations for learning efficiency."
      ],
      "weaknesses": [
        "The introduction of multiple observation scenarios may initially overwhelm readers unfamiliar with POMDPs.",
        "The analysis relies heavily on the availability of multiple observations at the end of episodes, which may not always be realistic.",
        "Sample efficiency discussion focuses on retrospective observations, which may not directly translate to online learning scenarios.",
        "Learnability is established in a PAC setting rather than absolutely, which might be a concern for applications requiring guaranteed convergence.",
        "Computational separations are discussed but lack concrete examples or settings that clearly illustrate these differences."
      ],
      "questions": [
        "How can the results be extended to settings where observations are available online rather than only retrospectively?",
        "What are concrete examples or settings that illustrate the computational or statistical separations between K=1 and K>1?",
        "How can the PAC learnability results be strengthened to provide absolute learnability guarantees?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1IaoWBqB6K",
    "title": "DiffDock-Pocket: Diffusion for Pocket-Level Docking with Sidechain Flexibility",
    "std_review": {
      "summary": "DiffDock-Pocket introduces a novel protein-ligand docking method that integrates sidechain flexibility into a pocket-centric model, significantly improving docking accuracy over traditional methods like SMINA and GNINA. The approach defines protein pockets and models sidechain atoms with flexibility criteria, evaluated across various protein types and docking scenarios. The paper demonstrates strong performance, especially in scenarios where sidechain movements impact binding affinity, though it acknowledges computational demands and data dependency.",
      "strengths": [
        "Innovative pocket definition enhances docking precision.",
        "Sidechain flexibility captures dynamic interactions crucial for accurate binding predictions.",
        "Consistently outperforms traditional docking methods, particularly in scenarios with significant sidechain movements."
      ],
      "weaknesses": [
        "Increased computational complexity may limit applicability to large-scale or resource-constrained environments.",
        "Performance heavily relies on the quality and diversity of training datasets.",
        "Predicted sidechain conformations can vary, impacting results in cases with significant sidechain involvement.",
        "Lack of extensive external validation datasets may limit confidence in performance across all scenarios."
      ],
      "questions": [
        "How does the model handle proteins with highly atypical or poorly structured sidechains?",
        "What strategies are employed to reduce computational demand while maintaining accuracy?",
        "How does the model's performance compare to other state-of-the-art methods when the binding site is predicted rather than known?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1ii8idH4tH",
    "title": "",
    "std_review": {
      "summary": "The paper introduces Momentum Screening (MS), an algorithm designed to improve robust training in the presence of Byzantine faults and gradient heterogeneity. MS adapts its parameters based on the Byzantine fraction and maximum gradient heterogeneity, achieving a minimax optimal error rate. Empirical evaluations show MS outperforms existing methods across various scenarios, highlighting its practical robustness and efficiency. However, the paper could improve by addressing unknown heterogeneity, computational complexity, scalability, and providing hyperparameter tuning guidelines.",
      "strengths": [
        "Adaptive parameter tuning based on Byzantine fraction and gradient heterogeneity",
        "Theoretical guarantee of minimax optimal error rate",
        "Empirical superiority over existing methods",
        "Comprehensive theoretical analysis of convergence rates"
      ],
      "weaknesses": [
        "Unknown heterogeneity scenario not fully addressed",
        "Lack of detailed computational complexity analysis",
        "Scalability concerns not thoroughly explored",
        "No empirical guidelines for hyperparameter tuning"
      ],
      "questions": [
        "How does MS perform when true heterogeneity is unknown?",
        "What is the detailed computational complexity of MS compared to other Byzantine-robust methods?",
        "How does MS scale with an increasing number of clients or more complex models?",
        "What empirical guidelines are provided for tuning hyperparameters like τt and the momentum coefficient?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1IIiQnLRe8",
    "title": "",
    "std_review": {
      "summary": "The paper introduces BiRDM, a bidirectional regularized diversity modulation framework for detecting semantic shifts in dynamic data streams. It effectively models feature diversity in both forward and backward directions, integrating a smoothness regularization component to balance reconstruction and suppression of out-of-distribution samples. Experimental evaluations demonstrate BiRDM's superior performance across various datasets, highlighting its robustness and effectiveness in dynamic environments. The reviewer finds the approach innovative, well‑validated, and a significant advancement over existing methods.",
      "strengths": [
        "Innovative bidirectional regularized diversity modulation framework for semantic shift detection.",
        "Balanced regularization strategy that enhances robustness in dynamic environments.",
        "Comprehensive experimental validation across multiple datasets, demonstrating superior performance."
      ],
      "weaknesses": [
        "Implementation complexity due to bidirectional architecture and dual regularization components.",
        "Sensitivity to hyper‑parameter choices, potentially limiting practical applicability without extensive tuning.",
        "Limited real‑world testing, with evaluation focused on synthetic and benchmark datasets."
      ],
      "questions": [
        "How can the implementation complexity of BiRDM be mitigated for broader practical use?",
        "What are the specific hyper‑parameter tuning strategies recommended for achieving optimal performance in real‑world scenarios?",
        "Could the framework be extended to handle non‑stationary environments where semantic shifts evolve over time?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1iKydVG6pL",
    "title": "Discovering Mathematical Formulas from Data via LSTM-guided Monte Carlo Tree Search",
    "std_review": {
      "summary": "The paper introduces AlphaSymbol, a method that combines LSTM networks with Monte Carlo Tree Search (MCTS) to perform symbolic regression, aiming to recover symbolic expressions from data more effectively than traditional methods. The approach shows promise, achieving higher recovery rates and computational efficiency on benchmark datasets. However, the review highlights several concerns, including unclear details on LSTM guidance, ambiguous evaluation metrics, and insufficient comparison with baseline methods. Overall, the method is promising but requires further clarification and validation.",
      "strengths": [
        "Innovative integration of LSTM and MCTS for symbolic regression.",
        "Demonstrated higher recovery rates and computational efficiency on benchmark datasets.",
        "Provides a solid theoretical foundation for the proposed method."
      ],
      "weaknesses": [
        "Lack of detailed explanation on how LSTM influences the MCTS search.",
        "Ambiguity in the definition and measurement of success metrics.",
        "Insufficient elaboration on the specific details of the new reward and loss functions.",
        "Limited comparison with a wide range of baseline approaches."
      ],
      "questions": [
        "How is the LSTM guidance coordinated with the MCTS search process?",
        "What are the specific details of the new reward function and loss function?",
        "How is the evaluation of the search process defined, and when is a search considered 'not recovered'?",
        "Are there any comparisons of running times between the proposed method and baselines?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "1jbh2e0b2K",
    "title": "Towards Few-Shot Adaptation of Foundation Models via Multitask Finetuning",
    "std_review": {
      "summary": "The paper introduces a Consistency‑Diversity Task Selection algorithm for multitask finetuning, aiming to balance diverse and consistent auxiliary tasks to improve few‑shot performance. Experiments on tieredImageNet, Meta‑Dataset, and ImageNet show that the method outperforms standard multitask finetuning and strong meta‑learning baselines like MAML across various sample complexities. While the theoretical framework and experimental results are strong, the lack of visual aids, ablation studies, and publicly available code limits understanding and reproducibility.",
      "strengths": [
        "Clear theoretical framework for task diversity and consistency",
        "Innovative task selection algorithm balancing diversity and consistency",
        "Comprehensive experiments across multiple datasets and sample complexities"
      ],
      "weaknesses": [
        "Absence of visual aids makes it hard to intuit task relationships",
        "No ablation studies to assess algorithm robustness to hyperparameters",
        "Code not publicly available, hindering reproducibility"
      ],
      "questions": [
        "Could visualizations help clarify the relationships between selected tasks and target tasks?",
        "What are the algorithm's robustness characteristics under varying hyperparameter settings?",
        "Are there plans to release the code and experimental setup for further validation?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1JbsdayvhO",
    "title": "Denoising Diffusion via Image-Based Rendering",
    "std_review": {
      "summary": "The paper introduces IB‑planes, a novel representation for image-based rendering that integrates with diffusion models to generate high-fidelity 3D reconstructions from multi-view images. The approach conditions on multiple views during both training and inference, leveraging a diffusion model to refine 3D details while dropping self-views to encourage robustness. Experiments demonstrate improved performance over existing methods like pixelNeRF and RenderDiffusion, especially with varying numbers of views and in the presence of camera calibration errors. The method is innovative, robust, and outperforms baselines in both quantitative metrics and visual quality, though it lacks qualitative evaluation and comprehensive baseline comparisons.",
      "strengths": [
        "Innovative representation for image-based rendering that integrates seamlessly with diffusion models.",
        "Robustness to camera calibration errors, making it practical for real-world applications.",
        "Improved performance over existing baselines, especially with varying numbers of views."
      ],
      "weaknesses": [
        "Lack of qualitative evaluation, such as comparison videos with baselines.",
        "No comparison against optimization-based pipelines or 3D-only diffusion models.",
        "Limited analysis of diminishing returns with varying numbers of conditioning views."
      ],
      "questions": [
        "Could you provide qualitative comparison videos with baselines like pixelNeRF, RenderDiffusion, and Viewset-Diffusion?",
        "How does the method compare to optimization-based pipelines using diffusion priors or 3D-only diffusion models?",
        "What is the detailed analysis of diminishing returns when varying the number of conditioning views?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1JiIKjcwrr",
    "title": "Robust Self-supervised learning in Heterogeneous graph based on Feature-Topology Balancing",
    "std_review": {
      "summary": "BFTNet presents a novel framework for self-supervised learning on heterogeneous graphs by balancing graph topology and node features through a dual attention mechanism. The approach effectively captures structural patterns and node embeddings, leading to significant performance improvements over existing methods, especially in noisy or skewed datasets. The paper is well-structured, theoretically justified, and demonstrates strong empirical results, making it a valuable contribution to the field.",
      "strengths": [
        "Balanced Integration of Topology and Features: BFTNet effectively integrates graph topology and node features through a dual attention mechanism.",
        "Robustness to Noisy Data: The framework includes mechanisms to handle noisy or skewed datasets, ensuring robust performance.",
        "Theoretical Justification: The approach is supported by theoretical insights into the importance of both graph structure and node attributes."
      ],
      "weaknesses": [
        "Computational Complexity: The dual attention mechanism may introduce significant computational overhead.",
        "Interpretability Challenges: The complex architecture may make it challenging to interpret the learned representations.",
        "Hyperparameter Sensitivity: The model's performance may be sensitive to hyperparameter tuning."
      ],
      "questions": [
        "How can the computational complexity be mitigated for very large graphs?",
        "What additional interpretability tools can be provided to aid in understanding the learned representations?",
        "Are there alternative mechanisms to reduce hyperparameter sensitivity?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1JPfHljXL4",
    "title": "When, Why and How Much?",
    "std_review": {
      "summary": "The paper investigates adaptive learning‑rate schedules for deep neural networks, proposing a novel scheme that adapts during training and theoretically justifying its benefits. Empirical experiments on GPT, RoBERTa, and ViT show improved convergence and performance over traditional schedules. While the work provides valuable insights and strong evidence, it has limitations in scope and generality that could be addressed in future work.",
      "strengths": [
        "Provides a rigorous theoretical analysis of gradient norm behavior under various learning‑rate sequences.",
        "Introduces a dynamic learning‑rate scheme that adapts during training, potentially overcoming limitations of static schedules.",
        "Demonstrates strong empirical validation across multiple state‑of‑the‑art models, showing clear performance gains."
      ],
      "weaknesses": [
        "Theoretical analysis is primarily focused on non‑convex deep learning settings, limiting applicability to convex problems.",
        "Empirical experiments are concentrated on specific model architectures (GPT, RoBERTa, ViT), which may restrict generalizability.",
        "The dynamic nature of the proposed learning‑rate scheme introduces additional computational overhead or complexity.",
        "Lacks comprehensive comparison with modern adaptive optimizers beyond a brief discussion of Adagrad."
      ],
      "questions": [
        "How does the proposed learning‑rate scheme perform when applied to convex optimization problems or other model types beyond GPT, RoBERTa, and ViT?",
        "What are the practical implementation details and computational costs of the dynamic learning‑rate approach?",
        "Could the method be combined with batch size adjustments or other heuristics for further performance gains?",
        "How does the proposed method compare to more recent adaptive optimizers like Adam or LAMB in terms of convergence speed and final performance?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1JR20YOE0H",
    "title": "On Feature Diversity in Energy-based Models",
    "std_review": {
      "summary": "The paper introduces (ϑ−τ)-diversity, a regularization technique for energy-based models that enhances feature diversity and improves generalization. Theoretical analysis provides novel insights into feature diversity's impact on generalization bounds, and empirical results on image classification and natural language processing tasks show significant improvements over state-of-the-art methods. While the theoretical assumptions and limited empirical validation are noted, the overall contribution is strong.",
      "strengths": [
        "Introduces a novel regularization technique for energy-based models.",
        "Provides theoretical analysis linking feature diversity to generalization bounds.",
        "Demonstrates strong empirical improvements on multiple tasks and datasets."
      ],
      "weaknesses": [
        "Theoretical analysis relies on specific assumptions about the energy function and data distribution.",
        "Empirical evaluation is limited to a few tasks and datasets.",
        "Computational implications of enforcing feature diversity are not fully explored."
      ],
      "questions": [
        "How does the proposed regularization perform on more diverse benchmarks?",
        "What are the theoretical guarantees under broader assumptions about the energy function?",
        "How does the computational cost scale with model size and data dimensionality?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1JtTPYBKqt",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a novel method for retrieving computational graphs using a context graph that captures both structural and functional relationships. It leverages graph embeddings and a retrieval framework, evaluated on a dataset of 12,000 labeled CGs, showing improved performance over baseline systems. While innovative and empirically validated, the method has concerns regarding reproducibility, limited baseline comparisons, and unclear relevance criteria.",
      "strengths": [
        "Innovative context graph representation for capturing structural and functional relationships.",
        "Scalable retrieval system suitable for large datasets.",
        "Empirical validation on a substantial dataset with clear performance metrics."
      ],
      "weaknesses": [
        "Lack of reproducibility due to unspecified data collection and availability.",
        "Limited comparison with other state-of-the-art retrieval techniques.",
        "Ambiguity in defining graded vs. non‑graded relevance."
      ],
      "questions": [
        "Will the 12,000 real-world computational graphs and their labels be made publicly available for reproducibility?",
        "How does the method compare to other recent graph retrieval techniques?",
        "What specific criteria define graded relevance versus non‑graded relevance?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "1JuMFjSkpD",
    "title": "Fair Attribute Classification via Distance Covariance",
    "std_review": {
      "summary": "The paper introduces a method for optimizing machine learning models for equal opportunity using distance covariance, a metric for measuring independence. It applies to both discrete and continuous variables, with a focus on continuous sensitive attributes, and compares favorably to baselines optimizing for differential privacy. The reviewer finds the method theoretically sound and practically advantageous, though with some areas for further exploration.",
      "strengths": [
        "Introduces a novel metric (distance covariance) for measuring independence, particularly suited for optimization tasks.",
        "Provides a clear theoretical framework for handling both discrete and continuous variables, enhancing the method's applicability.",
        "Demonstrates practical advantages over existing baselines that optimize for differential privacy, suggesting a more direct approach to fairness."
      ],
      "weaknesses": [
        "The convergence analysis of the empirical distance covariance does not directly address the quality of the fair solution.",
        "Theoretical properties do not fully address the optimization of the fairness-accuracy trade-off.",
        "Comparison with baselines optimizing for EO is not exhaustive."
      ],
      "questions": [
        "How does the convergence of the empirical distance covariance impact the optimization of the fairness-accuracy trade-off?",
        "Could additional analysis, such as bias-variance trade-off or sensitivity analysis, provide deeper insights into the relationship between convergence and fair solution quality?",
        "What are the specific advantages of the proposed method over existing baselines that directly optimize for equal opportunity?"
      ],
      "overall_score": "Accept",
      "confidence": "High"
    }
  },
  {
    "paper_id": "1k4yZbbDqX",
    "title": "InstaFlow: One Step is Enough for High-Quality Diffusion-Based Text-to-Image Generation",
    "std_review": {
      "summary": "InstaFlow presents a novel text‑conditioned rectified flow framework that accelerates diffusion‑based text‑to‑image generation to a single inference step, achieving competitive image quality with substantial computational savings. The authors demonstrate robust performance across diverse datasets, indicating general applicability. While the approach is technically innovative and efficient, concerns about training complexity, model architecture adaptability, and scalability to state‑of‑the‑art models remain. Overall, the paper is well‑structured, clearly documented, and makes a significant contribution to the field.",
      "strengths": [
        "Introduces a unique text‑conditioned rectified flow framework that reduces inference time to a single step.",
        "Achieves high image quality comparable to multiple diffusion steps with a single inference.",
        "Demonstrates robustness across various datasets, indicating broad applicability."
      ],
      "weaknesses": [
        "Training process involves complex adjustments that may affect reproducibility.",
        "Model architecture impact on adaptability to other architectures is not fully explored.",
        "Performance on advanced models like DeepFloyd IF and SDXL is not evaluated."
      ],
      "questions": [
        "How does InstaFlow scale to more advanced diffusion models such as DeepFloyd IF and SDXL?",
        "What is the impact of varying the depth and channel dimensions of the Stacked U‑Net architecture on performance?",
        "What strategies can be employed to address potential misuse of the rapid generation capability?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1M0qIxVKf6",
    "title": "Uncovering hidden geometry in Transformers via disentangling position and context",
    "std_review": {
      "summary": "The paper introduces a novel decomposition of Transformer hidden states into positional, contextual, and residual components, revealing low‑frequency positional embeddings and clustered contextual embeddings. It leverages Fourier analysis and operator norms to show smooth spiral patterns in low dimensions, indicating a low‑rank + diagonal structure. The decomposition aids interpretability and practical improvements in debugging and model design, though it may be complex for some readers and lacks explicit scalability analysis.",
      "strengths": [
        "Provides a clear, interpretable framework for understanding Transformer behavior.",
        "Demonstrates mathematical rigor using advanced tools like Fourier analysis and operator norms.",
        "Introduces a decomposition that separates positional, contextual, and residual components, offering a new perspective.",
        "Employs token randomization and arithmetic tasks to validate the decomposition's effectiveness."
      ],
      "weaknesses": [
        "The mathematical framework may be challenging for readers without a strong background in linear algebra and Fourier analysis.",
        "Focuses primarily on hidden states, potentially overlooking other aspects of model behavior.",
        "Scalability to very large models or specific architectures like Vision Transformers is not addressed.",
        "While connecting to prior work, it may not fully compare the novelty and impact of the proposed decomposition."
      ],
      "questions": [
        "How does the decomposition scale to very large models or specific architectures like Vision Transformers?",
        "What are the practical implications of the low‑frequency nature of positional embeddings on model training and inference?",
        "How does the clustering structure of contextual embeddings relate to semantic topic modeling beyond document‑level topics?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1M8yDTa0Pp",
    "title": "Cross-Model Semi-Supervised Prompt Learning for Vision-Language Models",
    "std_review": {
      "summary": "The paper presents a novel self-supervised learning approach for Vision-Language Models by adapting prompt learning techniques. It leverages the multimodal structure of VLMs to generate effective prompts, showing strong performance on benchmark datasets. While promising, the method's generalizability and robustness to out-of-distribution data are not fully explored. The authors should address these aspects in future work.",
      "strengths": [
        "Introduces a novel adaptation of prompt learning for VLMs, addressing a gap in current SSL literature.",
        "Effectively leverages the multimodal nature of VLMs, potentially leading to more robust representations.",
        "Demonstrates competitive performance on benchmark datasets, validating the approach's effectiveness."
      ],
      "weaknesses": [
        "Performance is primarily evaluated on in-distribution datasets, limiting evidence of generalizability.",
        "Lacks comprehensive analysis of robustness to out-of-distribution data or variations in dataset characteristics.",
        "Does not thoroughly explore trade-offs between different prompt learning strategies and their impact on VLM performance."
      ],
      "questions": [
        "How does the method perform on out-of-distribution datasets or with varying dataset characteristics?",
        "What measures are taken to ensure the learned prompts are not overfitted to specific datasets?",
        "Could additional experiments on diverse datasets or domain adaptation challenges provide further insights into the method's robustness?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "1mjsP8RYAw",
    "title": "Unsupervised Pretraining for Fact Verification by Language Model Distillation",
    "std_review": {
      "summary": "The paper presents a method for fact verification that combines a knowledge graph (Wikidata) with a transformer-based language model. It shows strong performance on the FEVER dataset, achieving competitive accuracy. However, its reliance on a fixed knowledge graph and limited benchmark evaluation raise concerns about generalizability and broader applicability.",
      "strengths": [
        "Effectively integrates structured knowledge with language understanding.",
        "Provides transparent evidence-based verification.",
        "Demonstrates strong performance on a well-established benchmark."
      ],
      "weaknesses": [
        "Limited generalizability due to fixed knowledge graph.",
        "Potential gaps in knowledge coverage from Wikidata.",
        "Evaluation confined to a single benchmark, limiting broader applicability."
      ],
      "questions": [
        "How does the method handle claims with additional contextual information (e.g., time, location)?",
        "What is the impact of knowledge graph coverage gaps on verification accuracy?",
        "How does the method compare to recent unsupervised approaches on other fact-checking benchmarks?",
        "What are the scalability implications for larger models or more extensive knowledge graphs?"
      ],
      "overall_score": "Borderline",
      "confidence": "Medium"
    }
  },
  {
    "paper_id": "1mNFsbvo2P",
    "title": "Domain constraints improve risk prediction when outcome data is missing",
    "std_review": {
      "summary": "The paper introduces a machine‑learning model that predicts disease risk for individuals who have not undergone genetic testing, using genetic risk scores and demographic information from a tested cohort. The model outperforms baseline methods across age groups, with strong theoretical justification for the negative coefficient on the genetic risk score. Despite promising results, the model's reliance on a tested cohort and the absence of a prevalence constraint limit its generalizability and clinical applicability.",
      "strengths": [
        "Innovative approach to extending risk predictions to untested populations using genetic and demographic data.",
        "Theoretical rigor in justifying the negative coefficient on genetic risk scores, reflecting real‑world limited information settings.",
        "Comprehensive evaluation across age groups and clear baseline comparisons demonstrate the model's added value."
      ],
      "weaknesses": [
        "Model's performance may be limited by its reliance on a tested cohort, restricting applicability to other populations.",
        "Absence of a prevalence constraint could lead to unrealistic predictions, especially for older populations.",
        "Using follow‑up data for validation introduces potential biases and uncertainties."
      ],
      "questions": [
        "How does the model perform when applied to populations with different genetic testing policies?",
        "What is the impact of incorporating additional demographic features beyond those used in the current study?",
        "How robust are the model's predictions when tested on data from different health systems or age distributions?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1mOeklnLf4",
    "title": "FroSSL: Frobenius Norm Minimization for Self-Supervised Learning",
    "std_review": {
      "summary": "FroSSL introduces a novel loss function that enhances rotational invariance in deep learning models by combining a Frobenius norm regularizer with a logarithmic term. It builds on Barlow Twins and shows superior performance on image classification tasks, outperforming both Barlow Twins and traditional softmax loss. Theoretical work justifies the logarithm's role in promoting invariance and the Frobenius norm's convergence benefits, though the paper could benefit from broader experimental validation.",
      "strengths": [
        "Introduces a novel loss function that effectively enhances rotational invariance.",
        "Demonstrates superior performance over existing methods on image classification tasks.",
        "Provides a clear theoretical motivation for the logarithmic term and Frobenius norm regularizer."
      ],
      "weaknesses": [
        "Limited experimental scope focusing primarily on image classification.",
        "Lacks comprehensive comparison with other state-of-the-art methods.",
        "Potential overfitting risks are not thoroughly analyzed."
      ],
      "questions": [
        "How does FroSSL perform on tasks involving geometric transformations beyond image classification?",
        "What additional experiments could better demonstrate FroSSL's advantages across diverse domains?",
        "How does the Frobenius norm regularizer specifically contribute to faster convergence?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1MRfyGLCcU",
    "title": "Graph Representation Learning Enhanced Semi-supervised Feature Selection",
    "std_review": {
      "summary": "The paper introduces G-FS, a graph-based feature selection method that leverages graph neural networks to identify informative features in tabular data. It demonstrates superior accuracy and computational efficiency, especially on large datasets, and performs well in both semi-supervised and fully supervised settings. While innovative, the method's complexity and lack of theoretical guarantees are noted.",
      "strengths": [
        "Innovative integration of GNNs for feature selection.",
        "Batch-attention mechanism enhances adaptability and robustness.",
        "Demonstrates superior scalability and efficiency over traditional methods."
      ],
      "weaknesses": [
        "Implementation complexity due to advanced GNN components.",
        "Potential for overfitting with limited data.",
        "Lack of theoretical underpinnings."
      ],
      "questions": [
        "How does the method handle overfitting in fully supervised settings?",
        "What are the optimal hyperparameters for the batch-attention mechanism?",
        "How does G-FS compare to other graph-based feature selection methods on diverse datasets?"
      ],
      "overall_score": "Accept",
      "confidence": "High"
    }
  },
  {
    "paper_id": "1ndDmZdT4g",
    "title": "Dynamic Sparse No Training \\(\\mathbf{\\mathcal{O}}\\):",
    "std_review": {
      "summary": "The paper introduces DS⊘T, a method for creating sparse language models without extensive fine-tuning, using a dynamic threshold to prune parameters. It shows significant efficiency gains with minimal loss in performance compared to baselines. The approach is praised for its simplicity and flexibility but has concerns about threshold sensitivity and scalability.",
      "strengths": [
        "Efficiently reduces computational requirements with dynamic pruning.",
        "Offers adjustable sparsity levels for user flexibility.",
        "Simplifies model deployment by eliminating extensive fine-tuning."
      ],
      "weaknesses": [
        "Threshold selection can greatly impact performance and efficiency.",
        "Limited comparison with a broader range of sparse techniques.",
        "Lack of detailed hardware compatibility information.",
        "Scalability to very large models or complex tasks is not fully addressed."
      ],
      "questions": [
        "How does DS⊘T perform on very large models or complex tasks?",
        "What are the detailed hardware compatibility considerations?",
        "How does the threshold ϵ affect long-term stability and performance?"
      ],
      "overall_score": "6: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1nfqABOIwQ",
    "title": "RIME: Robust Preference-based Reinforcement Learning with noisy human preferences",
    "std_review": {
      "summary": "RIME introduces a Preference-Based Reinforcement Learning method that improves robustness to noisy labels by integrating a preference discriminator into the learning pipeline. The discriminator distinguishes between clean and flipped labels, guiding the training process to focus on high-quality samples. Evaluated on the Walker-2D environment, RIME outperforms baseline PbRL methods and traditional regularization techniques across varying noise levels, demonstrating strong theoretical foundations and practical effectiveness.",
      "strengths": [
        "Innovative integration of a preference discriminator for dynamic label quality adjustment.",
        "Demonstrates strong performance and robustness to noise across a range of levels.",
        "Provides a solid theoretical basis for the discriminator's role in preference discrimination."
      ],
      "weaknesses": [
        "Complexity of implementation due to the added preference discriminator.",
        "Reliance on warm-start technique may limit applicability to other domains.",
        "Uniform sampling schedule for query selection lacks detailed justification.",
        "Limited details in user study protocol for replicability."
      ],
      "questions": [
        "How does RIME's performance scale to more complex environments beyond Walker-2D?",
        "What are the computational costs associated with maintaining and updating the preference discriminator during training?",
        "How robust is RIME to different types of noise beyond label flipping, such as environmental or sensor noise?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1NHgmKqOzZ",
    "title": "Data Distillation Can Be Like Vodka: Distilling More Times For Better Quality",
    "std_review": {
      "summary": "The paper introduces Progressive Dataset Distillation (PDD), a method that enhances dataset distillation by progressively refining distilled datasets. PDD captures training dynamics in multiple stages, leading to higher accuracy and efficiency compared to single-stage methods. The approach is evaluated against traditional techniques and various base methods, showing strong performance across different scenarios. Overall, PDD offers a novel and effective solution to dataset distillation with clear benefits.",
      "strengths": [
        "Improved performance over single-stage distillation methods.",
        "Captures training dynamics in a multi-stage manner.",
        "Enhances scalability and efficiency, especially for large datasets.",
        "Demonstrates versatility across different base distillation methods."
      ],
      "weaknesses": [
        "Increased implementation complexity due to multi-stage approach.",
        "Potential for overfitting with smaller datasets.",
        "Resource-intensive initial setup and training phases."
      ],
      "questions": [
        "How does PDD handle overfitting in scenarios with limited training data?",
        "What adaptive strategies can be employed to address challenges with datasets of varying complexity?",
        "Can PDD be integrated with other distillation techniques to further improve performance?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1OfAO2mes1",
    "title": "Backdoor Secrets Unveiled: Identifying Backdoor Data with Optimized Scaled Prediction Consistency",
    "std_review": {
      "summary": "The paper introduces MSPC, a novel method for detecting backdoors in machine learning models by enhancing SPC with a learnable mask and a bilevel optimization framework. It achieves competitive performance against state-of-the-art baselines under practical conditions without requiring a predefined detection threshold. While innovative, the method's computational complexity and potential false positive rates are concerns that need addressing for real-world deployment.",
      "strengths": [
        "Innovative learnable mask mechanism that adapts to model behavior.",
        "Threshold-free detection framework suitable for real-world scenarios.",
        "Comprehensive evaluation across various backdoor attacks and baselines."
      ],
      "weaknesses": [
        "Significant computational overhead due to bilevel optimization.",
        "Potential for high false positive rates in the absence of backdoors.",
        "Limited evaluation of effectiveness in environments with high poisoning rates."
      ],
      "questions": [
        "How does MSPC perform when integrated with other backdoor detection techniques?",
        "What is the impact of input value normalization on the effectiveness of the learnable mask?",
        "How does the method handle scenarios with extreme poisoning rates?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1oijHJBRsT",
    "title": "Self-Alignment with Instruction Backtrans-Lation",
    "std_review": {
      "summary": "The paper introduces a novel self‑alignment technique for instruction‑following language models, using multiple iterations of self‑curated instruction data from the ClueWeb dataset. Fine‑tuning a base model on this augmented data significantly outperforms standard distillation on various benchmarks, demonstrating strong performance gains and promising scalability. The study highlights the method's scalability, robustness across model sizes, and practical utility, though it also notes limitations in benchmark coverage and potential variability in data quality.",
      "strengths": [
        "Innovative self‑alignment method using self‑curated instruction data.",
        "Scalable data generation from a large web corpus.",
        "Strong performance improvements over traditional distillation.",
        "Clear experimental setup across different model sizes."
      ],
      "weaknesses": [
        "Limited benchmark coverage may not fully capture method's performance.",
        "Potential variability in data quality extracted from the web.",
        "Computational cost of generating large self‑curated datasets.",
        "Lack of detailed analysis on diminishing returns of additional iterations."
      ],
      "questions": [
        "How does the method perform on a broader set of instruction benchmarks?",
        "What detailed analysis is provided on the diminishing returns of further self‑curated iterations?",
        "How does the choice of segment size and filtering criteria impact the quality of the augmented data?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1OP4crhgkD",
    "title": "Semantically Aligned Task Decomposition in Multi-Agent Reinforcement Learning",
    "std_review": {
      "summary": "The SAMA framework introduces a novel approach to MARL by leveraging pre-trained language models to address sparse rewards and enable semantically aligned task decomposition. It generates task manuals and state/action translations from existing literature and code, facilitating language-grounded interactions. Preliminary results on benchmark tasks show improved sample efficiency and performance compared to traditional methods, though challenges remain in real-world deployment and handling complex tasks.",
      "strengths": [
        "Introduces a novel framework for MARL that effectively addresses the sparse reward problem using PLMs.",
        "Enables semantically aligned task decomposition and subgoal allocation through language-grounded interactions.",
        "Reduces manual effort by generating task manuals and state/action translations from existing papers and code."
      ],
      "weaknesses": [
        "Limited applicability to environments where human rationality is not easily expressible in language.",
        "Reliance on PLMs may introduce challenges in terms of cost and feasibility for real-world deployment.",
        "Effectiveness may depend on the quality and relevance of generated task manuals and translations."
      ],
      "questions": [
        "How does SAMA handle environments where human rationality is not easily expressible in language?",
        "What are the specific challenges and solutions for deploying SAMA in real-world scenarios?",
        "How does the framework ensure the quality and relevance of generated task manuals and state/action translations?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1op5YGZu8X",
    "title": "Theoretical Analysis of Robust Overfitting for Wide DNNs: An NTK Approach",
    "std_review": {
      "summary": "The paper introduces a novel theoretical framework using the Neural Tangent Kernel (NTK) to analyze adversarial training, deriving a regularization matrix that captures adversarial robustness. It shows improved robust test accuracy on SVHN and CIFAR-10 datasets, distinguishing between robust overfitting and adversarial training degeneration. While the theoretical insights are promising, practical limitations and the need for further empirical validation reduce the overall impact.",
      "strengths": [
        "Introduces a novel theoretical framework using NTK to analyze adversarial training.",
        "Derives a regularization matrix Ξ(t) that effectively captures adversarial robustness.",
        "Provides a clear distinction between robust overfitting and adversarial training degeneration."
      ],
      "weaknesses": [
        "Theoretical framework assumes large network widths, which may not be realistic in practice.",
        "Experiments use non-standard architectures without GAP layers, limiting generalizability.",
        "Lack of empirical confirmation for the phenomenon of adversarial training degeneration.",
        "Theoretical assumptions may limit applicability to real-world scenarios.",
        "Practical translation of NTK insights into adversarial training algorithms is challenging."
      ],
      "questions": [
        "Can the framework be extended to standard architectures like ResNet?",
        "What is the impact of network architecture (e.g., absence of GAP layer) on robustness?",
        "How can the theoretical insights be practically applied to adversarial training?",
        "What empirical evidence supports the distinction between robust overfitting and adversarial training degeneration?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "1oqedRt6Z7",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a convolutional Deep Kernel Method (convDKM) that extends the infinite‑width Neural Network Gaussian Process (NNGP) framework to convolutional architectures. By learning a Gram matrix for each layer, the method enables representation learning through kernel functions that capture hierarchical feature interactions. Experiments on CIFAR‑10 show improved interpretability and uncertainty estimation, though the impact on larger datasets like CIFAR‑100 remains unexplored. The convDKM bridges kernel methods and deep learning, offering a principled way to learn representations in convolutional networks.",
      "strengths": [
        "Extension of NNGP to Convolutional Networks",
        "Learnable Representation via Gram Matrices",
        "Interpretability and Uncertainty Estimation"
      ],
      "weaknesses": [
        "Limited Dataset Experiments",
        "Lack of Detailed Theoretical Analysis",
        "Potential Computational Complexity"
      ],
      "questions": [
        "How does the method generalize to larger datasets beyond CIFAR‑10?",
        "What is the theoretical convergence and generalization analysis for the learnable kernels?",
        "How does the computational complexity scale with model size, and what are the trade-offs?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1P1nxem1jU",
    "title": "Through the Dual-Prism: A Spectral Perspective on Graph Data Augmentation for Graph Classification",
    "std_review": {
      "summary": "The paper presents a novel spectral graph partitioning method that uses eigenvalue manipulations to create augmented graphs, aiming to improve efficiency and accuracy in large-scale graph classification. Experimental results show competitive performance, but several issues remain, such as unclear computational complexity and the need for more examples of augmented graphs. The method is theoretically sound but could benefit from stronger proofs and clearer explanations.",
      "strengths": [
        "Introduces a fresh perspective on spectral graph partitioning using eigenvalue modifications.",
        "Provides a solid theoretical foundation with clear observations and proofs.",
        "Demonstrates competitive empirical performance across multiple datasets."
      ],
      "weaknesses": [
        "Computational complexity of the eigendecomposition step is not clearly addressed.",
        "Lacks additional examples of augmented graphs to illustrate method flexibility.",
        "Marginal improvements over existing methods raise questions about limitations.",
        "Proof for Observation 4 relies heavily on a single prior work.",
        "Some figures have small font sizes, affecting readability."
      ],
      "questions": [
        "Can you clarify the computational complexity of the eigendecomposition step and its scalability with graph size?",
        "Providing additional examples of augmented graphs would help clarify the method's applicability.",
        "What factors contribute to the marginal improvements over existing methods in some cases?",
        "Extending the proof for Observation 4 to include more independent arguments would strengthen the theoretical claims.",
        "Increasing the font size in figures would improve their readability and accessibility."
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "1p4q1cXOX9",
    "title": "Attribute-Enhanced Similarity Ranking for Sparse Link Prediction",
    "std_review": {
      "raw_text": "{\n  \"summary\": \"The paper introduces Gelato, a GNN approach for link prediction that tackles biased testing in sparse graphs by integrating a topological heuristic, N-pair loss, and hard negative sampling via graph partitioning. Gelato combines attribute similarity, topological weights, and learned weights in the adjacency matrix to capture diverse relationship patterns, achieving superior performance on sparse datasets. However, its applicability to non-sparse graphs is limited, and computational/memory overheads could affect training efficiency. The hyperparameters \\(\\alpha\\) and \\(\\beta\\) require careful tuning, which is not fully addressed.\",\n  \"strengths\": [\n    \"Effectively addresses biased testing in sparse graphs through innovative negative sampling and loss functions.\",\n    \"Captures diverse relationship patterns by integrating attribute similarity, topological weights, and learned weights.\",\n    \"Demonstrates superior performance on sparse graph datasets compared to existing GNN-based methods.\"\n  ],\n  \"weaknesses\": [\n    \"Performance on non-sparse graphs is not well-documented, limiting broader applicability.\",\n    \"Computational and memory overheads from graph partitioning and hard negative sampling may impact training efficiency.\",\n    \"Optimal values for hyperparameters \\(\\alpha\\) and \\(\\beta\\) are not clearly identified, affecting model generalization.\"\n  ],\n  \"questions\": [\n    \"How does Gelato perform on non-sparse graph datasets, and what strategies could be employed to improve its generalizability?\",\n    \"What are the specific computational and memory trade-offs introduced by graph partitioning, and are there alternative approaches to reduce these overheads?\",\n    \"Could a sensitivity analysis of hyperparameters \\(\\alpha\\) and \\(\\beta\\) provide clearer guidance for practitioners?\"\n  ],\n  \"overall_score\": \"4: weak accept\",\n  \"confidence\": \"3: medium\"\n}",
      "parse_error": true
    }
  },
  {
    "paper_id": "1P92J25hdf",
    "title": "Going Deeper with General and Specific Inductive Bias for Real-Time Stereo Matching",
    "std_review": {
      "summary": "The paper presents a novel cost‑volume representation for 3D reconstruction that explicitly leverages a specific inductive bias to improve scale invariance and efficiency. It introduces a Dense Scale‑Aware Fusion (DSF) module that separates low‑resolution initialization from high‑resolution refinement, complemented by a Mixed Direct Long‑Range Compensation (MDLC) mechanism to capture long‑range dependencies beyond traditional Transformers. The model achieves real‑time inference with competitive accuracy on standard benchmarks and demonstrates strong generalization on unseen datasets without fine‑tuning.",
      "strengths": [
        "Innovative inductive bias for cost‑volume representation that explicitly targets scale invariance.",
        "Dense Scale‑Aware Fusion (DSF) effectively decomposes the scale problem into low‑ and high‑resolution components.",
        "Mixed Direct Long‑Range Compensation (MDLC) extends beyond Transformers to capture long‑range spatial context.",
        "Robust generalization on unseen datasets (SCARED) without requiring fine‑tuning.",
        "Real‑time performance while maintaining high accuracy."
      ],
      "weaknesses": [
        "The MDLC mechanism introduces additional complexity that may complicate implementation.",
        "Limited benchmark coverage; additional tests could assess robustness further.",
        "Lack of fine‑tuning on target datasets raises questions about adaptability to specialized scenarios.",
        "Utility of the new statistical indicators for guiding model design or debugging is underexplored."
      ],
      "questions": [
        "How does the MDLC mechanism compare to other multi‑scale compensation strategies in terms of computational cost?",
        "What is the impact of the specific inductive bias on the model's performance in highly dynamic or cluttered environments?",
        "Could the statistical indicators be refined to provide more actionable insights for debugging and model improvement?",
        "How does the model perform on benchmarks with extreme depth ranges or high occlusion rates?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1PPjf4wife",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a novel approach to multi-agent reinforcement learning (MARL) by leveraging multiple large language models (LLMs) to address sample inefficiency, policy generalization, and interpretability. Each agent is associated with a dedicated LLM that receives partial observations and generates policies. The authors evaluate their method on the BabyAI‑text and traffic junction environments, demonstrating improved performance over traditional RL baselines. While innovative, the paper raises concerns about the necessity of multiple LLMs, the design of prompt functions, and the generalizability of the approach.",
      "strengths": [
        "Innovative Use of LLMs: The paper creatively applies LLMs to MARL, potentially offering a solution to longstanding challenges in sample efficiency and policy generalization.",
        "Interpretability: LLM policies can be more interpretable than traditional RL policies, providing insights into decision-making processes.",
        "Communication Module: The discrete message passing module introduces a structured way for agents to share information, which could enhance coordination and performance."
      ],
      "weaknesses": [
        "Necessity of Multiple LLMs: The paper does not sufficiently justify why multiple LLMs are required, rather than a single central LLM receiving partial observations.",
        "Fixed vs. Trainable Prompt Function: The prompt function is fixed, which may limit the flexibility and performance of the policies. Making it trainable could be beneficial.",
        "Performance Gaps: The paper lacks detailed analysis on why LLM policies outperform traditional RL policies, which is crucial for understanding the method's advantages."
      ],
      "questions": [
        "Why are multiple LLMs necessary rather than a single central LLM receiving partial observations?",
        "How could the prompt function be made trainable to improve policy performance?",
        "What detailed analysis is needed to understand why LLM policies outperform traditional RL policies?",
        "What ablation studies are required to quantify the impact of the discrete message passing module?",
        "What additional training details are needed for baselines like MAPPO and MAPPO‑GLAM to ensure fair comparisons?",
        "How could the environments used be made more complex to demonstrate broader generalizability?",
        "How can the notation for parameters and discrete messages be standardized for clarity?",
        "How could the framework be adapted to handle heterogeneous agents beyond the current homogeneous assumption?",
        "What additional information is needed to reproduce the experimental results more reliably?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "1pSL2cXWoz",
    "title": "ConjNorm: Tractable Density Estimation for Out-of-Distribution Detection",
    "std_review": {
      "summary": "The paper presents ConjNorm, a method for density estimation using conjugate norms within the exponential family. It introduces a flexible approach by allowing the selection of a parameter p to balance model complexity and computational efficiency. Empirical results show improved performance, especially in high-dimensional settings, and the method is theoretically grounded with consistency and tractability guarantees. While implementation challenges and assumptions on data distribution exist, the method offers a valuable contribution to out-of-distribution detection.",
      "strengths": [
        "Innovative use of conjugate pairs for tractable partition function estimation.",
        "Flexibility and scalability through tunable parameter p.",
        "Strong theoretical backing with consistency and tractability guarantees."
      ],
      "weaknesses": [
        "Complexity in selecting an optimal p value for practical implementation.",
        "Assumptions on data distribution and density function form may limit applicability.",
        "Empirical validation limited to a few benchmark datasets."
      ],
      "questions": [
        "How can the choice of p be automated or guided in practice?",
        "What are the theoretical guarantees under more general data distribution assumptions?",
        "How does the method perform on a broader range of datasets beyond the current benchmarks?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1pTlvxIfuV",
    "title": "A Reparameterized Discrete Diffusion Model for Text Generation",
    "std_review": {
      "summary": "The paper introduces a reparameterized discrete diffusion model (RDM) that enhances training and decoding efficiency through a novel non-autoregressive inference technique. It demonstrates competitive performance on conditional tasks like machine translation, question generation, and paraphrasing, and provides insights into optimizing iteration steps for quality and efficiency. However, the model's evaluation is limited to specific tasks, and its performance on open-domain generation is not thoroughly benchmarked.",
      "strengths": [
        "Introduces a novel reparameterization technique enabling non-autoregressive inference, improving efficiency.",
        "Demonstrates competitive performance on conditional tasks such as machine translation, question generation, and paraphrasing.",
        "Provides a comprehensive analysis of the impact of iteration steps on generation quality and computational efficiency."
      ],
      "weaknesses": [
        "Limited evaluation on open-domain text generation tasks beyond specified conditional tasks.",
        "Computational cost comparison with other non-autoregressive models is not as extensive.",
        "Choice of iteration steps is not exhaustively explored, leaving room for further investigation.",
        "Model's performance on open-domain tasks is not thoroughly benchmarked against state-of-the-art models."
      ],
      "questions": [
        "How does the RDM perform on open-domain text generation tasks compared to state-of-the-art models?",
        "What is the impact of varying the number of iteration steps on open-domain generation quality?",
        "How does the RDM compare to other non-autoregressive diffusion models in terms of computational efficiency?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "1PXEY7ofFX",
    "title": "Bespoke Solvers for Generative Flow Models",
    "std_review": {
      "summary": "The paper introduces a novel solver for trajectory optimization that uses a learnable, scale‑time transformed velocity field to reduce the number of function evaluations needed for high‑quality trajectories. Experiments show significant speed improvements and competitive quality compared to existing methods, especially with fewer evaluations. The solver's efficiency and robustness are demonstrated through ablation studies and comparisons with distillation techniques. While the approach is innovative and effective, concerns about limited generalization and the lack of detailed training time breakdown for ground‑truth trajectory generation remain.",
      "strengths": [
        "Innovative solver design using a scale‑time transformed velocity field.",
        "Significant reduction in function evaluations leading to faster training without quality loss.",
        "Comprehensive ablation studies and strong baseline comparisons."
      ],
      "weaknesses": [
        "Limited generalization to other domains due to focused experiments.",
        "Training time justification is incomplete as the cost of generating ground‑truth trajectories is not detailed.",
        "Absence of robustness tests under varying conditions.",
        "Complexity of parameterization could be better explained."
      ],
      "questions": [
        "How does the solver perform when applied to a broader range of models and datasets?",
        "What is the exact computational cost of generating the ground‑truth trajectories used for training?",
        "Could you provide more details on the trade‑off analysis between speed and accuracy for the guidance weights?",
        "What are the specific impacts of the scale‑time transformation on solver order and the choice of base ODE solver?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1qDRwhe379",
    "title": "Refining Corpora from a Model Calibration Perspective for Chinese Spelling Correction",
    "std_review": {
      "summary": "The paper tackles the calibration issues of machine learning models trained on Chinese spelling correction datasets generated via OCR and ASR, proposing a BERT-based filtering method to improve calibration. It highlights differences between random replacement and OCR/ASR data augmentation, evaluates calibration impacts, and discusses implications for downstream tasks. While innovative, the study is limited to Chinese spelling correction and BERT-based models, with some concerns about generalizability and metric choices.",
      "strengths": [
        "Effectively addresses calibration challenges specific to OCR/ASR-generated datasets.",
        "Introduces a novel BERT-based filtering method to improve model calibration.",
        "Provides a thorough comparative analysis between random replacement and OCR/ASR data augmentation techniques."
      ],
      "weaknesses": [
        "Focuses solely on Chinese spelling correction, limiting generalizability.",
        "The filtering method is specific to BERT-based models, potentially limiting applicability.",
        "Does not extensively explore generalization to other data augmentation strategies or domains."
      ],
      "questions": [
        "How can the filtering approach be adapted for other languages or domains?",
        "What are the long-term effects of the proposed filtering method on model performance beyond calibration?",
        "How does the method perform with different types of models beyond BERT-based ones?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1qzUPE5QDZ",
    "title": "Rectifying Group Irregularities in Explanations for Distribution Shift",
    "std_review": {
      "summary": "The paper introduces Group‑aware Shift Explanations (GSE), a method that extends distributionally robust optimization by adding group constraints to minimize the worst‑group loss across demographic groups. Empirical results show improved robustness and fairness, with strong theoretical backing. However, the paper lacks clear guidance on defining groups when demographic information is ambiguous, and does not fully address scalability and computational complexity.",
      "strengths": [
        "Incorporates group constraints to address fairness in distributionally robust optimization.",
        "Provides strong theoretical guarantees for feasibility and robustness.",
        "Demonstrates empirical improvements in robustness and fairness across datasets."
      ],
      "weaknesses": [
        "Lacks a clear methodology for defining groups when demographic information is not explicitly available.",
        "Does not explicitly address how to handle ambiguous or biased group information.",
        "Theoretical guarantees are strong but their practical implications are not fully explored.",
        "Scalability and computational complexity are not adequately addressed."
      ],
      "questions": [
        "How should groups be defined when demographic information is ambiguous or missing?",
        "What safeguards are in place to handle potentially biased group information?",
        "How does the method scale to large datasets, especially when groups are automatically discovered?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "1RE0H6mU7M",
    "title": "MAMBA: an Effective World Model Approach for Meta-Reinforcement Learning",
    "std_review": {
      "summary": "MAMBA is a novel model-based meta-reinforcement learning algorithm that efficiently learns policies for tasks with decomposable structure. It introduces a hierarchical task decomposition and a dynamic horizon scheduling mechanism to improve sample efficiency and balance exploration and exploitation. Empirical results show that MAMBA outperforms existing methods on various decomposable tasks, demonstrating its effectiveness in high-dimensional environments. The paper highlights the algorithm's strengths in handling structured tasks but also notes its reliance on task decomposability and potential limitations in non-decomposable settings.",
      "strengths": [
        "Hierarchical task decomposition enables parallel learning and reduced sample complexity.",
        "Dynamic horizon scheduling balances exploration and exploitation based on task difficulty.",
        "Local reconstruction approach reduces computational burden while capturing essential task characteristics."
      ],
      "weaknesses": [
        "Effectiveness is limited to tasks that can be meaningfully decomposed.",
        "Local reconstruction may not capture global task dynamics as effectively as global methods.",
        "Performance is sensitive to hyperparameter choices, requiring careful tuning."
      ],
      "questions": [
        "How does MAMBA perform on non-decomposable tasks, and what adaptations would be needed for broader applicability?",
        "What are the theoretical guarantees for convergence and sample efficiency in non-decomposable settings?",
        "How does the choice of sub-episode horizon impact long-term performance in complex environments?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1rgMkDWfYV",
    "title": "",
    "std_review": {
      "summary": "The paper presents a semi-supervised learning framework that refines CLIP's loss formulation to improve zero-shot classification with noisy labels. It introduces a novel sample selection mechanism and demonstrates competitive performance on benchmarks. However, it lacks qualitative analysis, robustness evaluations, and a clear justification for the impact of label noise on the sample distribution.",
      "strengths": [
        "Introduces a novel sample selection mechanism for semi-supervised learning.",
        "Reformulates the CLIP loss to better handle noisy data, showing competitive results.",
        "Demonstrates practical utility with results on several benchmarks."
      ],
      "weaknesses": [
        "Lacks comprehensive qualitative analysis of how the method handles noisy data.",
        "Does not evaluate robustness across different model variants or vision-language models.",
        "The justification for label noise not affecting sample distribution is unclear."
      ],
      "questions": [
        "Could you provide visual or behavioral insights into how the method handles noisy data?",
        "What experiments demonstrate the method's robustness to variations in the backbone or different vision-language models?",
        "How does the method's performance compare to state-of-the-art methods in more detail?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "1RrOtCmuKr",
    "title": "Network Memory Footprint Compression Through Jointly Learnable Codebooks and Mappings",
    "std_review": {
      "summary": "The paper introduces a novel compression technique for large language models (LLMs) called Jointly Learnable Codebook and Mappings (JLCM), combining codebook quantization with scaling factors to achieve significant memory reduction while maintaining accuracy. The authors demonstrate strong empirical results across multiple models, showing practical viability and competitive performance compared to existing methods. Despite some implementation and comparison limitations, the paper is well‑structured, theoretically sound, and experimentally validated, leading to an acceptance recommendation.",
      "strengths": [
        "Innovative combination of codebook quantization and scaling factors for LLM compression.",
        "Clear theoretical framework with a mathematical relationship between compression ratio, codebooks, and scaling factors.",
        "Empirical validation across several benchmark models showing strong compression ratios and competitive accuracy.",
        "Discussion of computational overhead and practical implications for resource‑constrained devices."
      ],
      "weaknesses": [
        "Increased implementation complexity due to managing multiple codebooks and scaling factors.",
        "Lack of detailed justification or empirical evidence linking neuron clustering to performance gains.",
        "Limited comparison with recent state‑of‑the‑art techniques like SqueezeLLM and AWQ.",
        "Potential additional computational overhead during inference from codebook and mapping management."
      ],
      "questions": [
        "Could you provide more detailed empirical evidence or analysis on the trade‑offs between compression efficiency and computational overhead during inference?",
        "How does the clustering technique impact the overall compression ratio, and are there alternative clustering methods that could further improve results?",
        "What are the specific computational costs associated with managing codebooks and mappings during training and inference, and how do they compare to existing methods?",
        "Could you explore the impact of JLCM on latency and data transfer speeds on edge devices with limited resources?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1SbkubNdbW",
    "title": "Be Careful What You Smooth For:",
    "std_review": {
      "summary": "The paper introduces a novel technique for label smoothing that targets negative labels, aiming to improve model robustness against adversarial attacks while maintaining performance. Experiments across multiple datasets and models show significant gains in robustness, though the approach's generalizability and broader defensive capabilities remain underexplored. The study highlights practical benefits but lacks comprehensive comparative analysis and performance metrics beyond robustness.",
      "strengths": [
        "Introduces a novel method of label smoothing targeting negative labels.",
        "Demonstrates empirical improvements in adversarial robustness across multiple datasets and models.",
        "Clearly defines the problem, proposes a specific solution, and evaluates its effectiveness."
      ],
      "weaknesses": [
        "Focuses primarily on adversarial attacks, with limited exploration of other vulnerabilities.",
        "Findings are dataset and model specific, limiting generalizability.",
        "Performance metrics are not fully defined, focusing mainly on robustness.",
        "Lacks a broader comparative analysis with other defensive techniques."
      ],
      "questions": [
        "Can the technique be evaluated against other types of attacks, such as backdoor attacks?",
        "How does the technique affect model generalization to unseen data beyond adversarial examples?",
        "What are the computational or resource implications of applying negative label smoothing?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "1SIBN5Xyw7",
    "title": "",
    "std_review": {
      "summary": "The paper introduces Meta‑SpikeFormer, a novel spiking neural network architecture that combines transformer principles with spike‑driven mechanisms, achieving competitive accuracy on ImageNet‑1K while significantly reducing energy consumption. The authors highlight its potential for energy‑efficient deep learning, especially in neuromorphic hardware, and discuss its theoretical contributions and empirical validation. However, the paper has limitations such as limited scope to vision tasks, lack of detailed hardware integration discussion, higher parameter count, and insufficient benchmark comparisons across domains.",
      "strengths": [
        "Innovative architecture merging transformer principles with spike‑driven learning.",
        "Demonstrates significant energy efficiency improvements over existing SNN models.",
        "Makes valuable theoretical contributions with new SDSA operators and shortcut mechanisms.",
        "Provides comprehensive empirical validation on ImageNet‑1K with competitive accuracy and lower power consumption."
      ],
      "weaknesses": [
        "Evaluation is primarily focused on vision tasks, limiting the architecture's demonstrated versatility.",
        "Lacks detailed discussion on hardware integration with neuromorphic platforms.",
        "Model parameter count is higher than some competing SNN models, which may be a concern for resource‑constrained environments.",
        "Benchmark comparisons are limited to ImageNet‑1K, potentially limiting the generalizability of the results."
      ],
      "questions": [
        "How can the proposed architecture be extended to other domains beyond vision, such as natural language processing?",
        "What are the specific steps for integrating Meta‑SpikeFormer with existing neuromorphic hardware platforms?",
        "How does the model's performance scale with increasing parameter counts, and what trade‑offs are involved?",
        "Could a broader set of state‑of‑the‑art models be compared to better assess the architecture's generalizability across domains?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1SO93f7sVf",
    "title": "Training Neural Networks from Scratch",
    "std_review": {
      "summary": "The paper introduces Low‑Rank Tensor Estimation (LTE), a method that accelerates large‑scale model training by using multi‑head LoRA for parallel low‑rank updates, reducing communication overhead and improving efficiency. LTE achieves competitive performance with faster training times and lower memory usage compared to standard distributed training and other low‑rank methods. While promising, the approach has some limitations, such as limited quantitative analysis of staleness impact and scalability issues for very large models.",
      "strengths": [
        "Innovative parallel update mechanism using multi‑head LoRA.",
        "Significant reduction in communication overhead through infrequent synchronization.",
        "Strong empirical performance with reduced training time and memory usage."
      ],
      "weaknesses": [
        "Lack of detailed analysis on the trade‑offs between staleness and accuracy.",
        "Limited exploration of scalability for very large models.",
        "Insufficient comparison with other state‑of‑the‑art methods.",
        "Vague implementation details of the synchronization mechanism."
      ],
      "questions": [
        "How does the choice of staleness impact the final model accuracy?",
        "What are the practical resource requirements for scaling LTE to extremely large models?",
        "How does LTE compare to federated learning approaches in terms of efficiency and performance?",
        "Can the synchronization mechanism be made more explicit for reproducibility?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1tDoI2WBGE",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a framework for concept-based reasoning in machine learning models, aiming to improve interpretability by explicitly incorporating human-defined concepts (concept words) into the learning process. It demonstrates strong empirical results across multiple datasets, showing significant improvements in aligning model predictions with intended concepts compared to baselines. While the approach is innovative and addresses key interpretability challenges, some details, such as the curation of concept words and the exact role of learnable parameters, could be further clarified.",
      "strengths": [
        "Introduces a systematic way to integrate human-defined concepts into model training, addressing a key gap in current interpretability methods.",
        "Provides a clear evaluation strategy that assesses alignment of model predictions with intended concepts, offering concrete metrics for interpretability.",
        "Offers a solid theoretical foundation with a comprehensive mathematical formulation that delineates the role of learnable parameters in concept embeddings and aggregation.",
        "Demonstrates robust experimental validation across multiple datasets, showing significant improvements over baseline models."
      ],
      "weaknesses": [
        "The process of determining and curating concept words is not fully detailed, which may affect reproducibility and generalizability.",
        "The exact role of learnable parameters in modifying concept embeddings and influencing aggregation is somewhat abstract.",
        "The rationale for injecting neutral or irrelevant concept words during inference is not clearly articulated.",
        "The mathematical formulation, while comprehensive, may be challenging for readers without a strong background in machine learning."
      ],
      "questions": [
        "How are concept words curated to ensure they are relevant and distinct from potential noise or irrelevant terms?",
        "What is the precise role of learnable parameters in adjusting concept embeddings and influencing aggregation functions?",
        "Why are neutral or irrelevant concept words injected during inference, and how does this affect the interpretability benefits?",
        "Could additional examples or context be provided to help readers without a strong ML background understand the mathematical formulation?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1tZbq88f27",
    "title": "MiniGPT-4:",
    "std_review": {
      "summary": "The paper introduces a method for enhancing vision-language models by incorporating multi-modal instruction tuning using a diverse set of Advanced Abilities tasks. While the approach shows promise in improving the models' ability to generate concise captions, it has several weaknesses, including unclear task selection criteria, unspecified evaluation tools, and potential issues with the caption evaluation method. The authors should address these concerns and properly cite recent related work to strengthen the contribution.",
      "strengths": [
        "Introduces a novel set of Advanced Abilities tasks designed to challenge model captioning capabilities.",
        "Proposes a systematic multi-modal instruction tuning approach for vision-language models.",
        "Demonstrates effectiveness through extensive experiments on benchmark datasets."
      ],
      "weaknesses": [
        "Lack of clear criteria for selecting Advanced Abilities tasks.",
        "Unspecified version of ChatGPT used for answer revision.",
        "Potential issues with randomly selecting ground-truth captions for evaluation.",
        "Missing CHAIR score in Table 5 for comprehensive comparison.",
        "MiniGPT-4 fails to meet the 20-word instruction requirement.",
        "Claims no equivalent datasets exist, despite recent studies like LLaVA, InstructBLIP, etc."
      ],
      "questions": [
        "What are the specific criteria used to select the Advanced Abilities tasks?",
        "Which version of ChatGPT was used for answer revision in the experiments?",
        "How does the approach of randomly selecting ground-truth captions address potential inconsistencies?",
        "Why is the CHAIR score missing from Table 5?",
        "How can the model be encouraged to satisfy the 20-word instruction requirement?",
        "Should recent datasets like LLaVA, InstructBLIP, etc., be cited and considered for future work?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "1uHTIjXjkk",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a diffusion‑based motion planning framework that leverages diffusion processes to generate collision‑free paths. While theoretically promising for avoiding local minima and producing smooth trajectories, the method's novelty is largely theoretical with limited empirical validation on diverse obstacle configurations. The authors highlight potential benefits but also note significant gaps in empirical evaluation and theoretical guarantees.",
      "strengths": [
        "Introduces a novel diffusion‑based approach to motion planning.",
        "Leverages diffusion processes to theoretically ensure collision avoidance.",
        "Generates smooth and aesthetically pleasing trajectories."
      ],
      "weaknesses": [
        "Limited empirical validation on complex obstacle configurations.",
        "Lacks formal theoretical guarantees for optimality or completeness.",
        "Requires re‑training for each start‑goal pair, raising practicality concerns."
      ],
      "questions": [
        "Could additional results on concave obstacle environments better evaluate the method's performance relative to traditional potential‑field methods?",
        "What formal analysis justifies the collision‑free nature of the generated paths?",
        "How does the algorithm handle kinodynamic planning with dynamic constraints?",
        "What is the empirical success rate of the method under various conditions, and how does it compare to sampling‑based baselines?"
      ],
      "overall_score": "Borderline",
      "confidence": "Medium"
    }
  },
  {
    "paper_id": "1V1QQYARmd",
    "title": "Nearest neighbor-based out-of-distribution detection via label smoothing",
    "std_review": {
      "summary": "The paper presents a novel unsupervised out‑of‑distribution (OOD) detection method that uses intermediate embeddings from a pre‑trained network to identify OOD samples as those farthest from in‑distribution data in an embedding space. Experiments on several benchmark datasets show competitive performance, especially when only a small ID dataset is available. While the method is theoretically justified and empirically validated, it lacks comprehensive theoretical guarantees and thorough comparison with label‑distribution‑based baselines.",
      "strengths": [
        "Introduces a unique unsupervised OOD detection strategy based on embedding space distance.",
        "Works well with small ID datasets, making it broadly applicable.",
        "Provides a clear theoretical justification for preferring distance‑based approaches."
      ],
      "weaknesses": [
        "Lacks quantitative theoretical guarantees for the method.",
        "Performance is sensitive to the choice of the k‑NN radius.",
        "Does not compare with label‑distribution‑based baselines when auxiliary OOD data is unavailable.",
        "Missing ablation studies on the importance of intermediate embeddings versus softmax probabilities."
      ],
      "questions": [
        "Can the theoretical results be quantified with concrete bounds or guarantees?",
        "How sensitive is the method to the choice of the k‑NN radius, and are there guidelines for tuning it?",
        "How does the method compare to label‑distribution‑based baselines when no auxiliary OOD data is available?",
        "Could an ablation study demonstrate the importance of using intermediate embeddings versus softmax class probabilities?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "1VcKvdYbUM",
    "title": "",
    "std_review": {
      "summary": "The paper introduces APBench, a comprehensive benchmarking framework for evaluating data poisoning attacks on machine learning models. It defines a precise threat model and evaluates a wide range of attacks and defenses across multiple datasets and augmentations, revealing limitations of existing methods. The framework demonstrates that many defenses are vulnerable to sophisticated poisoning attacks, emphasizing the need for robust countermeasures. The reviewer finds the framework valuable and recommends acceptance.",
      "strengths": [
        "Comprehensive Threat Model",
        "Extensive Evaluation",
        "Benchmarking Framework",
        "Revealing Limitations"
      ],
      "weaknesses": [
        "Implementation Effort",
        "Reproducibility Challenges",
        "Scope Limitations"
      ],
      "questions": [
        "How can the benchmark be extended to include more specialized or emerging attack strategies?",
        "What steps can be taken to improve reproducibility and ease of implementation?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1vCnDyQkjg",
    "title": "Unified Human-Scene Interaction via Prompted Chain-of-Contacts",
    "std_review": {
      "summary": "The paper introduces UniHSI, a framework that integrates large language model planners with human-in-the-loop feedback to generate realistic human motions. It effectively models joint interactions and object contacts, using adversarial learning to refine motion realism. While demonstrating improvements over baselines, the paper lacks comprehensive comparisons with other methods and discusses limitations in handling dynamic scenes.",
      "strengths": [
        "Integration of LLMs and human feedback enhances motion realism and complexity.",
        "Adversarial learning ensures generated motions are both diverse and realistic.",
        "Scalable to complex interactions suitable for advanced robotic tasks."
      ],
      "weaknesses": [
        "Limited evaluation metrics may not fully capture global realism and semantic fidelity.",
        "Nearest-point contact mapping may not always yield meaningful contact points.",
        "Dataset quality concerns due to automatic generation by LLMs.",
        "Performance variability with different LLMs or prompting strategies is not thoroughly explored."
      ],
      "questions": [
        "How do success rates and contact errors align with global realism and semantic fidelity?",
        "What post-processing steps ensure the quality of the ScenePlan dataset?",
        "How robust is UniHSI to variations in LLM planners?",
        "What are the implications of using nearest-point contact mapping for meaningful contact points?",
        "How does UniHSI compare to other state-of-the-art methods for complex interaction tasks?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "1vDArHJ68h",
    "title": "",
    "std_review": {
      "summary": "The paper introduces R2I, a reinforcement learning method that integrates a learned world model into the RL loop, achieving sample efficiency comparable to state-of-the-art model-based RL systems while being more sample-efficient. It systematically explores how different components of the world model influence policy performance across various environments. The method shows strong empirical results but has limitations in generality, statistical rigor, and baseline selection.",
      "strengths": [
        "Innovative integration of world model predictions with RL offers a fresh perspective on model-based RL.",
        "Demonstrates significant sample efficiency gains over traditional RL methods, providing a compelling practical advantage.",
        "Comprehensive evaluation across multiple environments and tasks provides robust evidence of the method's generalizability."
      ],
      "weaknesses": [
        "Policy input selection is highly environment-specific, which may limit the method's broad applicability.",
        "A noticeable performance gap on standard RL benchmarks raises questions about the method's generality compared to state-of-the-art models.",
        "Lacks standardized statistical methodology for comparing RL models, affecting the interpretation of performance differences.",
        "Omits Transformer-based world models from the comparison, potentially overlooking significant alternatives.",
        "Lacks clear definition of what constitutes 'significantly worse' or 'on par' performance, making it difficult to fully assess results."
      ],
      "questions": [
        "How can the method be generalized to environments where the choice of policy input is not environment-specific?",
        "What is the impact of omitting Transformer-based world models from the comparison, and how does it affect the perceived generality of R2I?",
        "What statistical rigor should be adopted to more robustly compare RL models across different benchmarks?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "1VeQ6VBbev",
    "title": "Beyond Stationarity:",
    "std_review": {
      "summary": "The paper presents a dynamic policy gradient algorithm for finite-horizon MDPs, extending convergence analysis from infinite to finite horizons. It leverages a dynamic programming perspective to achieve tighter convergence guarantees and focuses on unregularized softmax policies, showing competitive performance in numerical experiments. However, scalability and robustness issues remain, and the analysis relies on specific MDP assumptions. Overall, the work is innovative and promising, with clear extensions to infinite-horizon and non-stationary settings.",
      "strengths": [
        "Innovative convergence analysis for finite-horizon MDPs",
        "Dynamic programming perspective leading to tighter guarantees",
        "Focus on unregularized softmax policies with practical benefits",
        "Empirical comparisons demonstrating effectiveness in tabular settings"
      ],
      "weaknesses": [
        "Limited scalability to larger MDPs",
        "Assumptions on MDP structure may not hold in all cases",
        "Lack of robustness analysis",
        "Comparative experiments limited to tabular MDPs"
      ],
      "questions": [
        "How does the algorithm scale to larger, more complex MDPs?",
        "What is the robustness of the algorithm to parameter variations or noisy environments?",
        "Can the dynamic programming perspective be extended to infinite-horizon or non-stationary settings without significant modifications?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1vmSEVL19f",
    "title": "Directly Fine-Tuning Diffusion Models on Differentiable Rewards",
    "std_review": {
      "summary": "The paper introduces DRaFT, a method for fine-tuning diffusion models using differentiable rewards, which directly optimizes model parameters to align generated outputs with desired criteria. Experiments show DRaFT outperforms baselines on various tasks, indicating practical utility. However, the paper lacks clear explanation of its relationship to prior work, limited validation of compatibility with other parameter-efficient fine-tuning methods, and comparison with relevant methods like DPOK. The choice of model version is also unexplained.",
      "strengths": [
        "Introduces a novel approach to fine-tuning diffusion models using differentiable rewards.",
        "Demonstrates empirical improvements over existing methods on multiple tasks.",
        "Provides a clear and accessible methodology."
      ],
      "weaknesses": [
        "Does not clearly articulate the relationship to prior work.",
        "Lacks detailed exploration of compatibility with other PEFT methods.",
        "Does not compare performance to DPOK.",
        "The use of the 'stop_grad' function is not adequately explained.",
        "The choice of Stable-Diffusion v1.4 is not justified."
      ],
      "questions": [
        "How does DRaFT extend or differ from prior methods that use differentiable rewards for model fine-tuning?",
        "What is the impact of using the 'stop_grad' function on DRaFT's performance?",
        "How does DRaFT's performance compare to DPOK?",
        "What is the justification for choosing Stable-Diffusion v1.4 over newer versions?"
      ],
      "overall_score": "6: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "1vqHTUTod9",
    "title": "Can Language Models be Instructed to",
    "std_review": {
      "summary": "The paper introduces PRIVQA, a benchmark for evaluating privacy risks in multimodal LLMs by assessing leakage of sensitive attributes like age, citizenship, and occupation. It provides a realistic threat model, a diverse dataset of public figures, and clear evaluation metrics. The self‑moderation technique is shown to reduce privacy breaches compared to baselines, highlighting practical implications and suggesting future research. Overall, the paper is well‑structured and makes a valuable contribution to privacy evaluation in LLMs.",
      "strengths": [
        "Comprehensive privacy evaluation framework for multimodal LLMs.",
        "Realistic threat modeling aligning with jailbreaking and model editing.",
        "Diverse dataset of public figures and protected attributes.",
        "Clear and interpretable privacy metrics.",
        "Robust baseline comparisons demonstrating effectiveness."
      ],
      "weaknesses": [
        "Limited scope focusing on a narrow set of protected attributes and public figures.",
        "Potential bias in dataset due to selection of scrutinized public figures.",
        "Lack of baselines like machine unlearning or differential privacy.",
        "Qualitative analysis gaps in attack scenarios.",
        "Generalizability concerns to under‑represented groups."
      ],
      "questions": [
        "How can the benchmark be extended to cover less common or under‑represented protected attributes?",
        "What are the implications of using public figures for dataset curation?",
        "How does the benchmark perform when applied to models with different architectures or sizes?",
        "Could additional baselines such as machine unlearning or differential privacy provide a more comprehensive evaluation?",
        "What qualitative analyses of successful attacks could further elucidate the practical impact of privacy leaks?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1vrS1zwekw",
    "title": "Multi-Crating Multi-Faceted Instructions for Improving Instruction-Following",
    "std_review": {
      "summary": "The paper introduces MUFFIN, a method that generates facets from LLMs to enhance the BBH benchmark for evaluating language models' ability to generate coherent and contextually relevant elaborations. While the facet generation process is effective, the resulting tasks introduce challenges that affect model performance, particularly on the BBH benchmark. The method is innovative but lacks rigorous evaluation and clear analysis of limitations.",
      "strengths": [
        "Innovative facet generation leveraging LLMs for scalable task expansion.",
        "Enhanced benchmark with richer evaluation of language models' elaboration capabilities.",
        "Methodological rigor with detailed analyses of facet quality and performance."
      ],
      "weaknesses": [
        "Lack of trustworthiness mechanisms beyond human inspection for facet reliability.",
        "Limited evaluation metrics for facet quality and diversity.",
        "Unclear explanation for significant performance gaps on the BBH benchmark."
      ],
      "questions": [
        "What mechanisms ensure the trustworthiness of facets generated by the LLM?",
        "How is facet diversity quantified and compared to benchmarks?",
        "What specific analyses explain the performance drop on the BBH benchmark?",
        "What criteria are used to select tasks for classification expansion?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "1WceuzWff5",
    "title": "Understanding the Transfer of High-Level Reinforcement Learning Skills Across Diverse Environments",
    "std_review": {
      "summary": "The paper introduces SEAL, a method that pads state dimensions to align different state spaces for multi-environment transfer learning. Evaluated on Meta-World, SEAL shows improved performance in adapting policies across diverse tasks, highlighting its effectiveness in mitigating state semantics and task structure challenges. While innovative, the method has concerns about overfitting, limited exploration of task diversity, and scalability in large state spaces.",
      "strengths": [
        "Innovative approach to aligning state spaces with semantic mismatches.",
        "Empirical success on Meta-World demonstrating practical utility.",
        "Clear theoretical foundation for state space alignment."
      ],
      "weaknesses": [
        "Potential overfitting in complex environments.",
        "Limited exploration of how source environment skill diversity affects target performance.",
        "Reliance on task IDs for relational structure lacks extensive validation."
      ],
      "questions": [
        "How does SEAL handle overfitting in environments with high-dimensional or complex state spaces?",
        "What is the impact of the diversity of skills in the source environment on the target policy's performance?",
        "How does the alignment of task IDs compare to other methods for incorporating relational task structure?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "1Wi0Ys33Nm",
    "title": "Beyond iid weights: sparse and low-rank deep neural networks are also Gaussian Processes",
    "std_review": {
      "summary": "The paper introduces a novel framework for analyzing deep neural network convergence by extending the pseudo‑iid assumption beyond the iid setting. It builds on prior work and provides theoretical insights into network behavior under pseudo‑iid conditions, suggesting benefits for initialization and regularization. While the theoretical contributions are significant, the paper has several weaknesses, including unclear notation, limited comparison with existing work, and insufficient experimental validation, leading to a recommendation of weak accept.",
      "strengths": [
        "Theoretical Contribution: Extends the pseudo‑iid assumption beyond iid, offering a more flexible framework for analyzing network convergence.",
        "Novel Example Distributions: Introduces low‑rank and block‑sparse distributions as concrete examples of pseudo‑iid variables.",
        "Practical Implications: Links the pseudo‑iid assumption to practical initialization schemes, suggesting benefits for convergence and stability."
      ],
      "weaknesses": [
        "Lack of Definition: The symbol 'a' is introduced without definition in Definition 1.",
        "Limited Comparison: Does not comprehensively compare the pseudo‑iid approach to prior work.",
        "Practical Significance: Does not clearly explain why the broader class of pseudo‑iid random variables is practically interesting.",
        "Input Space Assumption: Convergence results assume a countably infinite input space, limiting applicability.",
        "Generality of First‑Layer Assumption: Proofs assume the first layer's weights are Gaussian IID, which may not be realistic.",
        "Limited Experimental Validation: Experiments focus on a single initialization scheme, lacking broader validation."
      ],
      "questions": [
        "Please provide a clear definition of the symbol 'a' used in Definition 1.",
        "How does the pseudo‑iid approach fundamentally differ from and improve upon prior work such as Matthews et al. (2018)?",
        "What is the practical significance of considering a broader class of pseudo‑iid random variables?",
        "How does the assumption of a countably infinite input space affect the interpretation of the convergence results?",
        "Why are the example distributions (e.g., low‑rank, block‑sparse) considered novel and relevant?",
        "How can the generality of the results be extended beyond the assumption of Gaussian IID weights for the first layer?",
        "What additional experiments are needed to validate the theoretical findings across different initialization schemes, especially for convolutional networks?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "1WSd408I9M",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a framework for integrating generative AI into healthcare, addressing trustworthiness, safety, and interpretability. It proposes a methodological approach with concrete steps for ensuring model reliability and safety, though empirical validation is limited. The authors highlight ethical implications and potential benefits, but the lack of robust empirical evidence and more focused literature review are noted. Overall, the paper shows promise with a strong conceptual framework but requires further validation.",
      "strengths": [
        "Introduces a novel framework addressing key desiderata for generative AI in healthcare.",
        "Proposes concrete methodological steps for ensuring model reliability and safety.",
        "Provides a thorough discussion of ethical implications and challenges."
      ],
      "weaknesses": [
        "Empirical evidence is limited to illustrative case studies.",
        "Lacks detailed empirical studies demonstrating impact on healthcare outcomes.",
        "Calls for more rigorous testing and validation of the framework."
      ],
      "questions": [
        "What are the specific metrics for evaluating the impact of the framework on healthcare outcomes?",
        "How can the framework be validated in diverse healthcare settings?",
        "What additional empirical studies are needed to support the proposed framework?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "1XarNmzbgG",
    "title": "Understanding of Server-Assisted Federated Learning with Incomplete Client Participation",
    "std_review": {
      "summary": "The paper introduces SAFARI, a server‑assisted federated learning framework that improves PAC‑learnability in scenarios with incomplete client participation by leveraging an auxiliary server dataset. The authors provide theoretical PAC‑learnability analysis under bounded gradient dissimilarity assumptions and derive convergence rates influenced by the auxiliary dataset size. Empirical experiments validate the theoretical claims, showing improved performance over FedAvg, though practical challenges remain in obtaining suitable server data.",
      "strengths": [
        "Introduces a novel server‑assisted federated learning framework that enhances PAC‑learnability.",
        "Provides strong theoretical PAC‑learnability analysis under well‑defined assumptions.",
        "Demonstrates empirical improvements over FedAvg, aligning theory with practice."
      ],
      "weaknesses": [
        "Relies on a bounded gradient dissimilarity assumption that may be restrictive in real‑world settings.",
        "Practical challenges in obtaining a large, i.i.d. auxiliary dataset could limit deployment.",
        "Lacks clear guidance on optimal parameter settings despite highlighting sensitivity to q and η."
      ],
      "questions": [
        "How can the bounded gradient dissimilarity assumption be relaxed for broader applicability?",
        "What strategies can be employed to obtain a sufficiently large, privacy‑compliant auxiliary dataset?",
        "How do the theoretical convergence rates translate to practical training times on realistic datasets?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1XDG1Z5Nhk",
    "title": "",
    "std_review": {
      "summary": "SparseMixer presents a novel sparse mixture‑of‑experts architecture for vision transformers, leveraging a top‑k routing mechanism and ω‑scaling to improve efficiency and performance. The model shows competitive results on ImageNet‑1K and CIFAR while reducing computational overhead compared to Switch Transformers. The paper is well‑structured, clearly describing its contributions and empirical validation, though it acknowledges some implementation challenges. Overall, the work is promising and should be accepted.",
      "strengths": [
        "Introduces a top‑k routing mechanism that allows multiple experts to be active per layer, potentially capturing richer representations.",
        "Proposes ω‑scaling, a dynamic scaling factor that improves training stability and throughput without significant additional cost.",
        "Demonstrates strong empirical performance on standard benchmarks, achieving competitive results with reduced computational overhead.",
        "Provides a clear analysis of the trade‑offs between model efficiency and performance, offering insights into sparse MoE components."
      ],
      "weaknesses": [
        "Adapting the top‑k routing mechanism introduces additional computational complexity, which may be unintuitive for practitioners familiar with top‑1 MoE models.",
        "Lacks direct comparisons with Switch Transformers using ω‑scaling, making it difficult to fully assess the relative gains.",
        "Table 3 presents identical training costs for SparseMixer and Switch Transformer, but does not account for overhead from ω‑scaling, potentially misleading readers.",
        "Evaluation is limited to Switch Transformers, with limited exploration of SparseMixer's performance on other MoE architectures."
      ],
      "questions": [
        "Can SparseMixer be extended to k > 1 easily, and what are the computational implications?",
        "Please clarify the empirical contribution of ω‑scaling when compared to Switch Transformers with ω‑scaling.",
        "Please clarify the overhead in SparseMixer in Table 3 and report the total training time.",
        "What is the computational cost induced by SparseMixer, and how does it scale with the number of experts?",
        "How does SparseMixer perform when applied to other MoE gating methods or architectures (e.g., GLAM, XMoE) beyond Switch Transformer?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1XReHUSUp9",
    "title": "Monsters in the Dark: Sanitizing Hidden Threats with Diffusion Models",
    "std_review": {
      "summary": "The paper introduces DM‑SUDS, a diffusion model-based steganography method that embeds messages in images with improved robustness. It outperforms baseline and several steganography techniques in evaluations, showing strong noise resistance and consistent performance. However, the evaluation is limited to a single dataset, lacks comparison with robust steganography methods, and does not test robustness against JPEG compression or detailed parameter analysis.",
      "strengths": [
        "Innovative use of diffusion models for steganography, enabling gradual and controlled embedding.",
        "Demonstrated strong robustness against noise, a critical requirement for real-world applications.",
        "Consistent performance improvements across multiple steganography techniques compared to a baseline."
      ],
      "weaknesses": [
        "Evaluation limited to the CIFAR‑10 dataset, which may not fully represent real-world scenarios.",
        "No comparison with robust steganography methods, limiting the assessment of practical robustness.",
        "Lack of testing against JPEG compression, a common image format.",
        "Absence of detailed analysis of parameter selection, affecting reproducibility."
      ],
      "questions": [
        "Should DM‑SUDS be evaluated against robust steganography methods for a more comprehensive robustness assessment?",
        "What is the impact of the noise variance parameter and timestep choice on DM‑SUDS, and how can this be quantified?",
        "How does DM‑SUDS perform against JPEG compression, and what are the implications for real-world use?",
        "What is the typical message length hidden in images, and how does it affect the robustness of the hidden message?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "1xyar0Ko3E",
    "title": "Efficient Quantization-aware Training with Adaptive Coreset Selection",
    "std_review": {
      "summary": "The paper introduces EVS and DS metrics for adaptive coreset selection in quantization-aware training, showing significant speed improvements without accuracy loss. It provides theoretical guarantees linking the metrics to error bounds and offers extensive empirical evidence across datasets. While introducing computational overhead and being specific to QAT, the method demonstrates broad applicability and robustness, though further comparison and analysis are suggested.",
      "strengths": [
        "Introduces innovative EVS and DS metrics for quantization-aware training.",
        "Provides theoretical guarantees linking metrics to error bounds.",
        "Demonstrates strong empirical improvements in training speed and accuracy."
      ],
      "weaknesses": [
        "Adds computational overhead for EVS and DS calculation.",
        "Tailored for quantization-aware training, may need adaptation for other quantization types.",
        "Limited comparison scope with other methods."
      ],
      "questions": [
        "How does the method perform on very large models or datasets?",
        "What is the robustness of the method to different types of noise or outliers?",
        "How does the method compare to state-of-the-art post-training quantization techniques?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1yll8U12GT",
    "title": "Enhancing Decision Tree Learning with Deep Networks",
    "std_review": {
      "summary": "The paper introduces ZanDT, a novel oblique decision‑tree algorithm that uses a hyperplane discontinuity score (HDS) to select splits, improving accuracy over greedy methods in high‑dimensional spaces. Theoretical work justifies why greedy approaches fail in such settings, and experiments show ZanDT can recover true hyperplanes. A deep‑learning network enhances robustness, but the method is computationally intensive and lacks multi‑class extensions.",
      "strengths": [
        "Innovative splitting criterion using hyperplane discontinuity score (HDS).",
        "Strong theoretical foundation explaining why greedy methods fail in high dimensions.",
        "Empirical validation demonstrating superior performance on synthetic datasets."
      ],
      "weaknesses": [
        "High computational cost due to neural network training at each node and DBSCAN clustering.",
        "No clear extension to multi‑class classification problems.",
        "Relies on specific assumptions about data distribution that may not hold in practice."
      ],
      "questions": [
        "How can the method be extended to multi‑class classification?",
        "What is the impact of the computational cost on scalability for large datasets?",
        "How robust is the method to noisy or imbalanced data?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1YO4EE3SPB",
    "title": "A Variational Perspective on Solving Inverse Problems with Diffusion Models",
    "std_review": {
      "summary": "The paper introduces RED-diff, a diffusion-based denoiser that uses variational inference with a unimodal Gaussian to approximate the true posterior of noisy signals. It outperforms existing diffusion samplers in PSNR/SSIM and KID/LPIPS metrics across various inverse problems, supported by theoretical justifications. While the unimodal approximation may limit performance in multimodal cases, the method offers flexibility and strong empirical results.",
      "strengths": [
        "Introduces a novel variational approach using a unimodal Gaussian to approximate the true posterior.",
        "Demonstrates superior reconstruction quality and lower diffusion metrics compared to state-of-the-art samplers.",
        "Provides a theoretical foundation linking the score function to the true posterior, ensuring convergence.",
        "Offers flexibility by allowing non-zero dispersion parameters beyond MAP estimation."
      ],
      "weaknesses": [
        "The unimodal Gaussian approximation may struggle with highly multimodal true posteriors.",
        "The variational step introduces a unimodal Gaussian, differing from the fixed-point iteration of the RED framework.",
        "Lacks direct comparison with plug-and-play methods.",
        "The impact of the sampling schedule on performance is not thoroughly analyzed.",
        "Concerns about computational cost scaling with image size and iteration count."
      ],
      "questions": [
        "How does the method perform on highly multimodal true posteriors?",
        "What is the impact of the sampling schedule on the final reconstruction quality?",
        "How does the proposed method compare to plug-and-play approaches in terms of performance and robustness?",
        "What are the theoretical guarantees for convergence when the posterior is non-Gaussian?",
        "How does the computational cost scale with larger image sizes and more iterations?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1YSJW69CFQ",
    "title": "",
    "std_review": {
      "summary": "The paper presents a novel approach to uncertainty-aware ensemble boosting for medical image segmentation using V‑Net and a unique test-time augmentation method. It aims to improve both reliability and accuracy, addressing challenges like batch effects. While innovative, the paper lacks clarity in task definition, uncertainty incorporation, and originality of the URF technique, and does not sufficiently compare its methods or address batch effects.",
      "strengths": [
        "Innovative integration of a segmentation backbone with uncertainty estimation techniques.",
        "Novel test-time augmentation method that outperforms existing approaches.",
        "Clear motivation and relevance to medical imaging challenges."
      ],
      "weaknesses": [
        "Ambiguity in whether the task is pixel-wise segmentation or image-level classification.",
        "Unclear how uncertainty scores are incorporated into model predictions.",
        "Lack of detailed explanation of how the URF technique differs from existing methods.",
        "Insufficient comparison with baselines for the TTA approach.",
        "Unclear context for the referenced Grand Challenge 4.",
        "Limited discussion on how the method addresses batch effects."
      ],
      "questions": [
        "How exactly are the entropy scores from Monte Carlo Dropout used in the model's predictions or loss function?",
        "What differentiates the URF technique from other uncertainty-aware ensemble boosting methods?",
        "Could you provide a detailed comparison of the TTA method with other TTA techniques?",
        "How does the method specifically address batch effects in medical imaging datasets?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "1zhM0XkQh0",
    "title": "",
    "std_review": {
      "summary": "The paper introduces ProFeAT, a self-supervised pre-training framework that enhances model robustness against adversarial attacks by combining a projector, an augmented teacher, and a defense loss. It achieves state-of-the-art performance on both standard and adversarial benchmarks, including smaller datasets like Caltech 101. While the method shows strong empirical results, there are areas for improvement in component analysis and metric consistency.",
      "strengths": [
        "Innovative combination of techniques to improve robustness.",
        "Demonstrates strong empirical results on both standard and adversarial benchmarks.",
        "Shows effectiveness in low-data regimes."
      ],
      "weaknesses": [
        "Lack of isolated component analysis could provide deeper insights.",
        "Inconsistent metric reporting reduces clarity.",
        "Limited discussion on the impact of different attack losses."
      ],
      "questions": [
        "Could the impact of each component be isolated in future experiments?",
        "How does the choice of attack loss affect the trade-off between clean and robust accuracy?",
        "Would a more comprehensive set of baselines strengthen the comparative analysis?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "1zt8GWZ9sc",
    "title": "Quack: Automatic Jailbreaking Large Language Models via Role-playing",
    "std_review": {
      "summary": "The paper investigates jailbreak prompts for ChatGPT using healthcare questions, employing an iterative refinement process on a knowledge graph to guide responses. It evaluates different OpenAI library versions and introduces a Materializer role for oracle answers. While highlighting the vulnerability of AI systems in sensitive domains, the study's lack of clear effectiveness criteria, detailed refinement process, comprehensive testing, and thorough safety measures for the Materializer role weakens its impact.",
      "strengths": [
        "Provides a comprehensive evaluation of jailbreak prompts against healthcare questions.",
        "Introduces a novel iterative refinement process for mitigating jailbreak attacks.",
        "Demonstrates proactive safety measures with the Materializer role."
      ],
      "weaknesses": [
        "Effectiveness criteria for jailbreak prompts are not clearly defined.",
        "Iterative refinement process lacks detailed explanation.",
        "Limited set of testing questions restricts generalizability.",
        "Safety measures for the Materializer role are not thoroughly described."
      ],
      "questions": [
        "Could you clarify the specific effectiveness criteria used for evaluating jailbreak prompts?",
        "Please provide a more detailed explanation of the iterative refinement process for assigning weights in the knowledge graph.",
        "Are there additional testing questions and their corresponding oracle answers and jailbreak results that could be included?",
        "What specific safety checks and safeguards are implemented in the Materializer role to ensure reliable oracle answers?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "20KYsQ8Q4Z",
    "title": "High-dimensional Bayesian Optimization",
    "std_review": {
      "summary": "The paper presents GTBO, a novel Bayesian optimization method that uses group testing to reduce the number of evaluations needed for optimizing expensive black-box functions. Experiments show that GTBO significantly outperforms traditional baselines across various benchmarks, achieving faster convergence with fewer evaluations. The approach is theoretically sound, leverages Bayesian inference, and is flexible for different optimization problems. Despite its strengths, implementation complexity and parameter sensitivity are noted as areas for improvement.",
      "strengths": [
        "Innovative application of group testing to Bayesian optimization.",
        "Strong theoretical foundation based on Bayesian inference.",
        "Empirical performance improvements over existing methods.",
        "Flexibility to apply to a wide range of optimization problems."
      ],
      "weaknesses": [
        "Implementation complexity due to integration of group testing concepts.",
        "Sensitivity to hyperparameters such as batch size and number of groups.",
        "Limited benchmark set, primarily synthetic and a few real-world cases."
      ],
      "questions": [
        "How does GTBO scale to very high-dimensional problems?",
        "What is the impact of different acquisition functions on GTBO's performance?",
        "How does GTBO compare to recent state-of-the-art methods in Bayesian optimization?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "20L7txbIa8",
    "title": "UniPredict: Large Language Models are Universal Tabular Classifiers",
    "std_review": {
      "summary": "UniPredict demonstrates an innovative approach to few-shot tabular prediction by leveraging large language models (LLMs) without fine-tuning. It shows competitive performance on benchmark datasets, especially in scenarios with limited data. However, the paper lacks detailed hyperparameter tuning, statistical validation, and comprehensive ablations, which are crucial for robust evaluation. Concerns about reproducibility, data leakage, and ethical considerations also need addressing.",
      "strengths": [
        "Innovative integration of LLMs with tabular data.",
        "Strong performance in few-shot learning scenarios.",
        "Provides interpretable class probabilities."
      ],
      "weaknesses": [
        "Lack of detailed hyperparameter tuning for baselines.",
        "Absence of statistical testing for performance comparisons.",
        "No exploration of few-shot performance with larger datasets.",
        "Unclear interpretation of class probabilities.",
        "No ablations on handling numerical features.",
        "Potential data leakage not addressed.",
        "Code and data availability not mentioned.",
        "Limited evaluation of model robustness.",
        "No comparison with other recent tabular LLM approaches.",
        "Ethical considerations and fairness not discussed."
      ],
      "questions": [
        "How were hyperparameters for baselines selected and reported?",
        "What statistical tests were conducted to validate performance differences?",
        "Were experiments conducted to evaluate few-shot performance with larger datasets?",
        "Can the class probabilities be interpreted as true confidence measures?",
        "How were numerical features handled, and what ablations were performed?",
        "What steps were taken to identify and address potential data leakage?",
        "Is the code and data used in the experiments publicly available?",
        "How was the model's robustness to variations in input format or missing values evaluated?",
        "Did the paper compare UniPredict with other recent tabular LLM approaches?",
        "What ethical considerations and fairness concerns were addressed?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "20oxNYWQl9",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a novel (k,z)-clustering approach for efficient model sampling, leveraging a Holder‑continuity assumption to achieve multiplicative and additive error bounds. It demonstrates both improved quality and reduced computational cost compared to existing sampling techniques on neural network training tasks. Theoretical analysis establishes new guarantees for clustering‑based sampling under the Holder assumption, which is more restrictive than Lipschitz continuity but sufficient for certain model classes. While the method shows promise, there are concerns about the assumption's reliability across diverse datasets and the need for further empirical validation.",
      "strengths": [
        "Theoretical novelty: Introduces a Holder‑continuity assumption for sensitivity‑sampling, providing a new theoretical framework.",
        "Improved guarantees: Offers both multiplicative and additive error bounds, enhancing robustness.",
        "Empirical validation: Demonstrates practical benefits through targeted experiments on neural network training."
      ],
      "weaknesses": [
        "Assumption reliability: The Holder‑continuity assumption may not hold for all model classes.",
        "Empirical validation needed: Lack of evidence validating the assumption across diverse datasets.",
        "Computational costs: Required model queries and embedding computations could introduce hidden costs."
      ],
      "questions": [
        "Can the Holder‑continuity assumption be validated empirically across a broader range of datasets?",
        "What are the practical implications of the required number of model queries (k) for very large datasets?",
        "How does the method perform when the Holder assumption is relaxed or violated?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "228XQpErvW",
    "title": "",
    "std_review": {
      "summary": "The paper introduces ISMAQ, a reinforcement learning framework that combines TD3's stability with the ISMA's exploration efficiency. Empirical results on MuJoCo and Atari benchmarks show that ISMAQ outperforms both TD3+BC and TD3 alone, especially in high‑exploration environments. The integration of two loss functions may complicate implementation, and the method's real‑world applicability is not fully demonstrated.",
      "strengths": [
        "Innovative combination of TD3's stability with ISMA's exploration efficiency.",
        "Consistently superior performance across a wide range of tasks.",
        "Strong theoretical motivation linking the ISMAQ loss to entropy maximization and variance reduction."
      ],
      "weaknesses": [
        "Increased complexity due to the integration of two distinct loss functions.",
        "Potential computational overhead from additional computations.",
        "Limited validation on real‑world applications."
      ],
      "questions": [
        "How does ISMAQ scale to larger, more complex environments beyond simulated benchmarks?",
        "What are the practical debugging and implementation challenges associated with the combined loss functions?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "22OTbutug9",
    "title": "RA-DIT: Retrieval-Augmented Dual Instruction Tuning",
    "std_review": {
      "summary": "RA-DIT introduces a novel method that combines retriever fine-tuning with instruction tuning to enhance large language models' ability to handle complex tasks by grounding reasoning in external knowledge. The approach shows significant performance gains on benchmarks like TriviaQA and NQ, with improvements observed across different retrieval depths. While the method is robust and flexible, it also raises concerns about potential hallucinations and the impact of dataset size and retriever choice.",
      "strengths": [
        "Innovative dual approach combining retriever fine-tuning with instruction tuning.",
        "Demonstrates that deeper retrieval can yield incremental performance improvements.",
        "Provides strong baseline comparisons and robustness across multiple benchmarks."
      ],
      "weaknesses": [
        "Potential for hallucinations due to reliance on retrieved context.",
        "Performance sensitive to dataset size, which may limit applicability in resource-constrained settings.",
        "Effectiveness heavily depends on the choice of retriever, with limited exploration in the paper."
      ],
      "questions": [
        "How can the method be improved to mitigate the risk of hallucinations from retrieved information?",
        "What are the specific ablation studies on the impact of different retrievers and retrieval depths?",
        "How does the method perform in zero-shot settings, and what could improve its generalization capabilities?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "22pyNMuIoa",
    "title": "PromptAgent: Strategic Planning with Language Models Enables Expert-level Prompt Optimization",
    "std_review": {
      "summary": "PromptAgent introduces a novel method for optimizing prompts for large language models using Monte Carlo Tree Search (MCTS). The approach intelligently navigates the prompt space, incorporates error feedback from the base model, and balances exploration and exploitation. Experimental results show that PromptAgent outperforms existing baselines across various tasks and scales across different language models. While promising, the method has limitations in terms of generalizability, reliance on error feedback quality, and scalability for extremely large prompt spaces.",
      "strengths": [
        "Introduces a novel approach to prompt optimization using MCTS.",
        "Effectively incorporates error feedback from the base model.",
        "Demonstrates improved performance over existing baselines.",
        "Shows scalability and generalization across different language models."
      ],
      "weaknesses": [
        "Limited evaluation on a wide range of diverse tasks.",
        "Performance heavily relies on the quality of error feedback.",
        "Scalability for extremely large prompt spaces or models is not thoroughly explored.",
        "Reliance on existing MCTS techniques may limit novelty."
      ],
      "questions": [
        "How does PromptAgent perform on a broader set of diverse tasks?",
        "What is the impact of varying the quality of error feedback on the method's performance?",
        "How does the method scale to extremely large prompt spaces or models?",
        "What unique contributions does PromptAgent make beyond its reliance on MCTS?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "23b9KSNQTX",
    "title": "RETSim: Resilient and Efficient Text Similarity",
    "std_review": {
      "summary": "RETSim introduces a novel approach to document similarity matching by combining a character-level vectorizer with a lightweight transformer block and metric learning. Leveraging a typo-augmented multilingual C4 dataset, it improves adversarial robustness and outperforms traditional methods on W4NT3D, NEWS-COPY, and CORE datasets. The paper demonstrates scalability and efficiency, showing strong real-world performance in spam email clustering, though deployment challenges remain.",
      "strengths": [
        "Innovative architecture combining character-level vectorization with a lightweight transformer block.",
        "Enhanced adversarial robustness through multi-level augmentation.",
        "Custom Multi-Similarity Loss outperforms traditional Triplet Loss.",
        "Demonstrated scalability and efficiency for large-scale applications."
      ],
      "weaknesses": [
        "Potential computational overhead from the transformer block in resource-constrained environments.",
        "Performance sensitivity to hyperparameters in the Multi-Similarity Loss.",
        "Limited exploration of multilingual coverage and long-document effectiveness.",
        "Deployment challenges in dynamic environments like spam detection."
      ],
      "questions": [
        "How does RETSim perform on extremely long documents or highly specialized domains?",
        "What are the specific degradation metrics for RETSim's robustness against adversarial attacks?",
        "How does RETSim compare to state-of-the-art methods in large-scale real-world deployments?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "23OEmHVkpq",
    "title": "Disentanglement Learning via Topology",
    "std_review": {
      "summary": "The paper introduces Topological Disentanglement (TopDis), a novel regularization term for VAEs that improves disentanglement by focusing on the topological structure of latent spaces. It provides a theoretical link to existing disentanglement metrics and demonstrates strong empirical improvements across several datasets. While showing practical benefits, the approach has some limitations, such as hyperparameter sensitivity and limited theoretical guarantees.",
      "strengths": [
        "Introduces a novel perspective on disentanglement through topological properties of latent spaces.",
        "Provides a clear theoretical foundation linking the proposed loss to established disentanglement metrics.",
        "Demonstrates practical integration with existing VAE architectures with minimal computational overhead."
      ],
      "weaknesses": [
        "Effectiveness may be sensitive to hyperparameter choices (γ₁ and γ₂).",
        "Lacks comprehensive comparison with the latest state-of-the-art disentangled VAE methods.",
        "Gradient orthogonalization adds complexity to the optimization process.",
        "Limited theoretical guarantees on convergence or generalization."
      ],
      "questions": [
        "How robust is the TopDis loss to different hyperparameter settings across various datasets?",
        "What is the impact of gradient orthogonalization on convergence stability in practice?",
        "Can the theoretical relationship between TopDis and existing metrics be further strengthened with additional mathematical proofs?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "24CZaossxH",
    "title": "PyTorch Geometric High Order: A Unified Library for High Order Graph Neural Network",
    "std_review": {
      "summary": "The paper introduces PyGHO, a library for hierarchical one-dimensional graph neural networks using 1-D tensors, which outperforms existing methods on standard graph datasets, particularly large, sparse molecular graphs. It highlights advantages in flexibility and efficiency, though lacks detailed analysis of profiling techniques and ablation studies. The authors demonstrate strong scalability and community impact, but the paper could benefit from more comprehensive comparisons and real-world case studies.",
      "strengths": [
        "Innovative representation of hierarchical data using 1-D tensors.",
        "Significant performance gains over existing HOGNN implementations.",
        "Demonstrated scalability to large, real-world graph datasets."
      ],
      "weaknesses": [
        "Lack of thorough profiling analysis for the reported efficiency improvements.",
        "Limited comparison scope with only standard graph datasets.",
        "Absence of ablation studies to evaluate key design choices.",
        "Sparse data structure handling optimizations are not fully detailed."
      ],
      "questions": [
        "Could you provide a detailed profiling analysis of the efficiency gains reported?",
        "What are the specific ablation studies conducted to evaluate the impact of tuple sampling and pooling strategies?",
        "How does PyGHO perform on more complex or domain-specific datasets beyond the standard benchmarks?",
        "Could you include benchmarks or case studies demonstrating the real-world impact of PyGHO?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "258EqEA05w",
    "title": "",
    "std_review": {
      "summary": "FedRDN introduces a federated learning framework that dynamically adjusts feature distributions across clients using a novel normalization technique, improving model generalization and performance across various architectures and datasets. The method mitigates feature distribution skew by aggregating client-specific statistics, aligning with privacy-preserving principles. While demonstrating significant improvements over baselines, the approach raises concerns about communication overhead and security risks associated with sharing aggregated statistics.",
      "strengths": [
        "Dynamic adaptation improves model performance and generalization.",
        "Privacy-friendly by sharing aggregated statistics instead of raw data.",
        "Versatile across different network architectures and datasets."
      ],
      "weaknesses": [
        "Increased communication overhead due to shared statistics.",
        "Potential security risks from sharing aggregated statistics.",
        "Lack of extensive empirical validation across diverse datasets."
      ],
      "questions": [
        "How does FedRDN address communication overhead in large-scale federated learning settings?",
        "What security measures are implemented to protect shared aggregated statistics?",
        "Could you provide more detailed experimental results across a wider range of datasets and architectures?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "25VG15SnkH",
    "title": "United We Train, Divided We Fail!",
    "std_review": {
      "summary": "The paper introduces SICC, a novel loss function for fine‑tuning pre‑trained language models on biomedical datasets, achieving strong performance gains over existing baselines. While the theoretical motivation and experimental setup are well‑described, the study is limited to a few datasets and lacks statistical validation. The authors should address these concerns to strengthen the claim of generalizability and robustness.",
      "strengths": [
        "Introduces a novel loss function (SICC) designed to capture semantic and intrinsic correlations in biomedical text.",
        "Demonstrates strong empirical results on multiple datasets, outperforming standard baselines.",
        "Provides a clear and detailed experimental setup, enhancing reproducibility."
      ],
      "weaknesses": [
        "Limited to a small set of biomedical and clinical datasets, potentially limiting generalizability.",
        "Lacks statistical tests to validate the significance of performance improvements.",
        "The complexity of implementing and tuning the SICC loss may be a barrier for practitioners.",
        "Does not compare against a broader range of state‑of‑the‑art methods."
      ],
      "questions": [
        "How does the SICC loss perform on a more diverse set of biomedical datasets beyond those tested?",
        "What statistical tests were used to assess the significance of the observed performance gains?",
        "Could you provide more details on the training procedure, including data augmentation and handling of class imbalance?",
        "What is the sample efficiency of the fine‑tuning process, and how does it compare to other methods?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "26XphugOcS",
    "title": "Zero-Shot Continuous Prompt Transfer: Generalizing Task Semantics Across Language Models",
    "std_review": {
      "summary": "The paper presents a novel approach to improve prompt transferability across language models by leveraging a shared vocabulary of tokens. It identifies a common subset of tokens (anchors) between source and target models and optimizes prompt embeddings to maximize alignment of these anchors, leading to significant performance gains on both classification and generation tasks. The method is shown to be practical and broadly applicable, though it relies on shared vocabularies and has some implementation and evaluation limitations.",
      "strengths": [
        "Innovative transferability approach leveraging a shared vocabulary.",
        "Empirical validation demonstrating consistent performance gains.",
        "Broad applicability across different model types and domains."
      ],
      "weaknesses": [
        "Reliance on a shared vocabulary may limit applicability to models with significantly different vocabularies.",
        "Optimization complexity could be computationally intensive.",
        "Lack of detailed implementation guidance.",
        "Limited evaluation scope focusing on a few benchmark datasets and model types."
      ],
      "questions": [
        "How robust is the method to models with very different vocabularies?",
        "What are the practical steps for implementing the optimization process described in Equations 5 and 7?",
        "How does the method perform on a wider range of tasks and datasets beyond those evaluated?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "27YiINkhw3",
    "title": "Syntax Error-Free and Generalizable Tool Use for LLMs via Finite-State Decoding",
    "std_review": {
      "summary": "The paper introduces ToolDec, a framework that integrates finite state machines (FSMs) with large language models (LLMs) to enhance their tool use capabilities. It demonstrates that ToolDec improves LLMs' ability to handle complex tool interactions and generalizes to unseen tools, outperforming stronger LLMs lacking external knowledge. The evaluation includes both qualitative case studies and quantitative benchmarks, highlighting the method's effectiveness and scalability. Overall, the paper makes a significant contribution to advancing LLMs' tool use capabilities.",
      "strengths": [
        "Innovative Integration of FSMs: The paper effectively combines FSMs with LLMs to address tool use challenges, providing a novel approach to enhancing LLMs' capabilities.",
        "Robust Generalization: Demonstrates that LLMs can generalize to unseen tools, a significant advancement over existing methods.",
        "Comprehensive Evaluation: Uses a mix of qualitative case studies and quantitative benchmarks to validate the effectiveness of ToolDec.",
        "Scalability and Efficiency: Shows how the FSM-based approach can be integrated with LLMs without significant computational overhead, maintaining efficiency."
      ],
      "weaknesses": [
        "FSM Construction Complexity: The automatic construction of FSMs for complex tools may require significant manual intervention, limiting the method's applicability.",
        "Limited Benchmark Diversity: The evaluation primarily focuses on a specific set of benchmarks, which may not fully capture the method's performance across all potential use cases.",
        "Potential for Overfitting: The reliance on FSMs for tool name and argument structure may lead to overfitting, especially if the FSMs are not sufficiently generalized.",
        "Scalability Concerns: While the paper suggests scalability, the computational implications of integrating FSMs with LLMs for a large number of tools are not fully explored."
      ],
      "questions": [
        "How can the automatic construction of FSMs be improved to reduce the need for manual intervention?",
        "What are the specific computational overheads associated with integrating FSMs with LLMs, and how can they be mitigated?",
        "How does the approach handle ambiguous or unconventional tool naming conventions?",
        "What are the long-term scalability implications of using FSMs for a large number of tools?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "28gMnEAgl9",
    "title": "Large Language Models Are Not Strong Abstract",
    "std_review": {
      "summary": "The paper introduces the ARC benchmark for evaluating abstract reasoning in large language models, evaluating a wide range of models from 7B to 70B parameters. It highlights significant performance gains with scaling and fine-tuning, especially with curriculum learning and multi-task pre-training. The benchmark provides valuable insights into the limitations of current LLMs, particularly in memorization and causal reasoning, while also noting areas for improvement such as task diversity and cross-modal extensions.",
      "strengths": [
        "Novel benchmark design with diverse task formats",
        "Comprehensive evaluation across a wide range of model sizes",
        "Innovative fine-tuning protocols and prompting strategies",
        "Detailed robustness analysis"
      ],
      "weaknesses": [
        "Limited task diversity compared to more comprehensive benchmarks",
        "Lack of cross-modal extensions",
        "Insufficient exploration of edge cases",
        "Qualitative analysis may not be as in-depth",
        "No plans for maintaining a public leaderboard or versioning the dataset"
      ],
      "questions": [
        "How can the benchmark be extended to include more cross-modal reasoning tasks?",
        "What additional edge cases or novel blocking scenarios should be explored?",
        "How can the qualitative analysis be expanded to better understand model failure modes?",
        "What are the plans for maintaining the benchmark and encouraging community contributions?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "28kAFnQZ5V",
    "title": "Tensorized Attention Model",
    "std_review": {
      "summary": "The paper introduces TAM, a Transformer architecture with an integrated memory module that significantly improves the model's ability to capture long-term dependencies. Experimental results show TAM outperforms existing methods in computational efficiency and memory usage across various NLP tasks. The authors demonstrate TAM's versatility and scalability, but note potential implementation challenges and the need for further analysis of memory configurations.",
      "strengths": [
        "Introduces a novel memory module that effectively enhances the Transformer architecture's ability to capture long-term dependencies.",
        "Demonstrates superior performance compared to state-of-the-art methods in terms of computational efficiency and memory usage.",
        "Provides clear and comprehensive experimental results across multiple NLP tasks, showcasing the versatility of TAM."
      ],
      "weaknesses": [
        "The complexity of the TAM architecture may make it more challenging to implement and maintain compared to standard Transformer models.",
        "Lacks detailed analysis on the impact of different memory module configurations on model performance.",
        "Scalability to extremely large parameter sizes is not thoroughly explored."
      ],
      "questions": [
        "How does the complexity of the TAM architecture impact its practical implementation and maintenance compared to standard Transformer models?",
        "What is the impact of different memory module configurations on model performance, and how can these insights be leveraged?",
        "How does TAM scale to extremely large parameter sizes, and what are the implications for performance at this scale?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "28L2FCtMWq",
    "title": "Ground-A-Video: Zero-shot Grounded Video Editing using Text-to-image Diffusion Models",
    "std_review": {
      "summary": "The paper presents a novel video editing framework that integrates depth maps and optical flow maps to enable more natural and flexible object editing. It demonstrates improved editing quality and consistency through experiments, offering a flexible framework applicable beyond simple object addition or deletion. However, the lack of standardized evaluation metrics and the method's focus on specific editing tasks limit its broader utility and direct comparison with existing methods.",
      "strengths": [
        "Introduces a novel approach to video editing by combining depth maps and optical flow maps, providing a richer representation of video content.",
        "Demonstrates improved editing quality and consistency through experimental results, showcasing practical benefits.",
        "Offers a flexible framework that can potentially be applied to various video editing tasks beyond just adding or deleting objects."
      ],
      "weaknesses": [
        "Evaluation metrics are not directly comparable to those of existing methods, limiting relative performance assessment.",
        "Integration of depth maps and optical flow maps may lead to overly consistent editing results, potentially limiting flexibility for objects with inconsistent structures.",
        "The method appears primarily designed for adding or deleting objects, restricting its applicability to other editing tasks.",
        "Flow-guided smoothing is applied only to static areas, with no mention of warping operations, which could be important for complex editing scenarios."
      ],
      "questions": [
        "Could the proposed method be extended to handle more complex editing tasks beyond adding or deleting objects?",
        "How does the method compare to existing video editing techniques in terms of standard evaluation metrics?",
        "What impact does the integration of depth maps and optical flow maps have on the flexibility of editing objects with inherently inconsistent structures?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "29pGC6IYaL",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a novel approach to low-resource Mongolian-to-Chinese machine translation using knowledge distillation and reinforcement learning. It leverages Llama as a teacher model and incorporates adversarial noise to enhance distillation. The framework shows significant improvements over baselines, though some concerns remain about the choice of Llama, the lack of detailed reward function description, and the limited exploration of model size effects. Overall, the paper makes a valuable contribution.",
      "strengths": [
        "Novel combination of knowledge distillation and reinforcement learning for low-resource machine translation.",
        "Effective use of Llama as a teacher model despite not being trained on Mongolian or Chinese.",
        "Adversarial noise improves knowledge distillation and translation quality.",
        "Comprehensive ablation studies and statistically significant results."
      ],
      "weaknesses": [
        "Selection of Llama as a teacher model raises suitability questions.",
        "Reward function design is not fully detailed.",
        "Ablation studies do not explore component interactions.",
        "Performance trend with varying student model sizes is underexplored.",
        "Statistical significance of improvements is not thoroughly examined.",
        "Test sets and settings are not officially released, limiting reproducibility."
      ],
      "questions": [
        "How was the reward function designed and what was its impact?",
        "What is the performance trend with varying student model sizes?",
        "How was the statistical significance of improvements evaluated?",
        "Could additional baselines provide a more comprehensive comparison?",
        "What are the specific test sets and settings used in the experiments?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "2aebB2mf0q",
    "title": "",
    "std_review": {
      "summary": "The paper presents a novel approach to semi-supervised learning for infrared small target detection by classifying data augmentation techniques into robust (NUC) and mild (NUP) categories. It introduces a tailored loss function, AEWLoss, and evaluates its performance using IoU, Pd, and Fa metrics, showing improved detection accuracy over baselines. While the methodology and loss function are well-defined, the review highlights concerns about clarity in the methodology section and the interpretability of the augmentation classification.",
      "strengths": [
        "Proposes a novel classification of data augmentation techniques into robust and mild categories, providing a clear framework for semi-supervised learning.",
        "Introduces a tailored loss function (AEWLoss) that effectively handles both positive and negative samples, enhancing detection performance.",
        "Employs a comprehensive set of evaluation metrics (IoU, Pd, Fa) that are well-suited for assessing the performance of infrared small target detection systems."
      ],
      "weaknesses": [
        "The methodology section lacks clarity, particularly regarding the non-uniform chromaticity augmentation process and the interpolation method used.",
        "The overview figure is informal and ambiguous, making it difficult to understand the proposed framework and its components.",
        "The theoretical basis for classifying augmentations as robust or mild is not fully explained, potentially limiting the interpretability of the results."
      ],
      "questions": [
        "Could you provide a more detailed explanation of the non-uniform chromaticity augmentation process and the interpolation method used?",
        "Please clarify the theoretical basis for classifying augmentations as robust or mild.",
        "Could you improve the overview figure to better illustrate the proposed framework and its components?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "2bF381xEke",
    "title": "MapSelect: Sparse & Interpretable Graph Attention Networks",
    "std_review": {
      "summary": "MapSelect introduces a deterministic sparse attention mechanism for GNNs, claiming improved interpretability and parameter efficiency. While it shows promise on the BA‑Shapes dataset, the paper lacks comprehensive performance baselines, detailed experimental results, and a thorough evaluation of interpretability across graph-level tasks. The deterministic claim and parameter efficiency are central but not fully substantiated.",
      "strengths": [
        "Introduces a novel deterministic sparse attention mechanism for GNNs.",
        "Demonstrates interpretability gains on the BA‑Shapes dataset.",
        "Argues convincingly that sparsity reduces computational complexity."
      ],
      "weaknesses": [
        "Lacks empirical validation of the deterministic claim.",
        "Missing performance baselines against standard dense GATs.",
        "Evaluation limited to a single dataset without broader benchmarks."
      ],
      "questions": [
        "Can you provide empirical validation that MapSelect is truly deterministic across multiple runs?",
        "What are the performance baselines against standard dense GAT implementations?",
        "How does MapSelect perform on other graph-level classification benchmarks beyond BA‑Shapes?",
        "Are there runtime or scalability analyses for MapSelect?",
        "How does MapSelect compare to sparse GAT variants on the same datasets?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "2BfZMh9td4",
    "title": "Beyond One-Preference-for-All:",
    "std_review": {
      "summary": "The paper introduces MODPO, a method that decouples reward modeling from preference optimization in language model fine-tuning. It proposes training a reward model on noisy pairwise data and using it to guide a preference optimization process, contrasting with DPO LW which integrates both steps. Experiments on the BIG-bench Hard suite show that MODPO achieves competitive performance with reduced computational cost compared to DPO variants, suggesting a more efficient fine-tuning approach. The reviewer finds the method promising, highlighting its efficiency and robustness to noisy data, while noting implementation complexities.",
      "strengths": [
        "Decouples reward modeling from optimization, allowing more flexible and accurate reward representation.",
        "Reduces computational overhead by separating reward modeling and optimization, beneficial for large models.",
        "Demonstrates robustness to noisy pairwise comparison data, a common real-world issue."
      ],
      "weaknesses": [
        "Adds complexity through an additional reward model training step.",
        "Risk of overfitting due to the separate reward modeling stage.",
        "Computational cost of training the reward model, which may be significant for large models."
      ],
      "questions": [
        "How does MODPO compare to other methods that also decouple reward modeling from optimization but use different reward learning techniques?",
        "What are the long-term implications of training a separate reward model on noisy data for downstream fine-tuning tasks?",
        "Could the method be extended to handle more complex reward structures beyond pairwise comparisons?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "2boLXjsHsB",
    "title": "Multi-Objective Reinforcement Learning for Forward-Backward Markov Decision Processes",
    "std_review": {
      "summary": "The paper introduces FB-MOAC, a reinforcement learning framework that simultaneously learns forward and backward policies in a Markov Decision Process to improve learning efficiency and policy generalization. The authors provide theoretical analysis and empirical results on synthetic and real-world tasks, showing practical benefits. However, the approach is computationally intensive and has limited theoretical guarantees, which may limit its applicability.",
      "strengths": [
        "Innovative dual-direction learning approach",
        "Solid theoretical foundation with convergence guarantees",
        "Empirical validation on both synthetic and real-world tasks"
      ],
      "weaknesses": [
        "High computational complexity for large-scale problems",
        "Limited theoretical guarantees for general settings",
        "Assumption of observable backward states in real-world scenarios"
      ],
      "questions": [
        "How can the computational overhead be reduced for large-scale applications?",
        "What are the broader theoretical guarantees for convergence in more general settings?",
        "How can the framework be adapted for environments where backward states are not directly observable?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "2C3CWCPxNS",
    "title": "Preconditioning for Physics-Informed Neural Networks",
    "std_review": {
      "summary": "The paper introduces a novel preconditioning approach for PINNs that effectively addresses training pathologies caused by ill-conditioning in complex PDEs. The method uses the condition number to diagnose and rectify these issues, with empirical evidence showing improved convergence and stability across several high-dimensional problems. While promising, the approach's scalability to extremely high-dimensional problems and its comparison with other advanced methods remain areas for further exploration.",
      "strengths": [
        "Innovative diagnosis and rectification of training pathologies using the condition number.",
        "Extensive empirical validation across complex PDEs demonstrating improved performance.",
        "Valuable theoretical insights linking condition number to PINN performance."
      ],
      "weaknesses": [
        "Limited empirical scope with experiments restricted to a few specific PDE problems.",
        "Potential scalability challenges for extremely high-dimensional or very large-scale problems.",
        "Lack of detailed comparison with other advanced preconditioning methods."
      ],
      "questions": [
        "How does the proposed method perform on a broader range of complex PDEs beyond the specific examples provided?",
        "What strategies are employed to address potential scalability issues in extremely high-dimensional settings?",
        "How does the preconditioning approach compare to other state-of-the-art methods, such as domain decomposition techniques, in terms of performance and applicability?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "2cRzmWXK9N",
    "title": "Beyond Reverse KL: Generalizing Direct Preference Optimization with Diverse Divergence Constraints",
    "std_review": {
      "summary": "The paper introduces f-DPO, an extension of the DPO framework that generalizes the reverse KL divergence to a broader class of divergences, enhancing flexibility and effectiveness in language model fine-tuning. It provides theoretical insights and demonstrates empirical improvements over traditional methods. The reviewer finds the work novel, theoretically enriched, and practically beneficial, recommending acceptance.",
      "strengths": [
        "Theoretical Enrichment: Introduces closed-form mappings and calibration error analysis.",
        "Flexibility and Control: Allows nuanced trade-offs between accuracy and diversity.",
        "Empirical Validation: Shows significant improvements over traditional RLHF methods."
      ],
      "weaknesses": [
        "Complexity of Divergence Selection: May complicate model selection and tuning.",
        "Computational Considerations: Increased costs for large-scale applications.",
        "Limited Comparison with State-of-the-Art: Only compares to traditional methods."
      ],
      "questions": [
        "How does f-DPO handle the computational cost of using multiple divergences in large-scale applications?",
        "What are the specific scenarios where different divergence measures provide the most significant benefits?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "2CxkRDMIG4",
    "title": "Precision and Recall Reject Curves",
    "std_review": {
      "summary": "The paper introduces a novel evaluation framework for rejection‑based classifiers using precision and recall curves, tailored for class‑imbalanced datasets. It demonstrates that rejection strategies can improve model performance by selectively rejecting easy examples while retaining hard ones, showing higher precision and recall on several datasets. The study provides comprehensive insights into the benefits and trade‑offs of rejection, with empirical validation across multiple datasets, and is recommended for acceptance.",
      "strengths": [
        "Relevance to Imbalanced Datasets: Focus on precision and recall as evaluation metrics is well‑suited for class‑imbalanced problems.",
        "Comprehensive Evaluation: Presents precision and recall curves for both rejected and accepted samples, offering detailed performance insights.",
        "Theoretical and Practical Insights: Highlights benefits and trade‑offs of rejection, providing valuable guidance for practitioners."
      ],
      "weaknesses": [
        "Complexity of Evaluation: Multiple precision and recall curves for different rejection rates add evaluation complexity.",
        "Limited Scope: Focuses on binary classification, potentially limiting applicability to multi‑class or regression problems.",
        "No Comparison with Other Metrics: Does not compare rejection‑based performance against metrics like AUC or F1 in balanced settings.",
        "Potential Overfitting: Emphasis on rejection could lead to overfitting if rejection thresholds are not carefully tuned."
      ],
      "questions": [
        "How does the framework generalize to multi‑class classification problems?",
        "What are the long‑term maintenance and scalability considerations for the proposed evaluation framework?",
        "Can the framework be extended to regression tasks or other types of models beyond classification?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "2DbVeuoa6a",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a novel neural spectral method (NSM) for solving partial differential equations (PDEs) by leveraging spectral space representations, which avoids discretization errors and aliasing artifacts. Empirical results show superior performance compared to a PINN counterpart, attributed to differences in spectral transforms and training dynamics. The work highlights the theoretical advantages of spectral methods for PDEs and provides a framework for high‑accuracy neural operator solutions.",
      "strengths": [
        "Theoretical Advantages: NSM leverages spectral space to compute exact residuals, eliminating discretization errors that plague grid-based PINNs.",
        "Aliasing-Free Design: By using spectral coefficients as input, the method avoids aliasing artifacts, a common issue in grid-based approaches.",
        "Improved Performance: Despite identical loss functions, NSM outperforms CNO, suggesting that spectral transforms and training dynamics play a crucial role in method efficacy."
      ],
      "weaknesses": [
        "Complexity of Spectral Transforms: The reliance on spectral transforms may introduce computational complexity, potentially limiting scalability for very large problems.",
        "Dependency on Spectral Resolution: The number of modes (spectral resolution) significantly impacts performance, requiring careful selection and validation.",
        "Potential Overfitting: The high dimensionality of spectral space might lead to overfitting, especially if the training data is limited."
      ],
      "questions": [
        "How does the computational cost of spectral transforms scale with problem size, and what strategies can be employed to mitigate this complexity?",
        "What ablation studies have been conducted to explore the impact of varying spectral resolutions on model performance and convergence?",
        "Can the spectral formulation of NSM be made more interpretable, and if so, how?",
        "How does NSM handle boundary conditions compared to traditional grid-based methods?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "2DDwxbjP9g",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a discrete Wasserstein GAN (SWAG) that uses a patch-based CNN discriminator to enforce Lipschitz continuity, providing theoretical convergence proofs and demonstrating improved stability and sample quality on CIFAR-10. While the work offers novel insights and practical benefits, it relies on several assumptions and has limited empirical validation beyond CIFAR-10.",
      "strengths": [
        "Introduces a discrete formulation of Wasserstein GANs using patch-based CNN discriminators, offering a fresh perspective on enforcing Lipschitz continuity.",
        "Provides rigorous proofs for convergence under specific conditions, linking the discrete model to the continuous Wasserstein distance.",
        "Proposes a multiscale optimization approach that enhances convergence properties, demonstrating practical benefits."
      ],
      "weaknesses": [
        "The proofs rely on several assumptions (e.g., Lipschitz continuity, specific regularizers) that may limit the generality of the results.",
        "Notation for Wasserstein distances is inconsistent, which can be confusing and requires careful interpretation.",
        "Empirical validation is limited to CIFAR-10; broader validation across datasets and architectures would strengthen the claims.",
        "The requirement for a large number of latent vectors in the discrete setting may be impractical for real-world applications."
      ],
      "questions": [
        "How do the theoretical assumptions on Lipschitz continuity and regularizers generalize to other GAN architectures or distributions?",
        "What is the impact of the multiscale optimization approach on convergence rates for larger datasets or more complex models?",
        "How does the discrete latent space formulation compare to continuous latent space approaches in terms of scalability and expressiveness?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "2dHmhoWweE",
    "title": "",
    "std_review": {
      "summary": "The paper introduces Lookbehind Sharpness‑Aware Minimization (Lookbehind SAM), a variant of SAM that uses linear interpolation of gradients from multiple ascent steps to reduce variance and improve generalization, especially in robustness and lifelong learning. Experiments on CIFAR and a down‑scaled ImageNet show significant improvements over vanilla SAM and ASAM, with competitive performance against state‑of‑the‑art methods. However, the method incurs additional computational cost and lacks comparison with the latest SAM variants, raising questions about its practical scalability and robustness.",
      "strengths": [
        "Innovative gradient combination reduces variance and improves robustness.",
        "Theoretical motivation grounded in sharpness‑aware minimization.",
        "Demonstrated performance gains on standard benchmarks."
      ],
      "weaknesses": [
        "Increased computational overhead due to additional backward passes.",
        "Lack of comparison with the most recent SAM variants.",
        "Parameter sensitivity with an adaptive α that hasn't been fully validated.",
        "Unclear scalability to larger datasets and architectures."
      ],
      "questions": [
        "How does Lookbehind SAM compare to the latest SAM variants, such as Adaptive Sharpness‑Aware Minimization?",
        "What is the impact of the adaptive α parameter on model training, and how robust is it to hyperparameter variations?",
        "Can the method be scaled to larger datasets and more complex architectures, such as full ImageNet or large language models?",
        "Are there formal convergence guarantees for Lookbehind SAM?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "2dhxxIKhqz",
    "title": "Function-space Parameterization of",
    "std_review": {
      "summary": "The paper presents a novel sparse Gaussian Process model for continual learning, introducing a dual parameterization approach and a continual learning objective (Eq. 14) that balances expressiveness and efficiency. Experiments show improved performance over baselines in dynamic settings, though some aspects like inducing point selection and potential overfitting remain underexplored. Overall, the work is promising and could contribute valuable insights to the field.",
      "strengths": [
        "Introduces a novel continual learning objective (Eq. 14) that effectively captures temporal dependencies.",
        "Dual parameterization approach balances model complexity and computational efficiency for dynamic environments.",
        "Provides both theoretical insights and empirical validation across various continual learning tasks."
      ],
      "weaknesses": [
        "Lacks detailed justification for how inducing points are chosen, which could affect model performance.",
        "The continual learning objective (Eq. 14) is more complex than traditional objectives, potentially complicating optimization.",
        "Does not provide a thorough comparison with functional regularization methods.",
        "Risk of overfitting due to the penalty term related to the precision matrix."
      ],
      "questions": [
        "How are the inducing points selected for the sparse GP model, and what impact does this have on performance?",
        "What is the relationship between the continual learning objective (Eq. 14) and existing approaches like VCL or online Laplace methods?",
        "How does the dual parameterization approach compare to functional regularization methods in incorporating information from all data?",
        "Could optimizing the inducing points make the method equivalent to Ortega et al., 2023, or does the overall approach differ significantly?",
        "How does the objective in Eq. 14 fit into the broader framework of variational methods compared to other approaches lacking penalty terms?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "2DJUXmHZ2O",
    "title": "Generalizing Poincare Policy Representations in Multi-agent Reinforcement Learning",
    "std_review": {
      "summary": "The paper introduces a novel approach to policy representation in reinforcement learning using hyperbolic neural networks, which effectively models the hierarchical structure of trajectories. It demonstrates improved performance and generalization compared to Euclidean baselines across several benchmarks. While promising, the method has several limitations, such as unclear handling of continuous action spaces and multi-agent scenarios, and theoretical questions about convergence.",
      "strengths": [
        "Innovative use of hyperbolic geometry to model hierarchical trajectory data.",
        "Strong theoretical foundation linking hyperbolic space to trajectory representation.",
        "Empirical results showing clear performance improvements over Euclidean baselines."
      ],
      "weaknesses": [
        "Limited exploration of continuous action spaces and their theoretical justification.",
        "Unclear extension to multi-agent systems with different information structures.",
        "Assumptions about Euclidean properties of state, action, and observation spaces."
      ],
      "questions": [
        "How does the method extend to continuous action spaces and what are the theoretical justifications?",
        "Can the approach be naturally extended to multi-agent systems with history-dependent policies?",
        "What is the precise role of the trajectory sequence in the hyperbolic neural network?",
        "How are hyperbolic representations integrated with existing RL algorithms like PPO?",
        "What are the theoretical guarantees for convergence in hyperbolic space?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "2DldCIjAdX",
    "title": "",
    "std_review": {
      "summary": "LayerNAS introduces a novel approach to neural architecture search (NAS) by mapping candidate architectures into a transformed, polynomial-sized search space, enabling efficient exploration with reduced computational cost. The method shows competitive performance on size search tasks while significantly lowering training epochs compared to traditional NAS methods. However, concerns about early stopping, bucketing strategy sensitivity, limited generalization evidence, and incomplete comparisons with state-of-the-art methods remain.",
      "strengths": [
        "Efficient Search Space: The polynomial transformation via φ maintains the completeness of the search space, allowing exploration of all possible architectures while drastically reducing the search space size.",
        "Reduced Computational Overhead: By limiting training epochs and using bucketing, LayerNAS significantly cuts down the computational resources required, making NAS more practical for large-scale problems.",
        "Scalability: The method's design supports scalability to broader NAS tasks beyond size search, suggesting versatility in various application domains.",
        "Theoretical Foundation: The paper provides a rigorous mathematical framework for the mapping and bucketing strategies, offering a clear rationale for their effectiveness."
      ],
      "weaknesses": [
        "Early Stopping Reliability: Training models for only a few epochs may lead to unreliable performance estimates, potentially selecting suboptimal architectures.",
        "Bucketing Strategy Sensitivity: The choice of bucket size and candidate distribution could introduce bias, affecting the discovery of high-performing architectures.",
        "Limited Generalization Evidence: While the method is proposed to generalize to other NAS tasks, empirical evidence is lacking, particularly for topology search.",
        "Comparison Scope: The comparison with state-of-the-art methods is incomplete, omitting recent approaches like OFA and EfficientNet."
      ],
      "questions": [
        "How does the method handle the trade-off between search efficiency and the risk of missing high-performing architectures with different bucketing strategies?",
        "What empirical evidence supports the claim of generalization to other NAS tasks beyond size search?",
        "How does LayerNAS compare to recent state-of-the-art methods that incorporate distillation or other acceleration techniques?"
      ],
      "overall_score": "Borderline",
      "confidence": "Medium"
    }
  },
  {
    "paper_id": "2dLMPOY0HW",
    "title": "When Do MLPs Excel in Node Classification?",
    "std_review": {
      "summary": "The paper proposes InfoMLP, a model that enhances node classification by incorporating graph-augmented representations and mutual information maximization. It demonstrates significant improvements over baselines on several benchmark datasets, offering a clear and implementable approach. However, the lack of a thorough theoretical analysis and limited experimental scope are noted as areas for improvement.",
      "strengths": [
        "Introduces a novel approach to incorporating graph information into machine learning models.",
        "Demonstrates significant improvements over baseline models on several benchmark datasets.",
        "Provides a clear and concise description of the model architecture and training procedure."
      ],
      "weaknesses": [
        "Lacks a thorough theoretical analysis of the proposed approach.",
        "The choice of graph-augmented node feature matrix and mutual information estimator is not well-justified.",
        "Experimental results are limited to a small number of benchmark datasets.",
        "Does not provide a detailed analysis of the computational complexity."
      ],
      "questions": [
        "What are the theoretical guarantees or bounds on the mutual information that InfoMLP aims to minimize?",
        "How does the choice of the mutual information estimator affect the model's performance and optimization?",
        "Could the experimental results be extended to a broader range of tasks and datasets?"
      ],
      "overall_score": "6: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "2dnO3LLiJ1",
    "title": "",
    "std_review": {
      "summary": "The paper investigates outlier tokens in Vision Transformers (ViTs) during self-supervised pretraining, proposing that these tokens capture global image information similar to the CLS token. It introduces 'registers' to mitigate this issue and evaluates their impact on both the CLS token and downstream tasks using models like DINOv2 and OpenCLIP. While the study shows that registers can improve performance on tasks such as unsupervised object discovery, it also reveals inconsistencies, particularly with OpenCLIP performance, and leaves open questions about the trade-offs and generalizability of the findings.",
      "strengths": [
        "Insightful identification of outlier tokens as behaving like the CLS token.",
        "Practical solution with registers to mitigate the issue.",
        "Comprehensive evaluation of both CLS token impact and downstream tasks."
      ],
      "weaknesses": [
        "Performance discrepancy in Table 3 for OpenCLIP with registers.",
        "Lack of detailed ablations to explain the discrepancy.",
        "Limited exploration of how registers affect other downstream tasks.",
        "Potential overgeneralization of findings across model sizes and pretraining paradigms."
      ],
      "questions": [
        "Do the registers inherit the behavior of outlier tokens?",
        "Why does OpenCLIP performance slightly drop despite the authors' claim of improvement?",
        "How do image tokens behave after adding registers, and what are the exact mechanisms?",
        "How does the norm of the CLS token change after adding registers?",
        "What is the impact of registers on downstream tasks beyond unsupervised object discovery?",
        "How does dataset bias (label vs. sampling) influence the emergence of outliers?",
        "Why do outliers still appear in DINOv2 despite dense mask-image modeling?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "2drC319yHQ",
    "title": "RepoFusion: Training Code Models to Understand Your Repository",
    "std_review": {
      "summary": "RepoFusion presents a method for enhancing code completion in IDEs by incorporating repository context, particularly for Java projects. The approach truncates code snippets while preserving essential structural elements, leading to improved performance over standard models, especially in complex scenarios. Despite its innovative approach and clear evaluation framework, the method's Java-specific nature and limited baseline comparisons raise concerns about its broad applicability and impact.",
      "strengths": [
        "Innovative context utilization for code completion",
        "Scalable approach applicable to various completion tasks",
        "Demonstrated performance gains over baseline models"
      ],
      "weaknesses": [
        "Java-specific implementation may limit applicability",
        "Lack of comparison with models exposed to repository contexts",
        "Insufficient analysis of how different completion types benefit"
      ],
      "questions": [
        "How could RepoFusion be adapted for other programming languages?",
        "What detailed analysis is needed for how different code completion types benefit from RepoFusion?",
        "How does syntax-aware truncation affect model performance?",
        "How does RepoFusion's performance scale with model size or computational trade-offs?",
        "What real-world impact and usability considerations should be addressed?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "2Ed7b52z53",
    "title": "On the Matrix Form of the Quaternion Fourier Transform and Quaternion Convolution",
    "std_review": {
      "summary": "The paper introduces significant theoretical advancements in the quaternion Fourier transform and quaternion convolution, extending classical properties to quaternions. These results enable tighter Lipschitz constant bounds for quaternion convolutional neural networks (QCNNs), improving stability and generalization. The proofs are rigorous but may be challenging for readers without a strong background in quaternion algebra. The paper's impact is primarily demonstrated through its application to QCNNs, with limited experimental validation across other domains.",
      "strengths": [
        "Novel theoretical contributions extending Fourier transform and convolution to quaternions.",
        "Clear and rigorous mathematical proofs building on established foundations.",
        "Concrete application to QCNNs showing practical benefits and improved theoretical guarantees."
      ],
      "weaknesses": [
        "Complexity of proofs may limit accessibility for readers without advanced knowledge of quaternion algebra.",
        "Scope is narrowly focused on Lipschitz constant bounding for QCNNs, potentially limiting broader impact.",
        "Experimental validation is limited to a specific use case, not fully capturing the broader applicability of the results."
      ],
      "questions": [
        "Could the theoretical results be extended to higher dimensions or other types of quaternion-based models?",
        "What are the potential impacts of these results on other areas of quaternionic machine learning beyond QCNNs?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "2eIembMRQJ",
    "title": "Active Teacher Selection for Reinforcement Learning from Human Feedback",
    "std_review": {
      "summary": "The paper introduces the HUB framework for multi‑teacher reinforcement learning, formulating the problem as a POMCPOW and proposing an Active Teacher Selection (ATS) algorithm. It demonstrates improved efficiency and performance on recommendation and COVID‑19 vaccine testing tasks compared to single‑teacher baselines. While the approach is novel and theoretically sound, its complexity and lack of formal guarantees are significant concerns.",
      "strengths": [
        "Novel formulation of multi‑teacher RL as a POMCPOW.",
        "Dynamic teacher selection balances exploration and guidance.",
        "Solid theoretical foundation with definitions of optimal utility, teacher distribution, and regret."
      ],
      "weaknesses": [
        "Complexity of the POMCPOW formulation may hinder practical implementation.",
        "Absence of formal regret bounds or convergence proofs.",
        "Assumptions about teacher utility and feedback may limit real‑world applicability.",
        "Lack of ablation studies to assess robustness."
      ],
      "questions": [
        "What are the formal regret bounds or convergence guarantees for the ATS algorithm?",
        "How does the framework handle heterogeneous teacher utilities and delayed feedback?",
        "Could ablation studies provide more insight into the impact of teacher cost and number on performance?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "2FAPahXyVh",
    "title": "OptiMUS: Optimization Modeling Using MIP Solvers and Large Language Models",
    "std_review": {
      "summary": "OptiMUS is a system that uses large language models to automatically generate and refine mathematical formulations for optimization problems from natural language descriptions. It significantly reduces the time required for problem setup while maintaining accuracy, as shown on the NLP4LP benchmark. The system's interactive debugging process makes optimization more accessible, but its performance depends on solver choice and reproducibility can be affected by LLM variability.",
      "strengths": [
        "Efficiency gains by automating formulation",
        "Scalability across problem types and sizes",
        "User-friendly interactive debugging"
      ],
      "weaknesses": [
        "Solver dependency limits effectiveness",
        "Reproducibility issues due to LLM variability",
        "Benchmark may not fully capture real-world diversity"
      ],
      "questions": [
        "How does OptiMUS handle solver failures or infeasible problems?",
        "What strategies are employed to ensure reproducibility across different runs?",
        "How does the system perform on benchmarks with very large datasets or complex constraints?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "2fSyBPBfBs",
    "title": "Bilevel Optimization without Lower-Level Strong Convexity from the Hyper-Objective Perspective",
    "std_review": {
      "summary": "The paper introduces IGFM, a zeroth-order method for bilevel optimization that does not require lower-level strong convexity. It provides non-asymptotic convergence guarantees under convexity and regularity assumptions and demonstrates competitive performance on benchmarks. While novel and theoretically sound, practical applicability is limited by restrictive assumptions and a lack of thorough robustness analysis.",
      "strengths": [
        "Novel zeroth-order approach for bilevel optimization without LLSC.",
        "Strong theoretical foundation with non-asymptotic convergence rates.",
        "Demonstrates practical performance on benchmark problems."
      ],
      "weaknesses": [
        "Assumptions of convexity and regularity may be too restrictive.",
        "Algorithm choice for final output lacks clear justification.",
        "Complexity analysis is provided but lacks clear practical comparison.",
        "Sensitivity to hyper-parameters is not thoroughly examined."
      ],
      "questions": [
        "How can the method be extended to non-convex lower levels?",
        "What is the impact of hyper-parameter choices on practical performance?",
        "How does the total complexity compare to existing methods in practice?",
        "Can additional metrics (e.g., primal/dual gaps, running time) be provided for a more comprehensive evaluation?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "2GJm8yT2jN",
    "title": "URLOST: Unsupervised Representation Learning without Stationarity or Topology",
    "std_review": {
      "summary": "The paper presents a novel method that combines topological data analysis (TDA) with deep learning to analyze the stationarity and topology of time series data. It introduces a new metric for evaluating these properties and demonstrates its effectiveness on several benchmark datasets. The approach shows promise for applications in finance, environmental science, and network analysis, though its scalability and novelty remain underexplored.",
      "strengths": [
        "Integrates TDA with deep learning to provide a unique perspective on time series data.",
        "Introduces a novel metric for assessing stationarity and topology.",
        "Demonstrates robust performance across multiple benchmark datasets."
      ],
      "weaknesses": [
        "Complexity may limit accessibility for practitioners without expertise in TDA and deep learning.",
        "Evaluation relies on a limited set of datasets, potentially overlooking broader applicability.",
        "Lacks detailed discussion on scalability for large datasets."
      ],
      "questions": [
        "How does the method scale to very large datasets?",
        "What are the specific topological features extracted and how do they relate to stationarity?",
        "How does the proposed metric compare to existing benchmarks for stationarity and topology?"
      ],
      "overall_score": "6: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "2gMwe9Duc4",
    "title": "Neuroexplicit Diffusion Models",
    "std_review": {
      "summary": "The paper introduces a neuroexplicit diffusion model for optical flow inpainting, combining PDEs with CNNs to iteratively refine flow estimates. It demonstrates strong performance on synthetic Sintel data but lacks real-world validation, comparison with recent methods, and exploration of generalization to other vision tasks. The innovative approach offers interpretability through the diffusion process, but implementation details and robustness across varied conditions are underexplored.",
      "strengths": [
        "Innovative integration of PDEs with CNNs for optical flow inpainting.",
        "Coarse-to-fine refinement strategy improves speed without sacrificing quality.",
        "Provides inherent interpretability through the diffusion process."
      ],
      "weaknesses": [
        "Limited real-world validation on datasets like KITTI or Middlebury.",
        "No comparison with recent state-of-the-art methods.",
        "Absence of studies on generalization to other vision tasks."
      ],
      "questions": [
        "How does the model perform on real-world datasets beyond synthetic Sintel?",
        "What is the model's performance compared to recent state-of-the-art methods?",
        "Has the model been evaluated on other vision tasks such as depth completion or semantic scene completion?",
        "What are the theoretical guarantees of stability and convergence provided by the explicit PDE component?",
        "How does the coarse-to-fine approach affect output quality for unseen mask densities?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "2gwo9cjOEz",
    "title": "Neural Tangent Kernels Motivate Graph Neural Networks with Cross-Covariance Graphs",
    "std_review": {
      "summary": "The paper introduces a novel alignment concept for Neural Tangent Kernels (NTKs) in Graph Neural Networks (GNNs), aiming to provide theoretical insights into GNN behavior during inference tasks. It proposes new theorems that relate this alignment to GNN performance and demonstrates applicability on the HCP‑YA dataset. While innovative, the work lacks comprehensive experimental validation and explores limited practical implications, leading to a weak accept recommendation.",
      "strengths": [
        "Introduces a novel alignment concept for NTKs in GNNs.",
        "Provides new theoretical theorems extending NTK analyses to GNNs.",
        "Focuses on practical inference tasks like node and graph classification."
      ],
      "weaknesses": [
        "Lacks detailed experimental validation of the proposed theorems.",
        "Assumes output dimensionality matches input dimensionality.",
        "Dataset choice may limit generalizability.",
        "Limited discussion on layer depth and other tasks."
      ],
      "questions": [
        "Should include comprehensive experiments to validate the theorems.",
        "Clarify the impact of output dimensionality assumption.",
        "Explore the generalizability of the alignment concept across different datasets.",
        "Investigate the effect of layer depth on GNN performance with cross-covariance graphs.",
        "Consider extensions to other inference tasks such as link prediction."
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "2h3m61LFWL",
    "title": "",
    "std_review": {
      "summary": "The paper introduces VBMLE, a Bayesian optimization algorithm for solving non‑concave value‑function minimization in linear mixture MDPs, achieving ϵ‑optimal solutions in O(1/ϵ²) iterations with empirical performance superior to UCLK. It provides theoretical regret bounds and clarifies terminology, but has some ambiguity in notation and assumptions.",
      "strengths": [
        "Introduces Bayesian optimization to handle non‑concave VBMLE objectives.",
        "Provides rigorous theoretical regret analysis with O(1/ϵ²) convergence.",
        "Demonstrates strong empirical performance with low regret and computation time."
      ],
      "weaknesses": [
        "Computational cost of UCLK not fully quantified.",
        "Terminology between linear MDPs and linear mixture MDPs is unclear.",
        "GP‑UCB complexity and overhead are not fully addressed.",
        "Theoretical guarantee assumes specific conditions on α(t).",
        "Some notations are introduced without explicit definition."
      ],
      "questions": [
        "How does the computational cost of UCLK scale with problem size compared to VBMLE?",
        "Can the theoretical guarantee be extended to more general value‑function settings?",
        "What is the impact of the bias term in the MLE on practical performance?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "2HJRwwbV3G",
    "title": "What does the Knowledge Neuron Thesis Have to do with Knowledge?",
    "std_review": {
      "summary": "The paper investigates the identification of 'knowledge neurons' in a neural network trained on linguistic data, proposing a priori limits of 2–5 such neurons. It finds that these neurons do not consistently represent knowledge, challenging the notion of distributed knowledge representation. While the study is well-structured and clearly defines its scope, it is limited by its narrow focus on a small number of neurons and lacks broader examples of linguistic phenomena.",
      "strengths": [
        "Clear a priori limitation on the number of knowledge neurons",
        "Robust and reproducible findings about the non-robust representation of knowledge",
        "Concise and clearly outlined contributions section"
      ],
      "weaknesses": [
        "Limitation on exploring distributed representations due to the fixed neuron limit",
        "Inconsistent messaging regarding the non-robust representation of knowledge",
        "Lack of additional examples beyond minimal pairs to illustrate linguistic phenomena"
      ],
      "questions": [
        "Could the findings be extended to a larger set of linguistic knowledge beyond the minimal pairs used?",
        "How do the identified knowledge neurons compare to other types of neurons in the network?",
        "What are the implications of the limited neuron count on the overall knowledge representation of the model?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "2iGiSHmeAN",
    "title": "",
    "std_review": {
      "summary": "The paper introduces BROGNET, a framework that combines Brownian dynamics with machine learning to model complex systems from sparse trajectory data. It employs a graph-based approach where particles interact through a learned potential, with the dynamics captured by multi-layer perceptrals. The framework demonstrates improved accuracy over traditional methods in handling noisy data on synthetic Brownian systems, but its real-world applicability is limited by the lack of evaluation on complex systems and sensitivity to hyperparameters.",
      "strengths": [
        "Innovative integration of Brownian dynamics and machine learning for modeling sparse data.",
        "Effective handling of noisy data through learned dynamics.",
        "Scalable and flexible graph-based architecture."
      ],
      "weaknesses": [
        "Limited evaluation on real-world systems.",
        "High sensitivity to hyperparameter choices.",
        "Graph topology was not thoroughly investigated."
      ],
      "questions": [
        "How does BROGNET perform on real-world systems with complex interactions?",
        "What systematic approach could be used for hyperparameter selection?",
        "How would extending the model to handle external fields or non-deterministic forces affect performance?"
      ],
      "overall_score": "Borderline",
      "confidence": "Medium"
    }
  },
  {
    "paper_id": "2inBuwTyL2",
    "title": "Deep SE(3)-Equivariant Geometric Reasoning for Precise Placement Tasks",
    "std_review": {
      "summary": "The paper introduces a method for robotic manipulation that uses demonstration-based learning to estimate object poses from sparse visual cues, integrating a multilateration algorithm with a deep learning model trained on simulated demonstrations. Experimental results show significant improvements in task completion speed and accuracy compared to baseline methods, indicating practical value for real-world robotics applications. While the approach is robust in simulated environments, its performance in highly dynamic or unpredictable settings remains untested, and computational efficiency for real-time use could be improved.",
      "strengths": [
        "Integrates multilateration with deep learning for robust pose estimation from limited visual data.",
        "Leverages simulated demonstrations to enable efficient training and transfer to new tasks.",
        "Demonstrates clear improvements in task completion speed and accuracy over existing methods."
      ],
      "weaknesses": [
        "Reliance on simulated demonstrations may limit effectiveness in dynamic or unpredictable real-world environments.",
        "Computational efficiency of the multilateration step could be a bottleneck for real-time applications.",
        "Lack of exploration of robustness to varying lighting conditions and sensor noise."
      ],
      "questions": [
        "How does the method perform under highly dynamic or unpredictable real-world conditions?",
        "What strategies can be employed to improve the computational efficiency of the multilateration step for real-time applications?",
        "How robust is the method to varying lighting conditions and sensor noise, and what preprocessing techniques are required?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "2JF8mJRJ7M",
    "title": "Lipsum-Ft: Robust Fine-Tuning of Zero-Shot Models Using Random Text Guidance",
    "std_review": {
      "summary": "The paper introduces Lipsum-FT, a method for robust fine-tuning of zero-shot models by minimizing the energy gap between pre-trained vision and language models. The energy gap is defined as the squared difference of two inner products, measuring alignment between models' representations. The method generates text tokens for regularization and evaluates its impact on computational cost and performance compared to other techniques. The reviewer finds the approach innovative and well-motivated, with clear implementation and comprehensive evaluation, though notes some complexity and limited scope.",
      "strengths": [
        "Innovative approach to robust fine-tuning by focusing on minimizing the energy gap.",
        "Clear motivation emphasizing the importance of maintaining pre-trained connections.",
        "Practical implementation with a straightforward procedure for generating text tokens.",
        "Comprehensive evaluation comparing Lipsum-FT with other methods."
      ],
      "weaknesses": [
        "Complexity of energy gap definition may be less intuitive for some readers.",
        "Limited scope of evaluation may restrict generalizability of findings.",
        "Lack of detailed analysis on how computational cost scales with model size or dataset.",
        "Comparison with other methods is not exhaustive."
      ],
      "questions": [
        "How does the energy gap definition scale with different model architectures or sizes?",
        "Could the method be extended to other types of models beyond vision and language?",
        "What is the impact of the choice of text generation rules on the regularization effectiveness?"
      ],
      "overall_score": "Accept",
      "confidence": "High"
    }
  },
  {
    "paper_id": "2Kf1AIdeyt",
    "title": "",
    "std_review": {
      "summary": "The paper introduces HS‑SNE, a variant of t‑SNE that incorporates L2‑normalization to improve clustering in high-dimensional data, particularly single-cell RNA‑seq datasets. It demonstrates better cluster separation and reduced computational overhead compared to standard t‑SNE, highlighting its potential for complex biological data analysis. While innovative, the paper could benefit from more comprehensive comparisons and ablation experiments to fully establish the novelty and robustness of HS‑SNE.",
      "strengths": [
        "Introduces a novel L2‑normalization approach to preserve high-dimensional data geometry.",
        "Demonstrates improved clustering performance and computational efficiency.",
        "Provides clear experimental results relevant to single-cell RNA‑seq applications."
      ],
      "weaknesses": [
        "Lacks a broader comparison with other state-of-the-art clustering methods.",
        "Does not include ablation experiments to isolate the effect of L2‑normalization.",
        "Potential overfitting concerns are not thoroughly addressed."
      ],
      "questions": [
        "How does HS‑SNE compare to other recent clustering techniques in terms of performance?",
        "Could additional ablation experiments further validate the contribution of L2‑normalization?",
        "What is the robustness of HS‑SNE to overfitting, especially in high-dimensional settings?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "2kvDzdC5rh",
    "title": "IntentGPT: Few-shot Intent Discovery with Large Language Models",
    "std_review": {
      "summary": "IntentGPT introduces a novel few-shot intent discovery method that leverages GPT-4 feedback and a Knowledge Integration Rate (KIR) to improve performance with limited data. The approach shows strong empirical gains over baselines, especially in low-data scenarios, indicating practical utility for real-world open-world applications. While innovative, the paper could benefit from more thorough ablation studies and expanded appendices to fully substantiate its claims.",
      "strengths": [
        "Innovative feedback loop with GPT-4 for dynamic model refinement.",
        "Effective knowledge integration via KIR parameter.",
        "Strong empirical results, particularly in low-data settings."
      ],
      "weaknesses": [
        "Lack of comprehensive ablation analysis for feedback component.",
        "Insufficient detail in appendix regarding intent examples and statistical analysis.",
        "No direct comparison with vanilla 50-shot GPT-4.",
        "Ambiguous intent handling not adequately addressed.",
        "Ablation study details are not fully described."
      ],
      "questions": [
        "How does performance change when only the feedback component is ablated?",
        "Could Appendix A.7 be expanded with more examples and statistical analysis of discovered intents?",
        "How does a 50-shot vanilla GPT-4 with KIR = 0.75 compare to the proposed method?",
        "Should test examples with no intent or multiple intents be included in future testing?",
        "What is the specific prompt description used in the ICPG ablation study?"
      ],
      "overall_score": "Accept",
      "confidence": "High"
    }
  },
  {
    "paper_id": "2l7g7zwC4z",
    "title": "Embedding File Structure for Tabular File Preparation",
    "std_review": {
      "summary": "The paper introduces RenEMB, a method that tokenizes tabular data into structured strings using a pattern-based tokenizer, which are then processed by a transformer model like LLaMA to generate embeddings. This approach emphasizes a structural‑masking pre‑training task to enhance the model's understanding of tabular data structures, outperforming direct BPE tokenization on several benchmarks. The method is language‑agnostic and shows strong performance, indicating practical utility.",
      "strengths": [
        "Innovative tokenization that captures tabular structure more effectively than raw BPE.",
        "Structural‑masking pre‑training explicitly teaches the model about tabular data hierarchies.",
        "Potential for multilingual and general application across different table formats."
      ],
      "weaknesses": [
        "Multilingual performance may depend on transformer model generalization across languages.",
        "Pattern‑tokenization may struggle with language‑specific characters.",
        "Pre‑training complexity and scalability to large datasets are open questions."
      ],
      "questions": [
        "How does RenEMB handle truly multilingual tabular data with complex linguistic structures?",
        "What are the specific patterns used in the tokenizer for distinguishing between language characters and structural delimiters?",
        "How does the method scale to very large or complex datasets, and what are the computational trade‑offs?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "2lDQLiH1W4",
    "title": "Instant3D: Fast Text-to-3D with Sparse-View Generation and Large Reconstruction Model",
    "std_review": {
      "summary": "Instant3D presents a novel approach to 3D reconstruction using DINO features and a transformer-based reconstructor. It generates four views of a scene, processes them with a transformer network to predict NeRF triplanes, and demonstrates competitive rendering quality and diversity against optimization-based methods. The method addresses the Janus problem and offers a more efficient alternative, though it may suffer from lower resolution and reduced diversity compared to specialized approaches.",
      "strengths": [
        "Leverages DINO features for effective 3D representation.",
        "Generates four views using a tiled representation, potentially reducing computational complexity.",
        "Addresses the Janus problem with a transformer-based reconstructor.",
        "Achieves competitive rendering quality and diversity."
      ],
      "weaknesses": [
        "Limited resolution of NeRF triplanes may impact rendering fidelity.",
        "Potential lack of diversity compared to optimization-based methods."
      ],
      "questions": [
        "How does the method handle scenes with highly ambiguous or ambiguous-looking elements beyond the Janus problem?",
        "What is the impact of the limited resolution of NeRF triplanes on the overall rendering quality for complex scenes?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "2LhCPowI6i",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a novel generative‑replay method for class‑incremental learning that effectively mitigates catastrophic forgetting by combining a classifier‑based rejection filter with generative models to produce high‑quality pseudodata. Empirical results on CIFAR‑100 and Tiny ImageNet show significant improvements over existing continual learning baselines, indicating strong practical utility. However, the experimental scope is limited, and the method's generalizability could be further validated through additional ablation studies, visualizations, and broader benchmarking.",
      "strengths": [
        "Novel integration of classifier‑based rejection filtering with generative replay.",
        "Generative replay provides a scalable way to maintain task performance.",
        "Theoretical justification for the rejection filter enhances method reliability."
      ],
      "weaknesses": [
        "Limited experimental scope with only two benchmarks.",
        "Absence of ablation studies to isolate component contributions.",
        "Lack of qualitative visualizations of generated pseudodata."
      ],
      "questions": [
        "How does the method perform on a wider range of datasets and tasks?",
        "What is the impact of the rejection filter on learning dynamics?",
        "Could the method be extended to other architectures beyond those tested?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "2Mo7v69otj",
    "title": "Pooling Image Datasets with Multiple Covariate Shift and Imbalance",
    "std_review": {
      "summary": "The paper introduces a category theory-based framework for handling covariate shift in image datasets, aiming to pool data across datasets with different distributions while preserving invariance and equivariance properties. Empirical results show competitive performance against existing methods, but the approach relies on overlapping covariate values and lacks exploration of counterfactual reasoning. The paper suggests further experiments to validate generalization and assess computational efficiency.",
      "strengths": [
        "Provides a mathematically rigorous framework using category theory to formalize covariate shift and data pooling.",
        "Introduces novel functor and morphism mappings that enhance model robustness and generalization.",
        "Demonstrates competitive empirical performance compared to established methods."
      ],
      "weaknesses": [
        "Relies on the assumption of overlapping covariate values, which may limit effectiveness in datasets with minimal overlap.",
        "Does not fully explore counterfactual reasoning, potentially overlooking alternative robustness approaches.",
        "Lacks comprehensive analysis of computational efficiency and generalization to complex covariate shifts.",
        "Suggested experiments for sensitivity and ablation studies are not conducted."
      ],
      "questions": [
        "How does the method perform when applied to datasets with minimal or no overlapping covariate values?",
        "What are the computational efficiency implications compared to existing techniques?",
        "How robust is the approach to higher-dimensional or more complex covariate shifts?",
        "Could alternative methods like domain adaptation or transfer learning improve the proposed framework's robustness?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "2MpOjashKU",
    "title": "",
    "std_review": {
      "summary": "Divided Attention (DivA) introduces an unsupervised approach for multi-object segmentation using optical flow, achieving competitive performance, speed, and flexibility. The method employs an adversarial conditional encoder-decoder architecture that segments visual fields into independently moving regions, handling varying numbers of objects without retraining. While demonstrating strengths in unsupervised learning and optical flow utilization, DivA's weaknesses include limited real-world dataset evaluation and potential challenges with complex scenes.",
      "strengths": [
        "Unsupervised learning approach that discovers objects from scratch without pre-training.",
        "Utilizes optical flow to effectively distinguish static objects from the background.",
        "Adversarial conditional encoder-decoder architecture enhances segmentation accuracy and flexibility."
      ],
      "weaknesses": [
        "Limited evaluation on diverse real-world datasets to assess robustness and generalization.",
        "Potential challenges in handling complex scenes with highly dynamic objects or occlusions.",
        "Lack of detailed analysis on the impact of different hyperparameters on segmentation quality."
      ],
      "questions": [
        "How does DivA perform on a broader set of real-world datasets beyond the current benchmarks?",
        "What is the impact of different hyperparameters on the segmentation quality, and how can this be optimized?",
        "How does DivA handle scenarios with highly dynamic objects or occlusions?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "2msbbX3ydD",
    "title": "",
    "std_review": {
      "summary": "Ferret is a model for visual grounding and referring expression comprehension that combines discrete coordinates with continuous features. Trained on GPT-4 generated data and evaluated on Flickr30k, it outperforms baselines in referring and grounding tasks. The authors propose Ferret-Bench for benchmarking these tasks, but the model's broader applicability is limited by the lack of evaluation on non-referencing tasks and human evaluation of the generated data.",
      "strengths": [
        "Hybrid region representation enhances precise region selection",
        "High-quality data from GPT-4 improves performance on referring and grounding tasks",
        "Comprehensive evaluation on Flickr30k provides robust generalization assessment",
        "Proposed Ferret-Bench benchmark standardizes evaluation in visual grounding and referring"
      ],
      "weaknesses": [
        "Limited evaluation on non-referencing/non-grounding tasks",
        "Potential overfitting to GPT-4 generated data",
        "Lack of human evaluation for generated data",
        "Zero-shot performance may not fully capture model capabilities"
      ],
      "questions": [
        "How does Ferret perform on non-referencing/non-grounding tasks like image captioning or VQA?",
        "What are the human evaluation results for the data generated by GPT-4?",
        "How does the model handle complex or ambiguous visual references?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "2nD1SvxTZc",
    "title": "One-Versus-Others Attention:",
    "std_review": {
      "summary": "The paper introduces the One‑Versus‑Others (OvO) attention mechanism for multimodal fusion, showing strong performance gains over traditional methods on several benchmark datasets. OvO scales linearly with the number of modalities and requires fewer parameters, making it both computationally efficient and effective. While demonstrating clear advantages, the review notes limitations in comparison breadth, statistical validation, and dataset generalization.",
      "strengths": [
        "Linear scalability with the number of modalities.",
        "Parameter efficiency compared to self‑attention and cross‑attention.",
        "Strong performance gains across diverse multimodal datasets."
      ],
      "weaknesses": [
        "Limited comparison with newer techniques like hierarchical attention or contrastive learning.",
        "Lack of statistical analysis to assess significance of performance improvements.",
        "Insufficient testing on additional real‑world datasets for broader generalization."
      ],
      "questions": [
        "How does OvO perform when compared to more recent multimodal fusion techniques?",
        "What is the impact of hyper‑parameter tuning on the model's reproducibility?",
        "Can OvO be extended to handle extremely high‑dimensional data beyond the current 20‑modality simulation?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "2NpAw2QJBY",
    "title": "Neural Neighborhood Search for Multi-agent Path Finding",
    "std_review": {
      "summary": "The paper introduces a neural network architecture for subset selection in multi-agent pathfinding, leveraging transformer attention mechanisms. It compares the proposed neural approach to traditional handcrafted heuristics, showing improved solution quality with moderate computational overhead. The authors evaluate two transformer variants—light‑weight and heavy‑weight—across various map sizes and configurations, demonstrating competitive results. While the work is innovative and well‑evaluated, it could benefit from deeper hyperparameter analysis and scalability studies.",
      "strengths": [
        "Introduces a novel neural architecture tailored for multi-agent pathfinding using transformer attention.",
        "Provides a thorough comparative analysis with handcrafted heuristics, highlighting both quality and efficiency gains.",
        "Clearly differentiates and evaluates light‑weight and heavy‑weight transformer variants, offering insights into trade‑offs."
      ],
      "weaknesses": [
        "Limited baseline comparison with more detailed runtime analysis of competing methods.",
        "Lacks extensive exploration of hyperparameter sensitivity, affecting reproducibility.",
        "Scalability to very large maps or high numbers of agents is not thoroughly addressed.",
        "Training details, such as the exact loss function and optimization strategy, are not fully elaborated."
      ],
      "questions": [
        "How does the model perform when scaled to very large maps or a high number of agents?",
        "What is the impact of hyperparameter choices on model performance and reproducibility?",
        "Could additional scalability studies or more detailed training strategy documentation strengthen the paper?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "2NwHLAffZZ",
    "title": "Weak Correlations as the Underlying Principle for Linearization of Gradient-Based Learning Systems",
    "std_review": {
      "summary": "The paper introduces a novel framework for analyzing the linearization of neural networks through the lens of 'weak correlations' among the derivatives of the network's loss function. By formalizing these correlations and establishing asymptotic conditions under which the Neural Tangent Kernel (NTK) exhibits linearity, the authors provide a rigorous mathematical foundation for understanding when gradient-based learning systems behave linearly. The work extends prior results on NTK linearization by introducing a new asymptotic framework for random tensors and proving that weak correlations imply asymptotic linearity in the NTK. The reviewer finds the mathematical framework novel, rigorous, and conceptually clear, though with some limitations.",
      "strengths": [
        "Novel mathematical framework for analyzing linearization through weak correlations.",
        "Strong theoretical contributions with rigorous definitions and asymptotic conditions.",
        "Clear formalization using Big-O notation for random tensors.",
        "Comprehensive theorem proving with well-structured derivations.",
        "Interpretability with conceptual insights and examples."
      ],
      "weaknesses": [
        "Results are primarily applicable to infinitely wide networks.",
        "Assumptions on standard loss functions may limit generalizability.",
        "Complex notation and definitions introduced without extensive explanation.",
        "Lack of empirical validation through numerical studies or real-world applications."
      ],
      "questions": [
        "How do the results extend to finite-width neural networks?",
        "What is the impact of non-standard or non-convex loss functions on the linearization conditions?",
        "Could the notation and definitions be clarified to improve accessibility for a broader audience?",
        "What empirical evidence could be provided to validate the theoretical predictions about linearization under weak correlations?"
      ],
      "overall_score": "Accept",
      "confidence": "High"
    }
  },
  {
    "paper_id": "2Oiee202rd",
    "title": "",
    "std_review": {
      "summary": "PerceptionCLIP enhances CLIP's zero-shot classification by incorporating contextual attributes inferred from images. It improves accuracy and interpretability compared to the baseline model across several benchmarks. The approach is simple to integrate, showing robustness across datasets, but introduces computational overhead and may struggle with ambiguous attributes.",
      "strengths": [
        "Enhanced interpretability through explicit mapping of contextual attributes to textual descriptions.",
        "Significant boost in classification accuracy, especially in challenging zero-shot scenarios.",
        "Demonstrates robustness across diverse datasets with minimal additional tuning.",
        "Straightforward integration requiring only minor modifications to the existing CLIP architecture."
      ],
      "weaknesses": [
        "Increased computational complexity due to additional inference steps for attribute extraction and mapping.",
        "Potential struggles with ambiguous or uncertain contextual attributes leading to inconsistent performance.",
        "Effectiveness depends on the quality of textual descriptions generated by CLIP, which may vary.",
        "Limited generalization to entirely novel domains or datasets without prior training."
      ],
      "questions": [
        "How does PerceptionCLIP handle ambiguous or uncertain contextual attributes to ensure consistent performance?",
        "What is the impact of the additional computational overhead on inference time and resource requirements for large-scale applications?",
        "How does the method perform when applied to entirely novel domains or datasets without prior training on similar contexts?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "2ov9RiAkxE",
    "title": "Identifying and Mitigating Vulnerabilities in LLM-Integrated Applications+",
    "std_review": {
      "summary": "The paper identifies critical vulnerabilities in LLM-integrated applications and proposes a defense mechanism called Shield. Shield effectively detects and mitigates attacks while preserving application utility, but its cost implications and practical applicability are discussed. The review recommends acceptance with some noted limitations.",
      "strengths": [
        "Identifies critical vulnerabilities in LLM-integrated applications that are not adequately addressed by current safeguards.",
        "Provides a comprehensive framework for understanding and mitigating these vulnerabilities through four key properties.",
        "Introduces a novel defense mechanism, Shield, that effectively detects and mitigates attacks across different threat models.",
        "Conducts thorough experimental evaluations demonstrating the effectiveness of Shield in preserving application utility while enhancing security.",
        "Discusses the cost implications and practical considerations of implementing Shield, providing valuable insights for real-world deployment."
      ],
      "weaknesses": [
        "The proposed Shield defense mechanism relies heavily on the LLM's capabilities for attack detection, which may limit its effectiveness in scenarios where the LLM lacks sufficient context or knowledge.",
        "The experimental results are based on a limited set of applications and attack scenarios, which may not fully generalize to other types of LLM-integrated applications.",
        "The cost implications of employing Shield are not fully quantified, making it difficult to assess its overall impact on the cost per query in real-world scenarios.",
        "The paper does not provide a comprehensive analysis of the potential real-world implications and risks associated with the identified vulnerabilities, which could limit its impact on the development and deployment of secure LLM-integrated applications."
      ],
      "questions": [
        "How can the Shield defense mechanism be adapted to scenarios where the LLM lacks sufficient context or knowledge to detect attacks?",
        "What are the full cost implications of deploying Shield in real-world scenarios, and how can these costs be quantified?",
        "How can the identified vulnerabilities and the proposed Shield defense be generalized to a wider range of LLM-integrated applications?",
        "What are the potential real-world implications and risks of the identified vulnerabilities, and how can they be mitigated beyond the scope of this paper?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "2oWRumm67L",
    "title": "",
    "std_review": {
      "summary": "The paper introduces Light-MILPopt, a framework for efficiently solving large-scale MILP problems using graph-based methods and neural networks. It demonstrates strong performance against established solvers in benchmarks and real-world applications, though it has limitations in generalization and theoretical guarantees.",
      "strengths": [
        "Innovative graph representation of MILP problems",
        "Advanced EGAT model for initial solution prediction",
        "Efficient problem decomposition using FENNEL graph partitioning",
        "Strong performance in benchmarks and real-world applications"
      ],
      "weaknesses": [
        "Limited generalization due to small-scale training data",
        "Potential for local optima in iterative optimization",
        "Complexity of implementation and computational resource requirements",
        "Lack of detailed theoretical analysis"
      ],
      "questions": [
        "How does the framework handle problems with highly dynamic constraints?",
        "What is the impact of the choice of graph partitioning on the scalability of the solution?",
        "Can the framework be extended to handle non-linear constraints or mixed-integer nonlinear programming (MINLP) problems?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "2OwSqvxjP2",
    "title": "",
    "std_review": {
      "summary": "The paper introduces VCC and INFUSE, two methods that enhance semi-supervised learning by improving pseudo-label calibration and ensuring temporal consistency. VCC uses a Variational Autoencoder to refine labels, while INFUSE adds a Temporal Consistency score and a mix-up data augmentation strategy. Empirical results show significant accuracy and stability improvements over existing baselines across multiple datasets.",
      "strengths": [
        "Innovative calibration technique using a Variational Autoencoder.",
        "Introduces Temporal Consistency to maintain dataset stability.",
        "Practical data augmentation strategy to prevent overfitting."
      ],
      "weaknesses": [
        "Increased implementation complexity, especially with the VAE.",
        "Potential hyper-parameter sensitivity affecting reproducibility.",
        "Lack of detailed ablation studies on individual components."
      ],
      "questions": [
        "How robust are the methods to variations in hyper-parameter settings?",
        "Could the ablation studies be expanded to isolate the impact of each component more clearly?",
        "How do the methods perform on more recent state-of-the-art benchmarks?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "2Pup7olzxj",
    "title": "Differentiable Optimization in Plane-Wave Density Functional Theory for Solid States",
    "std_review": {
      "summary": "The paper introduces a neural network method for interpolating electronic band structures, demonstrated on LiF and Be. While offering a novel approach with potential accuracy and efficiency gains, the method's quantitative accuracy is limited, lacks direct comparison with established techniques like Wannier interpolation, and its geometry optimization is tested on a single system. These gaps suggest the method is promising but not yet fully validated.",
      "strengths": [
        "Introduces a novel neural network approach for band structure interpolation.",
        "Demonstrates versatility across different crystal structures.",
        "Provides a clear description of the methodology and neural network architecture."
      ],
      "weaknesses": [
        "Limited quantitative error analysis for band structure interpolation.",
        "No comparison with Wannier interpolation for k-space path calculations.",
        "Geometry optimization tested on a single system, limiting broader conclusions.",
        "Lacks comparison of efficiency, accuracy, and applicability with classical SCF methods.",
        "Figure 2 and Section 3 setup are unclear and inconsistent."
      ],
      "questions": [
        "Can you provide quantitative error/discrepancy analyses for the band structure interpolation across different scenarios?",
        "How does the proposed method compare with Wannier interpolation for deriving band structures along specific k-space paths?",
        "Could you test the geometry optimization on additional systems to strengthen conclusions?",
        "Please compare the method's efficiency, accuracy, and applicability with classical SCF approaches across various material types.",
        "Clarify the setup in Figure 2 and Section 3, particularly the interpretation of the first step and any interpolation performed."
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "2pvECsmld3",
    "title": "SparseFormer: Sparse Visual Recognition via Limited Latent Tokens",
    "std_review": {
      "summary": "SparseFormer introduces a novel vision transformer that significantly reduces computational cost by dynamically adjusting regions of interest (RoIs) for attention tokens, achieving comparable or better accuracy than dense models with far fewer parameters and FLOPs. The approach is particularly attractive for resource-constrained environments and shows promise in dense prediction tasks like object detection and semantic segmentation, though it may struggle with highly detailed or complex scenes. Overall, the paper makes a strong case for its innovative approach and potential impact.",
      "strengths": [
        "Efficient token pruning reduces computational cost while maintaining high accuracy.",
        "Dynamic RoI adjustment allows adaptive focus on relevant image regions.",
        "Demonstrates strong performance on dense prediction tasks beyond image classification."
      ],
      "weaknesses": [
        "Lack of explicit positional encoding may limit performance in complex scenes.",
        "Performance on high-resolution images with fine details is underexplored.",
        "Additional computational overhead from the focusing transformer.",
        "Limited ablation studies on token generation strategies."
      ],
      "questions": [
        "How does SparseFormer perform on high-resolution images with intricate details?",
        "What impact would explicit positional encoding have on the model's performance?",
        "How does SparseFormer compare to other sparse attention methods like ToMe or pruning techniques?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "2qLSkTuqrb",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a novel framework that combines cognitive modeling with a biologically plausible neural network to simulate locust swarming behavior. It effectively uses a Bayesian approach to infer proximity preferences and classifies behaviors into categories such as random, hungry, and follower. While the integration of these elements is innovative, the paper lacks clear validation of its model's accuracy against real-world data and provides limited details on how stochasticity is modeled or how the neural network contributes beyond the cognitive model.",
      "strengths": [
        "Innovative integration of cognitive modeling with a biologically plausible neural network.",
        "Use of Bayesian parameter inference to provide a robust statistical framework.",
        "Application to a real-world dataset of locust behavior, offering insights into model relevance."
      ],
      "weaknesses": [
        "Limited validation of model accuracy through real-world data comparison.",
        "Deterministic policy in the neural network raises questions about effective stochasticity modeling.",
        "Lack of clear explanation on how the neural network implementation supports biological plausibility.",
        "Reliance on proximity and trace features may be insufficient for capturing full animal behavior complexity."
      ],
      "questions": [
        "How does the model's accuracy compare to real-world locust behavior data?",
        "What specific mechanisms in the neural network account for the stochasticity observed in agent interactions?",
        "How were the handcrafted features (proximity and trace) chosen and validated for behavior classification?",
        "What additional features could be incorporated to improve the model's generalizability?"
      ],
      "overall_score": "Borderline",
      "confidence": "Medium"
    }
  },
  {
    "paper_id": "2RGQwJEcAC",
    "title": "",
    "std_review": {
      "summary": "The DCS-Transformer introduces a novel approach to model pruning by integrating the Information Bottleneck (IB) loss into channel selection, achieving significant reductions in model size and computational requirements while maintaining accuracy. The authors conduct extensive ablations and experiments, demonstrating substantial improvements over traditional pruning techniques. Despite these strengths, the paper has some limitations, such as lacking detailed analysis of the computational overhead introduced by the IB loss and not fully exploring hyperparameter trade-offs.",
      "strengths": [
        "Introduces a novel method for model pruning using the Information Bottleneck.",
        "Achieves significant reductions in model size and computational requirements.",
        "Maintains or improves model accuracy compared to existing pruning techniques."
      ],
      "weaknesses": [
        "Lacks detailed analysis of the computational overhead introduced by the IB loss.",
        "Does not fully explore hyperparameter trade-offs in ablations.",
        "Limited comparison with a broader range of state-of-the-art pruning techniques."
      ],
      "questions": [
        "Could the computational overhead of the IB loss be further analyzed to assess its practical applicability?",
        "How robust is the method to variations in hyperparameters such as the strength of the IB loss or the number of iterations?",
        "What is the scalability of the proposed method to larger models or more complex datasets?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "2RJAzSphy9",
    "title": "Sample Efficient Reinforcement Learning",
    "std_review": {
      "summary": "The paper presents a novel active learning algorithm for reinforcement learning fine-tuning, specifically targeting large language models. It introduces a Borda function and kernelized uncertainty estimation to guide sample selection, achieving significant performance improvements on both synthetic and real-world datasets. While the method scales to large context and action spaces, challenges in scalability and statistical significance are noted.",
      "strengths": [
        "Introduces a fresh perspective on sample selection in RL fine-tuning using Borda function and kernelized uncertainty estimation.",
        "Provides novel theoretical regret bounds under specific assumptions, offering a solid foundation for the proposed method.",
        "Demonstrates strong empirical performance on synthetic and real-world datasets, including Jeopardy and Anthropic."
      ],
      "weaknesses": [
        "The theoretical framework may be challenging for readers unfamiliar with advanced active learning and regret analysis concepts.",
        "Lacks detailed statistical significance tests, leaving some uncertainty about the robustness of the findings.",
        "Scalability challenges are not fully addressed, particularly for very large models.",
        "Empirical comparisons with state-of-the-art methods are limited."
      ],
      "questions": [
        "How can the method be further validated across different random seeds and dataset splits to ensure robustness?",
        "What are the specific hyperparameter sensitivities of the algorithm, and how do they affect performance?",
        "How does the proposed sampling strategy perform when applied to extremely large context and action spaces?"
      ],
      "overall_score": "Accept",
      "confidence": "High"
    }
  },
  {
    "paper_id": "2Rwq6c3tvr",
    "title": "Time Travel in LLMs: Tracing Data Contamination in Large Language Models",
    "std_review": {
      "summary": "The paper proposes a method to detect data contamination in LLM pipelines by using GPT‑4 safeguards to guide completions from random‑length prefixes. It shows strong empirical results on synthetic and real datasets, but lacks clear contamination thresholds, limited evidence on safeguard impact, and potential human‑evaluator bias. The approach is primarily designed for decoder‑only models and lacks clear generalizability to encoder‑only models.",
      "strengths": [
        "Innovative use of LLM safeguards to detect contamination.",
        "Scalable contamination detection method for large datasets.",
        "Thorough empirical validation across multiple datasets."
      ],
      "weaknesses": [
        "Lack of clear contamination thresholds for partitions.",
        "Limited empirical evidence on the impact of GPT‑4 safeguards.",
        "Potential human‑evaluator bias in GPT‑4 ICL.",
        "Applicability primarily to decoder‑only LLMs."
      ],
      "questions": [
        "What specific thresholds should be used to determine contamination at the partition level?",
        "How does the impact of GPT‑4 safeguards on completions affect contamination detection?",
        "What alternative approaches could be explored for encoder‑only models like BERT?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "2sCcTMWPc2",
    "title": "TimelyGPT: Recurrent Convolutional Transformer for Long Time-series Representation",
    "std_review": {
      "summary": "TimelyGPT introduces a novel recurrent convolutional transformer designed for irregular time-series data, leveraging pre-training to improve ultra-long-term forecasting accuracy and efficiency. The model outperforms existing methods in evaluation, but the review highlights several areas for improvement, including unclear dataset size calculation, lack of performance data without pre-training, and insufficient baseline details.",
      "strengths": [
        "Introduces a novel approach to model irregular time-series data.",
        "Demonstrates strong performance in ultra-long-term forecasting tasks.",
        "Provides a clear methodology that is easy to understand and replicate."
      ],
      "weaknesses": [
        "Lacks detailed explanation of dataset size calculation.",
        "Does not evaluate model performance without the pre-training step.",
        "Baseline details for ultra-long-term forecasting are not fully described."
      ],
      "questions": [
        "How is the dataset size calculated and reported?",
        "What is the performance of TimelyGPT when pre-training is removed?",
        "Could you provide the parameter count and pre-training details for the baselines used in ultra-long-term forecasting?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "2SuA42Mq1c",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a benchmark for evaluating machine learning algorithms across five medical domains using a unified dataset. It highlights performance differences among algorithms, especially when hyper‑parameters are not finely tuned. While comprehensive, the study has limitations such as limited hyper‑parameter exploration and potential dataset biases. Overall, it is a valuable contribution but requires improvements in documentation and future expansion.",
      "strengths": [
        "Comprehensive benchmarking across multiple medical domains",
        "Inclusion of hyper‑parameter tuning to provide insights into performance",
        "Clear reporting of results with a matrix for different hyper‑parameter settings"
      ],
      "weaknesses": [
        "Limited hyper‑parameter exploration, missing other critical parameters",
        "Lack of a detailed results matrix for each hyper‑parameter setting",
        "Potential biases in datasets sourced primarily from advanced countries"
      ],
      "questions": [
        "Should the benchmark include additional hyper‑parameters beyond learning rate and threshold?",
        "What strategies can be employed to update and maintain the benchmark over time?",
        "How can the benchmark be expanded to include more medical domains and modalities?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "2uHTuvDkLZ",
    "title": "Physics-aware Causal Graph Network for Spatiotemporal Modeling",
    "std_review": {
      "summary": "The paper introduces a physics-aware causal graph network designed for spatiotemporal modeling, combining graph neural networks with causal reasoning to enhance prediction accuracy and interpretability in climate applications. While the approach shows promise, it faces challenges such as handling ambiguous physics knowledge, noisy data, and limited extensibility beyond climate domains. The authors should address these issues and provide more comprehensive comparisons with existing methods to strengthen the case for acceptance.",
      "strengths": [
        "Integrates physics-based knowledge with machine learning to improve model performance in domains with physical constraints.",
        "Leverages graph neural networks to effectively model complex spatio-temporal relationships, particularly relevant for climate data.",
        "Incorporates causal reasoning to enhance model interpretability and trustworthiness for practical applications."
      ],
      "weaknesses": [
        "Performance under ambiguous or poorly defined physics knowledge is not thoroughly evaluated.",
        "Lack of detailed analysis on how the model handles noisy data.",
        "Limited demonstration of model extensibility to other domains.",
        "Missing comparison with state-of-the-art spatio-temporal GNN frameworks.",
        "Insufficient explanation of how causal relationships are integrated with real-world equations."
      ],
      "questions": [
        "How does the model perform when the prior physics knowledge is ambiguous or not well established?",
        "What mechanisms enable the model to handle noisy data effectively?",
        "Can you provide examples or case studies demonstrating the model's extensibility to other domains?",
        "How does the proposed method compare with state-of-the-art spatio-temporal GNN frameworks?",
        "Please clarify how causal relationships are integrated with real-world equations within the model."
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "2UlfvGU6rL",
    "title": "Equivariant Graph Neural Operator",
    "std_review": {
      "summary": "The paper introduces a novel approach to modeling dynamic systems by incorporating a multiplicative state that interacts with input sequences. It proposes performing a Discrete Fourier Transformation on a single time step to enable frequency domain analysis, improving accuracy in capturing periodic components. The model is evaluated on its ability to handle both single time-step inputs and sequences, with an embedding of the time interval Δt to capture temporal dynamics. While innovative, the approach has limitations such as training complexity and assumptions of stationarity, which could affect its applicability to real-world scenarios.",
      "strengths": [
        "Innovative state multiplication enhances expressive power.",
        "Efficient DFT implementation reduces computational complexity.",
        "Flexibility with input types broadens applicability."
      ],
      "weaknesses": [
        "Complexity of state multiplication may hinder training.",
        "Assumes stationarity, limiting applicability to non-stationary data.",
        "Limited scalability for very large datasets."
      ],
      "questions": [
        "How does the model handle non-stationary or time-varying systems?",
        "What robustness analysis has been performed against noisy or outlier inputs?",
        "Can the model be extended to handle multi-dimensional or graph-structured data?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "2UnCj3jeao",
    "title": "Unbalancedness in Neural Monge Maps",
    "std_review": {
      "summary": "The paper presents a novel neural approach to handle unbalancedness in Monge maps, showing improved efficiency and accuracy over existing methods. While innovative, the method introduces complexity and scalability concerns. The authors provide strong theoretical insights and empirical evidence, but the approach is limited to specific contexts. Overall, the work is promising with some practical considerations.",
      "strengths": [
        "Introduces a unique method for incorporating unbalancedness into Monge maps.",
        "Demonstrates superior empirical performance compared to traditional techniques.",
        "Provides novel theoretical contributions, such as Proposition 3.1."
      ],
      "weaknesses": [
        "Focuses primarily on theoretical and empirical improvements within Monge maps.",
        "Increases model complexity with the use of neural networks.",
        "Scalability to large datasets or complex problems is not fully explored."
      ],
      "questions": [
        "How does the method perform on datasets with varying degrees of unbalancedness?",
        "What are the practical implications of the increased model complexity?",
        "Can the approach be extended to other types of maps or applications beyond Monge maps?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "2uwvigLUr8",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a novel approach to recommender systems by incorporating randomness into learned propensities and imputed errors, aiming to improve robustness and accuracy. The authors provide a solid theoretical framework and empirical evidence showing improved performance over deterministic models. While the approach is promising, there are concerns about the rigor of the theoretical proof and the completeness of the empirical evaluation.",
      "strengths": [
        "Introduces a novel perspective by incorporating randomness into propensities and errors.",
        "Provides a solid theoretical foundation for the proposed approach.",
        "Demonstrates empirical improvements over deterministic models."
      ],
      "weaknesses": [
        "Theoretical proof of Theorem 1 could be more rigorous.",
        "Empirical evaluation lacks comparison with state-of-the-art models.",
        "Definition 1 omits a covariance term, potentially limiting practical applicability."
      ],
      "questions": [
        "Can the theoretical proof be strengthened to more rigorously justify the use of expectations and the double expectation formula?",
        "How does the method perform when compared to recent state-of-the-art models, such as neural network-based MF or graph neural network-based MF?",
        "What is the impact of omitting the covariance term in Definition 1 on the method's behavior in practical scenarios?"
      ],
      "overall_score": "Accept",
      "confidence": "High"
    }
  },
  {
    "paper_id": "2V1Z0Jdmss",
    "title": "On the Over-Memorization During",
    "std_review": {
      "summary": "The paper introduces the Data-Oblivious Augmentation (DOM) framework, which generates data augmentation patterns invariant to transformations to improve model robustness against noise, outliers, and contamination. It applies to three augmentation types and proposes a fixed loss threshold and a dynamic version (DOMDA) that adapts the threshold. Experiments on CIFAR-10 show effectiveness, but scalability and generalizability on larger datasets like Tiny-ImageNet and ImageNet are not fully demonstrated. The fixed loss threshold may limit generalizability, and the computational cost of DOMDA could be prohibitive for some applications.",
      "strengths": [
        "Provides a novel approach to data augmentation focusing on invariance to transformations.",
        "Introduces DOMDA with a dynamic loss threshold, offering flexibility.",
        "Clearly distinguishes between 'natural' and 'transformed' patterns, aiding interpretation."
      ],
      "weaknesses": [
        "Fixed loss threshold may limit generalizability across datasets and loss functions.",
        "Additional computational cost of DOMDA could be prohibitive for some applications.",
        "Abstract definition of 'pattern' may lead to ambiguity in results.",
        "Limited experiments on larger datasets may not fully demonstrate scalability."
      ],
      "questions": [
        "How does the fixed loss threshold impact performance on datasets with varying characteristics?",
        "What is the computational cost of DOMDA compared to traditional augmentation techniques?",
        "How can the abstract definition of 'pattern' be made more concrete for future comparisons?",
        "What are the scalability and robustness implications of applying DOM to larger datasets like Tiny-ImageNet and ImageNet?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "2VAi5F9BOJ",
    "title": "PLPP: Prompt Learning with Perplexity for Vision-Language Models",
    "std_review": {
      "summary": "The paper introduces PLPP, a method that enhances prompt readability in vision-language models by penalizing perplexity during optimization. Experiments show that PLPP improves prompt readability without significantly harming model performance on downstream tasks. The method is evaluated on the CoOp benchmark, demonstrating consistent gains in interpretability across various datasets and task difficulties. Overall, PLPP offers a practical and theoretically grounded approach to better align model outputs with human understanding.",
      "strengths": [
        "Innovative approach to optimizing prompts by directly penalizing perplexity.",
        "Demonstrates tangible improvements in prompt readability, crucial for AI usability.",
        "Provides a clear theoretical foundation linking perplexity minimization to both model performance and human comprehension."
      ],
      "weaknesses": [
        "Performance may be sensitive to hyperparameter choices, particularly the weight of the perplexity term.",
        "Evaluation is limited to the CoOp benchmark, which may not fully capture the method's broad applicability.",
        "Risk of overfitting to training data, potentially limiting generalizability.",
        "Lacks direct human evaluation to assess actual readability and interpretability improvements."
      ],
      "questions": [
        "How robust is PLPP to variations in the choice of language model and embedding layer?",
        "What strategies can be employed to mitigate the risk of overfitting to specific training data?",
        "How can human evaluation be incorporated to better assess the qualitative improvements in prompt readability?"
      ],
      "overall_score": "Accept",
      "confidence": "High"
    }
  },
  {
    "paper_id": "2wFXD2upSQ",
    "title": "A Demon at Work: Leveraging Neuron Death",
    "std_review": {
      "summary": "The paper introduces Dynamic Pruning (DemP), a method that leverages the concept of 'dead neurons' in convolutional layers to accelerate training. By modeling weight dynamics with an absorbing Brownian motion, DemP identifies and prunes unresponsive filters, achieving significant speedups without accuracy loss. The approach is evaluated on image classification tasks, showing strong results compared to existing pruning methods. While innovative, the paper has some clarity and reproducibility concerns that need addressing.",
      "strengths": [
        "Introduces a novel pruning approach using dead neurons.",
        "Demonstrates substantial training speedups on large models.",
        "Provides a rigorous theoretical framework for dynamic pruning.",
        "Shows broad applicability to various architectures."
      ],
      "weaknesses": [
        "Lacks clear baseline comparison with unstructured pruning.",
        "Does not clearly distinguish dynamic pruning from other sparse methods.",
        "Does not thoroughly explore hyperparameter sensitivity.",
        "Lacks quantitative validation of pruned neuron permanence."
      ],
      "questions": [
        "Clarify the exact regularization schedule used for unstructured pruning baselines.",
        "Provide concrete speedup results for larger models.",
        "Investigate the impact of hyperparameter choices on model accuracy.",
        "Explore the method's effectiveness on modern architectures like Vision Transformers.",
        "Include quantitative measures to confirm the permanence of pruned neurons."
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "2wwPG1wpsu",
    "title": "LST-Bench:A Benchmark for long sequence time-series forecasting Task",
    "std_review": {
      "summary": "The paper introduces LST-Bench, a benchmark for long sequence time-series forecasting in the electricity industry. It evaluates various model architectures and highlights that while models achieve low MSE, predictions often show repetitive patterns, indicating model degeneracy. The study also notes rapid convergence after a single epoch, raising questions about generalization. Overall, the paper provides valuable insights but has limitations in generalization evaluation and theoretical depth.",
      "strengths": [
        "Comprehensive benchmark setup with diverse model architectures and datasets.",
        "Clear focus on industry-relevant problem in the electricity sector.",
        "Insights into model degeneracy and rapid convergence, contributing to the field."
      ],
      "weaknesses": [
        "Limited generalization evaluation across different domains and time series characteristics.",
        "Insufficient analysis of hyper-parameter impact on model performance.",
        "Lack of theoretical underpinnings for observed phenomena."
      ],
      "questions": [
        "How can the benchmark be extended to evaluate model generalization across diverse domains?",
        "What systematic hyper-parameter tuning strategies should be employed to ensure robust results?",
        "What theoretical analysis can explain the causes of model degeneracy and rapid convergence?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "2XBBumBGeP",
    "title": "srgb Real Noise Modeling via Noise-Aware Sampling with Normalizing Flows",
    "std_review": {
      "summary": "The paper introduces NAFlow, a deep learning framework for non-far-field image denoising that effectively handles speckle noise and low SNR through a Noise‑Aware Sampling module and multi‑scale modeling. Extensive experiments on the SIDD dataset and additional datasets across devices demonstrate significant performance gains over existing methods, highlighting NAFlow's strong generalizability. While noting potential computational complexity and hyperparameter sensitivity, the review concludes with a strong acceptance of the work.",
      "strengths": [
        "Improved noise handling through a Noise‑Aware Sampling module.",
        "Effective multi‑scale modeling captures both coarse and fine image details.",
        "Demonstrated strong generalizability across multiple datasets and device types."
      ],
      "weaknesses": [
        "Potential computational complexity from the multi‑scale architecture.",
        "Performance may be sensitive to hyperparameter tuning.",
        "Impact on other imaging modalities remains to be fully validated."
      ],
      "questions": [
        "How does NAFlow perform on very low‑SNR images compared to state‑of‑the‑art methods?",
        "What is the computational cost of NAFlow in real‑time applications?",
        "Can the Noise‑Aware Sampling module be adapted for other types of noise beyond speckle noise?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "2XkTz7gdpc",
    "title": "Efficient and Scalable Graph Generation",
    "std_review": {
      "summary": "The paper presents a novel graph generative model that efficiently scales to large graphs by combining an iterative expansion process with spectral conditioning. It outperforms existing scalable baselines in both performance and scalability, while ensuring the validity and uniqueness of generated graphs. The model addresses key challenges in graph generation and demonstrates strong results, though some interpretability and domain-specific evaluation concerns remain.",
      "strengths": [
        "Introduces a novel iterative expansion process for efficient large-scale graph generation.",
        "Leverages spectral conditioning to improve generated graph quality.",
        "Demonstrates superior performance and scalability compared to current baselines.",
        "Provides comprehensive ablations to evaluate model components."
      ],
      "weaknesses": [
        "The spectral conditioning process may reduce model interpretability.",
        "Effectiveness on specific graph domains requires further investigation.",
        "Ablations do not cover all model variations, limiting robustness understanding."
      ],
      "questions": [
        "How can the interpretability of the spectral conditioning process be improved?",
        "What are the model's limitations on specific graph domains, and how can they be addressed?",
        "Are there additional ablations to explore the model's robustness across different variations?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "2XwBIcywWM",
    "title": "Learning Variational Neighbor Labels for",
    "std_review": {
      "summary": "The paper introduces a novel meta‑generalization framework for domain adaptation that does not require labeled target domain data. It leverages a meta‑learning paradigm to balance source and target domain losses, achieving improved performance on benchmarks like Office‑Home and VisDA compared to existing methods. While the approach is theoretically sound and empirically successful, it suffers from lower performance on Office‑Home, potential hyper‑parameter tuning issues, non‑executable code, and lack of single‑source validation.",
      "strengths": [
        "Introduces a novel meta‑generalization framework for domain adaptation without target domain labels.",
        "Provides a clear theoretical motivation for the meta‑loss formulation.",
        "Demonstrates substantial empirical improvements on challenging domain adaptation datasets."
      ],
      "weaknesses": [
        "Underperforms on the Office‑Home dataset compared to baseline results.",
        "Complexity of hyper‑parameter tuning may affect reproducibility.",
        "Supplementary code is non‑executable, hindering immediate validation.",
        "Lacks experiments in single‑source domain generalization settings."
      ],
      "questions": [
        "How can the method be extended to handle more complex domain shifts beyond Office‑Home?",
        "What impact does the choice of n (number of samples per domain) have on performance?",
        "Could additional regularization improve performance on Office‑Home?",
        "How robust is the method to variations in source domain size and diversity?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "2Y5Gseybzp",
    "title": "",
    "std_review": {
      "summary": "The paper presents a novel framework for weakly supervised learning that handles three types of imprecise annotations (Precise, Semi‑Precise, and Noisy Labels) using variational inference. It derives loss functions for each scenario and integrates ground‑truth or Bayes label distributions as latent variables, improving performance on image classification tasks. While innovative, the framework has some limitations in terms of mathematical complexity, novelty, and scalability.",
      "strengths": [
        "Innovative loss function derivation for three imprecise annotation scenarios.",
        "Flexible integration of latent variables enhances model robustness.",
        "Empirical performance surpasses existing methods on benchmark datasets."
      ],
      "weaknesses": [
        "Complex mathematical derivations may limit accessibility.",
        "Builds on prior work, raising questions about unique contributions.",
        "Does not thoroughly address local optima risks in EM optimization.",
        "Computational complexity and scalability are not fully discussed.",
        "Limited exploration of applicability beyond the three primary label settings."
      ],
      "questions": [
        "Should the derivations of the loss functions be expanded for clarity?",
        "How does the framework mitigate local optima issues during EM optimization?",
        "What is the computational complexity and scalability of the proposed EM formulation?",
        "How can the framework be extended to more complex learning scenarios?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "2Y5kBPtU0o",
    "title": "Mera dEmonstrationN Distillation for Efficient and Effective In-Context Learning",
    "std_review": {
      "summary": "The paper introduces MEND, a two-stage training method for large language models that uses demonstration examples to guide distillation. MEND shows strong performance on benchmarks while maintaining the models' in-context learning abilities. The method is efficient and introduces minimal additional computational overhead. Overall, the paper makes a valuable contribution to improving LLMs with demonstration data.",
      "strengths": [
        "Introduces a novel two-stage training approach that effectively combines demonstration distillation with in-context learning.",
        "Demonstrates strong performance across multiple benchmarks, often outperforming baselines.",
        "Maintains the LLMs' intrinsic in-context learning capabilities while leveraging demonstration data."
      ],
      "weaknesses": [
        "Performance is sensitive to hyperparameters like λ and the number of demonstration examples.",
        "Requires demonstration examples to be formatted in a specific way, which may limit applicability.",
        "Evaluation focuses on a limited set of benchmarks, potentially overlooking broader performance."
      ],
      "questions": [
        "How robust is MEND to variations in demonstration formatting across different datasets?",
        "Can MEND be integrated with existing LLM training pipelines without significant modifications?",
        "What is the impact of the size of demonstration vectors on the overall efficiency and effectiveness of MEND?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "2y8XnaIiB8",
    "title": "Vision-Language Dataset Distillation",
    "std_review": {
      "summary": "The paper presents a novel vision‑language dataset distillation method that creates compact datasets while preserving retrieval capabilities. By aligning image and text embeddings through bi‑trajectories, the method outperforms baselines on retrieval tasks and reduces computational costs. Despite promising results, the evaluation is limited to retrieval, and the method's robustness and theoretical foundations warrant further exploration.",
      "strengths": [
        "Innovative bi‑trajectory distillation technique that couples image and text embeddings.",
        "Demonstrated significant performance gains on retrieval tasks compared to baselines.",
        "Provides practical efficiency improvements with reduced storage and training requirements."
      ],
      "weaknesses": [
        "Evaluation focuses solely on retrieval tasks, lacking assessment of other vision‑language tasks.",
        "Baseline comparison is limited to retrieval metrics, potentially missing broader relevance.",
        "Lacks detailed analysis of robustness across model architectures and training conditions.",
        "Computational cost savings are mentioned but not quantified with specific metrics."
      ],
      "questions": [
        "How does the method perform on other vision‑language tasks beyond retrieval?",
        "What is the robustness of the distilled datasets across different model architectures and training conditions?",
        "Could you provide quantitative metrics for the computational cost savings?",
        "Is there a theoretical analysis supporting the effectiveness of bi‑trajectory matching?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "2zoi9YI21Y",
    "title": "",
    "std_review": {
      "summary": "The paper presents a novel zero-shot purification framework for adversarial examples called Iterative Natural-Manifold Purification (INMP). It combines a coarse blur operation to project adversarial samples onto the natural image manifold with an iterative refinement step to further reduce perturbations. Experiments show significant robustness gains over existing zero-shot methods with low computational overhead, indicating practical utility. However, the method lacks theoretical guarantees and may trade off clean accuracy, with domain specificity and computational cost not fully quantified.",
      "strengths": [
        "Introduces a data-agnostic zero-shot purification method.",
        "Effectively projects adversarial samples onto the natural image manifold using a simple blur operation.",
        "Iterative refinement systematically reduces perturbations with modest computational cost.",
        "Demonstrates strong empirical performance gains over existing zero-shot techniques."
      ],
      "weaknesses": [
        "Lacks formal theoretical analysis or convergence guarantees for the iterative refinement.",
        "Potential trade-off between robustness gains and clean accuracy is not fully quantified.",
        "Effectiveness is primarily validated on image data, raising questions about generalizability.",
        "Exact computational overhead relative to state-of-the-art methods is not quantitatively compared."
      ],
      "questions": [
        "What are the theoretical guarantees for the convergence and long-term behavior of the iterative refinement step?",
        "How does the method quantitatively quantify the trade-off between robustness gains and potential loss of clean accuracy?",
        "What additional analyses or experiments could address the domain specificity of the blur operation and refinement?",
        "How does the computational cost of INMP compare to other state-of-the-art zero-shot defense methods?"
      ],
      "overall_score": "Accept",
      "confidence": "High"
    }
  },
  {
    "paper_id": "30aSE3FB3L",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a novel approach to deep learning on non-Euclidean manifolds by leveraging gyrovector spaces, resulting in SPD and Grassmann manifold neural networks. It demonstrates improved performance on matrix data tasks compared to Euclidean baselines, offering a more interpretable and potentially more efficient framework. While the method is innovative and empirically effective, it is limited to specific manifolds and lacks strong theoretical guarantees.",
      "strengths": [
        "Introduces a novel way to handle non-Euclidean data using gyrovector spaces.",
        "Provides a more interpretable framework for building convolutional layers on matrix manifolds.",
        "Offers a computationally efficient alternative to traditional hyperbolic networks."
      ],
      "weaknesses": [
        "Applicability is limited to SPD and Grassmann manifolds.",
        "Implementation complexity may be high for practitioners unfamiliar with gyrovector spaces.",
        "Lacks strong theoretical guarantees for convergence or generalization."
      ],
      "questions": [
        "How can the method be extended to other types of matrix manifolds beyond gyrovector spaces?",
        "What are the theoretical guarantees for convergence and generalization of the proposed models?",
        "How does the proposed approach compare to other state-of-the-art manifold learning methods?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "30L0rr9W8A",
    "title": "LatentCBF: A Control Barrier Function in Latent Space for Safe Control",
    "std_review": {
      "summary": "The paper presents LatentCBF, a method for learning safe control policies by using a learned barrier function in a latent space. It encodes a safe set into the latent space and learns a barrier function there, then jointly trains an encoder and dynamics model before policy learning. The approach is evaluated on both simulated and real-world tasks, showing improved safety over baselines. Overall, the paper is well-received for its innovative approach and strong empirical results, though some concerns about complexity and generalization are noted.",
      "strengths": [
        "Novel integration of control barrier functions with learned latent representations.",
        "Ability to handle high-dimensional and complex state spaces efficiently.",
        "Joint training of encoder and dynamics model ensures consistency with system dynamics.",
        "Comprehensive evaluation on simulated and real-world robotic tasks."
      ],
      "weaknesses": [
        "Additional complexity and potential instability introduced by learning the barrier function.",
        "Assumption that the encoder accurately maps the safe set to the latent space.",
        "Reliance on learned dynamics may limit generalization to unseen aspects of the system.",
        "Safety verification relies on evaluating the barrier function, which may not capture all unsafe trajectories."
      ],
      "questions": [
        "How robust is the method to variations in the safe set definition and its representation in the latent space?",
        "What are the implications of the encoder's accuracy on the overall safety guarantees?",
        "How can the method be extended to handle systems with highly nonlinear dynamics or uncertain parameters?",
        "Are there theoretical guarantees on the convergence of the joint training process for the encoder and dynamics model?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "30N3bNAiw3",
    "title": "Separating common from salient patterns with Contrastive Representation Learning",
    "std_review": {
      "summary": "SepCLR introduces a contrastive learning framework that effectively separates common and salient patterns in multi-modal data. The approach leverages a novel InfoMax objective and k-JEM regularization to enhance pattern separation, with strong empirical results across various datasets and tasks. While demonstrating significant promise, the framework's complexity and limited analysis of hyperparameter impact and scalability are noted.",
      "strengths": [
        "Proposes a novel theoretical framework for separating common and salient patterns using contrastive learning.",
        "Introduces a unique InfoMax objective that effectively estimates mutual information between common and salient factors.",
        "Demonstrates strong empirical results across multiple datasets and tasks, outperforming baselines."
      ],
      "weaknesses": [
        "The complexity of the proposed framework may make it challenging to implement and optimize.",
        "The effectiveness of SepCLR could be limited to specific types of multi-modal data or tasks.",
        "Lacks detailed analysis of the impact of hyperparameters on performance.",
        "Scalability to large-scale datasets or high-dimensional data is not thoroughly explored."
      ],
      "questions": [
        "How does SepCLR's performance scale with increasing dataset size or dimensionality?",
        "What is the impact of different hyperparameter settings on SepCLR's effectiveness?",
        "Could the framework be adapted for other types of multi-modal data beyond those tested?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "31IOmrnoP4",
    "title": "",
    "std_review": {
      "summary": "The paper introduces Repelling Random Walks (RRW), an algorithm that improves graph sampling and Monte Carlo methods by preventing node revisits, leading to reduced variance and faster convergence. Theoretical analysis and empirical evaluations across tasks like PageRank estimation, graphlet detection, and kernel approximation show significant improvements over existing methods. While the approach has some limitations related to assumptions and implementation details, it demonstrates strong potential for practical applications in graph analysis.",
      "strengths": [
        "Introduces a unique mechanism to prevent node revisits in random walks, addressing a common limitation in traditional sampling methods.",
        "Provides strong theoretical guarantees with rigorous analysis showing improved variance reduction and convergence properties.",
        "Demonstrates substantial performance gains across multiple graph tasks with clear quantitative improvements over baseline methods."
      ],
      "weaknesses": [
        "Theoretical analysis relies on assumptions about graph structure and distribution that may limit applicability.",
        "Computational overhead of ensuring node uniqueness may impact scalability.",
        "Lacks detailed guidance on parameter tuning and handling edge cases, affecting reproducibility.",
        "Comparison with other methods is limited, though the paper shows competitive performance."
      ],
      "questions": [
        "How does the algorithm perform on disconnected or highly skewed graphs where the connectivity assumptions may not hold?",
        "What are the practical guidelines for tuning parameters to achieve optimal performance in real-world scenarios?",
        "How does the RRW algorithm compare to the latest graph-specific sampling techniques in terms of efficiency and accuracy?"
      ],
      "overall_score": "Accept",
      "confidence": "High"
    }
  },
  {
    "paper_id": "324zEJCo3a",
    "title": "Local Vs. Global Interpretability:",
    "std_review": {
      "summary": "The paper presents a theoretical framework for global sufficient reasons in model interpretability, defining and unifying subset‑minimal and cardinality‑minimal approaches. It highlights interpretability differences between linear classifiers and decision trees and discusses computational complexity. The work is well‑structured, with clear definitions and insights, though some results may seem straightforward.",
      "strengths": [
        "Clear and rigorous definition of global sufficient reasons.",
        "Unified characterization of minimal global sufficient reason.",
        "Valuable distinctions between local and global interpretability of different models."
      ],
      "weaknesses": [
        "Some propositions may be seen as direct consequences of definitions.",
        "Practical implications of theoretical results could be more detailed.",
        "Comparison with prior work on local interpretability is brief."
      ],
      "questions": [
        "Could the distinction between local and global interpretability be more explicitly motivated?",
        "How do the theoretical results inform the design and evaluation of interpretable models?",
        "What are the practical implications of the relaxed notion of global explainability?"
      ],
      "overall_score": "Accept",
      "confidence": "High"
    }
  },
  {
    "paper_id": "327tbF3S65",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a method for 3D shape representation using an occupancy function processed by a 2D CNN, aiming to generate new shapes from a 2D latent space via a VAE. It demonstrates competitive results on benchmark datasets but lacks thorough justification for using occupancy functions over SDFs, detailed explanation of sparse point cloud projection, and comprehensive comparison with other latent space models. The latent space dimension's impact is also underexplored.",
      "strengths": [
        "Introduces a novel occupancy function approach for 3D shape representation.",
        "Demonstrates effective 3D shape generation using a 2D CNN and VAE latent space.",
        "Provides clear methodology and competitive benchmark results."
      ],
      "weaknesses": [
        "Occupancy function choice over SDFs is not well justified.",
        "Projection of sparse point clouds onto a 2D CNN is not a standard method.",
        "Lacks comparison with other powerful latent space models.",
        "Latent space dimension impact is not thoroughly investigated."
      ],
      "questions": [
        "Why use the occupancy function to represent a 3D shape instead of the SDF?",
        "How is the projection of sparse point clouds onto a 2D CNN performed?",
        "Will the code be publicly available?",
        "Did you compare the proposed method with other powerful latent space models?",
        "What is the dimension of the latent space z, and how does it affect performance?"
      ],
      "overall_score": "Borderline",
      "confidence": "Medium"
    }
  },
  {
    "paper_id": "32camXjW25",
    "title": "Covariance-corrected Whitening Alleviates Network Degeneration on Imbalanced Classification",
    "std_review": {
      "summary": "The paper proposes Group‑Aware Resampling (GRBS), a heuristic‑based sampling method that dynamically adjusts sampling rates using a Bayesian Expectation‑Threshold (BET) approach to address class imbalance. While it introduces a novel way to control minority class sampling and provides a qualitative discussion on feature correlations, the method lacks a rigorous theoretical foundation and its experimental results are inferior to state‑of‑the‑art baselines. The review highlights several weaknesses, including insufficient feature analysis and a lack of comparison with recent advanced methods.",
      "strengths": [
        "Introduces a heuristic‑based sampling method that dynamically adjusts sampling rates based on a Bayesian Expectation‑Threshold, offering a flexible alternative to fixed sampling rates.",
        "Provides a thorough qualitative discussion on the impact of highly correlated features on model performance, supported by clear visualizations.",
        "Extends existing work on class imbalance by incorporating feature covariance and normalization considerations, offering a comprehensive approach."
      ],
      "weaknesses": [
        "Lacks a detailed theoretical analysis or motivation for the sampling strategy.",
        "The qualitative discussion on why highly correlated features degrade performance is superficial, and the SVD results are not adequately explained.",
        "Reported results are inferior to current baselines, raising questions about practical competitiveness.",
        "Ambiguity in comparing training losses across different sampling strategies due to variations in underlying training datasets."
      ],
      "questions": [
        "Can the authors provide a more detailed theoretical justification for the heuristic sampling approach?",
        "How does the feature analysis account for the impact of highly correlated features on model performance?",
        "Could the experimental setup be expanded to include comparisons with more recent state‑of‑the‑art methods using standard backbones like ResNet‑50 or EfficientNet‑B0?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "33XGfHLtZg",
    "title": "",
    "std_review": {
      "summary": "The paper presents a conformal risk control method using bounded loss functions, offering worst-case guarantees and theoretical grounding. While the approach is theoretically sound and addresses practical scenarios, the review highlights several areas for improvement, including clearer exposition, explicit computation details, and better articulation of novelty and advantages.",
      "strengths": [
        "Introduces a novel conformal risk control method leveraging bounded loss functions.",
        "Provides worst-case guarantees, stronger than traditional high-probability guarantees.",
        "Theoretical analysis is thorough, establishing conditions and guarantees."
      ],
      "weaknesses": [
        "The intuitive explanation in Section 1.1 is unintuitive and may hinder understanding.",
        "Computation of the optimal threshold λ^ is not explicitly detailed.",
        "Differences from existing conformal risk control works are not clearly explained.",
        "Assumptions in Theorem 2 lack sufficient justification.",
        "Notation and proofs in Section 2.1 are confusing.",
        "Lacks motivating examples of practical relevance.",
        "Computational feasibility of λ^ is not well-justified."
      ],
      "questions": [
        "Can you provide more intuitive examples of when bounded loss functions are preferable over unbounded ones?",
        "How is the optimal threshold λ^ computed explicitly, and what are the computational details?",
        "Could you clarify the specific differences and advantages of this method compared to existing approaches?",
        "What are the practical implications of the worst-case guarantees in real-world applications?",
        "How does the method handle scenarios where the loss function is not monotonic?"
      ],
      "overall_score": "6: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "34STseLBrQ",
    "title": "Polynomial Width is Sufficient for Set Representation with High-dimensional Features",
    "std_review": {
      "summary": "The paper introduces a theoretical framework for permutation‑invariant DeepSets that extends to high‑dimensional inputs, proving that polynomial embedding dimensions can be achieved through power mapping and exponential activation functions. Empirical results support the theory, showing effective representation of set functions. The work addresses key limitations of prior research and opens avenues for future study on smoothness and hierarchical representations.",
      "strengths": [
        "Generalizes permutation‑invariant DeepSets to arbitrary feature dimensions.",
        "Provides concrete constructions (power mapping, exponential activation) that achieve polynomial embedding dimensions.",
        "Proves invertibility of the sum‑pooling operation, enhancing model robustness.",
        "Offers geometric intuition and clear theoretical proofs."
      ],
      "weaknesses": [
        "Introduces computational complexity with the proposed constructions.",
        "Relies on specific input assumptions that may limit real‑world applicability.",
        "Empirical validation is based on a limited set of experiments."
      ],
      "questions": [
        "How does the computational complexity of the proposed constructions impact practical implementations?",
        "What are the broader implications of the input assumptions on real‑world scenarios?",
        "How can the empirical validation be expanded to demonstrate general applicability?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "36L7W3ri4U",
    "title": "Beating Price of Anarchy and Gradient Descent without Regret in Potential Games",
    "std_review": {
      "summary": "The paper introduces PRPGs and studies q-replicator dynamics within them, showing that in 2×2 PRPGs, gradient descent can achieve a higher average price of anarchy than replicator dynamics under certain conditions. It extends the analysis to higher dimensions with numerical simulations, addressing initial measure uncertainty favorably. While the results are strong and the analysis rigorous, the focus on 2×2 games and the limited exploration of alternative initializations may limit broader applicability.",
      "strengths": [
        "Introduces a novel class of games (PRPGs) that encompass most finite potential games.",
        "Provides a clear and rigorous mathematical analysis of convergence properties.",
        "Employs numerical simulations to validate theoretical results in higher-dimensional games."
      ],
      "weaknesses": [
        "The analysis is primarily focused on 2×2 PRPGs and higher-dimensional extensions.",
        "Does not explore alternative initialization strategies beyond random initialization.",
        "Practical implications for real-world multi-agent systems are not fully discussed."
      ],
      "questions": [
        "How do the results generalize to more complex game structures beyond 2×2 PRPGs?",
        "What are the implications of the findings for real-world multi-agent systems?",
        "Could alternative initialization strategies beyond random initialization provide additional insights?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "381QSrWdF2",
    "title": "Law of Balance and Stationary Distribution of Stochastic Gradient Descent",
    "std_review": {
      "summary": "The paper introduces a novel 'law of balance' to analyze SGD dynamics under symmetry, deriving a stationary distribution for diagonal linear networks and exploring phase transitions, loss of ergodicity, and fluctuation inversion. It extends findings to nonlinear networks, highlighting the impact of regularization and parameter degeneracy. While theoretically insightful, the results are limited to diagonal linear models, and practical implications for deep learning remain to be fully explored.",
      "strengths": [
        "Introduces a novel theoretical framework (law of balance) to analyze SGD dynamics under symmetry, offering a fresh perspective on parameter behavior.",
        "Derives a stationary distribution for SGD in diagonal linear networks, providing a rigorous mathematical foundation for understanding SGD's long-term behavior.",
        "Observes and explains key phenomena such as phase transitions, loss of ergodicity, and fluctuation inversion, which are crucial for understanding SGD's performance in different network depths."
      ],
      "weaknesses": [
        "The model's reliance on diagonal linear networks may limit the generalizability of the results to more complex, nonlinear architectures commonly used in practice.",
        "The theoretical analysis does not fully account for the effects of regularization beyond L2, which is a common practice in machine learning.",
        "The degeneracy of covariance matrices, while theoretically justified, may not fully capture the practical behavior of SGD in real-world scenarios with more complex loss landscapes."
      ],
      "questions": [
        "How do the findings generalize to more complex, nonlinear network architectures beyond diagonal linear networks?",
        "What is the impact of different regularization techniques (beyond L2) on the phase transitions and ergodicity observed in SGD?",
        "How does the degeneracy of covariance matrices manifest in practical scenarios, and what are the implications for real-world SGD optimization?"
      ],
      "overall_score": "Accept",
      "confidence": "High"
    }
  },
  {
    "paper_id": "38E4yUbrgr",
    "title": "Language Model Self-improvement by Reinforcement Learning Contemplation",
    "std_review": {
      "summary": "The paper introduces Reinforcement Learning Contemplation (RLC), a method that uses language models' own outputs as feedback for self-improvement. Evaluated on CommonGen, BigBench-Hard reasoning tasks, and CNN-Daily Mail summarization, RLC shows significant accuracy gains over baselines like best-of-N, RLHF, and plain RLAIF. While simple and general, the approach's novelty is limited by its reliance on self-generated feedback, and its scalability with larger models remains unproven. The paper lacks discussion on encoder-decoder vs decoder-only models, and reviewers raised questions about its applicability to decoder-only models and the statistical significance of gains.",
      "strengths": [
        "The method is simple and general, applicable to various language model architectures.",
        "RLC improves language models without requiring external supervision, making it more efficient.",
        "Empirical results demonstrate substantial gains on challenging tasks, validating the approach's effectiveness."
      ],
      "weaknesses": [
        "The novelty of RLC may be limited due to the well-explored idea of using self-generated outputs for feedback.",
        "The effectiveness of RLC with larger models remains unproven, potentially limiting its scalability.",
        "The paper lacks a discussion on the differences between encoder-decoder and decoder-only models, which could impact the approach's applicability."
      ],
      "questions": [
        "How does RLC apply to decoder-only models?",
        "What is the impact of using non-PPO trained models?",
        "What is the statistical significance of the improvements observed?",
        "How does RLC differ from RLAIF?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "39cPKijBed",
    "title": "Training Unbiased Diffusion Models From",
    "std_review": {
      "summary": "The paper proposes a time-dependent discriminator to improve temporal coherence in diffusion models, achieving significant improvements in metrics compared to baselines. While the approach is innovative and well-documented, it lacks comprehensive validation, scalability analysis, and comparison with related work, leading to a cautious acceptance.",
      "strengths": [
        "Introduces a novel time-dependent discriminator to enhance temporal coherence.",
        "Provides thorough empirical evaluations with visual and quantitative results.",
        "Clearly defines the contribution of improving temporal consistency."
      ],
      "weaknesses": [
        "Limited generalizability due to reliance on specific temporal dynamics.",
        "Increased computational complexity may hinder scalability.",
        "No thorough analysis of overfitting risks.",
        "Lacks benchmarking against related works like 'Fair Diffusion'."
      ],
      "questions": [
        "How does the method perform on datasets with varying temporal structures?",
        "What strategies can be employed to mitigate overfitting?",
        "How does the computational cost compare to existing time-independent methods?",
        "How does the proposed approach compare to 'Fair Diffusion' in terms of fairness and coherence?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "39HaKNXpsu",
    "title": "Adapt and Diffuse: Sample-Adaptive Reconstruction via Latent Diffusion Models",
    "std_review": {
      "summary": "The paper introduces a severity encoding framework for estimating degradation severity in image restoration, specifically Gaussian blur, and integrates it into an adaptive diffusion model called Flash-Flash. The approach outperforms existing methods on Gaussian blur benchmarks, achieving higher fidelity and faster inference. While innovative, the paper has some limitations, such as limited hyper-parameter analysis and evaluation scope.",
      "strengths": [
        "Introduces a principled severity encoding framework for degradation severity estimation.",
        "Develops an adaptive diffusion model (Flash-Flash) that leverages severity estimates to improve image restoration.",
        "Demonstrates superior empirical performance compared to state-of-the-art methods on Gaussian blur benchmarks."
      ],
      "weaknesses": [
        "Does not thoroughly investigate hyper-parameter sensitivity across datasets.",
        "Lacks a comprehensive comparison with non-diffusion restoration methods.",
        "Evaluation is primarily focused on Gaussian blur, limiting assessment of model capabilities for other degradations."
      ],
      "questions": [
        "How robust is the model to hyper-parameter sensitivity across different datasets?",
        "What is the impact of the severity encoding framework on performance for non-Gaussian degradations?",
        "How does Flash-Flash compare to traditional restoration algorithms in terms of efficiency and quality?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3a505tMjGE",
    "title": "AVOID: Alleviating VAE's Overestimation in Unsupervised OOD Detection",
    "std_review": {
      "summary": "The paper proposes PHP, a two-stage method to improve unsupervised OOD detection in VAEs by correcting posterior-prior mismatch and adjusting small OOD entropies. Experiments show significant performance gains over existing methods, but limitations include reliance on specific architectures and lack of evaluation on complex models or ablation studies.",
      "strengths": [
        "Introduces a novel two-stage PHP method to address VAE OOD detection overestimation.",
        "Effectively corrects posterior-prior mismatch and improves OOD detection.",
        "Utilizes a complexity measure in DEC to enhance performance on small OOD entropies.",
        "Demonstrates superior results on benchmark datasets compared to current approaches.",
        "Provides a clear and interpretable framework for understanding OOD detection."
      ],
      "weaknesses": [
        "Effectiveness may be limited to simpler datasets and model architectures.",
        "Relies on specific VAE architectures, potentially restricting applicability.",
        "Computational efficiency not explicitly evaluated.",
        "Lacks a thorough ablation study to assess individual contributions."
      ],
      "questions": [
        "How does the method perform on more complex generative models beyond standard VAEs?",
        "What is the computational efficiency of the proposed PHP and DEC methods?",
        "Could the ablation study provide clearer insights into the contributions of PHP and DEC?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3ARfhjGfdF",
    "title": "Towards Control-Centric Representations in Reinforcement Learning from Images",
    "std_review": {
      "summary": "The paper introduces ReBis, a method for learning control-centric representations in reinforcement learning from images using a bisimulation metric and a transformer-based dynamics model. It effectively addresses spatiotemporal redundancies and sparse rewards, achieving significant performance improvements on Atari and DeepMind control suite tasks. While demonstrating strong theoretical foundations and practical utility, the method's computational complexity and potential limitations in highly dynamic environments are noted.",
      "strengths": [
        "Introduces a novel approach to learning control-centric representations using a bisimulation metric.",
        "Effectively addresses spatiotemporal redundancies and sparse rewards through innovative techniques.",
        "Demonstrates strong performance improvements over existing methods on benchmark tasks.",
        "Provides a clear theoretical foundation by leveraging the bisimulation metric."
      ],
      "weaknesses": [
        "The complexity of the transformer-based dynamics model may lead to high computational costs.",
        "Effectiveness in highly complex or dynamic environments with rapidly changing states and rewards is not fully explored.",
        "Ablation studies do not comprehensively evaluate robustness across a wide range of scenarios."
      ],
      "questions": [
        "How does ReBis perform in highly dynamic or complex environments with rapidly changing states and rewards?",
        "What are the computational implications of using the transformer-based dynamics model in resource-constrained settings?",
        "How does ReBis compare to other recent methods in terms of sample efficiency and generalization?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3aSbJhaVDi",
    "title": "Exploiting Open-World Data for Adaptive Continual Learning",
    "std_review": {
      "summary": "The paper presents a novel approach to continual semi-supervised learning that effectively balances labeled and unlabeled data, addressing catastrophic forgetting while leveraging large unlabeled datasets. It demonstrates strong performance on benchmark datasets and offers a practical framework for real-world applications with abundant unlabeled data. The method's innovative handling of dynamic data and robust evaluation are its key strengths, though some assumptions about data availability and hyperparameter sensitivity could limit its general applicability.",
      "strengths": [
        "Innovative approach to continual learning by dynamically incorporating unlabeled data across tasks.",
        "Robust evaluation on multiple benchmark datasets, showing improved performance and reduced forgetting.",
        "Clear problem definition and practical relevance for real-world scenarios with abundant unlabeled data."
      ],
      "weaknesses": [
        "Assumption that large amounts of unlabeled data are always available and unaffected by task switching.",
        "Baseline comparison with the Independent baseline may not fully capture the benefits of the proposed method.",
        "Reliance on suggested hyperparameters from original implementations could introduce bias."
      ],
      "questions": [
        "How does the method handle changing dynamics in the unlabeled dataset and select samples when all data is exhausted?",
        "Could the authors provide more examples or case studies illustrating the practicality and importance of the Open SSCL problem definition?",
        "What is the impact of distribution shifts on the method's performance, and how does it address such shifts?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3aZCPl3ZvR",
    "title": "",
    "std_review": {
      "summary": "The paper introduces SAM, a novel regularization technique that modifies SGD by adding a Jacobian-based term to the loss function, aiming to improve robustness against label noise. It provides theoretical insights and empirical evidence across varying network widths and training sample sizes, showing SAM's effectiveness compared to standard SGD and other robust methods. While the analysis is limited to 2-layer linear networks, the findings suggest potential benefits in deeper architectures, though practical generalizability and overfitting concerns remain.",
      "strengths": [
        "Introduces a unique regularization method leveraging the Jacobian matrix.",
        "Offers theoretical analysis of SAM's impact on model robustness in over-parameterized settings.",
        "Demonstrates empirical improvements in robustness through comprehensive experiments."
      ],
      "weaknesses": [
        "Analysis limited to 2-layer linear networks, potentially limiting generalizability.",
        "Assumes label noise, which may not translate to scenarios without noise.",
        "Risk of overfitting in over-parameterized models.",
        "Lacks detailed implementation guidance, affecting reproducibility."
      ],
      "questions": [
        "How does SAM perform in deeper, nonlinear architectures beyond 2-layer linear networks?",
        "What is the impact of SAM on models trained without label noise?",
        "Can SAM be combined with other robust training techniques additively?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3b8CgMO5ix",
    "title": "Model guidance via explanations turns image classifiers into segmentation models",
    "std_review": {
      "summary": "The paper introduces a novel approach to weakly-supervised semantic segmentation by establishing a formal equivalence between differentiable heatmap architectures and encoder-decoder segmentation networks. It proposes an unrolled layer-wise relevance propagation (LRP) mechanism to train heatmap layers, integrated with a combined classification and segmentation loss function. The method is evaluated for robustness under class imbalance and diverse object classes, demonstrating competitive performance on standard benchmarks like Pascal VOC and CityScapes. The authors provide extensive ablation studies highlighting the contributions of various architectural components, though some concerns about complexity and code availability remain.",
      "strengths": [
        "Formal equivalence between heatmap and encoder-decoder architectures provides a solid theoretical foundation.",
        "Innovative unrolled LRP mechanism offers a novel way to train heatmap layers, potentially improving interpretability and performance.",
        "Comprehensive evaluation across multiple datasets and scenarios demonstrates robustness.",
        "Strong baselines and ablation studies effectively isolate and demonstrate the impact of different components."
      ],
      "weaknesses": [
        "Complexity of formal equivalence and mathematical derivations may be challenging for readers without a strong ML background.",
        "Unrolled LRP mechanism could introduce significant computational overhead, limiting applicability in resource-constrained environments.",
        "Limited evaluation on a wider variety of datasets could further validate generalizability.",
        "Interpretability trade-offs of the complex LRP mechanism might obscure certain aspects of model behavior.",
        "Absence of explicit code availability or reproducibility guidelines could hinder further research."
      ],
      "questions": [
        "How does the proposed method scale to larger datasets or more complex scenes?",
        "What are the specific computational cost implications of the unrolled LRP mechanism in practical scenarios?",
        "How does the method perform under extreme class imbalance conditions not covered in the current experiments?",
        "Could the tied activation functions be relaxed or replaced with more flexible alternatives without significant loss of performance?",
        "What are the long-term reproducibility and maintenance considerations for the proposed codebase?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3bmjHYX42n",
    "title": "Leveraging Human Revisions for Improving Text-to-Layout Models",
    "std_review": {
      "summary": "The paper introduces a novel dataset of 10,000 images across 50 categories and studies the impact of human-designed edits on machine learning model performance. The authors' systematic analysis reveals significant improvements in model accuracy when incorporating these edits, suggesting potential benefits for model robustness and interpretability. While the dataset is substantial, it may not fully capture real-world scenarios, and the study lacks detailed analysis of edit types and ethical considerations.",
      "strengths": [
        "Introduces a novel dataset of 10,000 images across 50 categories.",
        "Employs a systematic approach to analyze human-designed edits.",
        "Demonstrates clear and significant improvements in model performance.",
        "Contributes to the field by exploring human-designed interventions."
      ],
      "weaknesses": [
        "Dataset size may limit generalizability to real-world scenarios.",
        "Focus on specific categories and images may limit scope.",
        "Lacks detailed analysis of specific edit types.",
        "Does not address ethical considerations or IRB approval."
      ],
      "questions": [
        "How do the results generalize to a broader range of scenarios and categories?",
        "What is the detailed impact of different types of human-designed edits on model performance?",
        "What ethical considerations should be addressed in future research?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3bq3jsvcQ1",
    "title": "Step-Back Prompting Enables Reasoning Via Abstraction in Large Language Models",
    "std_review": {
      "summary": "The paper introduces a novel prompting technique called 'Step-Back' that improves large language models' ability to retrieve high-level facts and perform structured reasoning. Empirical evaluations across several benchmarks show clear improvements on multi-step reasoning tasks, though the method also introduces challenges such as potential loss of relevant facts and increased complexity in question design. The study highlights trade-offs between simplicity and effectiveness of prompting strategies in LLMs.",
      "strengths": [
        "Introduces a structured prompting approach that encourages LLMs to break down complex questions into intermediate steps.",
        "Provides comprehensive empirical evaluations across multiple benchmarks, demonstrating clear improvements.",
        "Grounded in a clear theoretical motivation for decomposing questions to aid reasoning."
      ],
      "weaknesses": [
        "Limited benchmark coverage may not fully capture the versatility of the method.",
        "Evaluation focuses on proprietary models (GPT-3) rather than more recent open-source LLMs.",
        "Potential for over-decomposition leading to loss of high-level facts.",
        "Designing effective Step-Back questions requires careful consideration, which could be challenging for non-experts."
      ],
      "questions": [
        "How does the method perform on a broader set of reasoning benchmarks, including more recent open-source LLMs?",
        "What are the specific criteria for designing effective Step-Back questions to minimize over-decomposition?",
        "Can the approach be adapted to work with less expert users or automated question generation?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3bqesUzZPH",
    "title": "FTA: Stealthy and Adaptive Backdoor Attack with Flexible Triggers on Federated Learning",
    "std_review": {
      "summary": "The paper introduces Feature Trigger Attack (FTA), a novel backdoor insertion method that embeds triggers directly into the global model's parameter space, offering a stealthy and flexible approach. FTA alternates between fixing the classifier and learning per-example triggers, achieving high backdoor hit rates while evading common defenses like clustering-based filtering and Neuron Clipping. Despite its innovative stealth mechanism and flexibility, scalability and federated learning validation remain areas for further exploration.",
      "strengths": [
        "Innovative stealth mechanism by embedding triggers in the parameter space.",
        "High flexibility and personalization through per-example trigger learning.",
        "Strong resistance to post-training defenses such as clustering-based filtering and Neuron Clipping.",
        "Clear theoretical foundation with an optimization formulation balancing stealth and effectiveness."
      ],
      "weaknesses": [
        "Complexity of implementation due to alternating optimization strategy.",
        "Potential scalability issues for very large datasets or complex models.",
        "Limited evaluation in federated learning settings.",
        "Risk of overfitting with highly personalized triggers."
      ],
      "questions": [
        "How does FTA scale to very large datasets or complex models?",
        "What are the implications of FTA in federated learning scenarios?",
        "How can the method be extended to non-IID data distributions?",
        "What strategies can be employed to mitigate overfitting with personalized triggers?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3cE6NKYy8x",
    "title": "Towards Fair Graph Anomaly Detection:",
    "std_review": {
      "summary": "The paper introduces a fairness-aware approach to graph anomaly detection, evaluating nine existing methods on Twitter and Reddit datasets. It highlights the bias in traditional GAD methods when applied across different political leaning groups. While the methodology and findings are novel, the review points out several limitations, such as the representativeness of the datasets, the choice of sensitive attribute, and the lack of exploration of edge definitions and semi-supervised approaches.",
      "strengths": [
        "Introduces a novel fairness-aware approach to graph anomaly detection.",
        "Provides a comprehensive evaluation of nine existing GAD methods.",
        "Uses real-world datasets to demonstrate practical relevance.",
        "Offers a clear methodology for identifying and mitigating bias."
      ],
      "weaknesses": [
        "Datasets may not be fully representative of all graph structures and sensitive attributes.",
        "Political leaning as the sensitive attribute may not capture broader fairness concerns.",
        "Edge definition in the Reddit dataset may not capture meaningful graph structures.",
        "Lacks evaluation of semi-supervised GAD methods.",
        "Does not explore the impact of edge definition on GAD performance.",
        "Does not address ethical implications or long-term dataset accessibility."
      ],
      "questions": [
        "How do the findings generalize to other graph structures and sensitive attributes?",
        "What impact does the choice of sensitive attribute have on fairness analysis?",
        "How does the edge definition in the Reddit dataset affect the performance of GAD methods?",
        "What are the ethical implications of using these datasets for anomaly detection in social networks?",
        "How can the interpretability and explainability of the proposed approach be improved?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3cuJwmPxXj",
    "title": "Identifying Representations for Intervention Extrapolation",
    "std_review": {
      "summary": "The paper introduces a method for identifying parameters in a linear model with noise, addressing identifiability issues. It derives conditions for parameter ℓ (linear relationship) and λ (noise variance) to be identifiable, showing they are identifiable only up to an additive constant without extra assumptions. The method is applied to intervention extrapolation, comparing favorably with existing approaches like iVAE. However, it lacks empirical validation and clarity on handling assumption violations.",
      "strengths": [
        "Provides clear conditions for parameter identifiability.",
        "Offers strong theoretical foundations with rigorous derivations.",
        "Applies the method to a practical problem of intervention extrapolation.",
        "Effectively compares with related work, highlighting unique advantages."
      ],
      "weaknesses": [
        "Relies on additional assumptions (differentiability, convex interior) that may limit applicability.",
        "Lacks empirical evidence on method performance when assumptions are violated.",
        "Notation for the domain of ℓ(z) is not explicitly confirmed, which can be confusing.",
        "Does not discuss robustness to assumption violations."
      ],
      "questions": [
        "How robust is the method when the assumptions about the linear relationship or injective mapping are not strictly held?",
        "What empirical results demonstrate the method's performance under assumption violations?",
        "Can the method be extended to scenarios where these assumptions are relaxed?"
      ],
      "overall_score": "Borderline",
      "confidence": "Medium"
    }
  },
  {
    "paper_id": "3d0OmYTNui",
    "title": "Privately Aligning Language Models with Reinforcement Learning",
    "std_review": {
      "summary": "The paper introduces a method for training reward models in reinforcement learning with differential privacy guarantees, comparing private and non-private models. It highlights the impact of DP on model utility and alignment, with practical implications for privacy-preserving RL. While innovative, the study has limitations in scope and lacks detailed analysis of certain trade-offs.",
      "strengths": [
        "Innovative approach to integrating differential privacy into reward model training.",
        "Clear methodology for comparing non-private and private reward models.",
        "Demonstrates practical implications of DP in RL, valuable for both theoretical and applied research."
      ],
      "weaknesses": [
        "Limited scope focusing on reward model alignment in RL.",
        "Complexity of integrating DP mechanisms into the alignment process.",
        "Lack of confidence intervals for reported results.",
        "Potential trade-offs in setting hyperparameters are not fully explored."
      ],
      "questions": [
        "How can the fine-tuning method be applied to other domains beyond the current examples?",
        "What are the detailed steps for calculating confidence intervals in the experiments?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "3edHHvu5GX",
    "title": "Adaptive Visual Scene Understanding:",
    "std_review": {
      "summary": "The paper introduces a novel dynamic graph structure for continual learning in scene graph generation, showing improved performance on a benchmark dataset. While promising, the work lacks detailed methodology, clear evaluation metrics, and a comprehensive comparison with existing methods. The reviewers recommend a weak accept.",
      "strengths": [
        "Introduces a novel dynamic graph structure for continual learning in scene graph generation.",
        "Demonstrates improved performance on a benchmark dataset compared to existing approaches.",
        "Addresses a significant gap in the literature by focusing on continual learning for scene graph generation."
      ],
      "weaknesses": [
        "Lacks detailed discussion of potential limitations of the dynamic graph structure.",
        "Evaluation metrics are not explicitly defined, making it difficult to fully assess improvements.",
        "Does not provide a comprehensive comparison with state-of-the-art continual learning methods.",
        "Experimental setup and dataset details are not fully described, hindering reproducibility."
      ],
      "questions": [
        "Could you provide a more detailed discussion of the potential limitations of the dynamic graph structure approach?",
        "Please define the evaluation metrics used to assess the performance of the proposed methods.",
        "How does the proposed approach compare with state-of-the-art continual learning methods in related domains?",
        "Could you clarify the experimental setup and dataset details used in the evaluation?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "3eFMnZ3N4J",
    "title": "Efficient-3Dim: Learning a Generalizable Single-image Novel-view Synthesizer in One Day",
    "std_review": {
      "summary": "The paper Efficient-3DiM presents a novel framework for single-image novel view synthesis that significantly speeds up the process while maintaining high quality. It introduces a crafted timestep sampling strategy, uses DINO-v2 for 3D feature extraction, and incorporates mixed-precision training and extra layer normalization. The approach is demonstrated on the Planet dataset and shows strong results, with potential for broader applicability to other 3D vision tasks.",
      "strengths": [
        "The crafted timestep sampling strategy intelligently reduces the number of timesteps needed for efficient novel view synthesis, leading to substantial computational savings compared to uniform sampling.",
        "The choice of DINO-v2 over CLIP for 3D feature extraction is well justified, as DINO-v2 is better suited for capturing high-level 3D semantics, which is crucial for generating realistic novel views.",
        "The introduction of mixed-precision training and extra layer normalization in the training scheme significantly enhances the speedup without compromising the quality of the synthesized images.",
        "The framework's design allows for easy adaptation to other 3D vision tasks, such as 3D object creation and scene reconstruction, indicating its broad applicability and generalizability."
      ],
      "weaknesses": [
        "The paper could benefit from a more detailed analysis of the trade-offs between the crafted timestep sampling strategy and uniform sampling, particularly in terms of synthesis quality and computational cost.",
        "While the choice of DINO-v2 over CLIP is justified, the paper does not provide a comprehensive comparison with other 3D vision models, which could strengthen the argument for its superiority.",
        "The training paradigm enhancements, while clearly described, lack quantitative benchmarks comparing their impact on speedup versus quality, which would be valuable for readers.",
        "The scalability of the proposed techniques in distributed or large-scale training setups is not thoroughly explored, leaving open questions about how the speedup benefits scale with increased computational resources."
      ],
      "questions": [
        "How do the trade-offs between the crafted timestep sampling strategy and uniform sampling manifest in terms of synthesis quality and computational cost?",
        "Could a more comprehensive comparison with other 3D vision models further support the choice of DINO-v2 over CLIP?",
        "What quantitative benchmarks are available to compare the impact of mixed-precision training and extra layer normalization on speedup versus quality?",
        "How does the scalability of the proposed techniques perform in distributed or large-scale training setups?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3EWTEy9MTM",
    "title": "Chain of Thought Empowers Transformers to Solve Inherently Serial Problems",
    "std_review": {
      "summary": "The paper investigates the expressive power of transformers equipped with Constant‑Time (CoT) reasoning, deriving theoretical upper bounds (AC0 class) and demonstrating that CoT enhances performance on arithmetic tasks. While the theoretical contributions are novel and the empirical evidence is compelling, the results are limited to non‑uniform embeddings and arithmetic tasks, raising questions about practical generalizability and comparison with recent work.",
      "strengths": [
        "Clear theoretical contributions: novel AC0 upper bounds for transformers with CoT.",
        "Empirical validation: experiments show CoT improves performance over hint strategies on arithmetic tasks.",
        "Insightful analysis: theorems on embedding size and rounding mechanisms provide nuanced understanding."
      ],
      "weaknesses": [
        "Practicality of non‑uniform embeddings may limit real‑world applicability.",
        "Empirical validation focused on arithmetic tasks, not all domains.",
        "Lacks extensive comparison with recent related work.",
        "Theoretical results may not fully align with empirical observations."
      ],
      "questions": [
        "How do the results generalize to models with uniform embeddings?",
        "Can the theoretical bounds be tightened or extended to other architectures?",
        "What is the impact of rounding mechanisms on expressiveness beyond arithmetic tasks?",
        "How do the findings compare with recent work like Merrill & Sabharwal (2023)?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3f5PALef5B",
    "title": "LEGO-Prover: Neural Theorem Proving with Growing Libraries",
    "std_review": {
      "summary": "LEGO-Prover presents a novel approach to neural theorem proving by combining large language models with a growing lemma library and a Directional Evolution component. The system decomposes problems, generates informal proofs, and formalizes lemmas that are added to a skill library, which is expanded by the Directional Evolution component. Evaluation on the miniF2F benchmark shows significant improvements over prior methods, though the system's reliance on LLMs and the management of a growing lemma library present challenges.",
      "strengths": [
        "Leverages LLMs to automate theorem proving, reducing manual intervention.",
        "Introduces a growing lemma library that learns and expands over time, enhancing capabilities.",
        "Directional Evolution component effectively refines and generates new lemmas, improving the theorem proving process."
      ],
      "weaknesses": [
        "Reliance on LLMs may lead to inconsistencies and errors in generated proofs.",
        "Growing lemma library may become unwieldy and difficult to manage.",
        "Evaluation limited to a single benchmark dataset, potentially overlooking broader performance.",
        "Performance could be further improved with additional techniques or optimizations."
      ],
      "questions": [
        "How does the system handle inconsistencies or errors in proofs generated by LLMs?",
        "What strategies are employed to manage the growth and relevance of the lemma library?",
        "Could the system's performance be further enhanced by integrating other theorem proving techniques?",
        "How does the system's approach compare to other neural theorem proving methods in terms of scalability and generalizability?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3fEKavFsnv",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a method for synthetic text detection that incorporates text from multiple large language models (LLMs) into the training corpus, treating entire paragraphs as single units. This approach significantly improves detection accuracy compared to using a single LLM or no LLM-generated text. The authors evaluate their method across a wide range of LLMs, demonstrating its robustness and effectiveness. While the paper shows promise, it lacks detailed analysis on LLM characteristics and potential overfitting, and does not fully explore computational costs.",
      "strengths": [
        "Introduces a novel approach to leveraging diverse LLM-generated text for synthetic text detection.",
        "Evaluates across a wide range of LLMs, providing a comprehensive analysis.",
        "Adopts an innovative method of treating paragraphs as single units, simplifying input processing."
      ],
      "weaknesses": [
        "Lacks detailed analysis on how specific LLM characteristics affect detection performance.",
        "Does not discuss potential overfitting issues with diverse training data.",
        "Relies on standard metrics (accuracy, precision, recall) without capturing all performance aspects.",
        "Does not explore the computational cost of training on a larger, more diverse dataset."
      ],
      "questions": [
        "How do the specific characteristics of each LLM (e.g., output length, style) influence the detection performance?",
        "What measures are taken to prevent overfitting when training on a diverse set of LLM-generated texts?",
        "How does the computational cost of training on a larger, more diverse dataset compare to traditional methods?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3FJOKjooIj",
    "title": "Self-supervised Heterogeneous Graph Learning: a Homophily and Heterogeneity Perspective",
    "std_review": {
      "summary": "The paper introduces HERO, a self-supervised learning framework for graphs that simultaneously leverages homophilous (in‑graph) and heterophilous (between‑graph) representations. HERO's novel fusion strategy—concatenating these representations and training a linear classifier—demonstrates strong performance on node classification and similarity search tasks across several benchmarks. While the theoretical foundation is solid, the empirical evaluation is limited to specific tasks and baselines, and alternative fusion methods are not explored. Overall, HERO shows promise but could benefit from broader validation.",
      "strengths": [
        "Innovative fusion strategy that captures both local and cross‑graph information.",
        "Strong theoretical foundation with a clear guarantee of performance.",
        "Empirical success across multiple downstream tasks."
      ],
      "weaknesses": [
        "Limited comparison with baselines that handle both homophilous and heterophilous information.",
        "No exploration of alternative fusion techniques.",
        "Theoretical guarantees do not fully address practical performance implications.",
        "Evaluation focused on specific tasks, potentially overlooking broader applicability."
      ],
      "questions": [
        "How does HERO perform when compared to methods that explicitly model both homophilous and heterophilous information?",
        "What impact does the choice of fusion (concatenation vs. other methods) have on performance across different tasks?",
        "Can the theoretical guarantees be extended to a wider range of downstream tasks beyond node classification and similarity search?"
      ],
      "overall_score": "6: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3fRbP8g2LT",
    "title": "Efficient Redundancy-Free Graph Networks:",
    "std_review": {
      "summary": "The paper introduces DLGN and ERFGN models that address the over‑squashing problem in message passing neural networks through a redundancy‑free design. Theoretical analyses provide guarantees on sensitivity and effective resistance, and empirical results show significant efficiency gains across various baselines and datasets. The authors demonstrate that their models can capture non‑isomorphic subgraphs more effectively than k‑WL tests and achieve substantial improvements in training time and parameter efficiency.",
      "strengths": [
        "Redundancy‑free design effectively eliminates over‑squashing in MPNNs.",
        "Theoretical guarantees provide concrete analyses of sensitivity and expressiveness.",
        "Empirical results demonstrate substantial efficiency gains across diverse datasets.",
        "Explicit cycle modeling via path trees enhances expressiveness beyond k‑WL tests."
      ],
      "weaknesses": [
        "Implementation complexity may introduce additional computational overhead.",
        "Empirical validation is limited to specific baselines and datasets.",
        "Theoretical expressiveness claims require further demonstration in practical applications."
      ],
      "questions": [
        "How does the model scale to extremely large graphs with millions of nodes?",
        "What is the impact of varying the tree-height L on model performance in real‑world scenarios?",
        "Can the expressiveness gains be quantified in terms of downstream task performance?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3GDKJSQnW2",
    "title": "",
    "std_review": {
      "summary": "PDEdit introduces a novel diffusion‑based approach for editing video motion using textual prompts, leveraging a dynamic motion prior and a spatial‑temporal focusing module to ensure temporal consistency. The method shows high‑quality results and scalability across video lengths and resolutions, though it faces challenges with longer videos, computational demand, and prompt sensitivity. Overall, the paper is well‑received for its innovative technique and strong visual results.",
      "strengths": [
        "Dynamic motion prior captures physical constraints for plausible edits.",
        "Spatial‑temporal focusing module enhances temporal coherence.",
        "Scalable and flexible across video sizes and content types.",
        "Produces high‑quality, context‑preserving edits."
      ],
      "weaknesses": [
        "High computational cost, especially for high‑resolution videos.",
        "Edit quality heavily depends on the relevance of the input text prompt.",
        "Potential artifacts like color drift and object misalignment remain.",
        "Does not utilize the original video caption for editing."
      ],
      "questions": [
        "How can the method be extended to handle more complex scene transformations beyond simple motion editing?",
        "What strategies can be employed to reduce computational demand for real‑time applications?",
        "How can prompt sensitivity be mitigated to improve robustness with less relevant text inputs?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3GunDQNKFJ",
    "title": "Reformulating Domain Adaptation of Large Language Models as Adapt-Retrieve-Revise",
    "std_review": {
      "summary": "The paper introduces the adapt-retrieve-revise framework for domain adaptation in legal document analysis, leveraging a small language model for initial drafts and GPT-4 for revisions. It improves answer quality and reduces computational costs compared to fine-tuning large models. Experiments show significant gains in precision and recall, especially for nuanced legal queries. The framework is efficient, scalable, and interpretable, though it still requires substantial computational resources.",
      "strengths": [
        "Efficient domain adaptation by using a small LM for initial drafts and GPT-4 for revisions.",
        "Improved answer quality with higher precision and more contextually accurate responses.",
        "Scalability to various domains with minimal changes.",
        "Interpretability through a clear lineage of answer evolution."
      ],
      "weaknesses": [
        "Computational overhead despite reduced demands compared to full fine-tuning.",
        "Reliance on retrieval module quality for handling legal nuances.",
        "Potential struggles with ambiguous or open-ended questions.",
        "Evaluation metrics may not fully capture legal reasoning quality."
      ],
      "questions": [
        "How does the retrieval module's choice (query-based vs. answer-based) impact retrieval quality?",
        "What domain-specific adaptations are needed for the retrieval module to ensure robust performance?",
        "How can the framework be extended to handle multi-modal evidence (e.g., images, tables) in legal contexts?",
        "What future work could improve the interpretability of the revision process beyond visual cues?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3GurO0kRue",
    "title": "On Harmonizing Implicit Subpopulations",
    "std_review": {
      "summary": "The paper introduces SHE, a method for handling class imbalance by balancing subpopulations in a latent space using a mixture of experts. It shows strong empirical improvements over baselines, especially in scenarios with large subpopulation shifts, and provides a theoretical argument supporting its effectiveness. However, the evaluation is limited to out-of-domain settings, and the method's performance in the critical in-domain scenario is not demonstrated. The approach also assumes balanced label distributions within subpopulations and may face implementation and overfitting challenges.",
      "strengths": [
        "Novel approach to class imbalance by focusing on subpopulation balance in a latent space.",
        "Strong theoretical foundation with a proposition suggesting non-underperformance of SHE compared to ERM in the limit.",
        "Empirical success demonstrated across synthetic and real-world datasets, particularly in challenging scenarios with subpopulation shift."
      ],
      "weaknesses": [
        "Limited evaluation to out-of-domain settings; in-domain performance is not assessed.",
        "Complex implementation relying on a mixture of experts, which may introduce computational costs.",
        "Assumes balanced label distributions within subpopulations, limiting applicability.",
        "Potential for overfitting due to the use of a mixture of experts."
      ],
      "questions": [
        "How does SHE perform when both training and testing data are imbalanced (in-domain scenario)?",
        "What is the method's performance under other notions of subpopulation shift where label distributions are not balanced?",
        "Could SHE be extended to handle arbitrary target distributions over the latent subpopulation?"
      ],
      "overall_score": "Borderline",
      "confidence": "Medium"
    }
  },
  {
    "paper_id": "3husFxdHI1",
    "title": "Duality of Information Flow: Insights in Graphical Models and Neural Networks",
    "std_review": {
      "summary": "The paper establishes a duality between information flow in graphical models and neural networks, particularly Bayesian neural networks, showing that backpropagation and belief propagation are equivalent. It proposes a belief propagation-based training algorithm for Bayesian neural networks, demonstrating its advantages through numerical experiments. While theoretically rigorous, the paper has some limitations, such as complex mathematical formalism and limited scalability, and suggests future research directions.",
      "strengths": [
        "Novel duality insight between graphical models and neural networks",
        "Unified framework bridging backpropagation and belief propagation",
        "Algorithmic contribution with potential advantages over traditional methods",
        "Strong theoretical foundation with mathematical proofs",
        "Empirical validation of the proposed algorithm"
      ],
      "weaknesses": [
        "Complexity of theoretical contributions may limit accessibility",
        "Numerical experiments lack broad coverage of scenarios",
        "Potential scalability issues for large networks",
        "Lack of extensive comparison with state-of-the-art methods",
        "Theoretical results depend on certain assumptions"
      ],
      "questions": [
        "How does the proposed algorithm perform on very large network architectures?",
        "What is the impact of the theoretical assumptions on practical applications?",
        "How does the proposed algorithm compare with other state-of-the-art Bayesian neural network training methods?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3i7iNGxw6r",
    "title": "Where does In-context Machine Translation Happen in Large Language Models?",
    "std_review": {
      "summary": "The paper investigates how large language models transition from input‑aware to task‑aware representations across layers, using few‑shot translation examples to identify specific layers where the model shifts focus to the translation task. The method analyzes attention patterns and token embeddings, revealing a clear shift in layer behavior that could inform model design. While the findings are insightful and broadly applicable across languages, they are specific to translation and rely on particular few‑shot examples, raising questions about generalizability and robustness.",
      "strengths": [
        "Clear and reproducible methodology",
        "Insightful findings on layer transition dynamics",
        "Broad applicability across multiple language pairs",
        "Theoretical contribution framing the transition as encoder‑like compression and decoder‑like refinement"
      ],
      "weaknesses": [
        "Limited scope to translation task",
        "Dependence on specific few‑shot examples",
        "Potential overfitting to model size (3‑B)",
        "Lack of robustness analysis"
      ],
      "questions": [
        "Can similar layer transitions be observed in other tasks like summarization or question answering?",
        "How robust are the identified task‑aware layers to variations in input or prompt phrasing?",
        "Would using different instructions lead to different patterns of layer transition?",
        "Is the transition behavior consistent across larger model sizes (e.g., 7B or 13B)?",
        "How unique are the L0 masks to the current model and dataset, and would biasing them affect the results?"
      ],
      "overall_score": "Accept",
      "confidence": "High"
    }
  },
  {
    "paper_id": "3ijmMNaSJk",
    "title": "Towards Understanding Masked Distillation",
    "std_review": {
      "summary": "The paper introduces masked distillation, a novel self-supervised learning approach that refines teacher-student learning through masked predictions. It demonstrates improved ImageNet-1k performance and model stability, with insights into attention patterns and loss landscapes. However, the definition of masked distillation is vague, and some comparisons and metric analyses are incomplete.",
      "strengths": [
        "Introduces masked distillation as a refined SSL technique.",
        "Extensively compares masked distillation against multiple SSL methods.",
        "Provides novel metrics to analyze model behavior."
      ],
      "weaknesses": [
        "Lacks a precise definition of masked distillation.",
        "Omits direct comparison with MIM.",
        "Experimental implementation may not fully cover all masked distillation variants.",
        "Performance metrics are not prominently featured.",
        "Uses entropy for attention metrics, which may be less appropriate."
      ],
      "questions": [
        "Should a direct comparison with MIM be included to highlight novelty?",
        "How representative is the experimental implementation of all masked distillation variants?",
        "Should ImageNet-1k performance scores be included in the main text?",
        "How should the relevance of frequency analysis be clarified?",
        "Why is SL excluded from the loss‑landscape analysis, and how does SL_MD compare?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "3IyC5lQTSi",
    "title": "Fairness Through Matching",
    "std_review": {
      "summary": "The paper introduces Matched Demographic Parity (MDP) and Fairness Through Matching (FTM) as a method to align predictions across demographic groups using optimal transport. It demonstrates effectiveness on both synthetic and real-world datasets, achieving fairness without significant performance loss. The reviewer finds the approach novel and mathematically grounded, though notes some limitations in preprocessing and visualization clarity.",
      "strengths": [
        "Introduces a novel fairness measure (MDP) focusing on matched distributions.",
        "Leverages optimal transport theory for a mathematically rigorous approach.",
        "Flexible target distributions allow tailored fairness applications.",
        "Empirical results on diverse datasets validate effectiveness."
      ],
      "weaknesses": [
        "Relies on squared Euclidean distance which may not capture all relevant similarities.",
        "Standardization preprocessing could be sensitive to distance metric choice.",
        "Small visualizations in the paper reduce clarity of results.",
        "Lacks analysis of computational complexity for large-scale use."
      ],
      "questions": [
        "How does the choice of distance metric affect the fairness outcomes in practice?",
        "What is the computational complexity of FTM, especially for large datasets?",
        "How robust is the method to variations in the preprocessing steps?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3j5bsiwRv6",
    "title": "Sparse Refinement for Efficient",
    "std_review": {
      "summary": "The paper presents a novel entropy-based refinement module for semantic segmentation models, targeting high-entropy regions to improve accuracy while reducing computational cost. Experiments across multiple datasets show significant speedups without substantial accuracy loss. The method is versatile, applicable to various segmentation architectures, and includes comprehensive evaluation. However, it introduces parameter overhead and requires careful threshold tuning. Overall, the approach is promising for efficient real-time segmentation.",
      "strengths": [
        "Innovative entropy-based refinement targets areas of uncertainty.",
        "Achieves notable speedups while maintaining competitive accuracy.",
        "Designed to be applicable to various segmentation models.",
        "Comprehensive evaluation across multiple datasets."
      ],
      "weaknesses": [
        "Adds significant parameter overhead, impacting model size and efficiency.",
        "Threshold selection is critical and not well-documented.",
        "Limited testing on other benchmarks like COCO or ADE20K.",
        "Comparison with token pruning is limited."
      ],
      "questions": [
        "How can the parameter overhead be mitigated for deployment on resource-constrained devices?",
        "What strategies can be employed to make the entropy threshold selection more robust across diverse datasets?",
        "Could additional experiments on benchmarks like COCO or ADE20K further validate the method's general applicability?",
        "How does the method compare to other state-of-the-art techniques in terms of parameter efficiency?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3J7foqnJkA",
    "title": "Understanding Parameter Saliency",
    "std_review": {
      "summary": "The paper introduces the Probability of Overfitting (POT) algorithm, which estimates the probability of overfitting based on model complexity and training data. While demonstrating improved generalization performance in experiments, the review highlights several weaknesses, including limited experimental validation, insufficient exploration of POT's parameters, reliance on a normal distribution assumption, and lack of discussion on addressing limitations of previous methods. The reviewer concludes with a 'Weak Accept' recommendation.",
      "strengths": [
        "Introduces a novel approach to prevent overfitting by estimating the probability of overfitting.",
        "Provides a theoretical foundation for the POT algorithm based on model complexity and training data.",
        "Demonstrates improved generalization performance in experiments compared to existing methods."
      ],
      "weaknesses": [
        "The experimental work is limited and lacks sufficient comparison experiments to validate the effectiveness of POT.",
        "The impact of POT's parameters on system performance is not thoroughly investigated.",
        "The assumption of normal distribution in the proposed POT system may not be representative enough for all problems.",
        "The paper lacks detailed discussion on the limitations of the previous solution (Levin) and how POT addresses those limitations."
      ],
      "questions": [
        "How will the parameters in the proposed POT system affect the system performance?",
        "What's the limitation in the previous solution (Levin) and how this solution can solve that?",
        "Why is a simple normal distribution used in proposition 1 and appendix B, and can it be representative enough for all problems?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "3JjJezzVkT",
    "title": "The Marginal Value of Momentum",
    "std_review": {
      "summary": "The paper provides a novel theoretical analysis showing that under small learning rates, stochastic gradient descent (SGD) and stochastic gradient descent with momentum (SGDM) exhibit nearly identical trajectories. It introduces Theorem 3.5, which has implications for convergence rates and regularization effects, especially when momentum is set to zero. While the analysis is technically rigorous and offers practical insights for optimization, it has limitations in scope and experimental setup that affect the validity of some conclusions.",
      "strengths": [
        "Novel theoretical insights into when SGD and SGDM behave similarly under small learning rates.",
        "Clear delineation of momentum's role across different regimes.",
        "Strong theoretical foundation with well‑structured proofs and lemmas."
      ],
      "weaknesses": [
        "Scope limitations regarding full‑batch gradient descent when momentum is zero.",
        "Assumptions on noise scaling (σ ≤ η^(–1/2)) may restrict generality.",
        "Unclear explanation of behavior for α > 1 when η → 0.",
        "CIFAR‑10 experiments lack proper rescaling of the learning rate for SGDM."
      ],
      "questions": [
        "How does the theoretical framework extend to scenarios where noise scaling exceeds the assumed threshold?",
        "What are the practical implications of the theorem's prediction that no limiting dynamics exist for α > 1?",
        "How can the experimental setup be improved to provide a fair comparison between SGD and SGDM?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "3Jl0sjmZx9",
    "title": "Large Multimodal Model for Real-World Radiology Report Generation",
    "std_review": {
      "summary": "The paper introduces DeMMo, a model that combines ChatGPT-generated context with a medical vision encoder to generate clinical radiology reports. It evaluates DeMMo on the MIMIC‑R3G benchmark, showing strong linguistic quality and clinical accuracy compared to baselines. While innovative, the model's reliance on ChatGPT introduces variability, and limited clinical validation is noted. Overall, the work is a valuable contribution to clinical report generation.",
      "strengths": [
        "Innovative integration of large language models with domain-specific medical vision encoders.",
        "Comprehensive evaluation using multiple linguistic and clinical metrics.",
        "Demonstrates competitive performance against established baselines."
      ],
      "weaknesses": [
        "Dependence on ChatGPT for context generation introduces variability and potential inaccuracies.",
        "Lack of detailed computational analysis of the medical vision encoder.",
        "Limited clinical validation beyond linguistic metrics."
      ],
      "questions": [
        "How robust is the model to variations in ChatGPT-generated context quality?",
        "What is the exact computational impact of the medical vision encoder on model efficiency?",
        "What strategies are in place to ensure long-term clinical trustworthiness of generated reports?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3JoQqW35GQ",
    "title": "Training-free linear image inversion via flows",
    "std_review": {
      "raw_text": "{\n  \"summary\": \"The paper introduces a novel diffusion model that replaces the stochastic DDIM sampler with an ODE sampler (VP-ODE), achieving improved performance on ImageNet-64/128 and AFHQ-256 datasets compared to the baseline $\\Pi$GDM. While the approach is innovative and the results promising, the choice of less common datasets for evaluation and the use of class‑conditional models introduce questions about the method's general applicability and the extent of its performance advantage over existing techniques.\",\n  \"strengths\": [\n    \"Innovative sampling approach using an ODE sampler (VP-ODE) for more stable and efficient diffusion.\",\n    \"Diverse dataset evaluation on ImageNet-64/128 and AFHQ-256, providing insights into model performance across different scales.\",\n    \"Relevance of class‑conditional model training for practical applications, making results directly applicable.\"\n  ],\n  \"weaknesses\": [\n    \"Limited benchmark comparison using less common datasets may understate the method's performance relative to more standard benchmarks.\",\n    \"Conditional modeling introduces additional complexity and potential bias, affecting the relevance of results to typical applications.\",\n    \"The marginal superiority of VP-ODE over OT-ODE lacks detailed justification, raising questions about consistency and reliability.\"\n  ],\n  \"questions\": [\n    \"How does the method compare to more widely used benchmarks like FFHQ and ImageNet?\",\n    \"What theoretical or practical reasons explain the marginal performance advantage of VP-ODE over OT-ODE?\",\n    \"How do the characteristics of ImageNet-64/128 and AFHQ-256 datasets influence the observed performance gains?\"\n  ],\n  \"overall_score\": \"4: weak accept\",\n  \"confidence\": \"3: medium\"\n}",
      "parse_error": true
    }
  },
  {
    "paper_id": "3jXCF5dNpC",
    "title": "Re-Reading Improves Reasoning in Language Models",
    "std_review": {
      "summary": "The paper introduces RE2, a two‑pass prompting technique that enhances reasoning in language models. It shows significant improvements on multiple reasoning benchmarks, with larger models benefiting more. While the approach is clear and reproducible, its theoretical underpinnings and statistical robustness are underexplored.",
      "strengths": [
        "Clear and reproducible methodology",
        "Comprehensive evaluation across reasoning datasets and model sizes",
        "Empirical evidence with quantitative improvements and qualitative analyses"
      ],
      "weaknesses": [
        "Lack of detailed mechanism for bidirectional understanding",
        "Limited evidence on non‑reasoning tasks",
        "Absence of statistical robustness metrics"
      ],
      "questions": [
        "What is the precise mechanism by which the second pass enables bidirectional understanding?",
        "How does RE2 perform on non‑reasoning tasks such as classification or generation?",
        "Are the observed improvements robust across different datasets and model scales?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "3klVRLhK7w",
    "title": "Budgeted Online Continual Learning by Adaptive Layer Freezing and Frequency-based Sampling",
    "std_review": {
      "summary": "The paper presents an adaptive layer freezing mechanism for online continual learning, aiming to balance computational efficiency and model accuracy. It demonstrates effectiveness across CNNs and Transformers, showing significant improvements over traditional methods. While promising, the method lacks detailed criteria for layer selection and robustness analysis, and computational gains are not quantified.",
      "strengths": [
        "Introduces a novel adaptive layer freezing mechanism for online continual learning.",
        "Demonstrates broad applicability across CNNs and Transformers.",
        "Shows significant improvements in computational efficiency and model performance."
      ],
      "weaknesses": [
        "Lacks detailed explanations of criteria for layer freezing/unfreezing.",
        "Limited discussion on method robustness to different data distribution shifts.",
        "Computational efficiency improvements are not quantified.",
        "No comprehensive comparison with state-of-the-art methods."
      ],
      "questions": [
        "Could you provide more details on the specific criteria used for layer selection?",
        "How robust is the method to various types of data distribution shifts?",
        "What are the exact computational efficiency metrics (e.g., training time, memory usage) improved?",
        "How does the method compare to other state-of-the-art approaches in online continual learning?"
      ],
      "overall_score": "6: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3LFy3dUS86",
    "title": "P2RBox: A Single Point is All You Need for Oriented Object Detection",
    "std_review": {
      "summary": "P2RBox introduces a novel approach to oriented object detection by leveraging a Symmetry Axis Estimation (SAE) module to enhance performance, particularly for symmetric objects. The method integrates single point annotations with a segmentation mask approach using Self-Attention Mask (SAM) to generate oriented bounding boxes. The paper evaluates P2RBox on the DOTA dataset and compares its performance against state-of-the-art fully supervised oriented object detectors, highlighting improvements in accuracy and efficiency. Overall, the paper presents an innovative method with strong performance gains, though it has some limitations in generalization and robustness.",
      "strengths": [
        "Innovative Symmetry Utilization: The SAE module effectively leverages object symmetry to improve detection accuracy, especially for symmetric objects like vehicles and animals.",
        "Efficient Mask Generation: By using SAM for mask generation, P2RBox reduces the computational burden associated with traditional bounding box regression.",
        "Robustness to Single Point Annotations: The method's reliance on single point annotations simplifies data collection and processing, making it more practical for real-world applications."
      ],
      "weaknesses": [
        "Limited Generalization: The method's performance may not generalize well to datasets with different object densities and occlusion rates, such as aerial imagery or urban scenes.",
        "Sensitivity to Point Quality: The effectiveness of P2RBox is highly dependent on the quality of single point annotations, which can be challenging to obtain accurately.",
        "Computational Cost of SAE Module: The SAE module introduces additional computational overhead, which may impact real-time applications."
      ],
      "questions": [
        "How does P2RBox perform on datasets with varying object densities and occlusion rates, such as aerial imagery or urban scenes?",
        "What strategies can be employed to improve the robustness of P2RBox to noisy or low-quality single point annotations?",
        "How can the computational cost of the SAE module be further reduced without significantly compromising performance?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3LLkES6nNs",
    "title": "Infinitely Deep Residual Networks: Unveiling Wide Neural ODEs as Gaussian Processes",
    "std_review": {
      "summary": "The paper presents a novel theoretical framework that links Residual Networks (ResNets) and Neural Ordinary Differential Equations (Neural ODEs) by interpreting ResNet depth as a time parameter. It provides both theoretical guarantees and empirical evidence showing that ResNets can be seen as discretized versions of Neural ODEs, converging under certain conditions. While the approach is innovative, some assumptions and formatting issues need addressing.",
      "strengths": [
        "Clear theoretical framework linking ResNets and Neural ODEs.",
        "Thorough convergence analysis under specific conditions.",
        "Empirical validation through image classification experiments."
      ],
      "weaknesses": [
        "Unclear assumptions for Equation (4).",
        "Convergence analysis assumes a fixed time T, which may limit practicality.",
        "Relies on controllable activation functions, which may not always hold."
      ],
      "questions": [
        "What are the precise assumptions required for Equation (4) to hold?",
        "How does the relationship between the number of layers L and the time step β ensure convergence?",
        "Can the results be generalized to activation functions without the controllability assumption?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3M0GXoUEzP",
    "title": "CriBo : Self-Supervised Learning via Cross-Image Object-Level Bootstrapping",
    "std_review": {
      "summary": "The paper presents CrIBo, a self-supervised learning framework that leverages cross-image object-level consistency to improve scene-centric visual representation learning. By using a memory bank and mask-based pooling, CrIBo effectively captures fine-grained object information, achieving competitive performance on dense downstream tasks. The innovative approach addresses a gap in existing methods that focus on image-level or cross-view consistency. While computationally demanding, CrIBo's effectiveness and robustness justify its acceptance.",
      "strengths": [
        "Innovative approach focusing on cross-image object-level consistency.",
        "Effective representation learning through memory bank and mask-based pooling.",
        "Competitive performance on dense downstream tasks."
      ],
      "weaknesses": [
        "Higher computational cost due to memory bank and mask-based pooling.",
        "Performance heavily dependent on the choice of clustering algorithm.",
        "Limited evaluation across diverse datasets and tasks."
      ],
      "questions": [
        "How can the computational cost be reduced while maintaining performance?",
        "What are the long-term scalability implications of the memory bank approach?",
        "Could alternative clustering algorithms improve robustness and generalization?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3mdCet7vVv",
    "title": "Maestro: Uncovering Low-Rank Structures via Trainable Decomposition",
    "std_review": {
      "summary": "The paper introduces a novel approach to structured pruning of neural networks that avoids SVD by using an initial factorized mapping and Lasso regularization to achieve low-rank, sparse weight matrices. It demonstrates effectiveness on ResNets and Vision Transformers with reduced model sizes and computational overhead. While innovative, the method lacks detailed theoretical foundations, comprehensive comparisons, and clear guidance on hyperparameter selection, leading to a weak accept recommendation.",
      "strengths": [
        "Novel factorization technique that bypasses traditional SVD, potentially reducing computational overhead.",
        "Achieves structured sparsity with Lasso regularization, leading to efficient inference without significant accuracy loss.",
        "Demonstrates scalability to large models like ViTs on ImageNet, indicating practical applicability."
      ],
      "weaknesses": [
        "Lacks a detailed methodology for choosing the initial maximal rank *r*.",
        "Limited comparison with other structured pruning methods.",
        "Insufficient analysis of hyperparameter sensitivity, particularly the Lasso coefficient.",
        "Ambiguous reporting of training cost, making it unclear whether reported values reflect training or inference costs."
      ],
      "questions": [
        "What is the detailed methodology for selecting the initial maximal rank *r*?",
        "How does the proposed method compare quantitatively with other structured pruning techniques like channel-based pruning?",
        "What is the comprehensive analysis of hyperparameter sensitivity, especially for the Lasso coefficient *λ*?",
        "Could you provide a detailed breakdown of the training cost (GMACs) to clarify whether it reflects training or inference overhead?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "3NmO9lY4Jn",
    "title": "Don't Play Favorites:",
    "std_review": {
      "summary": "The paper introduces a novel approach to generative modeling that focuses on generating samples from low-likelihood regions of the data distribution, termed 'minority data.' By integrating a minority score into the guidance mechanism of a diffusion model, the authors demonstrate improved diversity and authenticity of generated samples, especially in underrepresented areas. The method is theoretically justified and empirically validated through experiments showing better performance metrics compared to baseline models. Overall, the paper presents a compelling and effective technique for generating diverse and authentic samples from sparse data regions.",
      "strengths": [
        "Innovative guidance mechanism that integrates minority score with existing techniques.",
        "Enhanced diversity and authenticity of generated samples, particularly in underrepresented areas.",
        "Theoretically motivated approach that addresses the scarcity of data in low-likelihood regions.",
        "Strong empirical evidence supporting the method's effectiveness."
      ],
      "weaknesses": [
        "Complexity introduced by the minority score computation and tuning requirements.",
        "Potential risk of over-fitting to limited minority data examples.",
        "Lack of quantitative analysis on the interaction between minority guidance and other guidance forms.",
        "Threshold selection for minority score not clearly justified, affecting results and generalizability."
      ],
      "questions": [
        "How robust is the minority score to variations in dataset distribution?",
        "Could the method be extended to handle multimodal or high-dimensional data?",
        "What are the computational costs associated with integrating the minority score into existing diffusion models?",
        "How does the method perform when combined with other advanced guidance techniques?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3NMYMLL92j",
    "title": "Brain encoding models based on binding multiple modalities across audio, language, and vision",
    "std_review": {
      "summary": "The paper introduces ImageBind, a multimodal alignment framework that integrates text, audio, and video into a unified representation space to predict brain activity. It demonstrates superior performance over strong unimodal baselines across the whole brain and specific regions of interest. The study provides comprehensive analyses of brain prediction, modality perturbations, and feature correlations, offering insights into multimodal alignment. However, limitations in generalization, orthogonal modality experiments, and audio synthesis impact reduce its overall acceptance.",
      "strengths": [
        "Innovative multimodal alignment framework that integrates multiple sensory modalities.",
        "Comprehensive brain prediction analyses demonstrating superior performance over unimodal baselines.",
        "Robust experimental design with thorough ablation studies and cross-modal retrieval analyses."
      ],
      "weaknesses": [
        "Limited generalization due to reliance on specific neural network architectures.",
        "Lack of controlled experiments with orthogonal modalities.",
        "Insufficient exploration of the impact of audio synthesis on brain prediction.",
        "Computational requirements and scalability not thoroughly addressed."
      ],
      "questions": [
        "How do the findings generalize to other neural network architectures beyond BERT, AST, and ViT?",
        "What are the effects of multimodal alignment on brain prediction when using orthogonal modalities?",
        "How does the use of synthesized audio versus original text captions impact brain prediction accuracy?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "3NnfJnbJT2",
    "title": "Gio: Gradient Information Optimization for Training Dataset Selection",
    "std_review": {
      "summary": "The paper introduces a two-stage greedy algorithm for selecting instances that minimize the KL divergence from a target dataset. It is evaluated on FashionMNIST, showing improvements over baselines, and discusses theoretical aspects of approximation. However, the method has several concerns, including the complexity of defining the target set, lack of baselines, and limited guidance for real-world application.",
      "strengths": [
        "Clear theoretical foundation linking KL divergence minimization to instance selection.",
        "Novel two-stage greedy approach addressing both maximization and minimization of KL divergence.",
        "Empirical evidence on FashionMNIST supporting the effectiveness of the method."
      ],
      "weaknesses": [
        "Complexity of defining the target set as a mix of high- and low-quality data.",
        "Absence of baselines in experiments, limiting interpretability of results.",
        "Lack of detailed guidance on defining the target set and initial set for new domains.",
        "Theoretical analysis of approximation gap could benefit from more empirical validation."
      ],
      "questions": [
        "How should the target set X be defined in practice to align with the goal of KL minimization?",
        "Why were baselines omitted in the FashionMNIST experiments, and how would including them affect the interpretation of results?",
        "What guidance can be provided for defining the target set X and initial set D in real-world applications?",
        "How can the approximation gap between the greedy solution and the optimal solution be empirically validated?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "3nPFco1EKt",
    "title": "Evolving Deep Neural Network's Weights at ImageNet Scale",
    "std_review": {
      "summary": "The paper introduces SA‑SHADE‑tri‑ensin, an innovative ensemble method that iteratively recombines network weights using a novel operator (S₍Trig₎) to enhance performance. It combines Weight Averaging and Sparse Mutation Decomposition, showing significant accuracy and robustness gains over traditional ensembles, especially on complex datasets. The method is theoretically grounded and offers a fresh perspective on ensemble learning, though its computational complexity and parameter sensitivity may limit practicality.",
      "strengths": [
        "Introduces a novel ensemble approach that combines WA and SMD with a unique recombination operator.",
        "Demonstrates significant improvements in accuracy and robustness over existing ensemble methods.",
        "Grounded in a solid theoretical framework with clear definitions and operations."
      ],
      "weaknesses": [
        "Iterative recombination may increase computational complexity, affecting scalability.",
        "Performance may be sensitive to parameter choices, requiring extensive tuning.",
        "Limited baseline comparison could strengthen the claim of superiority."
      ],
      "questions": [
        "How does the method scale to very large datasets or real-time applications?",
        "What are the optimal parameter settings for different datasets?",
        "How does the method compare to other state-of-the-art ensemble techniques across a broader range of benchmarks?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3Ok7ccvtf3",
    "title": "Unlearning the Unwanted Data from a Personalized Recommendation Model",
    "std_review": {
      "summary": "The paper presents a novel convolution fusion-based method for unlearning specific data points from a trained recommendation model without full retraining. It introduces the 'fading effect' theorem, which explains how data influence model parameters over time, enabling targeted unlearning. Experiments on synthetic and real datasets demonstrate the method's effectiveness, outperforming baselines in efficiency and effectiveness. While innovative, the approach has limitations in theoretical accessibility and scalability, and further evaluation metrics are needed.",
      "strengths": [
        "Introduces a novel unlearning method without full retraining.",
        "Provides a solid theoretical foundation with the 'fading effect' theorem.",
        "Demonstrates effectiveness through comprehensive experiments on both synthetic and real datasets."
      ],
      "weaknesses": [
        "The theoretical framework may be challenging for readers without a strong ML background.",
        "Focuses on unwanted data in the training set, not in the test set.",
        "Lacks comprehensive evaluation metrics for unlearning effectiveness.",
        "Scalability concerns are not thoroughly addressed."
      ],
      "questions": [
        "How can the theoretical framework be made more accessible to a broader audience?",
        "What is the impact of unwanted data present in the test set on the model's predictions?",
        "What additional metrics could be used to evaluate the effectiveness of the unlearning process?",
        "How does the method scale to large‑scale models or datasets?"
      ],
      "overall_score": "Accept",
      "confidence": "High"
    }
  },
  {
    "paper_id": "3oTPsORaDH",
    "title": "Improving Generalization in Equivariant Graph Neural Networks with Physical Inductive Biases",
    "std_review": {
      "summary": "The SEGNO framework introduces a continuous-time GNN that preserves equivariance and offers superior performance in force field and trajectory prediction tasks across diverse benchmarks. It provides theoretical guarantees on error bounds and uses comprehensive evaluation metrics, outperforming existing baselines. However, its continuous-time approach may introduce computational complexity and sensitivity to hyperparameters, and a broader comparison of baselines could further validate its superiority.",
      "strengths": [
        "Preserves equivariance by continuously updating node representations.",
        "Provides theoretical guarantees on bounded errors in acceleration and position.",
        "Demonstrates superior performance across a wide range of benchmarks."
      ],
      "weaknesses": [
        "Continuous-time approach may introduce computational complexity.",
        "Performance could be sensitive to hyperparameter choices.",
        "Limited baseline comparison could be expanded."
      ],
      "questions": [
        "How does SEGNO scale to real-time applications compared to discrete-time models?",
        "What are the optimal hyperparameter settings for SEGNO across different datasets?",
        "How does the choice of backbone GNN affect performance on various types of data?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3OzQhhPLyW",
    "title": "Meta-Value Learning: a General Framework for Learning with Learning Awareness",
    "std_review": {
      "summary": "The paper introduces MeVa, a meta‑value function approach for two‑player games that aims to improve upon existing methods like LOLA, HOLA, and COLA. MeVa defines a meta‑value function using a correction‑based formulation to address high variance of policy‑gradient gradients and employs Gaussian noise for exploration. Empirical results on Atari games show competitive performance, though the impact of variance reduction and exploration choices is not fully quantified.",
      "strengths": [
        "Introduces a correction‑based formulation to mitigate high variance in policy‑gradient methods.",
        "Uses Gaussian noise for meta‑level exploration, potentially offering smoother convergence.",
        "Demonstrates strong empirical performance on Atari benchmarks."
      ],
      "weaknesses": [
        "Lacks variance metrics (standard deviations or confidence intervals) to quantify the impact of variance reduction.",
        "Does not compare Gaussian noise exploration with conventional methods like ϵ‑greedy.",
        "Limited discussion on scalability beyond two‑player games.",
        "Missing ablation experiments comparing the surrogate formulation directly with the naive formulation and standard exploration schedules."
      ],
      "questions": [
        "Can you provide standard deviations or confidence intervals for the results to better assess the impact of variance reduction?",
        "How does the Gaussian noise exploration strategy compare to simpler methods like ϵ‑greedy in terms of convergence and performance?",
        "What are the scalability and generalization capabilities of MeVa beyond two‑player games?",
        "Could ablation experiments comparing the surrogate formulation (Eq. 6) with the naive formulation (Eq. 5) and standard exploration schedules strengthen the analysis?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "3P87ptzvTm",
    "title": "Optimal Multiple Transport with Applications to Visual Matching, Model Fusion and Beyond",
    "std_review": {
      "summary": "The paper introduces Optimal Multiple Transport (OMT), extending optimal transport to multiple measures with a cycle-consistency constraint. It proposes an alternating optimization scheme using the Sinkhorn algorithm, achieving strong empirical performance on synthetic and real-world datasets. While theoretically sound, the method has some limitations, such as unclear guidance for cycle construction and limited empirical validation scope.",
      "strengths": [
        "Introduces a novel cycle-consistency constraint for multiple measures.",
        "Proposes an efficient alternating optimization scheme leveraging the Sinkhorn algorithm.",
        "Provides a solid theoretical analysis of solution existence.",
        "Demonstrates strong empirical performance on both synthetic and real-world datasets."
      ],
      "weaknesses": [
        "Lacks clear guidance for optimal ordering of measures in the cycle.",
        "Empirical validation is limited to synthetic and a few real-world datasets.",
        "Parameter sensitivity analysis is thorough but lacks comprehensive ablation studies.",
        "Theoretical analysis does not fully address convergence guarantees."
      ],
      "questions": [
        "What is the impact of different cycle constructions on the performance of OMT?",
        "How robust is the proposed method to variations in the regularization parameters?",
        "Can the theoretical guarantees be extended to more complex scenarios with varying measure properties?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3pf2hEdu8B",
    "title": "Rethinking The Uniformity Metric in Self-Supervised Learning",
    "std_review": {
      "raw_text": "{\n  \"summary\": \"The paper introduces a novel $\\mathcal{W}_2$ metric for evaluating the uniformity of self-supervised learning representations, addressing limitations of existing metrics. It demonstrates consistent improvements over baselines on CIFAR-10/100 and other datasets when combined with frameworks like MoCo, BYOL, and Barlow Twins. While the metric shows strong theoretical foundations and practical benefits, it lacks comprehensive theoretical proofs and extensive comparative analyses across more datasets and tasks.\",\n  \"strengths\": [\n    \"Introduces a novel $\\mathcal{W}_2$ metric with a solid theoretical basis for evaluating uniformity.\",\n    \"Demonstrates consistent empirical improvements over existing methods across multiple datasets and self-supervised learning frameworks.\",\n    \"Provides clear criteria for what constitutes a good uniformity metric, enhancing interpretability.\"\n  ],\n  \"weaknesses\": [\n    \"Lacks comprehensive theoretical proofs to establish sufficiency of the criteria for constructing an ideal metric.\",\n    \"Does not include extensive comparisons across a broader range of datasets and tasks.\",\n    \"Impact of the $\\mathcal{W}_2$ loss relative to existing $\\mathcal{L}_U$ losses is not fully explored.\"\n  ],\n  \"questions\": [\n    \"How can the theoretical sufficiency of the criteria be further established to solidify the metric's robustness?\",\n    \"What are the implications of the $\\mathcal{W}_2$ metric's performance relative to existing $\\mathcal{L}_U$ losses in various contexts?\",\n    \"Could a more extensive comparative analysis across additional datasets and tasks strengthen the claim of the metric's superiority?\"\n  ],\n  \"overall_score\": \"Accept\",\n  \"confidence\": \"High\"\n}",
      "parse_error": true
    }
  },
  {
    "paper_id": "3pgJNIx3gc",
    "title": "AlphaFold Distillation for Protein Design",
    "std_review": {
      "summary": "The paper introduces AF-Distill, a distilled version of AlphaFold used for protein inverse folding, aiming to improve sequence recovery and diversity. It integrates a structure-consistency loss (SC loss) into baseline models and evaluates the impact on training costs, performance, and interpretability. The study shows strong improvements in sequence recovery and diversity, though gains in other metrics are marginal. The method is cost-effective and integrates well with existing models, but further exploration of regularization parameters and dataset choices is suggested.",
      "strengths": [
        "Innovative use of a distilled model for protein inverse folding.",
        "Significant improvements in sequence recovery and diversity.",
        "Cost-effective training with reduced computational overhead."
      ],
      "weaknesses": [
        "Marginal gains in metrics like perplexity.",
        "Trade-offs in training cost depending on dataset choice.",
        "Discretized 50-bin output for pTM/pLDDT scores may limit precision."
      ],
      "questions": [
        "What is the optimal value of the regularization coefficient α in the SC loss?",
        "How does the choice of training datasets affect the generalizability of AF-Distill?",
        "Can the discretized output be improved to enhance score precision?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3pWSL8My6B",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a novel method for analyzing the sensitivity of deep neural networks (DNNs) to input perturbations through the concept of 'Sensitivity Sets' (S). It provides a practical approach to identify and quantify the impact of input variables on model predictions, offering insights into model robustness and interpretability. While the method is demonstrated across various DNN architectures and datasets, its applicability is limited to DNNs. The paper is well-explained but lacks error analysis and clear guidelines for forming Sensitivity Sets, which could affect its reliability and generalizability.",
      "strengths": [
        "Introduces a novel concept of Sensitivity Sets (S) to analyze DNNs, providing a new perspective on model interpretability.",
        "Proposes a practical method for identifying and quantifying the impact of input variables on model predictions.",
        "Demonstrates the method's effectiveness across a range of DNN architectures and datasets, highlighting critical input features."
      ],
      "weaknesses": [
        "The method is primarily applicable to DNNs, limiting its generalizability to other AI models.",
        "The process of forming Sensitivity Sets is not clearly defined, potentially leading to subjective interpretations.",
        "Lacks error bars and analysis of results across multiple random seeds, impacting the reliability of findings."
      ],
      "questions": [
        "Should the title be refined to reflect the method's specificity to DNNs?",
        "What clear criteria or step-by-step approach can be provided for forming Sensitivity Sets to enhance practicality and reproducibility?",
        "How can error bars be included for the top row of Table 1, Figure 4, and Figure 5 (a) to strengthen the robustness of the findings?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "3PWYAlAQxv",
    "title": "Neural Networks Trained by Weight Permutation are Universal Approximators",
    "std_review": {
      "summary": "The paper proposes a novel training method for neural networks that uses weight permutations to enhance generalization. Theoretical analysis links permutations to step function approximation, supporting the method's effectiveness. Empirical results across various datasets show significant performance improvements, especially on challenging tasks. However, the method's flexibility and broader applicability remain underexplored.",
      "strengths": [
        "Introduces a unique training paradigm leveraging permutations to improve model generalization.",
        "Provides a solid theoretical foundation linking permutations to step function approximation.",
        "Demonstrates clear empirical benefits across multiple datasets."
      ],
      "weaknesses": [
        "Lacks clear justification for the choice of permutation period k.",
        "Insufficient exploration of training dynamics, particularly in visualizations.",
        "Limited discussion on the method's impact on sparse initialization.",
        "Theoretical analysis is restricted to ReLU activation functions.",
        "Figures 1 and 4 are not fully explained, hindering understanding of key concepts."
      ],
      "questions": [
        "What criteria were used to select the permutation period k, and how does it affect flexibility?",
        "Can the training dynamics be better illustrated to clarify the role of permutations?",
        "How does the method perform with sparse weight initialization, and what are the observed effects?",
        "Are the findings generalizable to other activation functions beyond ReLU?",
        "What is the detailed interpretation of the phenomena observed in Figure 4?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "3QkzYBSWqL",
    "title": "Universal Backdoor Attacks",
    "std_review": {
      "summary": "The paper introduces a novel universal backdoor attack that can be transferred across different target classes in deep neural networks, even when those classes are far apart in the latent space. The attack leverages a surrogate classifier to extract latent features, which are then manipulated to embed a backdoor trigger. While demonstrating effectiveness on several image classification models, the paper highlights limitations such as trigger visibility and high sample efficiency. Overall, the work advances the field of adversarial attacks but requires further refinement for practical deployment.",
      "strengths": [
        "Novelty of Universal Transferability: Demonstrates that a single backdoor trigger can be transferred across multiple target classes.",
        "Robust Surrogate Classifier Design: Uses a surrogate classifier with distinct latent representations for each target class to facilitate backdoor injection.",
        "Empirical Validation: Provides extensive experiments across multiple datasets and model architectures, showing consistent performance."
      ],
      "weaknesses": [
        "Trigger Visibility: Generated triggers may be detectable by human observers or advanced input-space defenses.",
        "Sample Efficiency: Requires a high number of poisoned samples (e.g., 0.39% of the dataset), which may limit feasibility in real-world scenarios.",
        "Defensive Robustness: Defense parameters were optimized against a specific baseline, and their robustness against the proposed universal attack is not fully explored.",
        "Latent Space Complexity: Requires a surrogate classifier with a distinct latent representation for each target class, which may be restrictive."
      ],
      "questions": [
        "How can the attack be made more robust against input-space defenses that can detect the generated triggers?",
        "What is the impact of using a surrogate classifier with a more general latent space on the attack's effectiveness?",
        "How does the attack perform when applied to more complex model architectures beyond those tested in the paper?",
        "Can the defense parameters be generalized to provide robustness against a wider range of backdoor attacks?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "3QLkwU40EE",
    "title": "",
    "std_review": {
      "summary": "The paper introduces Spatial Prompt Tuning (SPT), a method that learns spatial prompts to guide object detection models. These prompts are learned alongside the model parameters and are applied as spatial augmentations during training. The approach shows improved performance on standard benchmarks, enhancing model interpretability and detection accuracy. While innovative, the paper lacks quantitative validation of prompt sparsity and invariance, and some methodology details are unclear, leading to a recommendation of weak accept.",
      "strengths": [
        "Novelty of Spatial Prompts: The concept of learning spatial prompts that act as discriminative augmentations is innovative and addresses the need for interpretability in deep learning models.",
        "Integration with Existing Frameworks: SPT can be seamlessly integrated with existing object detection architectures without requiring significant modifications, making it practical for widespread adoption.",
        "Empirical Performance: The experiments demonstrate clear improvements in detection accuracy and interpretability, providing strong empirical support for the proposed method."
      ],
      "weaknesses": [
        "Interpretability of Learned Prompts: The paper lacks quantitative validation of the sparsity and localization of learned prompts, which is crucial for establishing interpretability.",
        "Ablation Experiment Design: The ablation experiments could be more comprehensive by including a baseline where model parameters are trained to convergence before SPT parameters, to better isolate the effects of SPT.",
        "Training Design Clarification: The training procedure for different values of k is not clearly justified, and the results of a combined training approach are not detailed.",
        "Comparison with Global Prompts: The comparison with Bahng et al.'s global prompts is not fully explored, particularly how increasing the number of global prompts affects performance.",
        "Clarity in Methodology: The distinction between SPTNet and SPTNet-P is not clearly explained in the main text, requiring readers to refer to supplementary material, which can be confusing."
      ],
      "questions": [
        "Can you provide quantitative validation of the sparsity and localization of the learned SPT parameters after convergence?",
        "How does training the model parameters to convergence before training the SPT parameters affect the overall performance?",
        "Could you clarify the training procedure for different values of k and provide results for a combined training approach?",
        "How does increasing the number of Bahng et al.'s global prompts affect the performance compared to SPT?",
        "Please clarify the distinction between SPTNet and SPTNet-P in the main text and provide an example of computing the total number of SPT parameters.",
        "How does using learned prompts as augmentations impact the network's invariance and the contrastive loss?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "3qo1pJHabg",
    "title": "Lrr: Language-Driven Resample Continuous Representation against Adversarial Tracking Attacks",
    "std_review": {
      "summary": "The paper introduces LRR, a lightweight defense method that enhances the robustness of template-based trackers against adversarial attacks. Experiments show that LRR significantly outperforms baseline trackers like SiamRPN++ in precision and IoU against attacks such as RTAA, IoUAttack, and CSA, while maintaining low computational overhead. The defense is evaluated on multiple benchmarks, demonstrating robustness across diverse scenarios. The reviewer finds the method effective and efficient, with clear methodology, but notes areas for improvement.",
      "strengths": [
        "Effectiveness Against Adversarial Attacks: LRR demonstrates strong performance against a range of adversarial attacks, significantly improving precision and IoU compared to baseline trackers.",
        "Lightweight and Efficient: The defense method introduces minimal computational overhead, making it suitable for real-time tracking applications.",
        "Broad Applicability: The method is evaluated on multiple benchmarks, including both standard and more challenging datasets, showcasing its robustness and versatility.",
        "Clear Methodology: The paper provides a clear and reproducible methodology for implementing LRR, including detailed descriptions of attack implementations and evaluation metrics."
      ],
      "weaknesses": [
        "Limited Comparison with Advanced Defenses: The defense is compared primarily against baseline methods and other basic defenses, without extensive comparison against more advanced adversarial defense techniques.",
        "No Evaluation on Transformer-Based Trackers: The paper lacks experiments on state-of-the-art transformer-based trackers, which are increasingly prevalent in tracking tasks.",
        "Potential Overfitting: While the defense is shown to be effective, there is a lack of detailed analysis on potential overfitting issues, especially in varying tracking scenarios.",
        "No Discussion on Natural Language-Based Trackers: The defense method is not adapted or evaluated for natural language-based trackers, which could be a significant area for future research."
      ],
      "questions": [
        "Implementing Diffusion for Tracking Defense: Effectiveness, Computational Trade-offs",
        "More Visualization Results: Visual Comparisons and Tracking Results",
        "Effectiveness of the Proposed Method on the Entire Search Image",
        "Comparison with Basic Defense Methods: Implementation Details and Trade-offs",
        "Clarification of Attack Implementation in Experiments: Implementation Details and Reproducibility",
        "Evaluation on More Challenging Benchmarks: Results and Discussion",
        "Experiments with Transformer-Based Trackers: State-of-the-Art Trackers and Comparison",
        "Incorporation of Natural Language-Based Trackers: Challenges and Approaches"
      ],
      "overall_score": "Accept",
      "confidence": "High"
    }
  },
  {
    "paper_id": "3QR230r11w",
    "title": "Multi-Fidelity Active Learning",
    "std_review": {
      "summary": "The paper presents a novel multi-fidelity active learning algorithm that leverages GFlowNets to efficiently query expensive black-box objective functions in scientific discovery. It balances exploration and exploitation, improving sample efficiency and diversity of discovered candidates compared to baselines. The authors demonstrate practical implications across domains requiring expensive experimental data, though some limitations in scalability and robustness remain.",
      "strengths": [
        "Addresses a critical challenge in scientific discovery by efficiently querying expensive high-fidelity functions.",
        "Integrates GFlowNets with multi-fidelity active learning to balance exploration and exploitation.",
        "Demonstrates improved sample efficiency and diversity of discovered candidates.",
        "Provides thorough evaluation and comparisons with state-of-the-art methods."
      ],
      "weaknesses": [
        "Complexity of GFlowNets may limit applicability to smaller-scale problems.",
        "Relies on a well-defined acquisition function that may be hard to define in practice.",
        "Performance sensitive to oracle costs, acquisition function, and batch size.",
        "Lacks detailed analysis of scalability in high-dimensional spaces.",
        "No robustness analysis to noise and outliers in high-fidelity data."
      ],
      "questions": [
        "How does the approach scale to high-dimensional input spaces?",
        "What is the algorithm's robustness to noise and outliers in high-fidelity data?",
        "Can the acquisition function be generalized beyond the specific domains considered?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3rBu7dR7rm",
    "title": "Unified Long-Term Time-Series Forecasting Benchmark",
    "std_review": {
      "summary": "The paper introduces a comprehensive LTSF benchmark that evaluates both synthetic and real-life datasets, highlighting the effectiveness of newer models like N-HITS and PatchTST. It provides valuable insights into model performance across different data types and emphasizes the importance of diverse, challenging datasets. The benchmark is a significant contribution to the field, though it could benefit from more detailed analysis and clearer discussion of model selection biases.",
      "strengths": [
        "Innovative benchmark design that includes both synthetic and real-life datasets.",
        "Diverse dataset generation with specific challenges such as long-term dependencies and complex patterns.",
        "Comprehensive comparison of classical and newer forecasting models."
      ],
      "weaknesses": [
        "Limited number and diversity of real-life datasets.",
        "Lack of detailed information on hyperparameter tuning.",
        "Potential bias in model selection due to authors' expertise."
      ],
      "questions": [
        "Could the benchmark be extended to include more diverse real-life datasets?",
        "What are the specific hyperparameter tuning strategies used for each model?",
        "How do the synthetic datasets compare to real-world scenarios in terms of model generalizability?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3RfGSbXUt8",
    "title": "",
    "std_review": {
      "summary": "The paper introduces Option Boosting, a hierarchical reinforcement learning method that learns a set of options to solve complex tasks more efficiently. It demonstrates improved performance on gridworld scenarios and addresses the issue of redundant option-policies. However, the paper lacks a comprehensive comparison with existing methods and a detailed analysis of the redundancy issue, and the experiments are limited to controlled gridworld settings.",
      "strengths": [
        "Introduces a novel hierarchical reinforcement learning approach that can potentially improve efficiency and performance.",
        "Demonstrates effectiveness on gridworld scenarios, providing a clear evaluation environment.",
        "Addresses the issue of redundant option-policies, which is an important consideration in hierarchical reinforcement learning."
      ],
      "weaknesses": [
        "Does not provide a comprehensive comparison with other existing hierarchical reinforcement learning methods.",
        "Experiments are limited to gridworld scenarios, which may not fully capture the complexity of real-world environments.",
        "Lacks a detailed analysis of how redundant option-policies are effectively addressed in the proposed framework.",
        "Experiments use only 4 seeds, which may not provide a reliable estimate of the method's performance."
      ],
      "questions": [
        "How does Option Boosting compare to other existing hierarchical reinforcement learning methods in terms of efficiency and performance?",
        "What is the impact of redundant option-policies on the performance of Option Boosting, and how is this addressed?",
        "How does the method perform in more complex environments beyond gridworld scenarios?",
        "What is the variance of the results reported in the experiments, and how reliable is the performance estimate?"
      ],
      "overall_score": "Borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "3rmpixOjPS",
    "title": "Boosting Vanilla Lightweight Vision Transformers via Re-parameterization",
    "std_review": {
      "summary": "The paper introduces TDRL, a Transformer-based architecture that enhances lightweight Vision Transformers for image classification, achieving superior performance over existing models like VanillaNet, especially with limited data. It employs a pyramid multi-branch structure and batch normalization in linear layers to improve efficiency and stability. While demonstrating strong results, the increased model complexity and potential for overfitting are noted as areas for future work.",
      "strengths": [
        "TDRL outperforms existing lightweight ViT architectures, especially in data-scarce scenarios.",
        "The pyramid multi-branch structure and batch normalization improve both performance and training stability.",
        "The re-parameterization technique shows promise for broader applicability beyond Vision Transformers."
      ],
      "weaknesses": [
        "Increased model complexity may lead to higher computational costs during inference.",
        "Risk of overfitting, particularly with limited training data.",
        "Limited validation of generalization to other tasks or datasets."
      ],
      "questions": [
        "How does TDRL perform on larger datasets and more complex image classification tasks?",
        "What strategies can be employed to mitigate overfitting in scenarios with limited data?",
        "How can the re-parameterization technique be adapted for other neural network architectures?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3ROGsTX3IR",
    "title": "",
    "std_review": {
      "summary": "The paper investigates the scaling behavior of a neural network model in the infinite-width limit, identifying a phase transition related to feature learning. It employs a mean‑field parameterization and saddle‑point approximation to derive an action governing the model’s dynamics, revealing a critical regime where the likelihood term vanishes. While the analysis offers new insights into the limits of feature learning, it has methodological weaknesses and lacks clear justification for certain scaling assumptions.",
      "strengths": [
        "Clear formulation of the scaling limits and rigorous foundation for the analysis.",
        "Mean‑field parameterization simplifies the analysis and highlights feature learning.",
        "Identification of a phase transition in model dynamics as a function of width and noise variance.",
        "Connection to existing literature on phase transitions in neural networks."
      ],
      "weaknesses": [
        "Likelihood term vanishing in the infinite‑width limit may obscure the model’s ability to capture complex features.",
        "Unclear justification for the scaling of noise variance with respect to model parameters.",
        "Analysis primarily focused on infinite‑width limits, with limited discussion of finite‑width behavior.",
        "Lack of detailed comparison with alternative methods, such as sampling-based approaches."
      ],
      "questions": [
        "How does the vanishing likelihood term in the infinite‑width limit affect the model’s capacity to learn complex features compared to finite‑width networks?",
        "What is the precise justification for the scaling of noise variance σ² with respect to N, d, and n, and how does it impact the interpretation of the results?",
        "How do the observed phase transitions translate to practical performance in finite‑width networks?",
        "Could a more detailed comparison with sampling-based approaches provide additional insights into the strengths and limitations of the saddle‑point approximation?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "3SJE1WLB4M",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a spectral profile Λ for Gaussian kernel matrices, aiming to bound the generalization error of kernel ridge regression. It connects the continuous kernel to its discretized version used in practice, providing a novel learning measure ρ. While the theoretical framework is promising, ambiguities in parameter definitions and limited formalization of some conjectures reduce confidence in the results.",
      "strengths": [
        "Introduces a novel spectral profile Λ that offers a fresh perspective on bounding generalization error in kernel ridge regression.",
        "Provides a rigorous framework linking the continuous kernel to its discretized counterpart, bridging theory and practice.",
        "Defines a meaningful learning measure ρ that relates to excess risk, offering a new tool for analysis."
      ],
      "weaknesses": [
        "The role of the parameter P in defining Λ is not fully clarified, leaving ambiguity about whether it represents the exact or numerical rank.",
        "Some conjectures, particularly regarding discretization errors, lack formalization, making it difficult to assess their validity.",
        "The analysis primarily covers gradient flow, with limited discussion on its application to gradient descent, potentially limiting practical relevance."
      ],
      "questions": [
        "Can the parameter P be clearly defined as either the exact or numerical rank of the kernel?",
        "How can the conjecture on discretization errors be formally stated and proven?",
        "What additional assumptions are needed to extend the analysis from gradient flow to gradient descent?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "3sOE3MFepx",
    "title": "PDE-Diffusion: Physics guided diffusion model for solving partial differential equations",
    "std_review": {
      "summary": "The paper introduces PDE-Diffusion, a diffusion model that incorporates physics-based priors to solve PDEs, improving temporal coherence and accuracy over traditional solvers but at higher computational cost. It introduces two new datasets for evaluation, though the approach's generalizability and broader applicability remain limited.",
      "strengths": [
        "Incorporates physics-based priors into diffusion process to ensure physical constraints.",
        "Improves temporal coherence and accuracy over existing solvers.",
        "Introduces novel datasets to evaluate generalizability."
      ],
      "weaknesses": [
        "High computational cost may limit real-time or resource-constrained applications.",
        "Limited comparison with a broader range of methods.",
        "Evaluation based on only two new datasets may not fully capture performance across all PDEs."
      ],
      "questions": [
        "How does the model scale to high-dimensional or more complex PDEs?",
        "What is the impact of the computational cost on practical deployment?",
        "How robust is the model to variations in initial and boundary conditions?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "3TAhlGaMKD",
    "title": "",
    "std_review": {
      "summary": "The paper investigates the security of Instruction Tuned (IT) models against membership inference and backdoor attacks, demonstrating their vulnerabilities. It compares the robustness of IT models with standard fine-tuning, Sparse Prompt Tuning (SPT), and Low-Rank Adaptation (LoRA) across various datasets, finding LoRA to be most secure against membership inference attacks. While the study provides valuable insights into model security risks, it has limitations in scope and experimental variability.",
      "strengths": [
        "Comprehensive analysis of IT model security through membership inference and backdoor attacks.",
        "Methodological rigor with diverse datasets and multiple model adaptations.",
        "Clear and well-documented experimental setup facilitating replication."
      ],
      "weaknesses": [
        "Limited scope of membership inference focusing on the entire prompt rather than individual examples.",
        "Lack of diversity in backdoor labels tested, only using label 0.",
        "Potential for overfitting in backdoor implementation due to concatenating clean and backdoored samples.",
        "High variability in backdoor attack results, possibly due to insufficient sample size or model initialization variability."
      ],
      "questions": [
        "How does the paper address the potential for more granular membership inference vulnerabilities beyond the entire prompt?",
        "What are the implications of the backdoor attack variability on the generalizability of the findings?",
        "Could the experimental setup be expanded to test backdoor attacks with a broader range of target labels?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "3tjTJeXyA7",
    "title": "Revitalizing Channel-dimension Fourier Transform for Image Enhancement",
    "std_review": {
      "summary": "The paper presents a novel approach to image enhancement using a channel-dimension Fourier transform (CFTL) and its variants. Experiments show significant improvements over existing methods on exposure correction tasks, with strong generalization across diverse datasets. The method is innovative, versatile, and empirically effective, though it may be complex to implement and computationally intensive.",
      "strengths": [
        "Innovative modeling of channel discrepancy using Fourier transforms.",
        "Versatility across multiple variants tailored for different enhancement aspects.",
        "Strong empirical performance on exposure correction tasks.",
        "Robust generalization across diverse datasets."
      ],
      "weaknesses": [
        "Complexity of implementation due to multiple variants and Fourier transforms.",
        "Potential computational cost from applying Fourier transforms, especially in global pooling.",
        "Limited demonstration of effectiveness beyond exposure correction."
      ],
      "questions": [
        "How can the computational overhead of Fourier transforms be mitigated for resource-constrained environments?",
        "What is the impact of the proposed method on other image enhancement tasks such as denoising or super-resolution?",
        "Could the method be extended to handle non-image data with similar channel discrepancy issues?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3tM1l5tSbv",
    "title": "Generative Learning for Solving Non-Convex Problem with Multi-Valued Input-Solution Mapping",
    "std_review": {
      "summary": "The paper presents a novel generative framework for solving non-convex optimization problems by learning the probability distribution of optimal solutions. It demonstrates improved performance over existing methods on benchmark problems, highlighting the potential of generative models in optimization. However, the paper lacks a detailed theoretical analysis, has a limited experimental scope, and does not thoroughly discuss its limitations.",
      "strengths": [
        "Introduces a unique generative framework for optimization problems.",
        "Effectively learns the probability distribution of optimal solutions.",
        "Demonstrates improved performance compared to existing methods.",
        "Provides clear and accessible explanations of the methodology."
      ],
      "weaknesses": [
        "Lacks a detailed theoretical analysis.",
        "Experimental setup is limited to a few benchmark problems.",
        "Does not provide probabilities for samples in Figure 3.",
        "Does not thoroughly discuss limitations.",
        "Novelty is not clearly established compared to existing generative models."
      ],
      "questions": [
        "Could the authors provide a detailed theoretical analysis of the proposed method?",
        "How can the experimental setup be expanded to demonstrate broader applicability?",
        "What are the specific limitations of the proposed method, and how can they be addressed?",
        "How does the proposed method compare to existing generative models for optimization problems?"
      ],
      "overall_score": "4: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3TO3TtnOFl",
    "title": "BTR: Binary Token Representations for Efficient Retrieval-Augmented Language Models",
    "std_review": {
      "summary": "BTR introduces a binary token representation for passage encodings in retrieval-augmented language models, achieving significant storage savings and faster inference without substantial loss of task performance. The method decomposes the reader encoder offline, applies runtime compression, and uses query-aware distillation to enhance accuracy. While innovative, the approach introduces implementation complexity and potential overhead, and is currently limited to encoder-decoder models.",
      "strengths": [
        "Innovative binary token representation reduces storage requirements.",
        "Efficient offline decomposition lowers inference computational load.",
        "Runtime compression further enhances speed.",
        "Query-aware distillation improves task accuracy.",
        "Comprehensive evaluation with clear ablations."
      ],
      "weaknesses": [
        "Implementation complexity due to multiple compression layers.",
        "Potential overhead from offline decomposition.",
        "Limited applicability to decoder-only models.",
        "Possible trade-offs in task performance."
      ],
      "questions": [
        "How does the method scale to very large datasets?",
        "Can the approach be adapted for decoder-only architectures?",
        "What is the impact of quantization on downstream tasks?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3uITarEQ7p",
    "title": "Differentially Private Model Compression via Selective Pretraining",
    "std_review": {
      "summary": "The paper presents a selective pre‑training method that enhances small language models' performance on private data by using a domain classifier trained with DP‑SGD to select relevant data. It shows significant accuracy gains for small models and demonstrates scalability across model sizes, while integrating private data throughout the training pipeline. The method offers strong privacy guarantees but introduces implementation complexity and potential overfitting, with diminishing returns for larger models.",
      "strengths": [
        "Improved performance on private data for small models compared to using the full public dataset.",
        "Ensures strong privacy guarantees through DP‑SGD.",
        "Demonstrates consistent gains across a range of model sizes.",
        "Integrates private data throughout the training pipeline, enhancing model relevance."
      ],
      "weaknesses": [
        "Adds complexity to implementation, especially in managing the domain classifier and privacy budget.",
        "Risk of overfitting when selecting a subset of data based on domain classification.",
        "Potential diminishing returns in performance for larger models.",
        "Requires careful tuning of the privacy budget across pre‑training and fine‑tuning."
      ],
      "questions": [
        "How does the method handle cases where the domain classifier struggles to identify relevant data?",
        "What strategies are employed to mitigate overfitting when using a classifier‑selected subset?",
        "Can the method be extended to other domains beyond language models?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3ukT8oODY0",
    "title": "Careful at Estimation and Bold at Exploration for Deterministic Policy Gradient Algorithm",
    "std_review": {
      "summary": "The paper introduces BACC, a novel exploration strategy for dense-reward environments, leveraging a Double-DQN with Conservative Softmax to balance exploration and exploitation. Empirical results show improved sample efficiency and faster convergence compared to standard methods. While theoretically sound, the method's assumptions and comparisons need further validation.",
      "strengths": [
        "Introduces a unique action-centric exploration strategy for dense-reward settings.",
        "Grounded in a theoretical foundation linking policy and Q-function learning.",
        "Demonstrates strong empirical performance across various dense-reward tasks."
      ],
      "weaknesses": [
        "Lacks rigorous validation of the key assumption about policy and Q-function dynamics.",
        "Does not compare against state-space exploration methods.",
        "Relies on theoretical arguments rather than concrete real-world examples for multimodality in Q-function."
      ],
      "questions": [
        "Can the assumption that policy learning lags behind Q-function learning be empirically validated?",
        "How does BACC compare to state-space exploration techniques?",
        "What real-world examples support the claim of multimodality in the Q-function?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3UWuFoksGb",
    "title": "Learning Planning Abstractions",
    "std_review": {
      "summary": "The paper presents a novel planning abstraction method for robots that converts natural language instructions into detailed execution plans. It introduces an abstract transition model and a feasibility function to generate high-level plans efficiently. The approach shows promise in handling complex tasks and improving efficiency over baselines, though it has limitations in ambiguity handling and comprehensive evaluation.",
      "strengths": [
        "Efficient planning through an abstract transition model that reduces state space complexity.",
        "Robustness via a feasibility function ensuring valid actions.",
        "Enhanced human-robot interaction by interpreting natural language instructions."
      ],
      "weaknesses": [
        "Limited handling of ambiguous or incomplete language inputs.",
        "Training data reliance on demonstrations may restrict generalizability.",
        "Unclear training procedure for the feasibility function.",
        "Evaluation focused on specific tasks, not covering a broad range of scenarios."
      ],
      "questions": [
        "How does the system resolve ambiguities or incomplete language inputs?",
        "What is the exact number of trajectories used to train the abstract transition model?",
        "How is the feasibility function trained, and what dataset is used?",
        "What is the longest abstract plan required for the most complex problems, and how many abstract actions does it contain?",
        "What additional evaluation metrics or scenarios would strengthen the assessment of the system's performance?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "3VD4PNEt5q",
    "title": "Fusion is Not Enough: Single Modal Attacks on Fusion Models for 3D Object Detection",
    "std_review": {
      "summary": "The paper introduces a novel adversarial attack on 3D object detection models, specifically targeting camera-LiDAR fusion systems. It demonstrates high success rates in both simulation and real-world scenarios, effectively deceiving the system into classifying pedestrians as vehicles under various lighting conditions. While innovative, the attack's focus on pedestrian detection and patch placement complexity limit its broader applicability. Ethical considerations regarding the potential harm to human subjects are also noted.",
      "strengths": [
        "Innovative adversarial patch attack targeting camera-LiDAR fusion systems",
        "Demonstrates high effectiveness in both simulated and real-world scenarios",
        "Shows robustness across varying lighting conditions"
      ],
      "weaknesses": [
        "Focused solely on pedestrian detection, limiting broader applicability",
        "Patch placement complexity in real-world conditions poses practical challenges",
        "Ethical implications of deploying such attacks are not fully addressed"
      ],
      "questions": [
        "How can the attack be extended to other object types beyond pedestrians?",
        "What strategies can be employed to simplify patch placement in real-world scenarios?",
        "What additional ethical guidelines should be considered for deploying adversarial attacks?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3Vw7DQqq7U",
    "title": "LEMON: Lossless model expansion",
    "std_review": {
      "summary": "The paper introduces LEMON, a method for expanding model capacity by adding layers to existing models like Vision Transformers and BERT without retraining, showing improved performance on larger models. While the approach is versatile and offers insights into learning rate impacts, its generalizability to other architectures and theoretical foundations are underexplored. The incremental expansion strategy is briefly mentioned but requires further investigation.",
      "strengths": [
        "Provides a novel, efficient way to scale model capacity without retraining.",
        "Demonstrates effectiveness across Vision Transformers and BERT, showcasing versatility.",
        "Offers valuable insights into optimizing training with learning rate schedules."
      ],
      "weaknesses": [
        "Limited evaluation on other architectures reduces generalizability.",
        "Lacks thorough theoretical analysis of learning rate impacts.",
        "Practical challenges for applying LEMON to different architectures are not fully addressed.",
        "Incremental expansion strategy is underexplored."
      ],
      "questions": [
        "How does LEMON perform on other model architectures beyond Vision Transformers and BERT?",
        "What is the theoretical basis for the observed impact of learning rate schedules on model performance?",
        "What challenges arise when applying LEMON to different architectures, and how can they be addressed?",
        "How does the incremental model expansion strategy compare to single-step expansion in terms of benefits and challenges?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "3w6xuXDOdY",
    "title": "A Study of Generalization in Offline Reinforcement Learning",
    "std_review": {
      "summary": "The paper proposes a novel approach to reinforcement learning in webshop environments by integrating expectile regression with a modified IQL framework. It demonstrates competitive performance against baselines, suggesting potential value for e-commerce RL. However, the paper lacks clarity in justifying the unsuitability of IQL for webshops and in explaining the fine-tuning process and model selection.",
      "strengths": [
        "Integrates expectile regression to robustly handle uncertainty in high-dimensional webshop settings.",
        "Modified IQL framework effectively addresses the challenges of complex state-action spaces.",
        "Provides comprehensive experimental setup and clear comparisons to existing methods."
      ],
      "weaknesses": [
        "Does not adequately justify why IQL is unsuitable for webshop settings.",
        "Learning curve plots are too brief to draw definitive conclusions.",
        "Figure 3 lacks clear explanation for differing lines.",
        "Webshop environment setup is not fully detailed.",
        "Fine-tuning process and model selection criteria are not thoroughly explained."
      ],
      "questions": [
        "Why is IQL considered unsuitable for webshop settings, especially concerning the high-dimensional state-action space?",
        "Can the learning curve plots be extended with more data points to better illustrate convergence trends?",
        "Why do the blue and red lines in Figure 3 differ, given that the data is collected by expert PPO?",
        "Can the authors provide a more detailed description of the webshop environment, including state, action, reward, and transition dynamics?",
        "How are the algorithms fine-tuned and how are the best models selected?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "3WB5hT27zf",
    "title": "Partial Optimal Transport for Open-set Semi-supervised Learning",
    "std_review": {
      "summary": "The paper introduces a novel approach to Open-Set Semi-Supervised Learning (OSSL) by leveraging Partial Optimal Transport (POT) for detecting out-of-distribution (OOD) samples. The proposed Mass Score Function (MSF) uses the optimal transport plan to score unlabeled samples, distinguishing between in-distribution (ID) and OOD data. Experimental results show superior performance and robustness compared to existing OOD detection techniques in OSSL settings. The method is innovative, providing a clear and interpretable metric for OOD detection, and demonstrates strong performance across various experiments.",
      "strengths": [
        "Innovative Use of POT: The paper effectively applies POT to the OSSL problem, providing a novel framework for OOD detection.",
        "Mass Score Function (MSF): The MSF offers a clear and interpretable metric for assessing the likelihood of samples being outliers, enhancing the method's practical applicability.",
        "Robustness and Performance: The method outperforms traditional approaches like MTCF, T2T, and OpenMatch, particularly in challenging scenarios with high OOD presence.",
        "Comprehensive Experiments: The paper includes thorough ablation studies and comparative experiments, demonstrating the method's effectiveness and reliability."
      ],
      "weaknesses": [
        "Computational Complexity: The POT approach may introduce significant computational overhead, potentially limiting its applicability to large-scale datasets.",
        "Assumption of Known OOD Distribution: The method assumes a known distribution of OOD data, which may not always be feasible in real-world scenarios.",
        "Limited Generalization: The effectiveness of the MSF may vary across different domains and data types, requiring careful validation in diverse settings."
      ],
      "questions": [
        "How can the computational complexity of the POT approach be mitigated for large-scale datasets?",
        "What strategies can be employed to handle scenarios where the distribution of OOD data is unknown?",
        "How can the proposed method be generalized to different domains and data types?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3wGi5m2YHY",
    "title": "FlowHash: Accelerating Audio Search with Balanced Hashing via Normalizing Flow",
    "std_review": {
      "summary": "The paper presents FlowHash, a novel hashing method for audio retrieval that uses a normalizing flow to achieve balanced bucket distribution, aiming to improve retrieval accuracy and reduce memory overhead. Experimental results on several datasets show competitive performance, especially in speed and memory efficiency, but the novelty and robustness of the approach relative to existing techniques are not fully explored. The reviewer recommends a weak accept, suggesting the inclusion of more datasets and additional experimental metrics to strengthen the claims.",
      "strengths": [
        "Innovative use of normalizing flow for bucket balancing in audio hashing.",
        "Demonstrates significant memory reduction, crucial for large-scale systems.",
        "Provides empirical validation across multiple datasets, showing effectiveness and robustness.",
        "Clearly outlines contributions, distinguishing the method from existing bucket‑balance techniques."
      ],
      "weaknesses": [
        "Limited dataset coverage may not fully justify claims of robustness and balance.",
        "Lacks comparison of memory overhead across methods at the same recall rates.",
        "Marginal accuracy gains are not clearly highlighted; detailed raw results are needed.",
        "Novel aspects beyond the normalizing flow are not adequately discussed.",
        "Missing detailed metrics on query processing time and training time."
      ],
      "questions": [
        "Should the evaluation include more real-world datasets to better justify robustness claims?",
        "What is the memory overhead of the proposed method compared to other methods at the same recall rates?",
        "Could the highlighted results in Tables 1 and 2 be more clearly identified, possibly requiring a re‑check of raw results?",
        "How does the proposed method differ from or outperform alternative bucket‑balance techniques beyond the use of normalizing flow?",
        "Should query processing time and training time be reported to evaluate practical efficiency?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "3wL1tj3kqE",
    "title": "Fair Domain Generalization with Arbitrary Sensitive Attributes",
    "std_review": {
      "raw_text": "{\n  \"summary\": \"The paper introduces SISA, a framework that mitigates bias in machine learning models by selectively sampling sensitive attributes during training. It uses a fairness encoder to conditionally concatenate sampled attributes with input data and enforces equalized odds through a latent representation. Experiments show improved fairness without significant performance loss, especially with multiple attributes. The method is evaluated on several datasets and compared to baselines, demonstrating its effectiveness. While innovative, the paper has some theoretical and practical concerns.\",\n  \"strengths\": [\n    \"Innovative sampling strategy for incorporating fairness directly into training.\",\n    \"Latent representation approach for enforcing equalized odds.\",\n    \"Strong empirical validation across multiple datasets.\",\n    \"Flexibility to handle multiple sensitive attributes.\"\n  ],\n  \"weaknesses\": [\n    \"Lack of detailed ablation studies on the sampling strategy.\",\n    \"Unclear handling of dimensionality when reshaping binary attributes.\",\n    \"Complexity of the equalized odds loss formulation.\",\n    \"Limited exploration of hyperparameter sensitivity.\",\n    \"Insufficient guidance on balancing fairness and generalization with many attributes.\",\n    \"Rationale for choosing a single vs. dual encoder is not fully explored.\"\n  ],\n  \"questions\": [\n    \"What are the detailed ablation studies on the sampling strategy to ensure it does not introduce bias?\",\n    \"How does the method handle dimensionality when reshaping binary attributes, and what impact does this have on model learning?\",\n    \"Can the equalized odds loss be further clarified or theoretically justified?\",\n    \"What is the process for selecting hyperparameters \\(\\epsilon\\) and \\(\\gamma\\), and how robust are the results to different choices?\",\n    \"What guidance is provided for balancing fairness and generalization when multiple attributes are involved?\",\n    \"What theoretical reasoning supports the choice between a single and dual encoder architecture?\"\n  ],\n  \"overall_score\": \"6: accept\",\n  \"confidence\": \"4: high\"\n}",
      "parse_error": true
    }
  },
  {
    "paper_id": "3xDaj4pRna",
    "title": "Sharpness-Aware Minimization Promotes Diverse Feature Learning",
    "std_review": {
      "summary": "The paper introduces a theoretical framework linking feature diversity to model generalization, proposing a loss term (SAM) that encourages diverse feature learning. Empirical results on a toy dataset show improved generalization, but the findings are limited to simplified settings. While offering valuable insights and practical guidance, the work's applicability to real-world, high-dimensional data remains limited.",
      "strengths": [
        "Clear theoretical contribution linking feature diversity to generalization.",
        "Empirical validation demonstrating the effectiveness of the SAM loss.",
        "Insightful discussion on feature entanglement and its implications."
      ],
      "weaknesses": [
        "Scope limited to toy settings, potentially limiting real-world applicability.",
        "Assumes clean disentanglement of features, which may not hold in practice.",
        "Focuses on second-order effects, possibly overlooking higher-order influences.",
        "Defines diversity narrowly, without broader generalization metrics."
      ],
      "questions": [
        "How can the theoretical framework be extended to high-dimensional, real-world datasets?",
        "What methods can be used to detect and quantify feature entanglement in complex data?",
        "What are the practical implications of ignoring higher-order terms in the theoretical derivation?",
        "How does the concept of feature diversity relate to other robustness properties beyond in-distribution settings?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "3xHbRLymyZ",
    "title": "DeeDiff: Dynamic Uncertainty-Aware Early Exiting for Accelerating Diffusion Model Generation",
    "std_review": {
      "summary": "DeeDiff introduces an innovative early‑exiting framework for diffusion models that uses an uncertainty estimation module to dynamically decide when to stop sampling. The approach integrates a layer‑wise loss that combines standard diffusion loss with uncertainty‑aware terms, leading to significant improvements in sample efficiency across multiple datasets. While the method shows strong empirical results, it introduces additional implementation complexity and scalability concerns that warrant further exploration.",
      "strengths": [
        "Introduces a novel early‑exiting mechanism that leverages uncertainty estimation.",
        "Provides a theoretically grounded layer‑wise loss function.",
        "Demonstrates clear empirical improvements in sample efficiency."
      ],
      "weaknesses": [
        "Implementation complexity due to the uncertainty estimation module.",
        "Potential scalability issues for very large models or different architectures.",
        "Limited comparison with state‑of‑the‑art diffusion methods."
      ],
      "questions": [
        "How does the framework scale to very large diffusion models?",
        "What is the computational overhead of the uncertainty estimation module?",
        "How does DeeDiff compare to recent state‑of‑the‑art methods in terms of efficiency and quality?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3xHDeA8Noi",
    "title": "Sophia: A Scalable Stochastic Second-order Optimizer for Language Model Pre-training",
    "std_review": {
      "summary": "Sophia is a second-order optimizer designed to accelerate pre‑training of large language models by stabilizing updates with a clipping mechanism. It shows a 2× speed‑up on several benchmarks while maintaining comparable performance, with theoretical guarantees under non‑convex settings. However, scalability to very large models and downstream task performance are not fully demonstrated.",
      "strengths": [
        "Introduces a novel clipping mechanism to stabilize second-order updates in non‑convex landscapes.",
        "Provides theoretical guarantees for convergence under non‑convex conditions.",
        "Demonstrates empirical speed‑up across a range of model sizes with clear ablation studies.",
        "Shows improved robustness to noisy or ill‑conditioned Hessians."
      ],
      "weaknesses": [
        "Limited scalability testing on models with billions of parameters.",
        "No evaluation of downstream task performance beyond pre‑training.",
        "Theoretical guarantees are limited to specific classes of non‑convex functions.",
        "Lacks detailed guidance on hyper‑parameter tuning for the clipping mechanism.",
        "Comparison with state‑of‑the‑art methods is limited to a few competitors."
      ],
      "questions": [
        "How does Sophia scale to models with billions of parameters, such as GPT‑3 or LLaMA?",
        "What is the impact of Sophia on downstream task performance, such as fine‑tuning or few‑shot learning?",
        "Can you provide more detailed guidance on hyper‑parameter tuning for the clipping mechanism?",
        "How does Sophia compare to a broader range of state‑of‑the‑art optimizers in terms of computational cost and implementation effort?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "3y1K6buO8c",
    "title": "Brain decoding: Toward real-time reconstruction of visual perception",
    "std_review": {
      "summary": "The paper presents a novel two-stage method for decoding visual information from MEG signals and generating corresponding images. It combines a CNN for feature extraction with a supervised image model (VGG/ResNet) to produce coherent images. While the approach is innovative and empirically validated, several methodological concerns, such as the hyperparameter search for λ and the discussion of temporal resolution, need clarification. Overall, the work is promising but requires further refinement.",
      "strengths": [
        "Innovative integration of MEG decoding with image generation.",
        "Clear and transparent methodological framework.",
        "Empirical validation showing coherent image generation aligned with original stimuli.",
        "Standardization of retrieval metric using cosine similarity."
      ],
      "weaknesses": [
        "Ambiguity in hyperparameter search for λ and its evaluation.",
        "Limited discussion on the temporal resolution of MEG and its impact on low-level feature recovery.",
        "Omission of λ in hyperparameter search for retrieval.",
        "Unclear time windows used for decoding and retrieval analyses.",
        "Potential overemphasis on scientific insight without a concise statement."
      ],
      "questions": [
        "How was the hyperparameter λ selected for the retrieval task, and was it evaluated on the small test set used for image generation?",
        "How does the temporal resolution of MEG limit the recovery of low-level visual details, and how does this relate to existing literature?",
        "Was λ included in the hyperparameter search for the retrieval task, and if not, why?",
        "What specific time windows were used for the sliding and growing window analyses in Fig. 2, and how do they relate to retrieval performance?",
        "What is the main scientific insight derived from the MEG decoding and image generation process?",
        "Which layers of the supervised image models (VGG/ResNet) were used for generating images?",
        "Is the retrieval metric (e.g., relative median rank or top-5 accuracy) consistently applied across different window sizes and configurations?",
        "What is the size of the retrieval set used for evaluating top-5 accuracy?",
        "How could the decoding approach be extended to EEG for real-time applications?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "3y2TfP966N",
    "title": "T-Rep: Representation Learning for Time Series using Time-Embeddings",
    "std_review": {
      "summary": "The paper introduces T-Rep, a self-supervised framework for time series that learns robust temporal representations using two pretext tasks. It outperforms both supervised and existing self-supervised methods across multiple datasets, demonstrating strong performance in forecasting and anomaly detection. The theoretical motivation is solid, and the comprehensive evaluation supports its effectiveness, though implementation complexity and lack of formal guarantees are noted.",
      "strengths": [
        "Innovative dual pretext tasks enhance generalizability of learned representations.",
        "Consistently achieves state-of-the-art results across diverse datasets and tasks.",
        "Provides a clear theoretical foundation linking pretext tasks to capturing temporal dynamics."
      ],
      "weaknesses": [
        "Implementation complexity may limit accessibility for practitioners.",
        "Lacks formal theoretical guarantees for convergence or optimality.",
        "Evaluation could be strengthened by comparing against a broader range of state-of-the-art methods."
      ],
      "questions": [
        "How does T-Rep compare to recent self-supervised methods beyond those evaluated?",
        "What is the impact of hyperparameter tuning on T-Rep's performance?",
        "Can T-Rep be adapted for streaming data or online learning scenarios?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3Y7r6xueJJ",
    "title": "Continual Learning in the Presence of Spurious Correlations: Analyses and a Simple Baseline",
    "std_review": {
      "summary": "The paper introduces BGS, a method for bias mitigation in contrastive learning, and demonstrates its superior performance over existing baselines in reducing bias. However, the effectiveness diminishes with larger datasets, hinting at scalability issues. The study is well-structured, with clear problem definition and strong empirical support, though it lacks robustness analysis and alternative evaluation metrics.",
      "strengths": [
        "Clear problem definition and bias metric",
        "Innovative bias-aware gradient stacking approach",
        "Comprehensive comparison with GDumb and DFR",
        "Empirical evidence showing significant bias reduction"
      ],
      "weaknesses": [
        "Limited scalability insights",
        "Lack of robustness analysis",
        "Potential overfitting in bias reduction",
        "Absence of alternative performance metrics"
      ],
      "questions": [
        "How does BGS perform under different types of bias or varying data distributions?",
        "What are the underlying reasons for the limited scalability observed with larger datasets?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3yyGlNHnlj",
    "title": "GraphECL: Towards Efficient Contrastive Learning for Graphs",
    "std_review": {
      "summary": "GraphECL introduces a novel approach to learning on quantum circuits using complementary negative pairs, aiming to improve learning efficiency and accuracy, especially for large or complex circuits. Preliminary results show promise, but the paper lacks detailed experimental validation, scalability analysis, and thorough theoretical explanation, leaving open questions about its practical applicability and broader adoption.",
      "strengths": [
        "Introduces a novel approach to learning on quantum circuits using complementary negative pairs, which can potentially enhance learning efficiency and accuracy.",
        "Demonstrates the method's effectiveness on very large or complex quantum circuits, addressing a significant challenge in quantum machine learning.",
        "Provides a clear and structured methodology that can be easily understood and implemented by researchers in the field."
      ],
      "weaknesses": [
        "Lacks detailed experimental results and comparisons with existing methods, making it difficult to fully assess the method's performance and advantages.",
        "Does not thoroughly explore the scalability of GraphECL for extremely large quantum circuits, leaving open questions about its practical applicability.",
        "The theoretical underpinnings of the method are not fully explained, which could hinder its adoption by the broader research community.",
        "Does not discuss potential limitations or challenges in implementing GraphECL, such as computational requirements or data availability."
      ],
      "questions": [
        "Can you provide more detailed experimental results and comparisons with existing methods to assess the method's performance and advantages?",
        "What are the scalability considerations and limitations of GraphECL for extremely large quantum circuits?",
        "Could you elaborate on the theoretical foundations of the method to facilitate broader adoption by the research community?",
        "What are the potential limitations or challenges in implementing GraphECL, such as computational requirements or data availability?"
      ],
      "overall_score": "Borderline",
      "confidence": "Medium"
    }
  },
  {
    "paper_id": "3Z1gxuAQrA",
    "title": "PoSE: Efficient Context Window Extension of LLMs via Positional Skip-wise Training",
    "std_review": {
      "summary": "The paper introduces PoSE, a method for efficiently fine-tuning large language models on long-context tasks using prompts. It demonstrates that PoSE can achieve competitive performance on perplexity and downstream tasks while significantly reducing computational costs. The approach is theoretically sound and flexible, but its scalability and interpretability need further exploration.",
      "strengths": [
        "Efficiently reduces computational resources for long-context fine-tuning.",
        "Achieves comparable or superior performance on standard benchmarks.",
        "Demonstrates versatility across various tasks and datasets.",
        "Grounded in a solid theoretical framework."
      ],
      "weaknesses": [
        "Limited scope of evaluation focusing on perplexity and a few downstream tasks.",
        "Lacks comprehensive baseline comparisons.",
        "Scalability to larger models remains unproven.",
        "Insufficient discussion on interpretability of prompts."
      ],
      "questions": [
        "How does PoSE perform on a broader range of long-context tasks?",
        "What is the impact of prompt design on model reasoning and performance?",
        "Can PoSE be effectively applied to larger language models?",
        "How does the method compare to other prompt-based fine-tuning techniques?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3z60EWfh1p",
    "title": "Geometrically Aligned Transfer Encoder",
    "std_review": {
      "summary": "The paper introduces GATE, a transformer that uses differential geometry to learn cycle-consistent and metric-preserving mappings between heterogeneous data modalities. It outperforms conventional multi-task learning approaches across single-task, multi-task, and knowledge distillation tasks, demonstrating strong theoretical foundations and practical robustness. However, implementation complexity and scalability issues may limit its accessibility and applicability to large datasets.",
      "strengths": [
        "Innovative use of differential geometry to learn cycle-consistent and metric-preserving mappings.",
        "Robust performance across a range of tasks, including single-task learning, multi-task learning, and knowledge distillation.",
        "Clear theoretical foundation with rigorous mathematical derivations."
      ],
      "weaknesses": [
        "Complexity of implementation due to reliance on advanced differential geometry concepts.",
        "Potential scalability issues with very large datasets or high-dimensional spaces.",
        "Lack of extensive hyperparameter tuning, which may affect reproducibility and generalization."
      ],
      "questions": [
        "How can the implementation of GATE be made more accessible to practitioners without a strong mathematical background?",
        "What strategies can be employed to improve the scalability of GATE for very large datasets?",
        "Could additional hyperparameter tuning studies enhance the reproducibility and generalization of GATE across different domains?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3ZDEwhAlCO",
    "title": "ILPO-NET: convolution network for the recognition of arbitrary volumetric patterns",
    "std_review": {
      "summary": "ILPO-Net introduces a novel 3D equivariant convolution method using spherical harmonics combined with orientational pooling. It addresses limitations of existing spherical-harmonic and group-convolution techniques by providing a more efficient and flexible framework for handling arbitrary volumetric patterns while maintaining parameter efficiency. Experimental results on synthetic and real-world datasets demonstrate competitive performance, highlighting the method's ability to capture complex spatial and orientational features. The paper is well-structured, with clear contributions, thorough experiments, and a strong motivation for addressing current challenges in 3D equivariant processing.",
      "strengths": [
        "Novel integration of spherical harmonics and pooling for 3D equivariant convolution.",
        "Parameter-efficient design that reduces computational overhead compared to traditional methods.",
        "Demonstrated flexibility in handling a wide range of volumetric patterns across synthetic and real-world datasets.",
        "Clear experimental validation with thorough comparisons to state-of-the-art methods."
      ],
      "weaknesses": [
        "Implementation complexity due to the integration of spherical harmonics and pooling.",
        "Limited scope of real-world datasets used for evaluation.",
        "Lack of detailed theoretical analysis for the pooling mechanism."
      ],
      "questions": [
        "How does the method scale to very large or highly complex volumetric patterns?",
        "What is the computational cost of the spherical harmonic representation and pooling step compared to other 3D convolution approaches?",
        "Could the pooling mechanism be generalized to other types of data beyond volumetric patterns?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3zKtaqxLhW",
    "title": "Generalized Knowledge Distillation for Auto-regressive Language Models",
    "std_review": {
      "summary": "The paper introduces Generative Knowledge Distillation (GKD), a method that uses a student model to generate synthetic training data for a teacher model, improving distilled model quality. Evaluated across summarization, translation, and reasoning tasks with models of varying sizes, GKD consistently outperforms self-distillation, especially on tasks requiring high diversity, while maintaining competitive accuracy. Despite its innovative approach and strong empirical results, the method introduces complexity, hyperparameter sensitivity, and potential computational overhead.",
      "strengths": [
        "Introduces a generative mechanism to enhance knowledge distillation, offering a fresh perspective.",
        "Promotes a richer set of examples by allowing the student to generate data, potentially improving the teacher's ability to capture diverse knowledge.",
        "Demonstrates significant improvements over self-distillation across multiple tasks and model sizes, highlighting practical benefits.",
        "Provides a clear theoretical rationale for why generating diverse student outputs can lead to better knowledge transfer."
      ],
      "weaknesses": [
        "The additional step of generating and using student data introduces complexity in implementation and training.",
        "Performance is sensitive to the choice of divergence and teacher temperature, requiring careful tuning.",
        "The need to sample from the student distribution may increase computational costs, particularly for large models.",
        "Lack of robustness analysis to adversarial attacks or other perturbations."
      ],
      "questions": [
        "How robust are the distilled models to adversarial attacks or other perturbations?",
        "What is the impact of different divergence measures beyond the reverse KL on performance and diversity?",
        "How can the computational overhead of GKD be mitigated for large-scale applications?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3ZqKxMHcAg",
    "title": "Evaluating Language Model Agency through Negotiations",
    "std_review": {
      "summary": "The paper introduces a novel framework to evaluate Theory of Mind (ToM) in large language models (LLMs) through structured negotiation tasks. It defines ToM as the ability to predict and adapt to an opponent's preferences and proposes an external faithfulness metric to assess this capability. The study compares models initialized as 'average,' 'expert,' and 'novice' across various negotiation games, revealing distinct behavioral patterns linked to initial skill levels. The experimental setup is robust, but the paper could benefit from addressing ambiguities in scoring and comparing its methodology with prior work.",
      "strengths": [
        "Clear definition of ToM in the context of negotiation.",
        "Innovative faithfulness metric for measuring ToM in LLMs.",
        "Diverse model comparisons across different skill levels.",
        "Robust experimental framework with well-defined rules."
      ],
      "weaknesses": [
        "Utility function may oversimplify negotiation scenarios.",
        "Fixed prompt design could limit exploration of diverse negotiation styles.",
        "Ambiguity in cross-play scoring computation.",
        "Lack of comparative analysis with prior work."
      ],
      "questions": [
        "How does the utility function impact the evaluation of negotiation outcomes?",
        "Could varying prompts across negotiations reveal additional negotiation styles?",
        "What are the implications of cross-play scoring ambiguity on the interpretation of results?",
        "How does the proposed methodology compare to existing approaches in evaluating LLM social intelligence?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3zQo5oUvia",
    "title": "Retrieval-Based Reconstruction For",
    "std_review": {
      "summary": "The paper introduces REBAR, a method for motif comparison in time series using a convolutional cross-attention mechanism with an intermittent mask during evaluation. It shows strong performance on various datasets, outperforming existing methods in noisy data reconstruction. However, it lacks comprehensive ablation studies, detailed hyperparameter tuning, and visualizations, and the rationale for mask usage is not fully explained.",
      "strengths": [
        "Introduces a unique intermittent mask strategy for motif comparison.",
        "Leverages convolutional cross-attention to efficiently compare motifs.",
        "Demonstrates strong performance across diverse datasets."
      ],
      "weaknesses": [
        "Lacks comprehensive ablation studies to assess component contributions.",
        "Does not thoroughly discuss hyperparameter tuning.",
        "Few visualizations provided to illustrate learned embeddings.",
        "Rationale for using different masks for training and evaluation is unclear.",
        "Performance evaluated on specific datasets, not diverse characteristics."
      ],
      "questions": [
        "Could you provide more detailed ablation studies to isolate the impact of each component?",
        "Please elaborate on the hyperparameter tuning process, including mask size and receptive field.",
        "Additional visualizations, such as t-SNE plots, would help illustrate learned embeddings.",
        "What is the rationale behind using different masks for training and evaluation?",
        "How does REBAR perform on time series with varying lengths, noise levels, or other characteristics?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "3zvB14IF6D",
    "title": "DORSal: Diffusion for Object-centric Representations of Scenes _et al._",
    "std_review": {
      "summary": "DORSal presents a novel framework for 3D scene generation and editing using object slots and a multi-view diffusion decoder. It achieves high-quality 3D reconstructions and supports flexible editing with minimal supervision. While promising, the approach relies on pre-trained encoders and introduces training complexity. Overall, it is a strong contribution with practical applications.",
      "strengths": [
        "Introduces a novel object slot representation for structured scene understanding.",
        "Enables efficient 3D scene editing with minimal supervision.",
        "Maintains 3D consistency across multiple views.",
        "Designed to be scalable for future extensions."
      ],
      "weaknesses": [
        "Relies on pre-trained encoders which may limit performance on unseen scenes.",
        "Joint training of encoder and decoder adds complexity and computational cost.",
        "Limited to basic editing operations like removal and transfer.",
        "Potential for artifacts in complex scenes."
      ],
      "questions": [
        "How robust is the framework to variations in scene complexity and object occlusions?",
        "What are the specific strategies for extending the editing capabilities beyond removal and transfer?",
        "How does the framework handle fine-grained details in object slots compared to slots learned jointly with the decoder?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "3ZWdgOvmAA",
    "title": "LumiNet: The Bright Side of Perceptual Knowledge Distillation",
    "std_review": {
      "summary": "LumiNet introduces a perception matrix to enhance knowledge distillation by capturing inter-instance relationships more effectively than traditional methods. The approach recalibrates instance-level logits, preserving nuanced interactions overlooked by standard KD techniques. Empirical evaluations show significant improvements over both feature-based and logit-based KD methods, especially in tasks requiring precise inter-class and inter-instance modeling. Overall, LumiNet is a strong contribution to the field.",
      "strengths": [
        "Introduces a perception matrix that explicitly models inter-instance relationships.",
        "Improves logit calibration, addressing limitations of traditional KD methods.",
        "Demonstrates robust performance across heterogeneous architectures.",
        "Provides clear empirical justification for its effectiveness."
      ],
      "weaknesses": [
        "Adds complexity to the KD pipeline, potentially requiring more computational resources.",
        "Limited diversity in benchmark datasets could affect generalizability.",
        "Risk of overfitting due to additional parameters, mitigated by regularization."
      ],
      "questions": [
        "How does the perception matrix scale with very large datasets or models?",
        "Can the approach be adapted for real-time applications with limited computational resources?",
        "What is the impact of the perception matrix on model interpretability?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "41CYtxM2jQ",
    "title": "Boosting Fast and High-Quality Speech Synthesis with Linear Diffusion",
    "std_review": {
      "summary": "The paper presents a waveform generation framework that combines a Transformer-based architecture with a diffusion model for high-quality speech synthesis. It leverages continuous time steps during training and a single diffusion step for inference, balancing quality and efficiency. Experiments show competitive results against state-of-the-art methods on LibriTTS, particularly in MCD and F0 correlation. While promising, the framework's generalization potential and the impact of its design choices are not fully explored.",
      "strengths": [
        "Innovative integration of Transformers with diffusion models for improved synthesis quality.",
        "Efficient inference using a single diffusion step, balancing quality and speed.",
        "Strong performance on LibriTTS, especially in objective metrics like MCD and F0 correlation."
      ],
      "weaknesses": [
        "Limited analysis of continuous time step training effects.",
        "No thorough comparison of the necessity and impact of the Transformer backbone.",
        "Single diffusion step performance not fully evaluated with subjective metrics.",
        "Generalization to other tasks lacks extensive evaluation.",
        "Missing detailed ablations on patch size and inference speed trade-offs."
      ],
      "questions": [
        "How do continuous time step training effects compare to discrete step training?",
        "What is the necessity and impact of the Transformer backbone compared to other architectures?",
        "How does the single diffusion step perform subjectively (e.g., MOS) versus other methods?",
        "What is the framework's ability to generalize beyond vocoder tasks, such as in text-to-speech synthesis?",
        "What are the trade-offs between patch size, inference speed, and synthesis quality, especially for larger datasets?"
      ],
      "overall_score": "6: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "42lcaojZug",
    "title": "Neural Rate Control for Learned Video Compression",
    "std_review": {
      "summary": "The paper presents a novel two-stage learned video compression framework that separates rate allocation and implementation, using a hyperbolic R-λ model for allocation and a learned transformation for implementation. Experiments show significant RD improvements over existing learned methods and competitive results against traditional coders across multiple datasets. The approach is innovative, achieving state-of-the-art performance with a fully differentiable pipeline, though it introduces complexity and may benefit from additional ablation studies and out-of-domain evaluations.",
      "strengths": [
        "Innovative two-stage training for rate control",
        "Effective use of a hyperbolic R-λ model for non-linear rate-distortion trade-offs",
        "End-to-end learned approach with strong empirical results"
      ],
      "weaknesses": [
        "Increased training complexity and hyperparameter tuning requirements",
        "Potential lack of generalization to all content types and resolutions without further validation",
        "Absence of ablation studies to isolate component contributions"
      ],
      "questions": [
        "How does the method perform on very high-resolution or high-frame-rate content?",
        "What is the impact of the hyperbolic model on computational efficiency during inference?",
        "Could the two-stage training be optimized to reduce computational overhead?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "43cYe4oogi",
    "title": "Understanding Expressivity of Neural KG Reasoning from Rule Structure Learning",
    "std_review": {
      "summary": "The paper presents a novel rule-based formalism for knowledge graphs that integrates structural rules with graph neural networks, aiming to enhance expressivity while maintaining scalability. It introduces two models, QL‑GNN and EL‑GNN, and demonstrates their effectiveness on benchmark datasets, showing improved performance over existing methods. However, the paper has some clarity issues, such as a late definition of expressivity and opaque theoretical explanations, which could be addressed to strengthen its impact.",
      "strengths": [
        "Innovative rule-based formalism that bridges expressivity and scalability.",
        "Solid theoretical foundation with Theorem 4.4 explaining learnability limitations.",
        "Empirical validation on real-world datasets showing clear performance gains."
      ],
      "weaknesses": [
        "Definition of expressivity introduced late, potentially confusing readers.",
        "Lacks clear examples of how the formalism translates to real-world data.",
        "Theoretical explanation of Theorem 4.4 is somewhat opaque.",
        "Does not fully address computational constraints for large-scale graphs."
      ],
      "questions": [
        "How should expressivity be defined earlier in the paper to improve clarity?",
        "Could more concrete examples from real datasets better illustrate the practical relevance of the rule structures?",
        "What additional details can be provided in the explanation of Theorem 4.4 to clarify why certain rules cannot be learned?",
        "What strategies can be discussed to mitigate computational challenges when applying the models to very large graphs?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "43flsheS4s",
    "title": "Improving Robustness and Accuracy with Retrospective Online Adversarial Distillation",
    "std_review": {
      "summary": "The paper presents Retrospective Online Adversarial Distillation (ROAD), a method that enhances adversarial robustness and natural accuracy of deep neural networks using soft labels and asymmetric knowledge transfer during online distillation. ROAD shows significant improvements over baselines in both robustness and accuracy, supported by thorough ablation studies. However, it has higher computational costs and lacks evaluation of stability and generalization across seeds. The novelty of ROAD is not fully established compared to existing methods.",
      "strengths": [
        "Introduces a novel approach to adversarial distillation using soft labels and asymmetric knowledge transfer.",
        "Demonstrates significant improvements in both adversarial robustness and natural accuracy.",
        "Provides comprehensive ablation studies and experiments to validate the impact of individual components."
      ],
      "weaknesses": [
        "Higher computational costs and memory requirements compared to other methods.",
        "Stability and generalization across different random seeds and training runs are not thoroughly evaluated.",
        "Novelty of ROAD compared to other adversarial distillation methods is not clearly established."
      ],
      "questions": [
        "How does ROAD's performance compare across different random seeds and training runs?",
        "What is the practical impact of ROAD's computational costs relative to its performance gains?",
        "How does ROAD's novelty compare to other adversarial distillation methods in terms of practical applicability?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "43WKxTuJxu",
    "title": "Orthogonal Function Representations for Continuous Armed Bandits",
    "std_review": {
      "summary": "The paper introduces a novel algorithm for handling high-dimensional state spaces in reinforcement learning by leveraging a smoothness assumption on the reward function. It proposes a parameter N to control state space discretization, enabling efficient exploration and learning. Empirical results show improved performance over existing methods, indicating practical utility. However, the algorithm's reliance on an unknown smoothness parameter and the need for empirical tuning of N introduce complexity and limit reproducibility. Theoretical guarantees are contingent on the empirical choice of N, raising concerns about robustness.",
      "strengths": [
        "Novel algorithm leveraging a smoothness assumption for high-dimensional state spaces.",
        "Parameter N provides a clear mechanism for balancing exploration and computational efficiency.",
        "Empirical validation demonstrates improved performance over existing methods."
      ],
      "weaknesses": [
        "Complexity introduced by the unknown smoothness parameter s.",
        "Empirical tuning required to determine optimal N, impacting accessibility and reproducibility.",
        "Theoretical regret guarantee is contingent on the empirical choice of N, raising concerns about robustness."
      ],
      "questions": [
        "How can the algorithm be adapted to scenarios where the true smoothness s of the reward function is unknown?",
        "What are the theoretical guarantees when the optimal N is not known a priori?",
        "How does the algorithm perform when the number of inputs required becomes prohibitively large?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "468KWV14ll",
    "title": "Exploration and Anti-Exploration with Distributional Random Network Distillation",
    "std_review": {
      "summary": "The paper introduces SAC‑RND, a method that combines Random Network Distillation (RND) with Soft Actor-Critic (SAC) to improve offline reinforcement learning. It proposes using RND to generate intrinsic rewards that encourage exploration in environments with only past experience. Empirical results on MuJoCo tasks show competitive performance compared to online baselines, though challenges remain in optimizing the intrinsic reward and understanding the impact of hyperparameters.",
      "strengths": [
        "Innovative integration of RND with SAC for offline RL.",
        "Effective exploration through intrinsic rewards.",
        "Strong empirical evidence on MuJoCo tasks."
      ],
      "weaknesses": [
        "Low performance in some experiments compared to online baselines.",
        "Lack of backpropagation from intrinsic reward.",
        "Unclear definition of the desired distribution."
      ],
      "questions": [
        "How can the intrinsic reward be optimized without direct backpropagation?",
        "What is the desired distribution guided by the intrinsic reward?",
        "How does SAC‑RND scale with different offline datasets?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "47hDbAMLbc",
    "title": "",
    "std_review": {
      "summary": "The paper investigates the theoretical limits of robust memorization in ReLU networks, proving that constructing such networks with provable robustness is NP-hard under certain conditions. It introduces a novel construction of ReLU networks that can memorize a large number of examples while maintaining robustness, extending prior work. The authors demonstrate significant implications for designing neural networks with both memorization and adversarial robustness, though practical implementation challenges remain.",
      "strengths": [
        "Provides rigorous theoretical analysis of robust memorization complexity, establishing NP-hardness results.",
        "Introduces a concrete construction of ReLU networks achieving robust memorization, offering a new perspective on network design.",
        "Delivers detailed and well-structured proofs addressing the challenges of proving NP-hardness in this context."
      ],
      "weaknesses": [
        "Does not extensively address practical optimization challenges for such networks.",
        "Results are limited to specific conditions and do not fully explore generalization to unseen data.",
        "The defined robust budget may limit applicability to real-world scenarios with more flexible robustness requirements."
      ],
      "questions": [
        "How can the optimization challenges of implementing these robust networks be addressed in practice?",
        "What are the generalization capabilities of the constructed networks on unseen data?",
        "How can the robust budget be adapted to accommodate more flexible robustness requirements in real-world applications?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "488A64eOf6",
    "title": "Language Model Decoding as Direct Metrics Optimization",
    "std_review": {
      "summary": "The paper presents a novel decoding framework that simultaneously optimizes multiple human‑evaluated quality aspects of generated text using a multi‑objective loss function. Experiments show significant improvements over traditional methods across several benchmarks, demonstrating the framework's effectiveness in producing high‑quality, diverse, and coherent outputs. While the approach is theoretically sound and empirically validated, it introduces computational complexity and requires careful hyperparameter tuning. The authors also discuss potential extensions to other NLP tasks, though the evaluation is primarily focused on open‑ended text generation.",
      "strengths": [
        "Unified Multi‑Objective Optimization: Effectively integrates multiple quality metrics into a single decoding objective.",
        "Theoretical Foundation: Provides a solid theoretical basis for the proposed approach.",
        "Empirical Validation: Demonstrates clear improvements over baseline methods across various benchmarks."
      ],
      "weaknesses": [
        "Computational Complexity: Introduces significant computational overhead due to candidate sampling.",
        "Parameter Sensitivity: Performance is highly sensitive to hyperparameter choices.",
        "Limited Theoretical Guarantees: Lacks rigorous theoretical guarantees for convergence and optimality."
      ],
      "questions": [
        "How can the computational complexity be mitigated for practical deployment?",
        "What are the theoretical conditions under which the proposed multi‑objective loss function converges?",
        "How can the framework be adapted for other NLP tasks beyond open‑ended text generation?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "48CXLrx7K3",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a method for reconstructing face images from embeddings while preserving privacy, using different face attribute encoders and embedding techniques. It evaluates reconstruction quality and privacy, but lacks detailed explanations of privacy leakage, method comparisons, and a thorough ablation study. The reviewer finds the method novel but recommends weak acceptance due to these gaps.",
      "strengths": [
        "Proposes a novel approach to reconstruct face images from embeddings while ensuring privacy.",
        "Improves reconstruction quality by using different face attribute encoders and embedding techniques.",
        "Provides quantitative evaluation of reconstruction quality using similarity scores."
      ],
      "weaknesses": [
        "Does not clearly explain how private information is leaked in the reconstructed images.",
        "Lacks detailed comparisons of different face attribute encoder and embedding methods.",
        "Does not provide a comprehensive ablation study to justify loss function choices.",
        "Fails to analyze the trade-off between image quality and privacy."
      ],
      "questions": [
        "How exactly is private information leaked in the reconstructed face images?",
        "What are the detailed performance comparisons between different face attribute encoder methods?",
        "Could you provide a more thorough ablation study to justify the choice of loss functions for each block in StyleGAN?",
        "What is the trade-off between the quality of the reconstructed image and the level of privacy maintained?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "49Tn5mfTy5",
    "title": "Uncertainty Quantification",
    "std_review": {
      "summary": "The paper introduces UA-IB, a method that integrates uncertainty estimation directly into deep learning models, improving robustness and performance. It is theoretically grounded in information theory and demonstrates strong empirical results across various datasets. While computationally efficient, the method's hyperparameter sensitivity and lack of detailed high-dimensional experiments are noted. Overall, UA-IB is a valuable contribution to uncertainty quantification.",
      "strengths": [
        "Integrates uncertainty estimation directly into the learning process.",
        "Theoretically grounded in information theory.",
        "Demonstrates strong empirical performance across datasets.",
        "Computationally efficient for large-scale applications."
      ],
      "weaknesses": [
        "Hyperparameter selection, especially codebook size, can significantly affect performance.",
        "Lacks detailed experimental results on high-dimensional tasks.",
        "Integration with existing frameworks is not fully explored."
      ],
      "questions": [
        "Can UA-IB be integrated with trained models without retraining?",
        "How does UA-IB perform on high-dimensional image or language tasks?",
        "What are the detailed computational requirements for very large datasets?"
      ],
      "overall_score": "Accept",
      "confidence": "High"
    }
  },
  {
    "paper_id": "49z97Y9lMq",
    "title": "LCOT: Linear circular optimal transport",
    "std_review": {
      "summary": "The paper introduces LCOT, a novel extension of Optimal Transport to circular data, providing a solid theoretical foundation and clear mathematical definitions. While it demonstrates effectiveness on synthetic data, it lacks detailed algorithms, real-world experiments, and a comprehensive related work section. The proposed method shows promise for applications in domains dealing with circular data, but the current manuscript does not fully validate its practical utility.",
      "strengths": [
        "Innovative generalization of Optimal Transport to circular data.",
        "Strong theoretical foundation with clear definitions and equivalence to classical Optimal Transport under certain conditions.",
        "Potential for real-world applications in fields like image retrieval and color interpolation."
      ],
      "weaknesses": [
        "Missing detailed algorithm for computing the LCOT barycenter.",
        "Unclear experimental units in presented results.",
        "Absence of real-world benchmarks weakens practical applicability.",
        "Incomplete related work section lacking key references.",
        "Minor typographical errors that could be corrected for clarity."
      ],
      "questions": [
        "Could the authors provide a more intuitive explanation of the LCOT definition and its extension from classical OT?",
        "Should the equivalence between the LCOT and COT barycenters be formally proven, especially in the special case where LCOT recovers COT?",
        "What steps are required to compute the LCOT barycenter from the closed-form solution, and how can this be made more explicit?",
        "Could the unit of computation time in Figure 4 be clarified to improve interpretability?",
        "What potential real-world applications of LCOT exist, and how could experiments be designed to validate its effectiveness?",
        "Should the reference to 'The Statistics of Circular Optimal Transport' by Hundrieser et al., 2022, be included in the bibliography?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "49ZYkhEGmv",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a doubly‑efficient debate model for overseeing large language models (LLMs) by imposing polynomial‑time constraints on the proving model. This approach enhances scalability and maintains soundness and completeness, while using a constant number of human‑oracle queries. Despite its strengths, the model's practical implementation and oracle reliability pose challenges, leading to a weak accept recommendation.",
      "strengths": [
        "Efficiency and scalability through polynomial‑time proving model.",
        "Constant human‑oracle queries reduce overhead and maintain consistency.",
        "Formal guarantees of soundness and completeness."
      ],
      "weaknesses": [
        "Assumption of polynomial efficiency may be too restrictive for some LLMs.",
        "Reliance on a single unbiased human oracle.",
        "Complexity of setting up a robust reinforcement‑learning loop."
      ],
      "questions": [
        "How can the model be adapted for scenarios with limited or noisy human feedback?",
        "What are the scalability limits when dealing with highly complex or large‑scale problems?",
        "How does the model handle potential cascading failures due to subtle oracle biases?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "4A5D1nsdtj",
    "title": "An Effective Universal Polynomial Basis for Spectral Graph Neural Networks",
    "std_review": {
      "summary": "The paper introduces UniBasis, a polynomial basis aligned with a graph's homophily ratio, and proposes UniFilter to handle both homophilous and heterophilous graphs. Theoretical contributions include spectral frequency alignment and analysis of the basis and filter. Empirical results show strong performance across diverse datasets, though practical implications and limitations are not fully explored. The review recommends acceptance with high confidence.",
      "strengths": [
        "Introduces a novel polynomial basis (UniBasis) aligned with graph homophily ratios.",
        "Proposes UniFilter that effectively handles diverse graph structures.",
        "Provides strong theoretical contributions on spectral frequency alignment."
      ],
      "weaknesses": [
        "Lacks comprehensive comparison with state-of-the-art models.",
        "Evaluation could benefit from more detailed analysis and ablation studies.",
        "Practical implications and limitations of estimated homophily ratios are underexplored."
      ],
      "questions": [
        "How does the method perform on real-world large-scale graph datasets with incomplete node labels?",
        "What is the impact of noisy or missing label information on the UniFilter's performance?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "4aJg9e4nvF",
    "title": "",
    "std_review": {
      "summary": "The paper introduces an optimization‑based feature visualization method for Vision Transformers, demonstrating that ViTs preserve spatial information better than CNNs and that the CLS token plays a crucial role in final‑layer performance. While novel and insightful, the method has limited visualization of internal components and could benefit from deeper analysis of its limitations and broader comparisons.",
      "strengths": [
        "Introduces a novel optimization‑based feature visualization technique for ViTs.",
        "Provides strong theoretical and empirical evidence of ViT advantages in spatial information preservation.",
        "Highlights the significant impact of the CLS token on model performance."
      ],
      "weaknesses": [
        "Visualization of keys, queries, and values is limited.",
        "Lacks detailed discussion of method limitations compared to other techniques.",
        "Comparison with CNNs is superficial, lacking in-depth architectural analysis."
      ],
      "questions": [
        "How can the visualization method be extended to better interpret keys, queries, and values?",
        "What are the broader implications of the CLS token's role across different ViT architectures?",
        "How robust are the findings when tested on a wider range of datasets and transformer variants?"
      ],
      "overall_score": "6: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "4Ay23yeuz0",
    "title": "Mixed-Type Tabular Data Synthesis with Score-based Diffusion in Latent Space",
    "std_review": {
      "summary": "The paper presents a novel latent diffusion model for generating synthetic tabular data, addressing mixed data types through a VAE-diffusion framework. It demonstrates superior performance in quality metrics and privacy preservation compared to existing methods, though implementation complexity and limited dataset evaluation are noted. Overall, the work is innovative and valuable, warranting acceptance.",
      "strengths": [
        "Innovative combination of VAE and diffusion models for mixed-type tabular data synthesis.",
        "Comprehensive evaluation using multiple quality metrics and privacy scores.",
        "Outperforms state-of-the-art methods in both data quality and computational efficiency."
      ],
      "weaknesses": [
        "Implementation complexity due to the integration of VAE and diffusion models.",
        "Potential sensitivity to hyperparameter choices affecting model performance.",
        "Limited evaluation on diverse datasets may not fully capture model capabilities."
      ],
      "questions": [
        "How can the model's performance be further validated on a broader range of tabular datasets?",
        "What strategies can be employed to reduce the computational complexity of training the combined VAE-diffusion model?",
        "How does the model handle edge cases or highly imbalanced datasets?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "4aywmeb97I",
    "title": "Tackling the Data Heterogeneity in Asynchronous Federated Learning with Cached Update Calibration",
    "std_review": {
      "summary": "The paper introduces CA2FL, a caching-assisted asynchronous federated learning method that improves efficiency and scalability across diverse architectures. It demonstrates significant convergence speed and resource utilization gains on CIFAR-10/100 and ResNet-18, with a memory-efficient 4/8-bit quantization variant. While promising, the method's scalability, handling of practical constraints, and long-term adaptation are not fully explored.",
      "strengths": [
        "Innovative two-stage caching mechanism that dynamically selects model parameters based on their impact on global performance.",
        "Demonstrated broad applicability across various neural network architectures and datasets.",
        "Memory-efficient quantization reduces computational demands on resource-constrained devices."
      ],
      "weaknesses": [
        "Limited scalability testing on complex models like Vision Transformers and larger datasets like ImageNet.",
        "Insufficient discussion on handling practical constraints such as varying data quality and computational overhead.",
        "Lack of analysis on adapting to long-term data shifts or concept drift.",
        "Potential trade-offs between memory overhead reduction and computational complexity."
      ],
      "questions": [
        "How does CA2FL perform on more complex models and larger datasets beyond CIFAR-10/100 and ResNet-18?",
        "What mechanisms does CA2FL employ to address varying data quality and computational overhead compared to traditional FL frameworks?",
        "How does the method adapt to long-term data shifts or concept drift in dynamic environments?",
        "What is the detailed impact of 4/8-bit quantization on convergence rate and model accuracy, especially on resource-constrained devices?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "4bat0pSQBq",
    "title": "Flood Simulation with Physics-Informed Message Passing",
    "std_review": {
      "summary": "The paper presents a physics‑informed graph neural network (GNN) for simulating flood dynamics, using a two‑stage message‑passing framework to capture water retention and dispersion. It outperforms traditional ML baselines and matches a state‑of‑the‑art physics solver, showing strong theoretical backing and practical benefits. However, the static graph representation limits its handling of dynamic topographies, and the limited baseline comparison may not fully capture its advantages.",
      "strengths": [
        "Physics‑guided design that directly encodes conservation laws into the model.",
        "Two‑stage architecture effectively separates water retention and dispersion.",
        "Clear theoretical foundation linking GNN layers to shallow‑water equations."
      ],
      "weaknesses": [
        "Relies on a static graph derived from a digital elevation model, limiting adaptability to dynamic scenarios.",
        "Limited comparison with other baselines may not fully demonstrate the model's superiority.",
        "Absence of dynamic graph updates could be crucial for certain flood events."
      ],
      "questions": [
        "How does the model perform on real‑world flood datasets with varying topography and dynamic conditions?",
        "What is the impact of the static graph assumption on scalability for large‑scale applications?",
        "Could dynamic edge creation or removal improve performance in evolving flood scenarios?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "4bLXfRd0CX",
    "title": "EMO: Earth Mover Distance Optimization for Auto-regressive Language Modeling",
    "std_review": {
      "summary": "The paper introduces EMO, a novel approach to language modeling that simultaneously maximizes diversity and quality by incorporating Earth Mover's Distance into the training objective. Empirical evaluations show significant improvements in diversity metrics without sacrificing quality, and the theoretical framework is well-motivated. While some practical and theoretical limitations are noted, the work is a strong candidate for acceptance.",
      "strengths": [
        "Introduces a novel objective that explicitly encourages diversity alongside quality.",
        "Provides a clear theoretical motivation using Earth Mover's Distance.",
        "Demonstrates significant improvements in diversity metrics with competitive quality."
      ],
      "weaknesses": [
        "Empirical evidence for convergence properties and robustness is limited.",
        "Computational cost may be high due to Earth Mover's Distance calculations.",
        "Choice of cosine similarity as transport cost may not be optimal for all data distributions."
      ],
      "questions": [
        "How does EMO perform on real-world benchmarks beyond synthetic datasets?",
        "What are the convergence properties of EMO in practice, especially with large models?",
        "How does the choice of similarity metric affect performance in different application contexts?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "4bSQ3lsfEV",
    "title": "",
    "std_review": {
      "summary": "The paper proposes an Iterative Feature Magnitude (IFM) pruning method for neural networks, aiming to improve model compression by iteratively pruning features based on their magnitude. The method is evaluated on several benchmark datasets and shows competitive performance compared to existing techniques. While the authors discuss the sensitivity to the hyperparameter β and explore the relationship between feature complexity and generalization, the paper lacks detailed ablation studies and a thorough comparison with other pruning methods.",
      "strengths": [
        "Introduces a novel iterative pruning approach based on feature magnitude.",
        "Demonstrates competitive performance on benchmark datasets.",
        "Explores the relationship between feature complexity and generalization."
      ],
      "weaknesses": [
        "Lacks detailed ablation studies on hyperparameter sensitivity.",
        "Insufficient exploration of feature complexity and generalization trade-offs.",
        "Comparison with other pruning techniques is superficial."
      ],
      "questions": [
        "Should the authors provide ablation studies to illustrate the impact of different β values on performance?",
        "How can the relationship between feature complexity and generalization be more thoroughly explored?",
        "What additional comparisons with other pruning techniques are needed to highlight the IFM method's advantages and disadvantages?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "4DoSULcfG6",
    "title": "Chameleon: Increasing Label-Only Membership Leakage with Adaptive Poisoning",
    "std_review": {
      "summary": "The Chameleon attack introduces a dynamic shadow model approach to membership inference, achieving high true positive rates with low false positives. While demonstrating strong empirical performance on CIFAR-100 and VGG-16, concerns about empirical validation, overfitting, theoretical assumptions, and lack of robustness evaluation limit its acceptance.",
      "strengths": [
        "Innovative dynamic shadow model approach that improves attack efficiency and accuracy.",
        "Strong empirical performance with high true positive rates and low false positives compared to existing methods.",
        "Clear theoretical framework and evaluation on benchmark datasets."
      ],
      "weaknesses": [
        "Empirical validation of false positives is limited to specific observations rather than theoretical guarantees.",
        "Concerns about overfitting when increasing training epochs for larger models.",
        "Theoretical analysis relies on assumptions about posterior distributions and poisoning impacts.",
        "Lack of evaluation against simpler defenses like regularization or gradient clipping.",
        "Absence of detailed reproducibility data for training and test accuracies."
      ],
      "questions": [
        "How robust is the Chameleon attack against simpler defenses such as regularization or per-example gradient clipping?",
        "What is the impact of overfitting when increasing training epochs for larger models like VGG-16?",
        "Can the theoretical assumptions about the posterior distribution and poisoning be validated in practice?",
        "How can the reproducibility of the reported results be improved by providing exact training and test accuracies?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "4e0ItHjNo9",
    "title": "Rethinking Counterfactual Fairness:",
    "std_review": {
      "summary": "The paper introduces Protected Class Fairness (PCF), an extension of conventional fairness that incorporates protected attributes into the fairness definition. It proposes a method to ensure that protected attributes do not causally affect outcomes, addressing fairness concerns in contexts where protected attributes have a causal impact. The authors demonstrate PCF through theoretical analysis and a case study of university admissions with athletic scholarships. While the framework is theoretically sound and provides a clear extension of fairness definitions, it lacks clarity in handling situations where protected attributes do have causal effects on outcomes, and the motivating example is confusing. The paper also assumes that fairness researchers should define protected attributes, a view not widely shared in the field.",
      "strengths": [
        "Clear extension of fairness definitions",
        "Solid theoretical foundation with well-grounded assumptions",
        "Practical motivation through a relevant case study"
      ],
      "weaknesses": [
        "Unclear handling of causal effects when protected attributes impact outcomes",
        "Assumes CF defines protected attributes, not a widely accepted view",
        "Confusing motivating example; lacks a clearer real-life illustration",
        "Relies on potentially unrealistic assumptions like ignorability"
      ],
      "questions": [
        "How should the method address cases where protected attributes causally affect outcomes?",
        "Why should CF define which attributes are protected, given differing views in the field?",
        "Could a more detailed real-life example clarify why PCF is superior to CF in the admissions case?",
        "How realistic are the assumptions (e.g., ignorability) in typical fairness applications?"
      ],
      "overall_score": "4: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "4eJDMjYZZG",
    "title": "Language Model Detectors Are Easily Optimized Against",
    "std_review": {
      "summary": "The paper introduces a fine-tuning method that significantly improves the ability of language models to evade detection by existing content filters, while only slightly degrading text quality. It demonstrates scalability across different model sizes and includes extensive evaluations across multiple detectors. However, the technique's generalizability to other detection systems is limited, and there are concerns about potential overfitting and the lack of detailed data descriptions. The absence of countermeasures or defense strategies is also noted.",
      "strengths": [
        "Effective evasion technique that significantly improves undetectability.",
        "Demonstrates scalability with model size while maintaining effectiveness.",
        "Minimal impact on text quality, preserving original model performance."
      ],
      "weaknesses": [
        "Limited generalization to other detection systems.",
        "Potential for overfitting due to fine-tuning on detection data.",
        "Lack of detailed information on training and evaluation datasets.",
        "Absence of countermeasures or defense strategies."
      ],
      "questions": [
        "How does the evasion technique generalize to detectors beyond those evaluated?",
        "What are the detailed characteristics of the training and evaluation datasets?",
        "Are there any countermeasures or defense strategies proposed to mitigate the described evasion?",
        "How does the technique perform with larger model sizes beyond those tested?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "4fbFKO4a2W",
    "title": "Guided Sketch-Based Program Induction",
    "std_review": {
      "summary": "The paper introduces a novel approach to program synthesis using Natural Evolution Strategies (NES) to fill in program sketches, demonstrating efficiency and potential for neural-guided search extensions. While the method shows promise, its evaluation is limited to toy examples, and it lacks comprehensive comparison with other state-of-the-art methods. The authors distinguish between program induction and synthesis, highlighting the method's focus on generating exact solutions. Overall, the paper is promising but requires further evaluation and comparison.",
      "strengths": [
        "Introduces NES for program synthesis, offering a novel and efficient optimization strategy.",
        "Demonstrates significant efficiency gains over baseline approaches in terms of explored programs and search time.",
        "Explores the potential for extending the algorithm to neural-guided search strategies."
      ],
      "weaknesses": [
        "Evaluation is limited to two toy examples, which may not reflect real-world performance.",
        "Lacks comprehensive comparison with other state-of-the-art methods.",
        "Extension to neural-guided search strategies is discussed but not fully explored."
      ],
      "questions": [
        "How does the method perform on larger, more realistic program synthesis tasks?",
        "What are the theoretical underpinnings and limitations of the NES approach?",
        "How feasible and beneficial is the integration of neural-guided search strategies?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "4FUa5dxiiA",
    "title": "Risk-Sensitive Variational Model-Based Policy Optimization",
    "std_review": {
      "summary": "The paper introduces β‑VMBPO, a risk-sensitive reinforcement learning algorithm that extends VMBPO by incorporating a risk parameter β into the variational lower bound. This allows explicit control over risk-seeking behavior, improving robustness and performance across various environments. Theoretical foundations and empirical results strongly support the method's effectiveness, though implementation complexity and computational overhead are notable challenges.",
      "strengths": [
        "Innovative risk control through a risk parameter in the variational lower bound.",
        "Probabilistic modeling of dynamics enhances robustness by capturing uncertainty.",
        "Strong theoretical justification linking risk parameter to risk-sensitive utility functions."
      ],
      "weaknesses": [
        "Increased implementation complexity due to learning two models.",
        "Higher computational overhead from learning and computing KL divergence.",
        "Potential challenges in tuning the risk parameter and KL divergence constraint."
      ],
      "questions": [
        "How does the method scale to larger state-action spaces?",
        "What are the long-term stability implications of the dual-model approach?",
        "Can the probabilistic Gaussian ensembles be generalized to non-Gaussian environments?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "4fVuBf5HE9",
    "title": "Towards analyzing self-attention via linear neural networks",
    "std_review": {
      "summary": "The paper introduces a theoretical framework for analyzing a simplified linear‑attention Transformer model, proving linear convergence under certain conditions. While offering valuable insights into training dynamics and the role of linear attention, the results are limited to this specific model and may not directly apply to more complex Transformers. The study highlights potential benefits of linear attention but lacks comprehensive analysis of its behavior under poor initialization and practical comparisons with full Transformers.",
      "strengths": [
        "Introduces a novel theoretical framework for a simplified Transformer model.",
        "Provides clear insights into training dynamics and convergence properties.",
        "Demonstrates the potential of linear attention mechanisms despite reduced capacity."
      ],
      "weaknesses": [
        "Results are specific to the linear‑attention model and may not generalize to full Transformers.",
        "Theoretical guarantees rely on specific assumptions about initialization and loss functions.",
        "Limited analysis of loss behavior under poor initialization.",
        "No direct comparison to full Transformer architectures."
      ],
      "questions": [
        "How do the theoretical guarantees extend to more complex Transformer architectures?",
        "What is the comprehensive analysis of loss behavior under poor initialization?",
        "How does the simplified model compare to full Transformers in capturing true self‑attention mechanisms?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "4g02l2N2Nx",
    "title": "The Hedgehog & the Porcupine: Expressive Linear Attentions with Softmax Mimicry",
    "std_review": {
      "summary": "The paper introduces Hedgehog, a linear attention mechanism that captures the beneficial properties of softmax attention while achieving linear computational complexity. It evaluates Hedgehog across three settings and demonstrates competitive performance on NLP benchmarks, with promising cross-modal potential for vision tasks. However, scalability and cross-modal generalization remain areas for future research.",
      "strengths": [
        "Preserves softmax attention properties like low entropy and dot-product monotonicity.",
        "Achieves linear computational complexity, improving efficiency over traditional quadratic attention.",
        "Demonstrates strong performance across multiple evaluation settings, including from scratch, finetuned, and pretrained.",
        "Shows potential for generalization beyond NLP to vision tasks."
      ],
      "weaknesses": [
        "Scalability concerns for very large models (e.g., 1 B+ parameters).",
        "Limited empirical validation and ablation studies to fully understand component contributions.",
        "Implementation details for learned MLPs relative to original Transformer weights are not fully detailed.",
        "Cross-modal generalization evidence is preliminary."
      ],
      "questions": [
        "How does Hedgehog scale to extremely large models (e.g., 1 B+ parameters)?",
        "What further ablation studies are needed to clarify the contribution of each component?",
        "How does Hedgehog perform on a broader set of vision tasks beyond the initial experiments?",
        "What initialization and training strategies ensure the most stable and reproducible results?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "4GfEOQlBoc",
    "title": "",
    "std_review": {
      "raw_text": "{\n  \"summary\": \"The paper introduces a probabilistic framework to quantify perceptual sensitivity, linking small perturbations in visual input to changes in perceived quality. It derives parametric predictions for perceptual metrics and validates them with computational experiments using additive uniform noise. While offering a novel theoretical approach, the work has methodological limitations, such as a potentially oversimplified definition of perceptual sensitivity and ambiguous treatment of probability factors. Overall, the paper provides valuable insights but requires further refinement.\",\n  \"strengths\": [\n    \"Clear theoretical foundation using probability theory.\",\n    \"Novel parametric predictions for perceptual metrics.\",\n    \"Empirical validation with straightforward computational experiments.\"\n  ],\n  \"weaknesses\": [\n    \"Definition of perceptual sensitivity may oversimplify human perception.\",\n    \"Ambiguity in treating the probability factor \\(p(x)\\).\",\n    \"Choice of additive uniform noise may not capture all real-world distortions.\",\n    \"Interpretation of parametric predictions can become trivial under certain conditions.\"\n  ],\n  \"questions\": [\n    \"How does the directionality of perceptual changes align with the direction‑agnostic definition in Eq. (1)?\",\n    \"Could clarifying whether \\(p(x)\\) is a PDF or PMF improve the clarity of probabilistic analyses?\",\n    \"What impact does using additive uniform noise have on the generalizability of the results to real-world image distortions?\",\n    \"How can the parametric predictions be interpreted when they become trivial or meaningless under extreme conditions?\"\n  ],\n  \"overall_score\": \"4: weak accept\",\n  \"confidence\": \"3: medium\"\n}",
      "parse_error": true
    }
  },
  {
    "paper_id": "4h1apFjO99",
    "title": "Diffusion-TS: Interpretable Diffusion for",
    "std_review": {
      "summary": "The paper presents Diffusion-TS, a novel diffusion-based approach for time series imputation and forecasting that incorporates trend and seasonality decomposition. It demonstrates strong performance on long-term generation tasks, outperforming existing methods in many cases. The authors provide ablation studies to highlight the importance of the trend and seasonality synthesis blocks and Fourier regularization. However, the evaluation metrics are inconsistent, and the model's performance on conditional generation tasks is not as thoroughly evaluated.",
      "strengths": [
        "Introduces a novel approach to time series imputation and forecasting using diffusion models and trend/seasonality decomposition.",
        "Demonstrates strong performance on long-term generation tasks, outperforming existing methods in many cases.",
        "Provides a flexible framework that can be adapted for both imputation and forecasting tasks.",
        "Includes thorough ablation studies to highlight the importance of the trend and seasonality synthesis blocks and Fourier regularization."
      ],
      "weaknesses": [
        "The ablation studies could be more comprehensive, including additional experiments to further validate the contributions of the trend and seasonality synthesis blocks and Fourier regularization.",
        "The evaluation metrics used in the experiments are inconsistent, making it difficult to fully assess the performance of Diffusion-TS across different tasks.",
        "The model's performance on conditional generation tasks is not as thoroughly evaluated as the long-term generation tasks, leaving some uncertainty about its effectiveness in real-world scenarios."
      ],
      "questions": [
        "Could additional ablation studies further validate the contributions of the trend and seasonality synthesis blocks and Fourier regularization?",
        "How can the evaluation metrics be standardized to better assess the performance of Diffusion-TS across different tasks?",
        "What additional experiments could be conducted to evaluate the model's performance on conditional generation tasks in real-world scenarios?"
      ],
      "overall_score": "Accept",
      "confidence": "4"
    }
  },
  {
    "paper_id": "4Hf5pbk74h",
    "title": "Improving classifier decision boundaries using nearest neighbors",
    "std_review": {
      "summary": "The paper proposes a method to improve adversarial robustness by constructing an optimal decision boundary in a latent space derived from a pre-trained classifier. It leverages a distance metric in this latent space to mitigate adversarial examples, showing modest improvements on CIFAR-10 and CIFAR-100. While the approach is theoretically sound and empirically validated, its practical impact is limited by minor performance gains and unclear interpretability as explainable AI.",
      "strengths": [
        "Novel use of latent space for adversarial robustness.",
        "Clear theoretical formulation linking latent space to classifier performance.",
        "Empirical validation on standard benchmarks."
      ],
      "weaknesses": [
        "Minor performance gains over existing methods.",
        "Potential implementation complexity and limited interpretability.",
        "Lack of strong evidence for the assumed sparse latent space.",
        "Unclear rationale for adversarial attack targets."
      ],
      "questions": [
        "Can the method's performance be demonstrated with more state-of-the-art models?",
        "What empirical evidence supports the claim of a sparse latent space?",
        "How does the method address cases where one class encloses another in the latent space?",
        "What concrete examples illustrate the method's interpretability as 'local'?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "4i4fgCOBDE",
    "title": "Networked Inequality: Preferential Attachment Bias in Graph Neural Network Link Prediction",
    "std_review": {
      "summary": "The paper introduces a fairness metric and regularization approach to mitigate preferential attachment bias in GNN link prediction, showing promising results on both canonical and modern GNNs. While innovative, the theoretical analysis relies on assumptions that may not hold in all real-world networks, and the relevance of empirical validation to current practices is limited. The proposed methods are a valuable contribution but require further exploration of their impact and applicability.",
      "strengths": [
        "Introduces a novel fairness metric tailored for GNN link prediction, addressing a critical gap.",
        "Proposes a practical regularization approach with clear theoretical underpinnings.",
        "Extends analysis to more expressive link prediction methods, broadening applicability."
      ],
      "weaknesses": [
        "Relies on an independence assumption that may not hold in many real-world networks.",
        "Empirical validation on canonical GNNs, which are rarely used for link prediction today.",
        "Does not fully explore the impact of group size and homophily on within-group bias.",
        "Evaluation focuses primarily on fairness as a regularization term, lacking other metrics."
      ],
      "questions": [
        "How robust are the theoretical results under more realistic network assumptions?",
        "What is the impact of group size and homophily on within-group fairness?",
        "How does the fairness regularization affect overall link prediction performance across different baselines?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "4iPw1klFWa",
    "title": "",
    "std_review": {
      "summary": "The paper introduces SNNK, a method that integrates spiking neural networks with kernelized kernels to improve the efficiency of deep learning models. Empirical evidence shows significant reductions in training time and memory usage for models like Transformers. While innovative, the approach is limited to specific layers and lacks comprehensive comparative analysis or detailed exploration of performance trade-offs.",
      "strengths": [
        "Innovative integration of spiking neural networks with kernelized methods.",
        "Empirical evidence demonstrating reduced training time and memory usage.",
        "Broad applicability across various models, including Transformers."
      ],
      "weaknesses": [
        "Limited scope of replacement, focusing on specific layers rather than full model overhaul.",
        "Lack of detailed comparative analysis with other dimensionality reduction techniques.",
        "Scalability concerns not thoroughly addressed.",
        "Potential performance trade-offs, especially in inference, are not extensively explored."
      ],
      "questions": [
        "Can SNNK be practically applied to replace all feedforward layers in larger models?",
        "What are the detailed efficiency gains in inference speed compared to traditional methods?",
        "How does SNNK scale to more complex architectures beyond the evaluated models?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "4iQuByhNie",
    "title": "Context-NER: Contextual Phrase Generation at Scale",
    "std_review": {
      "summary": "The paper introduces Context-NER, a novel approach for extracting contextual information from financial reports using the EDGAR10-Q dataset. It proposes a baseline method and demonstrates significant improvements over existing techniques, highlighting its potential for enhancing financial data analysis. The comprehensive dataset and practical results make it a valuable contribution, though some aspects of the methodology and evaluation could be further elaborated.",
      "strengths": [
        "Introduces a novel context-ner task tailored for financial data analysis.",
        "Constructs a comprehensive dataset (EDGAR10-Q) from public company financial reports.",
        "Proposes a baseline approach that effectively addresses the specific challenges of the context-ner task in financial data.",
        "Demonstrates significant improvements in model performance compared to existing methods."
      ],
      "weaknesses": [
        "The dataset construction process could benefit from further elaboration and validation.",
        "The baseline approach may not be as effective for other types of financial data or context-ner tasks.",
        "The evaluation metrics used could be more comprehensive.",
        "The paper lacks a detailed discussion on potential limitations and future directions."
      ],
      "questions": [
        "How was the dataset validation conducted to ensure representativeness and reliability?",
        "Could the baseline approach be generalized to other financial data types or context-ner tasks?",
        "What additional evaluation metrics could be used to assess computational efficiency and scalability?",
        "What are the potential limitations of the proposed approach in other domains?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "4IT2pgc9v6",
    "title": "One for All: Towards Training One Graph Model for All Classification Tasks",
    "std_review": {
      "summary": "The paper presents a novel graph prompting framework that integrates large language models (LLMs) with graph structures, showing improved performance across several domains. While innovative, the approach has limitations in domain coverage, lacks visualizations, and does not fully isolate the impact of GNN architectures. Overall, it shows promise but requires further refinement.",
      "strengths": [
        "Innovative integration of LLMs with graph prompting for enhanced graph-based learning.",
        "Comprehensive ablation studies comparing different LLMs and prompting structures.",
        "Clear and well-structured presentation of methodology, experiments, and results."
      ],
      "weaknesses": [
        "Limited domain coverage in experimental evaluation.",
        "Absence of visualizations or qualitative analyses.",
        "Lack of detailed ablation studies on GNN architectures."
      ],
      "questions": [
        "Could the framework be evaluated across a broader range of domains to assess its versatility?",
        "What are the specific contributions of different GNN architectures in handling tasks across various domains?",
        "How does the LLM map nodes from different domains into a unified feature space, and could visualizations clarify this process?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "4IxtmklIym",
    "title": "",
    "std_review": {
      "summary": "The paper presents a novel synthetic dataset for fruit bin picking, addressing the gap between simulated environments and real-world robotic applications. The dataset is generated using a custom simulation environment that captures natural variation in fruit size and shape, with plans to integrate real-world data for future evaluation. While the dataset is a significant contribution, concerns remain about the reliance on outdated benchmarking methods and the lack of detailed plans for handling symmetric objects and real-world data integration.",
      "strengths": [
        "Comprehensive dataset capturing natural variation in fruit size and shape.",
        "Realistic simulation environment with advanced rendering techniques.",
        "Robust evaluation framework planning to assess sim2real gap with real-world data."
      ],
      "weaknesses": [
        "Limited real-world data integration demonstrated in the current paper.",
        "Benchmarking methodology using outdated methods from 2018-2019.",
        "No explicit handling of symmetric objects in benchmarking."
      ],
      "questions": [
        "How will the real-world data be collected and integrated into the evaluation process?",
        "What specific recent benchmarking methods will be incorporated to address outdated ones?",
        "How will symmetric objects be handled in future benchmarking to ensure accurate evaluation?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "4jBL79L5QS",
    "title": "Beyond Shortest-Paths: A Benchmark for Reinforcement Learning on Traffic Engineering",
    "std_review": {
      "summary": "The paper introduces eleganTE, a reinforcement learning framework for traffic engineering in software-defined networks using a novel SwarMDP formulation. It integrates custom ns‑3 modules for realistic simulation and demonstrates competitive performance in delay and drop ratio compared to traditional and other RL methods. While promising, the evaluation focuses narrowly on delay and drop, and the novelty of the SwarMDP approach needs clearer justification.",
      "strengths": [
        "Introduces a novel SwarMDP formulation combining MDP with swarm intelligence for RL in TE.",
        "Provides a comprehensive simulation environment with custom ns‑3 modules for realistic network interaction.",
        "Shows competitive performance in terms of packet delay and drop ratio compared to existing methods."
      ],
      "weaknesses": [
        "Evaluation primarily focuses on delay and drop, potentially overlooking other important TE metrics.",
        "Lacks a thorough comparison with a broader range of state-of-the-art TE techniques.",
        "Experiments are exploratory with limited ablation studies, limiting insights into robustness."
      ],
      "questions": [
        "How does the SwarMDP formulation compare to other decentralized RL approaches in terms of scalability and performance?",
        "What additional metrics (e.g., energy consumption, fairness) should be considered to fully evaluate the framework's effectiveness?",
        "How does the framework perform under dynamic network conditions or varying traffic patterns?"
      ],
      "overall_score": "6: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "4JbrdrHxYy",
    "title": "",
    "std_review": {
      "summary": "ZIP introduces an annotation-free instance segmentation method that combines CLIP and SAM, leveraging their complementary strengths to improve segmentation accuracy without manual annotations. The method uses a semantic-aware initialization and a classification-first-then-discovery pipeline, showing competitive performance on COCO and Pascal VOC datasets. However, it struggles with complex scenes, ambiguous object representations, and high computational demands, indicating areas for further improvement.",
      "strengths": [
        "Combines CLIP and SAM to leverage complementary strengths, addressing individual limitations.",
        "Introduces a semantic-aware initialization technique that improves initial segmentation quality.",
        "Proposes a classification-first-then-discovery pipeline, enhancing segmentation robustness.",
        "Demonstrates competitive performance on benchmark datasets, outperforming some annotation-based methods."
      ],
      "weaknesses": [
        "Limited evaluation on complex scenes with multiple overlapping objects or challenging lighting conditions.",
        "Performance may be affected by ambiguous object representations or rare object classes.",
        "High computational requirements could limit applicability to resource-constrained environments.",
        "Novelty is not fully established as it builds upon existing techniques rather than introducing a fundamentally new approach."
      ],
      "questions": [
        "How does ZIP perform compared to state-of-the-art methods on the COCO dataset?",
        "What are the quantitative results reported for ZIP on the Pascal VOC dataset?",
        "How does ZIP handle the challenge of occlusion in object segmentation?",
        "What are the limitations of ZIP in terms of its performance on complex scenes or ambiguous object representations?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "4JtwtT4nYC",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a novel reinforcement learning approach that parameterizes policies using shared parameters and task-specific embeddings, aiming to improve generalization across multiple tasks. Experiments demonstrate improved performance, suggesting the method effectively balances expressiveness and generalization. While innovative, the approach introduces complexity and potential overfitting concerns that need addressing.",
      "strengths": [
        "Innovative parameterization scheme that combines shared and task-specific parameters.",
        "Empirical evidence showing improved performance across diverse tasks.",
        "Potential to enhance scalability and applicability to real-world RL scenarios."
      ],
      "weaknesses": [
        "Increased model complexity may lead to higher computational costs.",
        "Risk of overfitting due to expanded parameter space.",
        "Lack of detailed analysis on how embeddings influence learning dynamics."
      ],
      "questions": [
        "How does the method handle the trade-off between expressiveness and overfitting?",
        "What are the specific hyperparameter sensitivities and their impact on performance?",
        "Can the approach be extended to more complex environments without significant loss of generalization?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "4kJfWZChJI",
    "title": "",
    "std_review": {
      "summary": "The paper introduces SMEE, a novel domain generalization method that combines a mixture-of-experts (MoE) paradigm with spectral ensemble learning. SMEE demonstrates competitive performance against traditional single-model approaches while maintaining computational efficiency, making it suitable for real-world applications. The reviewer finds the method promising but suggests further comparisons with state-of-the-art techniques and more detailed analysis of its scalability and inference speed benefits.",
      "strengths": [
        "Introduces a novel SMEE approach that effectively combines MoE and spectral ensemble learning for domain generalization.",
        "Demonstrates competitive performance compared to traditional single-model domain generalization methods.",
        "Addresses the computational complexity of spectral ensemble learning, particularly in online incremental settings without re-training or iterative optimization."
      ],
      "weaknesses": [
        "Limited empirical comparison with state-of-the-art domain generalization methods beyond traditional single-model approaches.",
        "Could provide more detailed analysis on the scalability and inference speed benefits of SMEE in large-scale real-world applications.",
        "The novelty of the SMEE approach could be further emphasized by comparing it to other MoE-based domain generalization methods."
      ],
      "questions": [
        "How does SMEE compare to other state-of-the-art domain generalization methods?",
        "What is the detailed analysis of SMEE's scalability and inference speed benefits in large-scale real-world applications?",
        "How does SMEE's novelty compare to other MoE-based domain generalization methods?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "4kLVvIh8cp",
    "title": "Pessimistic Nonlinear Least-Squares Value Iteration for Offline Reinforcement Learning",
    "std_review": {
      "summary": "The paper introduces PNLSVI, an offline RL algorithm with a novel instance‑dependent regret bound expressed via weighted D2‑divergence. Theoretical analysis is strong, covering a wide range of function classes, but lacks empirical validation and practical comparisons. The restrictive uniform coverage assumption and absence of state‑of‑the‑art benchmarks are significant concerns.",
      "strengths": [
        "Novel instance‑dependent regret bound for offline RL.",
        "Thorough theoretical analysis with clear assumptions.",
        "Generality across various function classes, including non‑linear ones."
      ],
      "weaknesses": [
        "No empirical evaluations to demonstrate practical benefits.",
        "Uniform coverage assumption in Assumption 3.5 may be overly restrictive.",
        "Lack of comparison with other state‑of‑the‑art offline RL algorithms."
      ],
      "questions": [
        "What empirical validation or numerical experiments will be conducted to demonstrate PNLSVI's practical performance?",
        "How can the uniform coverage assumption be relaxed for more realistic scenarios?",
        "What are the theoretical implications of applying the instance‑dependent bound to general (non‑linear) function approximations?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "4KqkizXgXU",
    "title": "Curiosity-driven Red-teaming for Large Language Models",
    "std_review": {
      "summary": "The paper presents an RL+Curiosity method to enhance red‑team attacks on large language models by dynamically generating diverse test cases. It shows improved success rates in triggering toxic outputs and increased prompt diversity across benchmarks. While promising, the method requires significant computational resources and relies on a specific toxicity classifier, raising concerns about scalability, robustness, and ethical safeguards.",
      "strengths": [
        "Innovative integration of RL and curiosity-driven exploration.",
        "Demonstrated effectiveness in both success rate and prompt diversity.",
        "Provides insights into scalability and generalization across models and tasks."
      ],
      "weaknesses": [
        "High computational cost limiting applicability.",
        "Dependence on a specific toxicity classifier.",
        "Lack of concrete ethical safeguards.",
        "Insufficient analysis of configurability effects."
      ],
      "questions": [
        "How can the method be made more scalable for larger models?",
        "What strategies can improve classifier robustness?",
        "What safeguards can be implemented to mitigate potential misuse?",
        "How do different reward configurations affect the trade‑off between effectiveness and diversity?"
      ],
      "overall_score": "6: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "4KZpDGD4Nh",
    "title": "Neurosymbolic Grounding for Compositional World Models",
    "std_review": {
      "summary": "The paper introduces COSMOS, a neuro-symbolic framework that integrates a frozen CLIP model with a symbolic grounding module to enable compositional reasoning in reinforcement learning. COSMOS uses a novel key-query attention mechanism to dynamically select the most relevant rule-slot pair for each state-action transition, achieving competitive and superior performance on benchmark tasks compared to existing baselines. The symbolic embeddings learned by COSMOS can be partially interpreted, providing insights into the learned compositional rules. The model also generalizes to unseen attribute combinations through a predefined symbolic vocabulary, offering a scalable solution with manageable computational overhead.",
      "strengths": [
        "Hybrid neuro-symbolic approach combining neural and symbolic reasoning",
        "Dynamic rule selection via key-query attention mechanism",
        "Interpretability of symbolic embeddings",
        "Scalability through use of a frozen foundation model",
        "Empirical performance improvements over neural baselines"
      ],
      "weaknesses": [
        "Interpretability of symbolic embeddings may vary for complex attribute combinations",
        "Reliance on a predefined symbolic vocabulary limits generalization to unseen attributes",
        "Initial training of the foundation model can be computationally intensive",
        "Baseline comparison may not fully capture the unique advantages of the neuro-symbolic approach"
      ],
      "questions": [
        "How robust are the symbolic embeddings' interpretations for highly ambiguous or complex attribute combinations?",
        "What strategies could be employed to expand the symbolic vocabulary to better handle unseen attribute combinations?",
        "How does the performance of COSMOS compare to other neuro-symbolic approaches that do not rely on a frozen foundation model?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "4L0xnS4GQM",
    "title": "Chain-of-Table: Evolving Tables in the Reasoning Chain for Table Understanding",
    "std_review": {
      "summary": "The Chain-of-Table (CoT) method introduces a novel approach for reasoning over tabular data by decomposing complex queries into a sequence of atomic operations, leveraging large language models to generate arguments for each operation. Experimental results show that CoT achieves competitive performance with fewer queries compared to baselines like Chain-of-Thought and Binder, especially with self-consistency. The method extends existing approaches with a structured operation set and improves query efficiency and flexibility.",
      "strengths": [
        "Efficient query processing with fewer required queries",
        "Flexible operation set covering comprehensive table manipulations",
        "Improved performance with self-consistency",
        "Structured argument generation enhancing interpretability"
      ],
      "weaknesses": [
        "Limited by a fixed set of five predefined atomic operations",
        "Potential computational overhead from LLM-generated arguments",
        "High dependency on LLM quality for effectiveness",
        "Risk of overfitting on smaller or specialized datasets"
      ],
      "questions": [
        "How can the predefined operation set be expanded to improve versatility?",
        "What strategies can mitigate the computational overhead of LLM argument generation?",
        "How does the method perform on larger, more complex datasets beyond the current experiments?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "4lOWCkhr4g",
    "title": "Unsupervised ASR",
    "std_review": {
      "summary": "The paper presents a cross‑lingual unsupervised speech recognition framework that uses a language model to iteratively refine pronunciation models without parallel data. It achieves state‑of‑the‑art word error rates across multiple language pairs, demonstrating strong potential for low‑resource and zero‑resource scenarios. While the method shows clear advantages, it also faces challenges such as high computational demand, reliance on high‑quality language models, and limited evaluation of robustness to noisy data.",
      "strengths": [
        "Effective pseudo‑labeling loop that significantly improves pronunciation model quality in low‑resource settings.",
        "Scalable language model architecture that generalizes across diverse linguistic structures.",
        "Competitive performance compared to recent unsupervised baselines, highlighting practical viability."
      ],
      "weaknesses": [
        "High computational requirements due to iterative pseudo‑labeling and large language model.",
        "Dependence on the quality of the language model; poor LM performance can degrade results.",
        "Limited exploration of alternative acoustic models beyond Transformer.",
        "Insufficient evaluation of robustness to noisy data and speaker variability."
      ],
      "questions": [
        "How does the method perform when trained on datasets exceeding 100 h of unlabeled audio without distributed training?",
        "What is the impact of using a CTC‑based acoustic model instead of a Transformer model on both performance and computational efficiency?",
        "How robust is the framework to background noise and speaker variability, and what preprocessing strategies could improve its robustness?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "4lqA5EuieJ",
    "title": "Prediction Tasks in Graphs: a Framework to Control the Interpretability-Performance Trade-off",
    "std_review": {
      "summary": "The paper introduces a bi-level optimization framework for Graph Neural Networks (GNNs) that simultaneously optimizes performance and interpretability by sparsifying graph representations. It demonstrates that the proposed approach achieves competitive accuracy while significantly improving interpretability through sparsity. The method is innovative, scalable, and provides a clear way to control the trade-off between sparsity and accuracy, though it is complex and sensitive to hyperparameters. Overall, the paper is well-received for its novel approach and strong empirical results.",
      "strengths": [
        "Innovative bi-level optimization framework for balancing interpretability and performance in GNNs.",
        "Scalable to large graph datasets, making it applicable to real-world scenarios.",
        "Provides a clear and quantitative way to control the trade-off between sparsity (interpretability) and accuracy.",
        "Empirical validation shows improved interpretability and computational efficiency compared to traditional methods."
      ],
      "weaknesses": [
        "Complexity of the bi-level optimization framework may make it challenging to implement and require significant computational resources.",
        "Performance is sensitive to hyperparameters, particularly those controlling sparsity, which could complicate practical application.",
        "Lack of direct human evaluation to assess the practical interpretability of the generated sparse graphs.",
        "Comparison with state-of-the-art interpretability methods is limited to traditional techniques."
      ],
      "questions": [
        "How does the method perform on extremely large graphs with millions of nodes?",
        "What is the impact of different edge removal policies on the interpretability and accuracy of the resulting sparse graphs?",
        "Could the method be extended to other types of neural networks beyond GNNs?",
        "How does the proposed method compare to recent multi-objective optimization approaches in terms of efficiency and interpretability?"
      ],
      "overall_score": "Accept",
      "confidence": "High"
    }
  },
  {
    "paper_id": "4lqo5Jwfnq",
    "title": "Class-Incremental Learning with Parameter-Efficient Cross-Task Prompts",
    "std_review": {
      "summary": "The paper presents a novel continual learning (CIL) method that limits prompt updates to mitigate catastrophic forgetting, operating on prompt parameters rather than all model parameters. It introduces a feature fusion module to integrate task-specific knowledge, achieving improved performance on standard CIL benchmarks. The approach is parameter-efficient and empirically successful, though it may limit model exploration and robustness to task variability.",
      "strengths": [
        "Introduces a unique constraint on prompt updates to prevent catastrophic forgetting.",
        "Focuses on prompt parameters, potentially reducing computational overhead.",
        "Incorporates a feature fusion module to effectively combine task-specific information.",
        "Demonstrates empirical success on standard CIL benchmarks."
      ],
      "weaknesses": [
        "Limiting prompt updates may restrict the model's ability to explore new solutions.",
        "Using a fixed set of prompts could hinder performance on tasks with large domain gaps.",
        "The complexity of the feature fusion module may pose tuning and optimization challenges.",
        "Lacks a thorough analysis of robustness to different task distributions or noise."
      ],
      "questions": [
        "How does the method handle scenarios with large domain gaps between tasks?",
        "What is the impact of the fixed prompt set on the model's ability to learn complex tasks?",
        "Could a more dynamic prompt set improve performance in certain applications?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "4MsfQ2H0lP",
    "title": "Generative Adversarial Policy Network for Modelling Protein Complexes",
    "std_review": {
      "summary": "The paper introduces GAPN, a method for predicting protein-protein interactions (PPIs) by integrating pre-computed dimer structures into its training pipeline. Experimental results show improved performance on benchmark datasets compared to existing methods, highlighting the potential of using pre-computed dimer information in PPI prediction. However, concerns about potential bias from ground-truth dimer usage, lack of dimer structure optimization, and scalability to larger complexes need addressing.",
      "strengths": [
        "Innovative integration of pre-computed dimer structures.",
        "Improved performance on benchmark datasets.",
        "Scalability and efficiency gains by leveraging pre-computed structures."
      ],
      "weaknesses": [
        "Potential bias from using ground-truth dimer structures.",
        "Lack of optimization of dimer structures.",
        "Unclear impact of pre-computed vs. ground-truth dimer structures.",
        "Scalability concerns for larger protein complexes."
      ],
      "questions": [
        "What is the source of the dimer structures used by GAPN, and could this introduce bias?",
        "How are dimer structures pre-computed or fetched, and what are the associated computational costs?",
        "How does GAPN handle errors in pre-computed dimer structures, and what is the impact on prediction accuracy?",
        "What is the performance of GAPN when applied to larger protein complexes, and are there any scalability limitations?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "4MvHiijJL3",
    "title": "Model Explanation Disparities as a Fairness Diagnostic",
    "std_review": {
      "summary": "The paper introduces Feature Importance Disparity (FID) as a novel metric to assess fairness in machine learning models, particularly in the context of model interpretability. It proposes an algorithm that identifies subgroups with significant FID using cost-sensitive learning and Lagrangian relaxation. The method is evaluated on multiple datasets and feature importance techniques, demonstrating its effectiveness and providing practical guidelines for practitioners. While the metric focuses on feature importance and has some computational complexity concerns, it offers valuable insights and actionable steps for addressing fairness issues.",
      "strengths": [
        "Introduces a novel and interpretable fairness metric (FID) that quantifies feature importance disparities across subgroups.",
        "Proposes an algorithm leveraging cost-sensitive learning and Lagrangian relaxation to identify subgroups with significant FID.",
        "Conducts comprehensive experiments on multiple datasets and feature importance methods, demonstrating robustness and applicability.",
        "Provides clear guidelines for practitioners on interpreting and acting upon the results, enhancing practical utility."
      ],
      "weaknesses": [
        "The metric and algorithm are specific to feature importance, which may not capture all aspects of fairness.",
        "Computational complexity could be a concern for large-scale datasets, limiting practical applicability.",
        "Does not fully address the relationship between FID and other established fairness metrics.",
        "Evaluation is limited to a few datasets and feature importance methods, which may not generalize well."
      ],
      "questions": [
        "How does FID compare to other fairness metrics in terms of capturing different aspects of fairness?",
        "What are the computational efficiency improvements that could be made for large-scale datasets?",
        "How can FID be integrated with existing fairness evaluation frameworks?",
        "Are there specific model types or feature importance methods where FID might be particularly effective or ineffective?"
      ],
      "overall_score": "Accept",
      "confidence": "High"
    }
  },
  {
    "paper_id": "4N7v4w2r3b",
    "title": "",
    "std_review": {
      "summary": "ProxyBench introduces a standardized benchmark for evaluating the robustness of proxy reward models, which are increasingly used in reinforcement learning. The benchmark assesses how easily these models can be exploited through adversarial attacks, providing a comprehensive evaluation framework. The authors demonstrate that existing proxy models often fail under such attacks, highlighting the need for robustness. They propose several methods to mitigate proxy gaming and evaluate their effectiveness using ProxyBench. The paper provides actionable insights and empirical validation, making it a valuable contribution to the field.",
      "strengths": [
        "Standardized Evaluation Framework: ProxyBench provides a unified benchmark for assessing proxy model robustness, addressing the lack of standardized metrics in prior work.",
        "Comprehensive Evaluation: The benchmark evaluates proxy models across various domains and architectures, offering a broad assessment of their vulnerability to adversarial attacks.",
        "Practical Insights: The paper provides actionable insights into improving proxy robustness, including specific mitigation strategies and their trade-offs.",
        "Empirical Validation: The authors conduct extensive experiments to validate the effectiveness of their proposed methods, using real-world proxy models as case studies."
      ],
      "weaknesses": [
        "Scope Limitations: The benchmark primarily focuses on adversarial robustness, potentially overlooking other critical aspects of proxy model evaluation, such as alignment with true objectives or computational efficiency.",
        "Assumptions in Attack Simulations: The evaluation assumes specific attack scenarios that may not fully capture the complexity of real-world adversarial environments.",
        "Limited Generalizability: The findings may not be easily transferable to all domains or model architectures, as the benchmark is tailored to the specific attack methods and environments used in the study.",
        "Resource Intensity: The proposed methods for improving robustness may require significant computational resources, limiting their applicability in resource-constrained settings."
      ],
      "questions": [
        "How can the benchmark be extended to evaluate other aspects of proxy model performance, such as alignment with true objectives or computational efficiency?",
        "Are the attack scenarios used in the benchmark representative of real-world adversarial environments, and how can the benchmark be adapted to better capture these complexities?",
        "What are the trade-offs between robustness and performance when applying the proposed mitigation methods, and how can these be optimized for resource-constrained settings?"
      ],
      "overall_score": "Accept",
      "confidence": "High"
    }
  },
  {
    "paper_id": "4N97bz1sP6",
    "title": "",
    "std_review": {
      "summary": "The paper presents a novel method for audio separation that uses textual descriptions to guide the separation process, leveraging a consistency reconstruction loss to align generated audio with the textual input. This approach aims to improve robustness in the presence of background noise and unmentioned sources, showing competitive performance against state-of-the-art methods. While promising, the method's effectiveness in handling background noises not described in the text and discrepancies between specified and actual sources remains uncertain.",
      "strengths": [
        "Introduces a unique approach to audio separation by incorporating textual descriptions, enhancing model interpretability and generalizability.",
        "Utilizes a consistency reconstruction loss (CRL) to enforce alignment between generated audio and textual input, potentially improving separation accuracy.",
        "Demonstrates competitive performance against state-of-the-art methods, suggesting practical applicability."
      ],
      "weaknesses": [
        "Performance may be impacted by background noises not mentioned in the textual input.",
        "Handling discrepancies between specified sources in the prompt and those present in the recording could pose challenges.",
        "Model's performance may vary depending on background noise levels and the presence of extraneous source components in training data.",
        "The effectiveness of the CRL component in scenarios where textual captions do not fully capture all components of the mixture remains unclear."
      ],
      "questions": [
        "How does the model handle background noises not mentioned in the textual input?",
        "What strategies can be employed to improve the model's performance when the prompt mentions specific sources but the recording includes unexpected background noise?",
        "How does the model's performance vary with different levels of background noise and source combinations in the training data?",
        "What are the specific scenarios where the consistency reconstruction loss (CRL) may not effectively enforce alignment between generated audio and textual input?"
      ],
      "overall_score": "Accept",
      "confidence": "4"
    }
  },
  {
    "paper_id": "4NhMhElWqP",
    "title": "DAM: Towards A Foundation Model for Time Series Forecasting",
    "std_review": {
      "summary": "The DAM paper introduces a novel adaptive time series forecasting model that dynamically adjusts its context size and basis functions to improve accuracy and interpretability. Empirical results show strong performance, especially in long-term forecasts, but the model's complexity and computational cost are concerns. The paper is well-structured, with clear strengths in adaptability and interpretability, though it lacks ablation studies and a comprehensive comparison with state-of-the-art methods.",
      "strengths": [
        "Adaptive context and basis function selection enhances flexibility and performance.",
        "Provides interpretable insights into temporal dynamics, improving model transparency.",
        "Demonstrates superior long-term forecasting capabilities compared to traditional methods."
      ],
      "weaknesses": [
        "Model complexity may hinder interpretability for users without advanced time series expertise.",
        "Computational cost could limit applicability in resource-constrained environments.",
        "Absence of ablation studies to quantify component contributions.",
        "Limited comparison with recent state-of-the-art forecasting models."
      ],
      "questions": [
        "How does the adaptive nature of the DAM impact interpretability for users without a strong background in time series analysis?",
        "What strategies could be employed to reduce the computational cost of the DAM while maintaining its performance?",
        "Could ablation studies provide additional insights into the contribution of individual components to the model's overall effectiveness?",
        "How does the DAM perform when compared to recent state-of-the-art models in time series forecasting?"
      ],
      "overall_score": "Accept",
      "confidence": "High"
    }
  },
  {
    "paper_id": "4nyTlyTtfX",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a theoretical framework analyzing the performance gap between fully autonomous and mixed-autonomy systems with human agents. It derives regret bounds showing that human involvement can significantly reduce regret compared to an autonomous-only system, supported by empirical results on simulated scenarios. While the work offers valuable insights and a realistic model of human behavior, it has limitations such as oversimplified assumptions and a narrow scope, suggesting further research for broader applicability.",
      "strengths": [
        "Clear theoretical contributions with novel regret bounds quantifying the performance gap.",
        "Realistic modeling of human agents with bounded rationality and limited planning horizons.",
        "Empirical validation on simulated mixed-autonomy scenarios supporting theoretical findings."
      ],
      "weaknesses": [
        "Assumptions about bounded rationality and planning horizons may oversimplify human behavior.",
        "Derived regret bounds may not be tight, not fully capturing all interactions.",
        "Empirical validation limited to a two-agent setting, potentially limiting generalizability.",
        "Lacks comparative experiments with other multi-agent frameworks."
      ],
      "questions": [
        "How can the regret bounds be tightened to better reflect the full potential of human decision-making?",
        "What further comparative experiments could be conducted to validate the framework in more complex mixed-autonomy systems?",
        "How do the assumptions about bounded rationality and planning horizons impact the generalizability of the results to real-world scenarios?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "4olqbTBt1Y",
    "title": "DREAM: Dual Structured Exploration with Mixup for Open-set Graph Domain Adaption",
    "std_review": {
      "summary": "DREAM introduces a novel method for open-set graph domain adaptation, leveraging attention mechanisms, a graph-of-graph design, and a tailored loss function. The approach shows promise in adapting to new graph structures while maintaining performance on known ones, as demonstrated by empirical results. However, the paper lacks clear comparisons with existing methods and comprehensive ablation studies, which limits the assessment of its relative strengths and the contributions of its components.",
      "strengths": [
        "Innovative approach combining attention mechanisms and a graph-of-graph design for open-set graph domain adaptation.",
        "Demonstrated effectiveness in adapting to new graph domains with minimal degradation on known domains.",
        "Scalable design suitable for real-world applications with increasing complexity."
      ],
      "weaknesses": [
        "Absence of clear comparisons with existing graph domain adaptation and open-set graph classification methods.",
        "Limited ablation studies prevent thorough evaluation of individual contributions.",
        "Potential resource intensity of the 'dream' mechanism in complex scenarios."
      ],
      "questions": [
        "How does DREAM compare to state-of-the-art methods like DEAL, CoCo, RIGNN, OpenWGL, and OpenWRF?",
        "What are the individual contributions of the attention mechanism and the graph-of-graph design to the model's performance?",
        "Could additional ablation studies provide deeper insights into the model's components?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "4pnhzuRtJ2",
    "title": "Optimized Tradeoffs for Private Majority Ensembling",
    "std_review": {
      "raw_text": "{\n  \"summary\": \"The paper introduces DaRRM, a framework that combines randomized response with differential privacy for multi-class aggregation, offering strong theoretical privacy guarantees and flexibility with non-uniform priors. While empirical evaluations show benefits over traditional methods, the optimization problem's complexity and some notational ambiguities limit its practicality. The paper is recommended for weak acceptance.\",\n  \"strengths\": [\n    \"Introduces a novel framework that combines randomized response with differential privacy.\",\n    \"Provides strong theoretical privacy amplification guarantees under \\((\\epsilon, \\delta)\\)-DP.\",\n    \"Allows for non-uniform priors to optimize utility in specific contexts.\"\n  ],\n  \"weaknesses\": [\n    \"The optimization problem for designing \\(\\gamma\\) is computationally intractable for large \\(K\\).\",\n    \"Notation \\(\\gamma\\) is used ambiguously, leading to potential confusion.\",\n    \"Empirical results do not always directly support theoretical claims, especially with non-uniform priors.\",\n    \"The paper lacks detailed analysis of extending the framework to multi-class settings.\"\n  ],\n  \"questions\": [\n    \"How can the computational complexity of the optimization problem be addressed for large \\(K\\)?\",\n    \"Can a unified definition of \\(\\gamma\\) be provided to improve clarity?\",\n    \"What are the specific challenges and adaptations needed to extend DaRRM to multi-class outputs?\",\n    \"How can the framework be compared with other state-of-the-art methods beyond Laplace and GNMax?\"\n  ],\n  \"overall_score\": \"4: weak reject\",\n  \"confidence\": \"3: medium\"\n}",
      "parse_error": true
    }
  },
  {
    "paper_id": "4pW8NL1UwH",
    "title": "LIRE: listwise reward enhancement for preference alignment",
    "std_review": {
      "summary": "The paper introduces LIRE, a listwise distribution designed to improve candidate response quality in open-domain question answering. It modifies the pointwise approach by constructing a listwise dataset and using softmax over sampled generations to guide sampling. Evaluated on the HH dataset, LIRE achieves competitive results against strong baselines like Alpaca‑7B, with a clear theoretical foundation and effective offline dataset generation. Despite its strengths, the method's complexity and limited ablation studies are noted.",
      "strengths": [
        "Introduces a novel listwise distribution that leverages offline dataset generation to improve candidate response quality.",
        "Effectively uses Equation 4 to create a listwise dataset, enhancing response diversity and quality.",
        "Provides a clear theoretical framework for understanding the listwise sampling process and its impact on model behavior.",
        "Achieves strong empirical results on the HH dataset, outperforming baselines such as Alpaca‑7B."
      ],
      "weaknesses": [
        "The listwise approach introduces additional complexity in dataset generation and model training, requiring more computational resources.",
        "The PPO model achieves a lower reward compared to the Alpaca‑7B baseline, which may be surprising given the training objectives.",
        "Lacks detailed evaluation metrics on the divergence between the LIRE‑tuned policy and the anchor policy.",
        "Limited comparison with other listwise methods could provide a more comprehensive analysis of LIRE's performance.",
        "Insufficient ablation studies or hyperparameter sensitivity analyses to fully understand the method's robustness and limitations."
      ],
      "questions": [
        "How does the choice of temperature parameter T in the softmax function affect the sampling behavior and overall performance of LIRE?",
        "Could a more detailed analysis of the divergence between the LIRE policy and the supervised policy provide additional insights into the regularization effect?",
        "What are the computational and resource implications of implementing the listwise dataset generation process compared to traditional pointwise approaches?",
        "How does LIRE's performance scale with a larger or more diverse dataset, and what are the potential trade-offs?",
        "Are there specific types of questions or domains where LIRE's advantages are more pronounced, and could targeted ablations explore these effects?"
      ],
      "overall_score": "Accept",
      "confidence": "High"
    }
  },
  {
    "paper_id": "4PzxLPEGRn",
    "title": "OCAtari: Object-Centric Atari 2600 Reinforcement Learning Environments",
    "std_review": {
      "summary": "The paper introduces OCAtari, an object‑centric Atari representation that transforms raw pixel observations into a structured object grid using two complementary methods. It demonstrates improved performance and sample efficiency on classic Atari games compared to pixel‑based baselines and addresses non‑determinism in RL. While offering significant advantages, the approach relies heavily on accurate object modeling and may struggle with certain game elements.",
      "strengths": [
        "Improved abstraction by converting raw pixels into a structured object grid, enhancing the representational power of deep RL algorithms.",
        "Dual detection methods (Vision‑Enhanced Model and RAM Extraction) provide a robust and versatile approach to object detection.",
        "Benchmark robustness through deterministic Atari variants, leading to more reliable performance metrics.",
        "Scalability across a wide range of Atari games, showcasing the framework's general applicability."
      ],
      "weaknesses": [
        "Effectiveness heavily depends on accurate object modeling, which may not be necessary for all Atari tasks.",
        "RAM Extraction Method may struggle with blinking, partially occluded, or non‑gameplay objects.",
        "Benchmark focuses on classic Atari games, potentially limiting generalizability to more modern environments.",
        "Evaluation could benefit from deeper analysis of how different RL algorithms interact with the OCAtari representation."
      ],
      "questions": [
        "How does OCAtari's performance compare to other state‑of‑the‑art object‑centric representations in more complex or modern environments?",
        "What are the specific trade‑offs between object modeling and pixel‑based approaches for different Atari tasks?",
        "How does the benchmark address the stochastic nature of RL beyond deterministic environment variants?"
      ],
      "overall_score": "Accept",
      "confidence": "High"
    }
  },
  {
    "paper_id": "4QaKdsh15T",
    "title": "",
    "std_review": {
      "summary": "The paper introduces LEO, an embodied AI framework that integrates CLIP with a learned motion policy to enable robots to follow natural language instructions in complex indoor environments. It demonstrates competitive performance on the Embodied AI benchmark, particularly excelling in tasks requiring language understanding and dynamic motion planning. While innovative, the paper's evaluation is limited, with only a subset of 3D tasks evaluated and no baselines for embodied navigation. The authors should address these gaps to strengthen the claim of novelty and impact.",
      "strengths": [
        "Innovative integration of CLIP for combining language understanding with visual perception.",
        "Scalable policy learning enabling generalization across diverse tasks.",
        "Robustness across environments demonstrated through comprehensive benchmark results."
      ],
      "weaknesses": [
        "Limited evaluation of 3D tasks, only covering 3 out of 10 original tasks.",
        "Absence of baselines for embodied navigation, hindering performance assessment.",
        "Ambiguity regarding the impact of human demonstrations versus shortest path training.",
        "Potential reporting error regarding soft‑SPL metrics.",
        "Insufficient comparison of navigation performance against recent state‑of‑the‑art methods."
      ],
      "questions": [
        "Should the full results of the remaining 7 3D tasks from the original CLIPort experiment be provided and included in the supplementary material?",
        "What baselines should be presented for the embodied navigation task, such as comparisons to Habitat‑Web and other recent benchmarks?",
        "How does training on human demonstrations compare quantitatively to using shortest path trajectories, despite the higher success rate on navigation tasks?",
        "Is the claim of presenting soft‑SPL in Section 4.3 a typo, and if so, should the missing results be provided?",
        "What additional baselines should be included to better contextualize LEO's navigation performance?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "4qFIkOhq24",
    "title": "Fundamental limitations of alignment",
    "std_review": {
      "summary": "The paper introduces a theoretical framework for analyzing alignment in large language models (LLMs) by modeling their output distribution as a mixture of positive and negative components. It derives conditions under which the negative component can dominate, leading to misaligned behavior, and demonstrates these concepts through experiments on a synthetic LLM. The work provides a clear theoretical model and practical insights into detecting and mitigating misalignment, but its simplifying assumptions and granularity limitations may limit the generality and realism of the results.",
      "strengths": [
        "Clear theoretical framework for understanding misalignment in LLMs.",
        "Provides actionable insights for detecting and mitigating misalignment through prompt design.",
        "Empirical validation through well-designed experiments supports the theoretical claims."
      ],
      "weaknesses": [
        "Simplifying assumptions about the LLM's output distribution may oversimplify real-world behavior.",
        "Treating LLMs as generating single sentences may not capture the complexity of longer, more contextually rich outputs.",
        "The construction of a negative behavior LLM as a non-true sub-component raises questions about feasibility and accuracy."
      ],
      "questions": [
        "How can the framework be extended to capture the nuances of longer, more contextually rich outputs?",
        "What are the practical implications of the critical constants (α, β, γ) for real-world alignment challenges?",
        "How can the negative behavior LLM be constructed more precisely, and what impact would this have on the results?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "4QtywskEyY",
    "title": "",
    "std_review": {
      "summary": "The paper presents Multi-Stage Distillation (MDR), a novel knowledge distillation framework that uses a Relational Decouple Module (RDM) to break down the teacher's output into multiple stages and an Adaptive Distillation Selection (ADSS) module to dynamically select the most informative stages for the student model. Experiments on ImageNet show that MDR often outperforms state-of-the-art KD methods, including the teacher network in some cases. The approach is theoretically justified and introduces a more nuanced and selective knowledge transfer, though it adds complexity and computational overhead.",
      "strengths": [
        "Introduces a novel RDM that enables more granular and context-aware knowledge transfer.",
        "Demonstrates superior performance on ImageNet, often surpassing both the teacher and other KD methods.",
        "Provides a solid theoretical foundation for the proposed methods."
      ],
      "weaknesses": [
        "Adds complexity to the distillation process, which could be challenging for practitioners.",
        "Incorporates computational overhead due to processing multiple stages.",
        "Lacks extensive validation across a wider range of datasets and tasks."
      ],
      "questions": [
        "How does MDR perform on other benchmark datasets beyond ImageNet?",
        "What is the impact of the computational overhead on resource-constrained environments?",
        "How does MDR compare to the latest advancements in knowledge distillation?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "4Qz9BT4mpM",
    "title": "Predicting the Performance of Foundation Models via Agreement-on-the-Line",
    "std_review": {
      "summary": "The paper proposes a method to improve neural network training stability by introducing diversity through differently initialized random heads. Empirical evaluations across several datasets show reduced variance in model performance, leading to more consistent test accuracy. While the method is innovative and promising, its effectiveness is modest and depends on the degree of diversity introduced. The paper lacks absolute performance metrics, making it difficult to fully assess the magnitude of improvements.",
      "strengths": [
        "Clear motivation for addressing training stability, a well‑documented issue.",
        "Introduces a novel diversity mechanism via differently initialized random heads, offering a promising direction for improving model robustness.",
        "Conducts thorough empirical evaluations across multiple datasets and models, providing robust evidence of effectiveness.",
        "Provides a comparative analysis highlighting practical benefits over standard training protocols."
      ],
      "weaknesses": [
        "Lacks absolute test accuracy values, making it hard to quantify the magnitude of performance gains.",
        "Does not clearly quantify the significance of observed deviations in test accuracy.",
        "Relies on random initializations, which may limit the exploration of diversity compared to other initialization strategies.",
        "Potential for overfitting due to introduced diversity, especially if not carefully controlled."
      ],
      "questions": [
        "Could the method's performance be further improved by exploring alternative initialization strategies beyond random heads?",
        "How does the method's stability compare when applied to different model architectures or training protocols?",
        "What are the absolute test accuracy improvements achieved by the proposed method, and how do they compare to baseline models?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "4r2ybzJnmN",
    "title": "Learning Delays in Spiking Neural Networks using Dilated Convolutions with Learnable Spacings",
    "std_review": {
      "summary": "The paper introduces DCLS, a method for learning delays in spiking neural networks using dilated convolutions with learnable spacings. It shows promise in improving delay learning efficiency and has practical benefits for neuromorphic hardware. While the method is effective, it could benefit from broader comparisons and more detailed robustness analysis.",
      "strengths": [
        "Introduces a novel approach to learning delays in SNNs.",
        "Enhances performance and computational efficiency compared to existing methods.",
        "Provides thorough evaluation using the LIF neuron model."
      ],
      "weaknesses": [
        "Lacks comprehensive comparison with a broader range of existing methods.",
        "Limited evaluation on neuromorphic hardware.",
        "Robustness analysis could be more detailed.",
        "Theoretical underpinnings are not as thoroughly explored."
      ],
      "questions": [
        "How does the proposed method compare to other state-of-the-art approaches?",
        "What are the detailed practical benefits on neuromorphic hardware?",
        "How robust are learned delays across a wider range of network architectures?",
        "What are the long-term theoretical implications of the DCLS method?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "4rBEgZCubP",
    "title": "Learning 3D Particle-based Simulators",
    "std_review": {
      "summary": "The paper introduces Visual Particle Dynamics (VPD), a method for long-term video prediction that uses a UNet variant to generate per-pixel latent features, which condition a particle simulation in a defined work space. Experiments show that VPD outperforms baselines in handling long-term dynamics and reducing blurring, as quantified by PSNR metrics. The approach is innovative, achieving superior performance in visual fidelity and dynamic handling. However, its complexity, potential for overfitting, and scalability concerns are noted.",
      "strengths": [
        "Innovative latent feature map for detailed conditioning of particle simulations.",
        "Effective conditioning mechanism linking visual observations to particle dynamics.",
        "Quantitative performance gains with superior PSNR scores over baselines."
      ],
      "weaknesses": [
        "Increased implementation complexity due to novel latent feature map and conditioning mechanism.",
        "Potential for overfitting with detailed per-pixel features.",
        "Scalability concerns not thoroughly tested for large or high-resolution inputs."
      ],
      "questions": [
        "How does the model handle scenarios with limited or non-representative training data to mitigate overfitting?",
        "What is the impact of latent feature granularity on the model's ability to generalize to unseen scenarios?",
        "How can the conditioning set be dynamically adjusted for varying input sizes or resolutions?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "4sGoA7Eih8",
    "title": "Unmasking Transformers: A Theoretical Approach to Data Recovery via Attention Weights",
    "std_review": {
      "summary": "The paper presents a novel inversion attack on transformer models using attention weights and outputs, leveraging a constrained optimization approach to iteratively refine input samples. While theoretically sound and empirically validated across multiple models, the method's computational intensity and reliance on model outputs limit its practical scalability and generalizability. The paper highlights potential privacy risks but does not extensively explore broader implications or mitigation strategies.",
      "strengths": [
        "Innovative approach targeting transformer attention mechanisms.",
        "Solid theoretical foundation with clear convergence guarantees.",
        "Empirical validation across various transformer architectures."
      ],
      "weaknesses": [
        "High computational complexity, especially for large models.",
        "Dependence on availability of model outputs.",
        "Limited generalization across different architectures and training regimes.",
        "Privacy implications not fully explored."
      ],
      "questions": [
        "How can the optimization process be made more computationally efficient for large-scale models?",
        "What are the practical mechanisms for obtaining model outputs in real-world scenarios?",
        "How does the method's effectiveness vary across different transformer architectures and training conditions?",
        "What are the broader privacy and security implications of this attack, and what mitigation strategies can be proposed?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "4SmhpF1nO4",
    "title": "Tabular Deep-SMOTE:",
    "std_review": {
      "summary": "Tabular Deep-SMOTE extends SMOTE with a deep auto‑encoder to generate synthetic samples in a learned latent space, aiming to improve minority class representation. The method introduces a metric‑learning loss and importance‑sampling tailored to the latent representation, showing strong empirical gains on binary tabular datasets. However, it lacks ablation studies, statistical significance testing, and theoretical justification, which reduce confidence in its robustness and generalizability.",
      "strengths": [
        "Integrates deep learning to capture complex relationships in tabular data.",
        "Uses a metric‑learning loss to explicitly separate minority and majority classes.",
        "Adapts SMOTE with importance‑sampling based on latent space geometry."
      ],
      "weaknesses": [
        "Lacks ablation studies to isolate component contributions.",
        "Does not perform statistical significance testing for reported improvements.",
        "Excludes relevant baselines (DAEGO, TAEI) from experimental comparison.",
        "Focuses only on binary datasets, limiting multi‑class evaluation.",
        "Missing theoretical analysis or generalization bounds."
      ],
      "questions": [
        "Could ablation studies clarify the impact of the auto‑encoder, metric‑learning loss, and importance‑sampling?",
        "What statistical tests would be appropriate to validate the reported improvements?",
        "How does the method perform on multi‑class imbalanced datasets?",
        "What theoretical framework justifies the separation of minority classes in the latent space?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "4SrzKsJocx",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a generative linear model to compare intrinsic dimensionality (IDR) and supervised dimensionality reduction (SDR) methods, finding that SDR methods like regularized canonical correlation analysis (rCCA) outperform IDR methods like PCA on synthetic data. The study explores parameter effects on correlation reconstruction, suggesting SDR may be preferable but limited by strong independence assumptions and reliance on synthetic data. Overall, the paper provides valuable insights but its findings may not fully generalize to real-world scenarios.",
      "strengths": [
        "Introduces a novel generative linear model for comparing IDR and SDR methods.",
        "Uses synthetic data to allow controlled exploration of parameter effects.",
        "Provides clear insights into strengths and limitations of IDR and SDR methods."
      ],
      "weaknesses": [
        "Strong independence assumptions in the generative model may limit real-world applicability.",
        "Conclusions based on synthetic data may not generalize to real-world datasets.",
        "Lacks theoretical underpinnings and guarantees for observed method differences."
      ],
      "questions": [
        "How do the findings generalize to real-world datasets with complex, nonlinear relationships?",
        "What are the theoretical guarantees for the observed performance differences between IDR and SDR methods?",
        "How do the generative model's assumptions affect the practical applicability of the proposed methods?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "4stB7DFLp6",
    "title": "InstructRetro: Instruction Tuning post Retrieval-Augmented Pretraining",
    "std_review": {
      "summary": "InstructRetro presents a novel retrieval‑augmented pretraining method for instruction following, where a transformer encoder is removed and retrieval is optimized through instruction‑tuning. The approach leverages a Faiss index with carefully chosen hyper‑parameters, achieving competitive performance on various tasks while being more efficient than full encoder models. The paper is well‑structured, with clear experiments and ablations, though it leaves some open questions about robustness and completeness.",
      "strengths": [
        "Innovative retrieval‑augmented pretraining approach with encoder removal.",
        "Efficient indexing using Faiss with well‑chosen hyper‑parameters.",
        "Strong empirical results on instruction‑following tasks."
      ],
      "weaknesses": [
        "Lack of detailed analysis on the impact of encoder removal.",
        "Limited baseline comparison with state‑of‑the‑art models.",
        "Potential data leakage between training and testing phases."
      ],
      "questions": [
        "How robust is the encoder removal on different instruction‑following datasets?",
        "Could exploring alternative encoder architectures improve performance?",
        "What is the impact of data leakage on the generalizability of the results?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "4u0ruVk749",
    "title": "Dfite: Estimation of Individual Treatment Effect Using Diffusion Model",
    "std_review": {
      "summary": "The paper proposes a diffusion‑based generative model for imputing unobserved confounders in causal inference, aiming to improve treatment effect estimation. The method leverages a reverse diffusion process to generate plausible values for missing variables from observed covariates, showing superior performance on real‑world datasets. While theoretically sound and empirically effective, the paper lacks clarity in how observed variables guide the generation of unobserved confounders and does not fully justify its theoretical assumptions or compare it to other state‑of‑the‑art methods.",
      "strengths": [
        "Flexibility in modeling complex relationships without strong structural assumptions.",
        "Strong theoretical foundation linking the reverse diffusion process to the true data distribution.",
        "Empirical performance that outperforms baseline methods, especially in the presence of unmeasured confounding."
      ],
      "weaknesses": [
        "Lack of clear explanation of how observed covariates are used to infer unobserved confounders.",
        "Theoretical contribution is not fully substantiated by clear conditions for accurate latent recovery.",
        "Hyperparameter choices are not well justified, potentially affecting model performance.",
        "No comprehensive comparison with other advanced methods like TARnet and CFR_MMD."
      ],
      "questions": [
        "How exactly are observed covariates used to guide the generation of unobserved confounders in the diffusion process?",
        "What specific conditions or assumptions ensure the diffusion model accurately recovers true latent confounders?",
        "How does the choice of distance metric and hyperparameters impact the model's performance, and how is this justified?",
        "How does the proposed method compare to other state‑of‑the‑art methods in terms of ITE estimation, especially under varying levels of unmeasured confounding?",
        "What are the key assumptions or conditions under which the unobserved confounders can be accurately inferred from observed variables?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "4Ua4hKiAJX",
    "title": "Locality-Aware Graph Rewiring in GNNs",
    "std_review": {
      "summary": "The paper introduces a novel graph rewiring technique for GNNs that improves connectivity while preserving local structure, addressing the over‑squashing problem. Empirical results on benchmark datasets show significant performance gains over baselines, but the method's novelty and generalizability are limited by limited baseline comparisons and unclear parameter tuning. Overall, the work is promising but requires further validation.",
      "strengths": [
        "Innovative rewiring strategy that enhances connectivity without disrupting the original graph structure.",
        "Preserves local structural information, crucial for tasks with short‑range interactions.",
        "Provides thorough empirical validation across multiple datasets, demonstrating clear performance improvements."
      ],
      "weaknesses": [
        "Limited comparison with other rewiring techniques, potentially undermining perceived novelty.",
        "Parameter sensitivity, particularly the $\rho$ parameter, is not thoroughly explored.",
        "Computational complexity may be a concern for very large graphs.",
        "Effectiveness across diverse graph types and tasks is not fully demonstrated."
      ],
      "questions": [
        "Why must we respect locality in the rewiring process?",
        "How does the choice of the number of walks as a connectivity measure affect the rewiring balance between locality and sparsity?",
        "What are the implications of computing connectivity and locality measures only once versus at each rewiring step?",
        "How does the proposed method compare to other recent rewiring techniques like GTR and BOFR?",
        "What is the impact of the $\rho$ parameter on the trade‑off between preserving the original graph structure and improving connectivity?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "4uaogMQgNL",
    "title": "",
    "std_review": {
      "summary": "The paper introduces UpFusion, a method that uses a 3D NeRF framework to generate novel views from unposed images, addressing pose ambiguity through per-frame alignment and neural mode distillation. While innovative, the approach has several limitations, including unclear evaluation of global consistency, lack of justification for using the DINOv2 backbone, and potential color inconsistencies in generated views. The authors should address these issues to strengthen the method's acceptance.",
      "strengths": [
        "Innovative use of 3D NeRF for capturing and synthesizing novel views.",
        "Effective per-frame alignment mitigates pose ambiguity.",
        "Neural mode distillation efficiently transfers 3D information across views."
      ],
      "weaknesses": [
        "Per-frame alignment may not fully resolve global consistency issues.",
        "Lack of detailed justification for choosing the DINOv2 backbone.",
        "Reliance on the first input image as an anchor introduces scale ambiguity.",
        "Insufficient comparison with pose-optimization and single-image-to-3D baselines.",
        "Potential color inconsistencies in generated views."
      ],
      "questions": [
        "How does the per-frame alignment approach compare to global alignment in terms of overall view consistency?",
        "Why was the DINOv2 backbone specifically chosen over other feature extraction methods?",
        "How does the method handle scale ambiguity when using the first input image as an anchor?",
        "How does the performance of UpFusion compare to pose-optimization and single-image-to-3D baselines?",
        "What strategies can be employed to address the observed color inconsistencies in generated views?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "4UIBysXjVq",
    "title": "Rayleigh Quotient Graph Neural Networks for Graph-level Anomaly Detection",
    "std_review": {
      "summary": "The paper introduces Rayleigh Quotient Graph Neural Networks (RQGNN) for graph-level anomaly detection, leveraging spectral properties to outperform existing methods across various datasets. The approach is theoretically sound, with strong experimental validation, though its generalization to other domains and deeper theoretical exploration of detectable perturbations remain areas for improvement.",
      "strengths": [
        "Innovative use of Rayleigh Quotient to capture spectral characteristics of graphs.",
        "Solid theoretical foundation and justification for anomaly detection.",
        "Superior experimental performance across multiple datasets, including chemical graphs."
      ],
      "weaknesses": [
        "Limited validation on datasets from other domains, such as social networks.",
        "Insufficient exploration of the detectable range of perturbations using the Rayleigh Quotient.",
        "Lack of comprehensive comparison with a broader range of state-of-the-art methods."
      ],
      "questions": [
        "How does RQGNN perform on datasets from domains other than chemistry?",
        "What is the theoretical limit of perturbations that can be detected using the Rayleigh Quotient?",
        "How does RQGNN compare to other recent methods in terms of computational efficiency?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "4UiLqimGm5",
    "title": "",
    "std_review": {
      "summary": "The paper introduces Continuous Activation Mapping (CAM) for neural fields, enhancing expressiveness and training stability while improving rendering efficiency. Experimental results show significant improvements over baselines, demonstrating CAM's potential for various computer graphics and vision applications. The method's strengths include improved expressiveness, training stability, and rendering speed, though it introduces complexity and scalability concerns. Overall, the paper is well-received with strong experimental evidence and clear future research directions.",
      "strengths": [
        "Improved expressiveness and training stability of neural fields.",
        "Enhanced rendering efficiency and speed.",
        "Robustness to input variability."
      ],
      "weaknesses": [
        "Increased model complexity and computational resource requirements.",
        "Potential scalability issues with very large datasets.",
        "Limited experimental baselines compared to the proposed method."
      ],
      "questions": [
        "How does CAM scale to very large datasets?",
        "What are the interpretability implications of the continuous activation mapping function?",
        "How does CAM compare to real-time rendering applications?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "4UP387Adir",
    "title": "",
    "std_review": {
      "summary": "The paper introduces WSNet, a weakly supervised graph neural network that uses community information to improve performance on graphs with noisy labels. It proposes a novel labeling function framework and a community-aware contrastive learning objective, achieving higher accuracy than existing methods, especially under high label noise. The work highlights the importance of incorporating community structure when training GNNs with weak supervision, demonstrating strong scalability and real-world applicability through large-scale experiments.",
      "strengths": [
        "Innovative LF Framework: The paper introduces a systematic way to generate weak labels using multiple labeling functions, which is a practical approach for real-world scenarios where ground-truth labels are scarce.",
        "Community-Aware Contrastive Learning: By integrating community information into the contrastive learning objective, WSNet effectively captures structural dependencies within graph communities, leading to improved performance.",
        "Robustness to High Label Noise: The experiments convincingly show that WSNet maintains high accuracy even when the label noise is substantial (53 % accuracy), demonstrating its robustness.",
        "Scalability: Evaluation on large-scale datasets (OGB, Aminer‑CS) provides strong evidence of WSNet's scalability and its potential for real-world applications."
      ],
      "weaknesses": [
        "Limited Comparison with State-of-the-Art: While the paper compares WSNet to several existing methods, it would benefit from a more comprehensive comparison with recent state-of-the-art graph contrastive learning methods that also handle weak supervision.",
        "Lack of Detailed Reproducibility Guidelines: The methodology section is thorough but lacks explicit reproducibility guidelines, which could hinder efforts to replicate the experiments.",
        "Insufficient Analysis of Label Noise Impact: Although the paper discusses label noise qualitatively, a more detailed analysis of how different levels of noise affect WSNet's performance would strengthen the findings.",
        "Potential Overfitting on Community Structure: The heavy reliance on community information might lead to overfitting, especially on graphs with less pronounced community structures. The paper should discuss this trade-off more explicitly."
      ],
      "questions": [
        "How does WSNet compare to recent state-of-the-art graph contrastive learning methods that also handle weak supervision?",
        "What are the specific reproducibility guidelines that could be provided to facilitate replication of the experiments?",
        "Could a more detailed analysis of how different levels of label noise impact WSNet's performance be included?",
        "How does the method handle graphs with less pronounced community structures to avoid overfitting?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "4VgBjsOC8k",
    "title": "Unveiling the Unseen: Identifiable Clusters in Trained Depthwise Convolutional Kernels",
    "std_review": {
      "summary": "The paper investigates kernel structures in EfficientNet models, revealing distinct DoG filter clusters that influence interpretability and efficiency. It offers valuable insights into DS‑CNN design and performance, though with some limitations. Overall, the work is well‑executed and contributes meaningfully to the field.",
      "strengths": [
        "Innovative analysis of kernel structures using DoG filters.",
        "Clear and reproducible methodology for classifying kernel patterns.",
        "Provides comparative insights with traditional CNNs."
      ],
      "weaknesses": [
        "Scope limited to EfficientNet‑B4 and B6, limiting generalizability.",
        "Lacks quantitative metrics to assess impact on model performance.",
        "Potential for misinterpretation of filter cluster distinctions."
      ],
      "questions": [
        "How do the identified filter patterns generalize to other architectures or datasets?",
        "What quantitative metrics could complement the visual analysis to better understand performance impacts?",
        "How do training dynamics specifically influence the emergence of these filter clusters?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "4VGEeER6W9",
    "title": "Towards Non-Asymptotic Convergence for Diffusion-Based Generative Models",
    "std_review": {
      "summary": "The paper introduces a deterministic sampler for diffusion models based on solving a probability-flow ODE, establishing convergence rates under certain assumptions. It highlights the impact of score-estimation and Jacobian errors, with a d‑dependence in the convergence rate. While novel and theoretically grounded, practical verification of assumptions remains a concern.",
      "strengths": [
        "Introduces a novel deterministic sampler for diffusion models.",
        "Provides a comprehensive convergence analysis with clear assumptions.",
        "Offers insights into the impact of score-estimation and Jacobian errors."
      ],
      "weaknesses": [
        "Assumptions, especially the Jacobian-error assumption, may be hard to verify in practice.",
        "Analysis focuses only on the first step of the diffusion process.",
        "Relies on theoretical metrics like TV and KL divergence for convergence."
      ],
      "questions": [
        "How can the Jacobian-error assumption be practically verified?",
        "What are the convergence guarantees for longer diffusion chains?",
        "Could alternative performance metrics like the Wasserstein distance yield better bounds?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "4VIgNuQ1pY",
    "title": "Stable Neural Stochastic Differential Equations in Analyzing Irregular Time Series Data",
    "std_review": {
      "summary": "The paper introduces Neural Stochastic Differential Equations (Neural SDEs) for modeling irregular time series with noise and drift, proposing three model classes and demonstrating improved performance over traditional models in handling missing data and distribution shifts. While the theoretical analysis provides robustness bounds, practical applicability remains underexplored due to missing details on hyper‑parameter tuning, solver comparisons, computational efficiency, and reproducibility.",
      "strengths": [
        "Introduces versatile Neural SDE classes for complex stochastic processes.",
        "Provides theoretical bounds on model robustness.",
        "Shows empirical improvements over baseline models in handling missing data and distribution shifts."
      ],
      "weaknesses": [
        "Lacks detailed hyper‑parameter tuning information.",
        "Missing ablation studies on numerical solvers.",
        "Does not detail computational efficiency or training time.",
        "Theoretical bounds may not be tight in real-world scenarios."
      ],
      "questions": [
        "Should be clarified: Which hyper‑parameters were tuned for training the Neural SDE models?",
        "Should be clarified: What are the key findings from the ablation studies comparing different solvers?",
        "Should be clarified: What is the computational time and complexity of training Neural SDE models?",
        "Should be addressed: How tight are the theoretical bounds in practical applications?",
        "Should be addressed: Is the implementation code and environment documentation publicly available?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "4vPVBh3fhz",
    "title": "",
    "std_review": {
      "summary": "The paper presents a novel algorithm to mitigate label shift in machine learning models by adjusting importance weights using Gaussian elimination. It demonstrates improved accuracy in dynamic settings but has concerns regarding robustness to extreme shifts and computational efficiency.",
      "strengths": [
        "Effectively addresses label shift with importance weights.",
        "Provides a systematic refinement of weight estimates.",
        "Shows practical benefits in maintaining model accuracy."
      ],
      "weaknesses": [
        "Sensitivity to estimation errors in importance weights.",
        "Lack of mechanisms to mitigate weight estimation inaccuracies.",
        "Computational overhead from Gaussian elimination may limit scalability."
      ],
      "questions": [
        "How robust is the algorithm under extreme label shift conditions?",
        "What mitigation strategies can be employed for estimation errors in importance weights?",
        "How does the algorithm scale with large datasets?"
      ],
      "overall_score": "6: borderline",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "4w4PDIT3h4",
    "title": "",
    "std_review": {
      "summary": "The paper introduces Diverse Data Augmentation (DDA) and Differential Diverse Data Augmentation (D3A) methods that leverage a lightweight segmentation network (Segnet) to generate diverse masks for reinforcement learning agents in the Domain Randomization (DMC) environment. These methods significantly improve the agent's performance and robustness compared to existing object-centric approaches and traditional domain randomization techniques. The reviewer finds the approach innovative and practical, though additional experiments are needed to evaluate its generalizability beyond the DMC environment.",
      "strengths": [
        "Introduces innovative data augmentation techniques (DDA and D3A) that leverage segmentation to generate diverse masks, enhancing the agent's ability to generalize across varied visual conditions.",
        "Utilizes a lightweight segmentation network (Segnet), which is computationally efficient compared to more complex segmentation methods, making the approach practical for real-world applications.",
        "Demonstrates superior performance and robustness of the proposed methods over existing object-centric approaches and traditional domain randomization techniques."
      ],
      "weaknesses": [
        "The paper could benefit from more detailed ablation studies to comprehensively evaluate the impact of different hyperparameters on the performance of DDA and D3A.",
        "Additional experiments or benchmarks are needed to thoroughly evaluate the generalizability of the proposed methods beyond the DMC environment.",
        "The potential overfitting of the pre-trained encoder to the DMC environment is mentioned but not extensively addressed, which could limit the practical applicability of the methods."
      ],
      "questions": [
        "How do the proposed methods perform when applied to other reinforcement learning environments beyond the DMC environment?",
        "What specific ablation studies are planned to evaluate the impact of different hyperparameters on the performance of DDA and D3A?",
        "How can the potential overfitting of the pre-trained encoder to the DMC environment be mitigated to improve the practical applicability of the methods?"
      ],
      "overall_score": "Accept",
      "confidence": "High"
    }
  },
  {
    "paper_id": "4WKDwIaF7y",
    "title": "",
    "std_review": {
      "summary": "The paper introduces EG‑SAM, an extension of SAM that uses an extra‑gradient step to escape saddle points more effectively. Theoretical analysis supports the approach, and experiments show significant performance gains, especially in deep neural networks with many saddle points. While the method is theoretically sound and empirically validated, its practical overhead and broader applicability need further exploration.",
      "strengths": [
        "Clear motivation for using extra‑gradient steps to improve SAM's saddle‑point escape.",
        "Solid theoretical foundation based on infinitesimal step sizes and quadratic loss.",
        "Empirical validation demonstrates substantial performance improvements in challenging scenarios."
      ],
      "weaknesses": [
        "Theoretical guarantees are limited to specific conditions not fully representative of practical training.",
        "The introduction of extra steps increases computational time, potentially limiting scalability.",
        "Lack of extensive real‑world validation beyond theoretical ODE analysis and specific experiments."
      ],
      "questions": [
        "How does EG‑SAM perform on large‑scale training scenarios with non‑quadratic loss functions?",
        "What is the practical computational overhead of EG‑SAM compared to standard SAM?",
        "Can EG‑SAM be integrated with existing deep learning frameworks without significant modifications?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "4WM0OogPTx",
    "title": "Learning from Sparse Offline Datasets via Conservative Density Estimation",
    "std_review": {
      "summary": "The paper introduces Conservative Density Estimation (CDE), an offline RL method that balances exploration and exploitation using an out‑of‑distribution constraint and density estimation. Evaluated on MuJoCo tasks, CDE shows improved robustness to OOD actions and better performance under sparse rewards compared to existing methods. Theoretical analysis provides bounds supporting empirical gains, though practical challenges and scalability concerns remain.",
      "strengths": [
        "Balanced exploration and exploitation through a principled OOD constraint and density estimation.",
        "Strong theoretical guarantees, including importance‑ratio and performance‑gap bounds.",
        "Empirical superiority across multiple MuJoCo tasks, especially in sparse data and reward settings."
      ],
      "weaknesses": [
        "Hyperparameter tuning for the OOD constraint (ε and μ) may be challenging.",
        "Potential scalability issues to high‑dimensional or continuous control problems.",
        "Theoretical bounds may be overly conservative, possibly overestimating robustness."
      ],
      "questions": [
        "How can the OOD constraint parameters be automatically tuned in practice?",
        "What is the impact of CDE on high‑dimensional or continuous control tasks?",
        "Can the theoretical bounds be tightened to better reflect the method's performance?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "4WnqRR915j",
    "title": "Lemma: an open language model for mathematics",
    "std_review": {
      "summary": "The paper introduces Llemma, an open-source language model trained on diverse mathematical datasets, achieving strong performance on benchmarks like MATH and GSM8k. It highlights the benefits of open‑source release and a mixed data approach but lacks detailed training specifics and reproducibility. The reviewer finds the work innovative and valuable for advancing mathematics‑oriented language modeling.",
      "strengths": [
        "Diverse Data Mixture: Combines multiple mathematical datasets to enhance model versatility.",
        "Open‑Source Release: Encourages community participation and accelerates research.",
        "Strong Performance: Outperforms other open‑source models on standard benchmarks."
      ],
      "weaknesses": [
        "Lack of Detailed Training Details: Missing specifics on training objectives, loss functions, and hyper‑parameters.",
        "Limited Comparison with State‑of‑the‑Art Models: Only compares with other open‑source models, not the latest proprietary ones.",
        "Absence of Reproducibility Package: Training process and data release details are insufficient for reproducibility.",
        "Potential Overfitting: Fine‑tuning may limit the model's generalizability to unseen problems."
      ],
      "questions": [
        "Can you provide more details on the training objectives, loss functions, and hyper‑parameters used?",
        "How does the model perform on more recent or challenging mathematical benchmarks?",
        "What steps are being taken to ensure reproducibility of the results?",
        "Are there plans to address potential overfitting issues through additional training techniques?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "4XCfu7fTgw",
    "title": "",
    "std_review": {
      "summary": "The paper introduces Lstd, a novel loss function designed to enhance adversarial robustness by encouraging proportional feature-label distances. Empirical experiments across multiple datasets demonstrate significant improvements over baseline models, supported by theoretical arguments and comprehensive evaluations. While the work is strong, it could benefit from broader performance analysis and clearer explanations of terminology.",
      "strengths": [
        "Introduces a novel loss function (Lstd) that explicitly targets proportional feature-label distances, offering a fresh approach to adversarial training.",
        "Provides a clear theoretical rationale linking proportional distances to improved robustness, grounded in robust statistics.",
        "Demonstrates strong empirical improvements in adversarial robustness across several benchmark datasets.",
        "Includes thorough evaluation with ablation studies and visualizations that support the proposed methodology."
      ],
      "weaknesses": [
        "Focuses primarily on adversarial robustness, potentially overlooking other performance metrics like clean-data accuracy.",
        "Ablation study on the hyperparameter β shows limited variation, which may understate its sensitivity.",
        "Visualizations could be enhanced with additional t-SNE plots for the singular-value loss term and combined loss.",
        "Terminology such as 'FT' (fine-tuning) is used without explicit definition, which may confuse readers."
      ],
      "questions": [
        "How does the proposed Lstd loss affect model performance on clean data compared to adversarial attacks?",
        "Could a broader range of β values be explored to better understand its impact on model robustness?",
        "Would additional t-SNE visualizations for the singular-value loss term and combined loss provide clearer insights?",
        "Is there a clear discussion comparing the approach to existing adversarial training methods or robust statistics literature?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "4y3GDTFv70",
    "title": "A Latent Space Theory for Emergent Abilities in Large Language Models",
    "std_review": {
      "summary": "The paper introduces a novel concept of ε-ambiguity for universal approximators, linking it to neural network training dynamics and SGD optimization. It provides a theoretical framework and explores implications for language modeling, particularly comparing character-based and BPE tokenizers. While the work is theoretically sound, practical and scope limitations suggest a cautious acceptance.",
      "strengths": [
        "Introduces a novel definition of ambiguity that offers fresh insights into the expressiveness of universal approximators.",
        "Provides a clear theoretical framework linking ambiguity to neural network training and SGD, with a well-structured theorem.",
        "Conducts insightful analysis of tokenization methods, highlighting differences between character-based and BPE tokenizers."
      ],
      "weaknesses": [
        "The role of the sampled parameter θ₀ is not clearly defined, which may obscure the theorem's practical applicability.",
        "The theorem's scope is limited to specific neural network architectures and SGD, potentially limiting its generalizability.",
        "Results are based on synthetic data, which may not fully capture the complexities of real-world language data.",
        "The analysis focuses on character-based and BPE tokenizers, potentially overlooking other tokenization methods."
      ],
      "questions": [
        "Clarify the role of θ₀ in the definition of ε-ambiguity and its interpretation as a sampled parameter.",
        "Explain how the proof of Theorem 1 connects to neural network training beyond the stated scope.",
        "Address the implications of using synthetic data for the generalizability of the findings.",
        "Compare the theoretical results and experimental observations between character-based and BPE tokenizers.",
        "Explore how the model's findings can be extended to real-world natural language data, considering tokenization and context handling."
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "4yaFQ7181M",
    "title": "",
    "std_review": {
      "summary": "The paper presents a novel hybrid neural network model that integrates discrete and continuous dynamical systems within a graph neural network framework to simulate fluid dynamics. It effectively handles sparse data and offers interpretability through attention maps, while achieving computational efficiency gains over traditional methods. Despite promising results, the model's complexity and limited real-world validation raise concerns that need addressing.",
      "strengths": [
        "Innovative architecture combining discrete and continuous dynamical systems with GNNs and RNNs.",
        "Effective handling of sparse or missing data through learned latent representations.",
        "Provides interpretability via attention maps to highlight influential factors in predictions.",
        "Achieves significant computational efficiency improvements over traditional simulations."
      ],
      "weaknesses": [
        "The hybrid architecture introduces significant complexity, potentially hindering interpretability and requiring extensive hyperparameter tuning.",
        "Results are primarily validated on synthetic datasets, raising concerns about the model's generalizability to real-world scenarios.",
        "Despite efficiency gains, the model still requires substantial computational resources, which may limit accessibility for some users.",
        "Lack of thorough robustness analysis to hyper-parameter variations could affect practical deployment."
      ],
      "questions": [
        "How robust is the model to variations in hyperparameters, particularly learning rate and batch size?",
        "What strategies can be employed to validate the model's performance on real-world fluid dynamics datasets?",
        "Are there specific techniques to further enhance the interpretability of the model's latent space representations?",
        "How can the model's efficiency be optimized for deployment on resource-constrained devices?"
      ],
      "overall_score": "6: accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "4YESQqIys7",
    "title": "NfgTransformer: Equivariant Representation Learning for Normal-form Games",
    "std_review": {
      "summary": "The NfgTransformer introduces a novel architecture that learns equivariant representations of normal-form games, leveraging their inherent permutation symmetry. Theoretical work establishes that the model's outputs are invariant to player order, and empirical results show improved performance on several game-theoretic tasks. While promising, the approach relies on assumptions about game structure and lacks formal guarantees, limiting its broad applicability.",
      "strengths": [
        "Innovative architecture that explicitly incorporates permutation equivariance.",
        "Strong theoretical foundation leveraging a key property of normal-form games.",
        "Empirical validation demonstrating meaningful representation learning across diverse tasks."
      ],
      "weaknesses": [
        "Relies on the assumption of permutation equivariance, which may not hold for all game structures.",
        "Lacks formal convergence or consistency guarantees for the model.",
        "Empirical scope is limited, potentially overlooking broader applicability."
      ],
      "questions": [
        "What are the formal guarantees for convergence or consistency of the NfgTransformer?",
        "How does the model generalize to non-standard game structures beyond those tested?",
        "Could you provide more detailed implementation specifics for handling invalid joint actions and DISC game generation?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "4YgfwJBJeQ",
    "title": "StructChart: Perception, Structuring, Reasoning for Visual Chart Understanding",
    "std_review": {
      "summary": "The paper introduces Structured Triplet Representation (STR) and StructChart, a two-stage pipeline that enhances the interpretability and understanding of chart images. STR reformats chart data into structured triplets, improving interpretability over linearized CSV formats. StructChart integrates STR with a reasoning model (GPT-3.5) to tackle chart understanding tasks, and introduces the SCRM metric for evaluation, showing superior results compared to benchmarks. The review recommends acceptance with high confidence.",
      "strengths": [
        "STR significantly enhances interpretability by structuring chart data into triplets.",
        "The two-stage pipeline effectively separates perception and reasoning, potentially improving model performance.",
        "SCRM provides a robust evaluation framework tailored for chart understanding tasks."
      ],
      "weaknesses": [
        "Scalability of STR for large and complex datasets is not thoroughly analyzed.",
        "Evaluation relies on a single reasoning model, limiting generalizability.",
        "Potential limitations in handling noisy or incomplete data are not extensively explored.",
        "Comparison with other methods is limited to specific evaluation settings."
      ],
      "questions": [
        "How does the STR approach scale to large and complex datasets?",
        "What are the robustness considerations for handling noisy or incomplete chart data?",
        "How does the performance of StructChart change when evaluated with different reasoning models?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "4YK1e3Ehdy",
    "title": "Understanding Deep Neural Networks as Dynamical Systems: Insights into Training and Fine-tuning",
    "std_review": {
      "summary": "The paper introduces a novel framework for interpreting deep neural networks (DNNs) by mapping them onto dynamical systems, defining a 'dynamical discrepancy' metric that correlates with the network's capacity to capture complex patterns. It provides both theoretical analysis and empirical evidence across vision and language models, demonstrating the metric's practical relevance. While innovative, the paper's novelty is limited by its application of existing dynamical systems theory, and its complexity may hinder accessibility for some readers.",
      "strengths": [
        "Innovative framework for interpreting DNNs as dynamical systems.",
        "Introduces a quantitative 'dynamical discrepancy' metric linking network capacity to internal dynamics.",
        "Strong theoretical foundation with theorems connecting dynamical discrepancy to model expressivity and training stability.",
        "Empirical validation across diverse datasets and architectures supports the practical relevance of the metric."
      ],
      "weaknesses": [
        "Novelty is limited to applying dynamical systems theory to DNNs rather than introducing new theoretical breakthroughs.",
        "Complex mathematical definitions and notation may be challenging for readers without a strong background in dynamical systems.",
        "Empirical studies are limited to specific architectures and datasets, potentially limiting generalizability.",
        "Visualization techniques could be sensitive to noise, leading to potentially misleading interpretations."
      ],
      "questions": [
        "How does the dynamical discrepancy metric compare to existing interpretability tools in terms of interpretability and practical utility?",
        "What are the theoretical guarantees or bounds on the dynamical discrepancy for different types of neural network architectures?",
        "How robust is the dynamical discrepancy to variations in training data, hyperparameters, or model initialization?",
        "Can the framework be extended to analyze the interpretability of other types of neural networks beyond feedforward and recurrent models?"
      ],
      "overall_score": "Accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "4zfbwpGhd8",
    "title": "",
    "std_review": {
      "summary": "The paper introduces VITAL, a method that enhances instruction tuning for efficient fine-tuning of large language models by combining multiple instruction sets. It shows strong performance on benchmarks and offers efficiency gains, but also introduces computational overhead. The novelty of the instruction mixture and clear methodology are highlighted, though scalability and exhaustive baseline comparisons are noted as areas for improvement.",
      "strengths": [
        "Innovative Instruction Mixture: The use of an enhanced instruction mixture is a novel approach that differentiates VITAL from existing methods like LoRA and Adapter.",
        "Efficiency Gains: The method demonstrates significant efficiency gains, particularly in terms of reduced fine-tuning costs.",
        "Strong Benchmark Performance: VITAL achieves competitive results across multiple multimodal benchmarks."
      ],
      "weaknesses": [
        "Computational Overhead: The introduction of an enhanced instruction mixture may increase computational overhead.",
        "Limited Baseline Comparison: The comparison with other recent methods is not exhaustive.",
        "Ablation Studies: While ablation studies are conducted, they could be more comprehensive.",
        "Scalability Concerns: The scalability of the method to very large models or datasets is not thoroughly addressed."
      ],
      "questions": [
        "How does the computational overhead of the enhanced instruction mixture scale with model size?",
        "Could more extensive ablation studies on the instruction generation methods provide clearer insights?",
        "What are the scalability implications of applying VITAL to very large language models?"
      ],
      "overall_score": "Accept",
      "confidence": "High"
    }
  },
  {
    "paper_id": "4znwzG92CE",
    "title": "Habitat 3.0: A Co-Habitat for Humans, Avatars and Robots",
    "std_review": {
      "summary": "The paper introduces Habitat 3.0, a co-habitat system that integrates motion capture data with a physics-based simulator to generate realistic humanoid locomotion. It uses VPoser to convert motion capture data into humanoid poses, which are then simulated for improved realism compared to baseline methods. The approach effectively addresses issues like rigid rotations and straight-line paths, but may still struggle with complex motions and relies on high-quality input data.",
      "strengths": [
        "Effectively combines motion capture data with a physics-based simulator for realistic locomotion.",
        "Utilizes VPoser to generate realistic humanoid poses from motion capture data.",
        "Demonstrates significant improvements in realism over existing methods."
      ],
      "weaknesses": [
        "May still exhibit rigidity in motion, especially during transitions.",
        "Limited ability to handle complex motions beyond simple interpolation.",
        "Dependence on high-quality motion capture data for optimal performance."
      ],
      "questions": [
        "How can the method be extended to handle more complex and varied motion types?",
        "What strategies can be employed to improve the robustness to lower-quality motion capture data?",
        "How can the system be adapted for multi-agent scenarios involving physical collaboration?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "4Zz5UELkIt",
    "title": "",
    "std_review": {
      "summary": "The paper introduces DIA, a method that improves sample efficiency in machine learning by combining influence functions with multi-rejection importance sampling. It provides strong theoretical guarantees and demonstrates significant performance gains on several datasets. While the method is computationally intensive and its generalizability could be further explored, the experimental results are promising.",
      "strengths": [
        "Introduces a novel approach to improve sample efficiency in high-dimensional settings.",
        "Provides strong theoretical guarantees for the proposed estimator.",
        "Demonstrates clear experimental benefits over existing methods."
      ],
      "weaknesses": [
        "Implementation complexity and high computational requirements may limit accessibility.",
        "Lack of detailed discussion on trade-offs between adaptivity and data independence.",
        "Experimental validation is limited to a few datasets."
      ],
      "questions": [
        "How can the method be made more accessible to practitioners with limited computational resources?",
        "What are the practical trade-offs between adaptivity and data independence in DIA?",
        "How do the theoretical guarantees hold in practice for a broader range of datasets?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "4zZFGliCl9",
    "title": "",
    "std_review": {
      "summary": "The paper provides novel theoretical insights into posterior collapse in Conditional Variational Autoencoders (CVAEs) and Hierarchical Linear Variational Autoencoders (MHVAEs), extending previous work on standard linear VAEs. It identifies key hyperparameters and the role of encoder variance in mitigating collapse, offering actionable recommendations for practitioners. The study is well-supported by empirical evidence and contributes to a deeper understanding of latent space dynamics in complex VAE models.",
      "strengths": [
        "Theoretical Contributions: Introduces new conditions for posterior collapse in CVAEs and MHVAEs.",
        "Empirical Validation: Demonstrates the impact of identified hyperparameters and encoder variance.",
        "Practical Implications: Provides actionable recommendations for mitigating collapse in advanced VAE models."
      ],
      "weaknesses": [
        "Complexity of Models: Findings may be limited to complex model architectures.",
        "Empirical Scope: Validation is based on specific model configurations.",
        "Theoretical Rigor: Requires further validation or extension to other model families.",
        "Limited Comparison: Could benefit from broader comparisons with existing models."
      ],
      "questions": [
        "How do the identified hyperparameters generalize to other model architectures beyond CVAEs and MHVAEs?",
        "What is the impact of varying encoder variance on model performance beyond posterior collapse mitigation?",
        "How do the theoretical conditions for posterior collapse compare with empirical observations in practice?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "506Sxc0Adp",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a novel diversity coefficient metric for quantifying the heterogeneity of pre‑training data for large language models (LLMs). The metric is theoretically grounded and validated through experiments showing that higher diversity leads to better LLM performance. While the approach offers valuable insights and practical benefits, it has limitations in generalizability and could benefit from deeper analysis of potential biases.",
      "strengths": [
        "Introduces a novel and theoretically grounded metric for assessing data diversity, crucial for LLM pre‑training.",
        "Provides clear theoretical bounds that contextualize the metric's values and validate its relevance.",
        "Employs robust experimental evidence to demonstrate the correlation between data diversity and LLM performance."
      ],
      "weaknesses": [
        "The metric's reliance on specific theoretical bounds may limit its applicability to diverse datasets across different domains.",
        "Experimental validation is primarily focused on a limited set of datasets, which may not generalize well.",
        "Lacks a detailed discussion on potential biases or limitations in the diversity coefficient."
      ],
      "questions": [
        "How does the metric perform on datasets from different domains beyond those tested?",
        "What are the specific theoretical bounds and how were they derived?",
        "Are there any biases or limitations in the diversity coefficient that could affect its practical use?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "50P9TDPEsh",
    "title": "Critique Ability of Large Language Models",
    "std_review": {
      "summary": "The paper introduces a benchmark to evaluate the critique ability of large language models across math, code, and commonsense reasoning domains. It proposes a self-check baseline that uses LLMs to critique their own outputs, aiming to improve self-critique. Evaluated on GSM8K, TruthfulQA, and HumanEval, the benchmark shows effectiveness in error identification and correction, though some limitations and biases are noted.",
      "strengths": [
        "Comprehensive benchmarking across multiple domains",
        "Innovative self-check baseline for evaluating LLM critique ability",
        "Clear and reproducible evaluation metrics"
      ],
      "weaknesses": [
        "Arbitrary choice of k values without detailed justification",
        "Brief description of prompting strategy lacking specifics",
        "Lack of concrete bias mitigation strategies",
        "Qualitative comparison to baselines without comprehensive empirical analysis"
      ],
      "questions": [
        "Could you provide more details on the justification for selecting specific k values for each task?",
        "What are the exact prompt templates used for generating critiques, and how were they evaluated?",
        "Can you elaborate on the bias mitigation techniques employed and their effectiveness?",
        "How does the self-check baseline compare to other quantitative methods across different tasks?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "50vyPuz0iv",
    "title": "Iteratively Refined Behavior Regularization for Offline Reinforcement Learning",
    "std_review": {
      "summary": "The paper introduces Iteratively Refined Behavior Regularization (IRBR), a method that enhances offline reinforcement learning by adding a KL regularization term to the TD3+BC objective. IRBR improves policy stability and performance by iteratively aligning the behavior policy with the target policy. Empirical evaluations on both toy and D4RL benchmark datasets show significant improvements over baseline methods. While theoretically sound, practical challenges such as computational complexity and robustness to out-of-distribution data remain.",
      "strengths": [
        "Novel approach to refining behavior policies in offline RL",
        "Improved policy stability through KL regularization",
        "Strong theoretical foundation with convergence guarantees"
      ],
      "weaknesses": [
        "Computational and implementation complexity of iterative refinement",
        "Potential impact on sample efficiency and convergence speed not fully explored",
        "Lack of robustness analysis for out-of-distribution queries"
      ],
      "questions": [
        "How does the iterative refinement process affect sample efficiency and convergence speed?",
        "What are the theoretical guarantees for convergence when using function approximation?",
        "How does IRBR perform on more complex and varied tasks beyond the evaluated benchmarks?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "51cjeYcXjs",
    "title": "",
    "std_review": {
      "summary": "The paper introduces DDGs as a program representation for malware similarity analysis, arguing they capture operational semantics and structural characteristics more effectively than traditional graphs. It demonstrates the method on two Trojan samples, showing accurate identification of functionally equivalent code fragments even with obfuscation. The approach balances coarse‑grained search with fine‑grained accuracy, using specific metrics to validate functional overlap. The reviewer finds the method promising, with strong empirical results and a well‑chosen evaluation framework.",
      "strengths": [
        "Enhanced semantic capture through data‑dependency graphs.",
        "Robustness to obfuscation and anti‑debugging techniques.",
        "Fine‑grained similarity detection with adjustable feature resolution."
      ],
      "weaknesses": [
        "Computational complexity and scalability issues in DDG extraction.",
        "Potential information loss during static reverse‑engineering.",
        "Limited generalizability to other malware families."
      ],
      "questions": [
        "How does the method scale to large malware datasets with diverse obfuscation techniques?",
        "What is the impact of information loss during the binary-to-assembly translation on DDG accuracy?",
        "Can the approach be extended to other malware families beyond Trojans?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "52fz5sUAy2",
    "title": "",
    "std_review": {
      "raw_text": "{\n  \"summary\": \"KuaiRec proposes a novel recommendation framework using a custom probability density function (PDF) for personalized item scoring, incorporating kernel-based similarity measures. The approach effectively models local interaction patterns with a mixture of Epanechnikov and Gaussian kernels. While experiments on synthetic and semi-synthetic datasets show improved recommendation quality, the paper lacks detailed justification for kernel choice, clear definitions of key terms, and quantitative validation of neighboring effect modeling. These issues need addressing for broader applicability.\",\n  \"strengths\": [\n    \"Innovative PDF specification for personalized scoring\",\n    \"Flexible kernel selection strategy with clear rationale\",\n    \"Explicit modeling of neighboring effects\"\n  ],\n  \"weaknesses\": [\n    \"Lack of detailed justification for preferring Epanechnikov kernel\",\n    \"Ambiguous definition of neighboring set \\( N_{u,i} \\)\",\n    \"No quantitative validation of neighboring effect modeling\",\n    \"Unclear method for adjusting \\( p \\) to achieve observed sample size\",\n    \"Missing details on recording MAR and MAR watching ratios\"\n  ],\n  \"questions\": [\n    \"Could you provide empirical comparisons or theoretical justification for preferring the Epanechnikov kernel over other kernels?\",\n    \"Please clarify the definition and implementation of the neighboring set \\( N_{u,i} \\)\",\n    \"What quantitative validation was performed on the neighboring effect modeling approach?\",\n    \"Could you detail the method used to adjust \\( p \\) to ensure the observed sample is 5% of the entire matrix?\",\n    \"How are Missing At Random (MAR) and MAR watching ratios recorded and measured?\"\n  ],\n  \"overall_score\": \"4: weak reject\",\n  \"confidence\": \"3: medium\"\n}",
      "parse_error": true
    }
  },
  {
    "paper_id": "52igC7K5Mf",
    "title": "GC-Mixer: A Novel Architecture for Time-varying Granger Causality Inference",
    "std_review": {
      "summary": "GC-Mixer presents a hierarchical causal discovery framework that extends cMLP with a graph-based architecture to capture complex, multi-level dependencies in time-series data. The method improves accuracy and interpretability through iterative fine-tuning across temporal scales, outperforming cMLP and cLSTM on synthetic datasets. However, several methodological issues, such as ambiguous loss function definitions and lack of complexity analysis, need addressing. Overall, the paper shows promise but requires further refinement.",
      "strengths": [
        "Hierarchical causal modeling captures both immediate and long-range dependencies.",
        "Parameter efficiency reduces resource usage compared to cMLP and cLSTM.",
        "Scalability to larger datasets makes it practical for real-world applications."
      ],
      "weaknesses": [
        "Ambiguous loss function in Equation 12 may lead to confusion about its computation.",
        "Threshold selection for Granger causality inference is not clearly derived.",
        "Limited evaluation on nonlinear or non-lag based datasets raises questions about generalizability."
      ],
      "questions": [
        "How is the loss function in Equation 12 computed exactly (averaged or summed across time and series)?",
        "What is the precise method for selecting the threshold ϵ in Equation 13?",
        "How does GC-Mixer perform on nonlinear or non-lag based datasets like Dream-3 or Lotka-Volterra?",
        "What is the computational cost of the multi-level fine-tuning process, and how does it compare to single-level training?",
        "Is manual splitting of data an option, and how does it compare to automatic splitting in terms of performance and parameter requirements?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "532tcx7IHF",
    "title": "RLLTE: Long-Term Evolution Project of Reinforcement Learning",
    "std_review": {
      "summary": "RLLTE introduces a modular RL framework that decouples RL algorithms from the exploitation-exploration trade-off, integrating large language models as a copilot to assist in RL research and application. The framework aims to improve modularity, ease of use, and performance compared to existing RL frameworks, with preliminary results showing enhanced performance and flexibility across various RL tasks. While promising, the paper has some limitations, such as limited benchmarking, integration complexity, scalability concerns, and a lack of detailed implementation guidance.",
      "strengths": [
        "Modularity and decoupling of RL algorithms from the exploitation-exploration trade-off",
        "Integration of an LLM as a copilot to enhance the research and application process",
        "Ease of use, making the framework accessible to researchers and practitioners with varying expertise",
        "Preliminary results indicating improved performance and flexibility compared to existing RL frameworks"
      ],
      "weaknesses": [
        "Lack of comprehensive benchmarking against a wide range of existing RL frameworks",
        "Complexity introduced by the integration of LLMs, which may be challenging for users unfamiliar with LLMs",
        "Potential scalability concerns, especially for very large-scale RL problems",
        "Insufficient detailed implementation guidance for users not familiar with RL or LLMs"
      ],
      "questions": [
        "How does RLLTE perform when benchmarked against a broader set of existing RL frameworks?",
        "What strategies can be employed to simplify the integration of LLMs for users who are not familiar with them?",
        "What measures have been taken to address scalability concerns, particularly for large-scale RL problems?",
        "Could the paper provide more detailed guidance on implementing the framework, especially for users with limited RL or LLM experience?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "53gU1BASrd",
    "title": "Evaluating and Finetuning Models For Financial Time Series Forecasting",
    "std_review": {
      "summary": "The paper introduces a novel evaluation framework for financial time series forecasting using large pre‑trained models, demonstrating superior risk‑adjusted returns compared to traditional baselines. While innovative, the study suffers from limited dataset scope, lack of reproducibility, and omission of alternative architectures and market frictions. These issues reduce the impact of the findings.",
      "strengths": [
        "Innovative use of the Sharpe ratio as the primary performance metric.",
        "Demonstrates the potential of transfer learning with large pre‑trained models.",
        "Provides a comprehensive back‑testing pipeline that includes transaction costs."
      ],
      "weaknesses": [
        "Reliance on web‑scraped data may introduce biases and limit generalizability.",
        "Absence of reproducibility details (open‑sourced code, API dependencies).",
        "Evaluation limited to Transformers, ignoring other architectures.",
        "Omitted consideration of other market frictions (bid‑ask spreads, liquidity)."
      ],
      "questions": [
        "What specific web‑scraping tools and validation methods were used for data collection?",
        "How were transaction costs and slippage modeled in the back‑testing?",
        "Could the evaluation be extended to other market regimes or asset classes?",
        "Are there plans to release the code and dependencies for reproducibility?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "53kW6e1uNN",
    "title": "AFDGCF: Adaptive Feature De-correlation Graph Collaborative Filtering for Recommendations",
    "std_review": {
      "summary": "The paper proposes the Adaptive Feature Decorrelation (AFD) loss function to mitigate over-smoothing and over-correlation in GNNs used for recommendations. It establishes a theoretical link between correlated node embeddings and degraded recommendation quality, and demonstrates significant empirical improvements over existing methods on benchmark datasets. While the approach is innovative and well-supported by theory and experiments, concerns about dataset preprocessing and the potential benefits of integrating with self-supervised learning methods limit its overall acceptance.",
      "strengths": [
        "Clear theoretical foundation linking over-smoothing and over-correlation to recommendation quality.",
        "Innovative AFD loss function that directly addresses feature correlation in GNNs.",
        "Empirical validation showing substantial performance gains on benchmark datasets."
      ],
      "weaknesses": [
        "Dataset preprocessing may introduce bias by excluding less active users/items.",
        "No exploration of integrating AFD with self-supervised learning methods.",
        "Evaluation limited to a few benchmark datasets, potentially limiting generalizability."
      ],
      "questions": [
        "How does the AFD loss function compare to other methods for addressing over-correlation in GNNs?",
        "What are the computational implications of applying AFD to larger, more complex recommendation datasets?",
        "Could integrating AFD with self-supervised learning techniques further enhance recommendation performance?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "5451cIQdWp",
    "title": "On Synthetic Data and Iterative Magnitude Pruning: A Linear Mode Connectivity Study",
    "std_review": {
      "summary": "The paper introduces a novel approach to pruning neural networks using synthetic data derived from distilled models, aiming to create more stable subnetworks. It employs metrics like loss landscape analysis and Hessian approximation to demonstrate that synthetic subnetworks are smoother and generalize better than standard pruning methods. The findings are linked to the information bottleneck framework, suggesting that synthetic pruning leads to more effective information compression. While promising, the approach faces scalability and theoretical rigor challenges, and further work is needed to fully realize its practical benefits.",
      "strengths": [
        "Introduces a novel pruning technique using synthetic data.",
        "Provides comprehensive analysis of loss landscape and stability metrics.",
        "Connects findings to the information bottleneck framework."
      ],
      "weaknesses": [
        "Scalability to larger models is not fully addressed.",
        "Lacks rigorous theoretical substantiation for the IB connection.",
        "Practical retraining of synthetic subnetworks is not explored."
      ],
      "questions": [
        "How does the approach scale to very large models?",
        "What is the theoretical basis for the connection to the information bottleneck?",
        "How can synthetic subnetworks be adapted for specific tasks without extensive retraining?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "54AwQUaDZo",
    "title": "Bounding the Robustness and Generalization for Individual Treatment Effect",
    "std_review": {
      "summary": "The paper introduces RITEWASS and RITEMMD, methods that estimate the counterfactual treatment effect (CATE) using Lipschitz regularization with Wasserstein and MMD metrics. These methods improve robustness and interpretability, outperforming baselines across various datasets and noise levels. While innovative, the paper has theoretical and methodological concerns that need addressing.",
      "strengths": [
        "Introduces a novel approach to CATE estimation using Lipschitz regularization.",
        "Provides strong theoretical foundations with theorems on Lipschitz continuity.",
        "Conducts comprehensive experimental evaluations across diverse datasets and noise levels."
      ],
      "weaknesses": [
        "Raises questions about the definition and necessity of the Lipschitz constant.",
        "Concerns about the Lipschitz constant for the loss and interpretation of covering numbers.",
        "Lacks detailed analysis of performance across different noise levels.",
        "Does not clearly compare methods on original CATE benchmarks without added noise.",
        "Lacks detailed description of hyper-parameter tuning and contains potential clerical errors."
      ],
      "questions": [
        "Clarify the definition and necessity of the Lipschitz constant used in the theorems.",
        "Provide a detailed analysis of method performance across various noise levels.",
        "Compare performance on original CATE benchmarks without added noise.",
        "Detail the hyper-parameter tuning procedure for reproducibility.",
        "Address any clerical errors in mathematical symbols or formulas."
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "55uj7mU7Cv",
    "title": "Towards Identifiable Unsupervised Domain Translation: A Diversified Distribution Matching Approach",
    "std_review": {
      "summary": "The paper presents a novel approach to unsupervised domain translation that tackles content misalignment by using auxiliary variables to eliminate the multiple translation functions (MPA) problem. Empirical results show improved content alignment and sample quality compared to existing methods, supported by a clear theoretical framework for model identifiability. While the identifiability analysis relies on several assumptions and the model assumes invertibility, which may not always hold, the method demonstrates strong promise and outperforms state-of-the-art techniques.",
      "strengths": [
        "Introduces a novel method for addressing content misalignment in unsupervised domain translation.",
        "Proposes the use of auxiliary variables to eliminate the MPA issue, a significant advancement in the field.",
        "Provides a clear theoretical framework for understanding the identifiability of the proposed model."
      ],
      "weaknesses": [
        "The identifiability analysis relies on several key assumptions that may not hold in all scenarios.",
        "The justification for using auxiliary variables is based on theoretical considerations, but practical applicability may be limited.",
        "The proposed model assumes invertibility, which may not always be realistic in practice."
      ],
      "questions": [
        "How robust is the method to violations of the key assumptions underlying the identifiability analysis?",
        "What are the practical implications of the invertibility assumption on the applicability of the proposed model?",
        "How does the method perform on a broader range of datasets beyond those evaluated in the empirical results?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "567BjxgaTp",
    "title": "How to Catch an AI Liar:",
    "std_review": {
      "summary": "The paper introduces a method for detecting lies in language models by using unrelated follow-up questions to probe for inconsistencies. It evaluates the approach across several models and tasks, showing effectiveness in distinguishing truthful from deceptive outputs. While innovative, the method has limitations such as subjective question selection and limited robustness against sophisticated lies.",
      "strengths": [
        "Provides a clear definition of what constitutes a 'lie' from a language model perspective.",
        "Introduces an innovative methodology using unrelated follow-up questions to detect inconsistencies.",
        "Demonstrates robust evaluation metrics and generalization across different models and tasks."
      ],
      "weaknesses": [
        "The selection criteria for unrelated follow-up questions may be too subjective.",
        "Lacks comprehensive benchmarks for evaluation metrics.",
        "Does not fully address robustness against sophisticated or nuanced lies.",
        "Generalization experiments could be expanded to more diverse models and tasks."
      ],
      "questions": [
        "How can the selection criteria for unrelated follow-up questions be made more objective?",
        "What benchmarks or comparisons with existing methods would strengthen the evaluation?",
        "How robust is the method against sophisticated or nuanced lies?",
        "Could the generalization experiments be expanded to include a broader range of language models and tasks?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "56jIlazr6a",
    "title": "Unified Uncertainty Calibration",
    "std_review": {
      "summary": "The paper introduces a unified framework for estimating both aleatoric and epistemic uncertainties in deep learning models, aiming to improve calibration and uncertainty estimation. It proposes a novel calibration function τᵤ and demonstrates strong empirical results on benchmark datasets. While the approach is theoretically sound and empirically validated, concerns about the calibration of τᵤ, the choice of epistemic uncertainty estimator, and the clarity of some theoretical explanations remain.",
      "strengths": [
        "Unified Approach: Presents a single method for estimating both aleatoric and epistemic uncertainties.",
        "Calibration Focus: Emphasizes high calibration accuracy, crucial for reliable model predictions.",
        "Theoretical Foundation: Grounded in a solid theoretical framework with clear definitions."
      ],
      "weaknesses": [
        "Calibration Function Dependency: Unclear if τᵤ itself needs further calibration.",
        "Uncertainty Estimator Requirements: The choice of epistemic uncertainty estimator u is not clearly defined.",
        "Equation Ambiguity: Equation (7) uses τ̃ ambiguously; τᵤ(x) should be used instead.",
        "Interpretation of Non-linearity: The concept of τ̃ᵤ being non-linear is not well-explained."
      ],
      "questions": [
        "Does τᵤ require further calibration when its logits are used for class c+1?",
        "What criteria should be used to select and validate the epistemic uncertainty estimator u?",
        "Should Equation (7) involve τᵤ(x) rather than τᵤ(u(x))?",
        "Can you provide an example of a non-linear τ̃ᵤ, such as a ReLU MLP?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "59nCKifDtm",
    "title": "Improve Temporal Consistency In Diffusion Models through Noise Correlations",
    "std_review": {
      "summary": "ARTDiff introduces an innovative approach to enhance temporal consistency in diffusion models by using an autoregressive temporal prior (ART) with an AR(1) model. The method improves temporal coherence in generated sequences, outperforming existing techniques, especially in complex scenarios. While showing promise, the approach has limitations such as hyperparameter sensitivity and increased computational cost, which may affect its real-time applicability.",
      "strengths": [
        "Introduces a unique combination of autoregressive priors and AR(1) models to address temporal consistency.",
        "Significantly enhances temporal coherence of generated sequences.",
        "Demonstrates broad applicability across different domains like audio and motion."
      ],
      "weaknesses": [
        "Performance is sensitive to hyperparameter choices.",
        "Increased computational complexity may limit real-time use.",
        "Specifically designed for sequential data, requiring modifications for non-sequential data."
      ],
      "questions": [
        "How robust is ARTDiff to highly irregular or rapidly changing dynamics?",
        "What are the computational trade-offs for extending ARTDiff to 3D sequential data like video?",
        "Can the method be adapted for non-sequential data types without significant architectural changes?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "5a79AqFr0c",
    "title": "ControlVideo: Training-free Controllable Text-to-Video Generation",
    "std_review": {
      "summary": "The paper presents ControlVideo, a method for generating long-form videos from text prompts using a cross-frame interaction mechanism to ensure temporal consistency and reduce flickering. It integrates a diffusion-based text-to-video model with cross-frame attention, improving motion coherence and background synchronization. Experiments show superior performance over existing methods, especially in long video generation and handling complex motion patterns. While innovative, the approach has limitations in long-video validation, handling flickering backgrounds, and ensuring reproducibility.",
      "strengths": [
        "Introduces a novel cross-frame interaction mechanism for improved temporal consistency and flickering reduction.",
        "Demonstrates strong quantitative performance over baseline models, particularly in long video generation.",
        "Provides extensive comparisons with Text2Video-Zero, highlighting strengths in pose consistency and handling complex conditions."
      ],
      "weaknesses": [
        "Lacks additional long-video validation results to further demonstrate scalability and robustness.",
        "Does not fully address flickering backgrounds, which could be improved with video-based annotators or smoothing filters.",
        "Struggles with maintaining consistent scene correspondence across frames, leading to potential incoherence.",
        "Lacks assurance of code, models, and data availability, hindering reproducibility.",
        "Does not explore adaptive modifications to input motions based on text prompts."
      ],
      "questions": [
        "Could additional long-video validation results further validate the method's efficacy?",
        "What are potential solutions to improve handling of flickering backgrounds beyond stabilization techniques?",
        "How can the method better address motion correspondence challenges to improve scene coherence?",
        "What steps can be taken to ensure reproducibility and make the code, models, and data publicly available?",
        "How might adaptive modifications to input motions based on text prompts enhance user control and video coherence?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "5AbtYdHlr3",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a novel learning algorithm for stochastic action models (SAM) that handles actions with multiple effects using tensor decomposition. It provides theoretical guarantees under a bounded tensor rank assumption and demonstrates improved learning efficiency and accuracy on synthetic and real-world datasets compared to existing methods. The approach addresses a gap in the literature by explicitly modeling multi-effect actions, offering a significant advancement over prior work focused on single-effect actions. However, the reliance on a small tensor rank may limit its applicability to domains with many effects, and the computational complexity of tensor decomposition could be a bottleneck for large-scale problems.",
      "strengths": [
        "Novel handling of multi-effect actions with tensor decomposition.",
        "Provides theoretical guarantees under bounded tensor rank assumptions.",
        "Demonstrates practical performance gains over existing methods."
      ],
      "weaknesses": [
        "Assumes a small, fixed number of effects per action, limiting applicability.",
        "Introduces computational complexity via tensor decomposition.",
        "Lacks validation across diverse domains.",
        "Performance may be sensitive to the choice of tensor rank."
      ],
      "questions": [
        "How does the algorithm perform on datasets with actions having a large number of effects?",
        "What is the impact of the tensor rank choice on the algorithm's performance and accessibility?",
        "Can the theoretical guarantees be extended to more complex or unbounded scenarios?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "5aHmaMFJns",
    "title": "Reason for Future, Act for Now: A Principled Architecture for Autonomous LLM Agents",
    "std_review": {
      "summary": "The paper proposes a novel architecture that integrates large language models (LLMs) with traditional planning techniques to enhance planning and optimization. It demonstrates improved performance on various tasks compared to conventional methods, highlighting the potential of LLMs in automating complex planning processes. However, the paper lacks detailed information on computational resources, lacks comprehensive comparisons with state-of-the-art methods, and does not quantify the effort spent on prompt tuning.",
      "strengths": [
        "Integrates LLMs with traditional planning to address complex planning problems.",
        "Shows significant improvements in task completion speed and accuracy.",
        "Provides a thorough analysis of computational requirements and robustness across different LLM models."
      ],
      "weaknesses": [
        "Lacks detailed time and resource metrics for learning and execution.",
        "Limited comparison with existing planning and optimization techniques.",
        "Does not quantify the effort and impact of prompt tuning.",
        "Computational resource requirements are not fully detailed, which may limit applicability."
      ],
      "questions": [
        "Can the method be applied in resource-constrained environments?",
        "How does the proposed approach compare to state-of-the-art planning methods?",
        "What is the exact computational cost and time for learning on each task?",
        "How does the choice of LLM model affect the method's performance?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "5BCFlnfE1g",
    "title": "",
    "std_review": {
      "summary": "The paper introduces MetaCLIP, a curated image-text dataset that significantly improves CLIP's performance by filtering and balancing image-text pairs using Wikipedia and WordNet. It outperforms the original CLIP dataset and other high-quality benchmarks in tasks like image-text retrieval and zero-shot classification. The methodology is transparent, reproducible, and could inspire data creation in other domains, though it relies on specific metadata sources and is sensitive to hyper‑parameters.",
      "strengths": [
        "Innovative curation process using Wikipedia and WordNet.",
        "Demonstrated superior performance over existing datasets.",
        "Transparent and reproducible methodology."
      ],
      "weaknesses": [
        "Dependence on specific metadata sources may limit diversity.",
        "High sensitivity to threshold hyper‑parameters.",
        "Randomness in balancing stage can affect reproducibility."
      ],
      "questions": [
        "How does the dataset perform on more diverse or sensitive applications?",
        "What are the long-term maintenance and update strategies for the curated data?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "5bNYf0CqxY",
    "title": "Certified Adversarial Robustness for Rate Encoded Spiking Neural Networks",
    "std_review": {
      "summary": "The paper introduces a novel approach to enhance adversarial robustness in Spiking Neural Networks (SNNs) through rate encoding, establishing a formal connection to randomized smoothing. It proposes an adversarial training method that improves robust accuracy over existing methods, though at the cost of slightly lower clean accuracy. The empirical analysis highlights trade-offs and provides insights into the limitations of current theoretical bounds, making a significant contribution to the field.",
      "strengths": [
        "Establishes a formal connection between rate encoding and randomized smoothing.",
        "Introduces a novel adversarial training method for rate-encoded SNNs.",
        "Provides comprehensive empirical analysis of robustness trade-offs."
      ],
      "weaknesses": [
        "Empirical robustness trade-offs with lower clean accuracy.",
        "Limited details on training parameters and hyperparameters.",
        "Lacks a thorough comparison with the latest state-of-the-art methods.",
        "Insufficient discussion on generalization across attack types."
      ],
      "questions": [
        "Could the proposed method be extended to other types of spiking networks beyond SNNs?",
        "How does the method perform under more sophisticated adversarial attacks?",
        "What are the theoretical limits of the proposed adversarial training method?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "5BoXZXTJvL",
    "title": "Beyond Size: How Gradients Shape Pruning Decisions in Large Language Models",
    "std_review": {
      "raw_text": "{\n  \"summary\": \"The paper introduces GBLM-Pruner, a gradient-based pruning framework for large language models that achieves high sparsity while maintaining performance. It outperforms existing methods on the LLaMA-2-70B model, reducing size and latency with minimal accuracy loss. The innovative pruning metric and demonstrated scalability justify its acceptance.\",\n  \"strengths\": [\n    \"Introduces a novel pruning metric that combines weight magnitude and gradient information.\",\n    \"Achieves high sparsity with minimal accuracy loss, demonstrating practical benefits.\",\n    \"Shows significant improvements in computational efficiency on large models.\"\n  ],\n  \"weaknesses\": [\n    \"Introduces a scaling term that adds complexity and requires hyperparameter tuning.\",\n    \"Lacks comprehensive ablation studies on the impact of the scaling term.\",\n    \"Baseline comparisons are limited to a single model, potentially limiting general applicability.\"\n  ],\n  \"questions\": [\n    \"Could the scaling term \\(\\alpha\\) be optimized using automated hyperparameter search methods?\",\n    \"How does GBLM-Pruner perform on models of different sizes and architectures?\",\n    \"What is the impact of GBLM-Pruner on latency for real-time applications?\"\n  ],\n  \"overall_score\": \"7: accept\",\n  \"confidence\": \"4: high\"\n}",
      "parse_error": true
    }
  },
  {
    "paper_id": "5BXAXOpaWu",
    "title": "Image2Sentence based Asymmetric Zero-shot Composed Image Retrieval",
    "std_review": {
      "summary": "The paper presents ZSCIR, a novel asymmetric text-to-image retrieval approach that leverages a dual-stream architecture to capture semantic relationships between images and texts, achieving superior performance over existing symmetric methods across multiple benchmarks. While promising, the method has limitations such as limited comparison with other asymmetric methods, lack of detailed analysis of text augmentation techniques, and insufficient exploration of t-SNE visualizations. Despite these concerns, the strengths of the approach and empirical evidence justify its acceptance.",
      "strengths": [
        "Introduces a novel text-to-image asymmetry approach in image retrieval, potentially offering improved performance over traditional symmetric methods.",
        "Utilizes a dual-stream architecture that effectively captures semantic relationships between images and texts, enhancing retrieval accuracy.",
        "Demonstrates strong empirical results across multiple benchmarks, showcasing the method's effectiveness.",
        "Provides a comprehensive analysis of the impact of token length on retrieval performance, offering valuable insights into the trade-offs involved."
      ],
      "weaknesses": [
        "Limited comparison with other asymmetric text-to-image retrieval methods, which could provide a more comprehensive evaluation of ZSCIR's performance.",
        "The effectiveness of the text augmentation techniques used to ensure diversity and representativeness of descriptive texts is not thoroughly analyzed.",
        "The t-SNE visualizations, while promising, are not fully explored to provide deeper insights into the feature distributions and separability of the methods.",
        "The explanation for the degradation in retrieval performance with larger token lengths could be more detailed, potentially revealing deeper insights into the underlying causes."
      ],
      "questions": [
        "How does ZSCIR compare to other asymmetric text-to-image retrieval methods?",
        "What specific data augmentation techniques are used to ensure diversity and representativeness of descriptive texts, and how do they impact model performance?",
        "Could deeper analysis of t-SNE visualizations provide additional insights into feature distributions and separability?",
        "What are the underlying causes of the degradation in retrieval performance with larger token lengths, and how can they be mitigated?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "5Ca9sSzuDp",
    "title": "",
    "std_review": {
      "summary": "The paper introduces TextBase, a method for interpreting CLIP models by decomposing attention heads into roles based on a description pool. It demonstrates interpretability gains across zero‑shot classification, retrieval, and segmentation, while also highlighting potential performance trade‑offs. The reviewer finds the method valuable for model debugging and optimization, though it has limitations in human interpretability and computational cost.",
      "strengths": [
        "Decomposes attention heads into interpretable roles using a description pool.",
        "Extensively evaluated across multiple tasks and model variants.",
        "Provides actionable insights for model debugging and optimization."
      ],
      "weaknesses": [
        "Interpretability for non‑experts may still be challenging.",
        "Effectiveness depends on the quality and diversity of the description pool.",
        "Computational overhead may limit scalability."
      ],
      "questions": [
        "How can the method be made more accessible to non‑expert users?",
        "What impact does the size of the description pool have on the robustness of head role assignments?",
        "How does the method's effectiveness vary across different CLIP variants and fine‑grained tasks?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "5CBxA1l5RO",
    "title": "TimewarpVAE: Simultaneous Time-Warping and Representation Learning of Trajectories",
    "std_review": {
      "summary": "TimewarpVAE introduces a variational autoencoder that jointly reconstructs spatial and temporal components of trajectory data, addressing variable-length challenges through a time-warping module. The model shows improved spatial reconstruction when temporal information is integrated, highlighting its potential for motion planning and trajectory prediction. While demonstrating strong performance, the paper acknowledges training complexity and the need for clearer interpretation of the regularization parameter.",
      "strengths": [
        "Joint Spatial-Temporal Modeling: Captures complex dependencies by integrating spatial and temporal information in a single latent space.",
        "Flexibility with Variable-Length Trajectories: Handles varying trajectory lengths without resampling, preserving natural data variability.",
        "Improved Reconstruction Performance: Enhances spatial reconstruction accuracy when temporal dynamics are included."
      ],
      "weaknesses": [
        "Complexity of Training: The time-warping module adds computational complexity, potentially increasing training time and difficulty in hyperparameter tuning.",
        "Interpretation of Regularization Parameter λ: The role of λ in controlling time-warping influence is not always intuitive, complicating model application and fine-tuning.",
        "Limited Comparison with State-of-the-Art: The paper could benefit from a more comprehensive comparison with other temporal-spatial models."
      ],
      "questions": [
        "How does the model's performance compare to other state-of-the-art models that handle temporal-spatial data?",
        "What are the best practices for selecting the regularization parameter λ in practical applications?",
        "Can the model be extended to handle trajectories with additional modalities, such as velocity or acceleration?"
      ],
      "overall_score": "Accept",
      "confidence": "High"
    }
  },
  {
    "paper_id": "5COCYDObes",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a bi-level framework for prompt selection and action in embodied domains, using a learned policy to generate and select prompts and apply them with chain of thought reasoning. The authors demonstrate effectiveness on several tasks, outperforming baselines. While the approach is novel and clear, concerns about formatting, lack of illustrations, and applicability to image observations remain. The reviewers raise questions about performance improvements and learning mechanisms, and suggest further exploration of alternative architectures.",
      "strengths": [
        "Proposes a novel bi-level mechanism for prompt selection and action in embodied domains.",
        "Clear and accessible method that is generally easy to understand.",
        "Effectively uses chain of thought reasoning to improve performance."
      ],
      "weaknesses": [
        "Formatting issues with small spacing between headings and text.",
        "Results would benefit from more illustrations of the process.",
        "Applicability to image observations with text input for LLMs is limited.",
        "Framework may not be suitable for decision-making in embodied domains with image observations."
      ],
      "questions": [
        "Why does the approach improve performance over baselines?",
        "How does the prompt generation policy learn to make the action policy more confident about its decisions?",
        "Is the non-stationarity during training a concern, and how does the alternative training scheme address this?",
        "Would a vanilla PPO use RNN/LSTM/transformer architecture instead of an MLP for POMDP settings?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "5dlfiJIXoh",
    "title": "Structured Video-Language Modeling with Temporal Grouping and Spatial Grounding",
    "std_review": {
      "summary": "The paper presents a novel video‑language pre‑training framework that uses a cut‑and‑paste operation within video clips to improve visual‑text alignment. It introduces a fixed set of group tokens aligned with nouns from video captions via a spatial grounding loss. Experiments show improved performance over older baselines, though spatial‑temporal evaluation is limited. The authors suggest future work to expand spatial‑temporal experiments and refine the method.",
      "strengths": [
        "Innovative intra‑clip temporal grouping loss with cut‑and‑paste.",
        "Dynamic noun‑group token alignment using spatial grounding.",
        "Robust evaluation against older baselines."
      ],
      "weaknesses": [
        "Limited spatial‑temporal evaluation on real‑world datasets.",
        "Potential overfitting with a fixed number of group tokens.",
        "Lack of ablation studies on loss weighting."
      ],
      "questions": [
        "How does the method handle videos with multiple actions or complex scene changes?",
        "What impact does varying the number of group tokens (k) have on performance?",
        "How does the spatial grounding loss compare to other grounding techniques?"
      ],
      "overall_score": "Accept",
      "confidence": "High"
    }
  },
  {
    "paper_id": "5Dwqu5urzs",
    "title": "Physics-Regulated Deep Reinforcement Learning: Invariant Embeddings",
    "std_review": {
      "summary": "The paper introduces Phy-DRL, a framework that integrates a residual physics policy into deep reinforcement learning to ensure safety. It demonstrates improved safety and faster training towards safety in a simulated robotic arm task compared to existing methods. However, the necessity of the physics policy and the completeness of safety guarantees are not fully justified, and some experimental details are lacking.",
      "strengths": [
        "Novel integration of physics into DRL to address safety.",
        "Demonstrated improved safety and faster training in simulations.",
        "Clear comparison with existing approaches highlighting benefits."
      ],
      "weaknesses": [
        "Lack of thorough analysis on the necessity of the residual physics policy.",
        "Limited comparison with non-safety-focused methods.",
        "Potential applicability issues due to state requirements."
      ],
      "questions": [
        "How critical is the residual physics policy for the learning process and safety guarantees?",
        "What are the trade-offs between safety and performance compared to existing methods?",
        "How would the framework perform if the required state cannot be obtained from the environment?",
        "What additional metrics (e.g., sample efficiency, wall-clock time) are needed to fully demonstrate training efficiency?"
      ],
      "overall_score": "Borderline",
      "confidence": "Medium"
    }
  },
  {
    "paper_id": "5e0yWSNGIc",
    "title": "Exposing the Silent Hidden Impact of Certified Training in Reinforcement Learning",
    "std_review": {
      "summary": "The paper introduces an adversarial regularizer designed to train Q-functions that overestimate optimal actions while mis‑ranking sub‑optimal ones, aiming to improve policy safety. Empirical results on several environments show the regularizer induces the desired Q‑function behavior but degrades performance. While the motivation and theoretical framework are clear, the paper lacks formal proofs, comprehensive empirical validation, and thorough analysis of policy impacts. It also fails to compare against baselines, explore mitigations, assess robustness to perturbations, or evaluate scalability.",
      "strengths": [
        "Clear motivation for robust Q-function estimation to prevent sub‑optimal policy selection.",
        "Introduces a novel adversarial regularizer with a fresh theoretical approach to safety constraints.",
        "Demonstrates empirical validation across multiple environments, supporting the regularizer's intended behavior."
      ],
      "weaknesses": [
        "Lacks a formal proof that the regularizer forces the Q-function to overestimate optimal actions and mis‑rank sub‑optimal ones.",
        "Empirical results are limited to a few environments, raising questions about generalization.",
        "Does not quantify the impact on policy performance, only discussing it qualitatively.",
        "Missing baseline comparisons against robustness techniques like double‑DQN.",
        "No exploration of mitigations or trade‑offs for over‑estimation and ranking issues.",
        "Does not connect mis‑rankings to human decision‑making or provide human‑subject studies.",
        "No evaluation of robustness to real‑world perturbations.",
        "Scalability concerns are not addressed, particularly in high‑dimensional settings."
      ],
      "questions": [
        "Can you provide a formal proof that the adversarial regularizer enforces the desired Q-function properties?",
        "How do the observed over‑estimation and ranking issues generalize across a broader set of environments?",
        "What is the quantitative impact of the over‑estimated and mis‑ranked Q-values on policy performance?",
        "How do adversarially trained policies compare against strong baselines in terms of safety and performance?",
        "Are there any proposed mitigations or trade‑offs for the over‑estimation and ranking problems?",
        "How do the mis‑rankings relate to human decision‑making, and can you provide evidence from human‑subject studies?",
        "What is the robustness of the adversarially trained policies against real‑world perturbations?",
        "How does the adversarial regularizer scale to high‑dimensional settings in terms of computational and memory costs?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "5E1HnzEBSf",
    "title": "",
    "std_review": {
      "summary": "The paper introduces Low-Stochastic Surrogate (LSS), a method for federated learning that connects low-loss local minima across clients to improve generalization on non-IID data. Theoretical work provides a novel framework for modeling error landscapes, and empirical results show clear performance gains over standard baselines. While the approach is promising, it introduces additional complexity and lacks some detailed analysis and comparison with the latest methods.",
      "strengths": [
        "Novel theoretical framework modeling connections between local minima.",
        "Empirical validation demonstrates clear performance improvements.",
        "Innovative diversity/affinity terms enhance model robustness."
      ],
      "weaknesses": [
        "Increased implementation complexity and potential for overfitting.",
        "Lack of detailed error landscape analysis.",
        "Limited comparison with state-of-the-art methods."
      ],
      "questions": [
        "How does the diversity term affect computational efficiency compared to the benefits gained?",
        "What is the impact of the affinity term on model generalization?",
        "Could the method be further improved by integrating more recent state-of-the-art techniques?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "5eLgTLusaR",
    "title": "Loco3D: Indoor Multiuser Locomotion 3D Dataset",
    "std_review": {
      "summary": "Loco3D introduces a large-scale multi‑person trajectory dataset generated in VR and a U‑Net planner for predicting smooth, collision‑avoidant trajectories. The dataset is rich and diverse, and the planner outperforms baselines in trajectory quality, though evaluation focuses on collision avoidance rather than complex social interactions. The paper is well‑structured but lacks comprehensive metrics, ethical considerations, and thorough real‑world testing, leading to a weak accept recommendation.",
      "strengths": [
        "Large and diverse multi‑person trajectory dataset in varied VR scenes.",
        "U‑Net architecture effectively generates smooth, realistic trajectories.",
        "Scalable model that generalizes across different datasets without extensive retraining."
      ],
      "weaknesses": [
        "Limited evaluation metrics; primarily qualitative assessments.",
        "Lack of explicit consent information and public availability details for the dataset.",
        "Ethical concerns regarding privacy and re‑identification risks are not fully addressed.",
        "No exploration of real‑world generalization or multi‑person adaptability."
      ],
      "questions": [
        "Should the paper include quantitative metrics like FDE for trajectory accuracy?",
        "What consent procedures were followed for releasing trajectory and pose data?",
        "Where will the dataset be publicly available after the review?",
        "How does the model perform on real‑world datasets with complex scene dynamics?",
        "What are the implications of extending the model to more than two people?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "5EniAcsO7f",
    "title": "Tailoring Retrieval Representations to Long-term Visual Localization",
    "std_review": {
      "summary": "The paper introduces Ret4Loc-HOW-Synth, a novel approach that enhances location-based question answering in visual environments by extending the tuple set and proposing a new loss function. Experimental results show significant improvements in accuracy and efficiency compared to existing methods. The authors also explore the approach's impact on training time and its application to a visual classification task, though the evaluation is limited and some ablation studies are missing.",
      "strengths": [
        "Introduces a novel loss function leveraging an extended tuple set to improve location-based question answering.",
        "Demonstrates significant improvements in accuracy and efficiency compared to existing methods.",
        "Provides a comprehensive evaluation, including analysis of training time impacts."
      ],
      "weaknesses": [
        "The extended tuple set may limit the approach's generalizability.",
        "Lacks a detailed discussion of trade-offs between accuracy and training time improvements.",
        "Evaluation on visual classification is limited to a single dataset.",
        "Does not include a thorough ablation study."
      ],
      "questions": [
        "How does the approach perform on other visual tasks beyond location-based question answering?",
        "What are the specific trade-offs between the extended tuple set and training time improvements?",
        "Could the impact of the extended tuple set be isolated more clearly in the experiments?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "5ep85sakT3",
    "title": "Contextual Bandits with Online Neural Regression",
    "std_review": {
      "summary": "The paper introduces NeuFastCB, a reinforcement learning algorithm that uses KL‑loss for reward approximation, analyzed under the Neural Tangent Kernel framework. It provides theoretical regret bounds tied to network width and offers practical guidance on when to use KL‑loss over squared‑loss. While demonstrating near‑optimal performance in simulations, the approach relies on strong assumptions about reward function realizability and initialization, limiting its broad applicability.",
      "strengths": [
        "Introduces a novel reinforcement learning algorithm (NeuFastCB) using KL‑loss.",
        "Provides rigorous theoretical analysis under the NTK framework with insightful regret bounds.",
        "Offers clear practical recommendations on when to use KL‑loss versus squared‑loss."
      ],
      "weaknesses": [
        "Assumes the reward function can be perfectly interpolated by a neural network.",
        "Results are limited to Gaussian‑initialized networks with full‑rank NTK.",
        "Regret bounds depend explicitly on network width, which may be problematic for deep networks.",
        "Oversized notation (O~) is used without explicit definition."
      ],
      "questions": [
        "How robust is the performance of NeuFastCB when the reward function cannot be perfectly interpolated by a neural network?",
        "What are the implications of the Gaussian initialization and full‑rank NTK assumptions for real‑world applications?",
        "Can the theoretical results be extended to other initialization schemes or network architectures?",
        "How does the choice between KL‑loss and squared‑loss affect performance in high‑dimensional or sparse‑reward settings?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "5ES5Hdlbxw",
    "title": "A Theoretical Explanation of Deep RL Performance in Stochastic Environments",
    "std_review": {
      "summary": "The paper introduces SQIRL, a sample-efficient RL algorithm that reduces the effective horizon by allowing a limited number of sticky actions before resetting. Theoretical analysis and empirical results show SQIRL outperforms PPO in various environments, especially where sticky actions are beneficial. While the approach is innovative and well-supported by experiments, concerns about hyperparameter sensitivity and the theoretical assumptions limit its broad applicability.",
      "strengths": [
        "Introduces a novel method to handle long horizons via k‑QVI solvability, improving sample efficiency.",
        "Provides a solid theoretical foundation with a theorem bounding sample complexity.",
        "Demonstrates strong empirical performance across multiple benchmark environments."
      ],
      "weaknesses": [
        "Does not extensively explore the sensitivity of performance to the choice of k.",
        "Theoretical bound assumes k‑QVI solvability, which may not hold in practice.",
        "Empirical sample complexity improvements do not always align with theoretical predictions.",
        "Lacks comparisons with other state-of-the-art methods beyond PPO."
      ],
      "questions": [
        "How does the performance of SQIRL change with different values of k beyond the minimum k‑QVI‑solvable value?",
        "What are the practical implications of the hyperparameter sensitivity observed in experiments?",
        "How does the theoretical bound in Theorem 3.6 generalize to environments with larger k values?",
        "Can SQIRL be combined with other techniques to further improve sample efficiency in high‑stochastic environments?"
      ],
      "overall_score": "6: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "5EtSvYUU0v",
    "title": "Connecting NTK and NNGP:",
    "std_review": {
      "summary": "The paper introduces the Neural Dynamic Kernel (NDK), a framework that unifies the Neural Tangent Kernel (NTK) and Neural Network Gaussian Process Kernel (NNGP) by incorporating noise into training dynamics via Langevin equations. It derives the NDK through a path-integral formulation, identifying two distinct learning phases and linking the transition between NTK and NNGP to specific time-scale limits. The authors connect their theoretical insights to neuroscience, particularly representational drift, enhancing the practical relevance of the work. While mathematically rigorous, the paper's complexity and limited experimental validation are noted.",
      "strengths": [
        "Novel framework that bridges NTK and NNGP by incorporating noise.",
        "Mathematically rigorous derivation using path-integral formulation.",
        "Provides deep insights into two distinct phases of learning dynamics.",
        "Links theoretical findings to neuroscience, enhancing practical relevance."
      ],
      "weaknesses": [
        "Mathematical derivation may be challenging for readers without advanced background.",
        "Lacks experimental validation to support theoretical claims.",
        "Focus on theoretical aspects may limit appeal to some audiences."
      ],
      "questions": [
        "Could additional experimental studies further validate the NDK framework and its phases?",
        "How can the complexity of the path-integral formulation be made more accessible to a broader audience?",
        "What are the potential implications of the NDK for practical applications in neural network training?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "5Gt68fnttu",
    "title": "Dynamic Electroencephalography Representation Learning for Improved Epileptic Seizure Detection",
    "std_review": {
      "summary": "The paper presents a Dynamic Seizure Network (DSN) that uses a graph neural network to detect epileptic seizure onset in real-time from EEG data. The DSN shows competitive performance on benchmark datasets, outperforming several baselines in detection rate and latency. However, it lacks comprehensive clinical validation and a thorough discussion of model efficiency and limitations, leading to a weak accept recommendation.",
      "strengths": [
        "Innovative use of graph neural networks to capture temporal and spatial dependencies in EEG data.",
        "Real-time processing capability suitable for clinical applications.",
        "Comprehensive evaluation using multiple datasets and metrics."
      ],
      "weaknesses": [
        "Limited clinical validation by clinical experts.",
        "Lack of discussion on computational efficiency and resource requirements.",
        "Insufficient comparison with the latest state-of-the-art models."
      ],
      "questions": [
        "Should the model be validated by clinical experts to ensure reliability?",
        "What are the computational efficiency and resource requirements for practical deployment?",
        "How does the DSN compare with the most recent state-of-the-art models?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "5GX6s5TpmV",
    "title": "The Certification Paradox:",
    "std_review": {
      "summary": "The paper presents a novel method for certifying neural network robustness by combining interval bounding (IBP) with adversarial training, achieving tighter certification bounds compared to existing techniques like randomized smoothing. While the experimental results show competitive performance across various datasets and architectures, the approach struggles with MACER models and may be complex to implement. Overall, the work is innovative but requires further refinement.",
      "strengths": [
        "Introduces a unique combination of IBP with adversarial training to improve certification bounds.",
        "Provides comprehensive experimental evaluations across multiple datasets and model architectures.",
        "Defines clear metrics such as the '%-C' metric, facilitating reproducibility and understanding."
      ],
      "weaknesses": [
        "Implementation complexity may be challenging for practitioners.",
        "Performance variability, especially poor results with MACER models.",
        "Lacks detailed analysis of why the method underperforms in certain scenarios.",
        "Evaluation is limited to a narrow set of attack methods."
      ],
      "questions": [
        "Could the method be adapted to better handle a broader range of adversarial attacks?",
        "What are the specific challenges in integrating IBP with adversarial training that affect implementation?",
        "How can the method's performance with MACER models be improved?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "5h0qf7IBZZ",
    "title": "MiniLLM: Knowledge Distillation of Large Language Models",
    "std_review": {
      "summary": "MiniLLM presents a white‑box knowledge distillation framework for LLMs that improves robustness and generalization by balancing teacher‑student alignment with a regularization term to reduce exposure bias. Experiments show significant gains in response distinctiveness and reduced hallucinations compared to baselines, and a new 4‑gram proportion metric is proposed for evaluating generated responses. While innovative, the approach has some methodological and evaluation limitations.",
      "strengths": [
        "Introduces a clear, white‑box knowledge distillation framework that is interpretable and reproducible.",
        "Effectively reduces exposure bias through a carefully designed loss function.",
        "Demonstrates strong empirical improvements in response quality and distinctiveness across multiple datasets.",
        "Proposes a practical, computationally efficient evaluation metric (4‑gram proportion) as an alternative to GPT‑4 feedback."
      ],
      "weaknesses": [
        "The loss function's multiple terms and the need to tune the weight α may complicate training.",
        "Reliance on GPT‑4 for baseline evaluation raises concerns about overfitting and generalizability.",
        "Evaluation focuses primarily on response distinctiveness and hallucination reduction, without assessing other aspects like factual accuracy or user engagement.",
        "Lack of robustness analysis on adversarial or out‑of‑distribution inputs."
      ],
      "questions": [
        "How does the proposed method scale to larger LLMs and more complex tasks?",
        "What is the impact of the 4‑gram proportion metric on downstream applications compared to Rouge‑L?",
        "Can the approach be extended to other types of generative models beyond LLMs?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "5hAMmCU0bK",
    "title": "Towards Robust Offline Reinforcement Learning under Diverse Data Corruption",
    "std_review": {
      "summary": "The paper introduces RIQL, a method that improves the robustness of imitation learning against data corruption by stabilizing Q-targets with Huber regression and normalizing observations. Empirical results across various corruption scenarios demonstrate significant robustness gains, supported by theoretical analysis. While promising, the study has limitations such as limited corruption scenarios and hyperparameter sensitivity, and could benefit from broader comparisons and more rigorous theoretical justification.",
      "strengths": [
        "Clear identification of heavy-tailed Q-targets as a learning stability issue.",
        "Practical mitigation using Huber regression, which is both novel and effective.",
        "Empirical validation across multiple corruption settings showing robustness improvements."
      ],
      "weaknesses": [
        "Limited data corruption scenarios tested.",
        "Empirical results heavily dependent on specific hyperparameter choices.",
        "Comparison with baselines is limited, lacking diversity in RL algorithms.",
        "Theoretical justification for robustness could be more rigorous.",
        "Explanation of normalization's impact is somewhat vague."
      ],
      "questions": [
        "Could RIQL's robustness be further demonstrated with a broader range of data corruption scenarios?",
        "What is the theoretical basis for the heavy-tailed nature of Q-targets in IQL?",
        "How sensitive are RIQL's performance improvements to hyperparameter choices, and what guidelines can be provided for practitioners?",
        "Would comparing RIQL to a more diverse set of baselines strengthen the argument for its robustness?",
        "How does normalization affect performance in other RL algorithms beyond those in the RIQL framework?"
      ],
      "overall_score": "Accept",
      "confidence": "4"
    }
  },
  {
    "paper_id": "5HCnKDeTws",
    "title": "When Scaling Meets LLM Finetuning:",
    "std_review": {
      "summary": "The paper investigates scaling laws for large language models across translation and summarization tasks, exploring how different finetuning methods interact with model size and data volume. It proposes a multiplicative joint scaling law that captures the interplay between model size, pretraining data, finetuning data, and PET parameter size, demonstrating its predictive power across various setups. While comprehensive and innovative, the study is limited to two translation tasks and one summarization task, and may exhibit overfitting with larger models. The findings are significant but could be further validated with more diverse tasks and larger model scales.",
      "strengths": [
        "Comprehensive experimental design varying model sizes and finetuning methods across multiple tasks.",
        "Innovative multiplicative joint scaling law providing a novel framework for understanding scaling factors.",
        "Detailed hyperparameter analysis enabling reproducibility and comparison.",
        "Clear interpretation of results highlighting differences between translation and summarization tasks."
      ],
      "weaknesses": [
        "Limited scope of tasks focusing only on two translation tasks and one summarization task.",
        "Potential overfitting in larger models, which may skew scaling law conclusions.",
        "Focus on parameter-efficient methods that may have limitations in certain scenarios.",
        "Absence of cross-lingual transfer experiments limiting insights into generalization capabilities.",
        "Extensive computational resources required may limit accessibility for broader research communities."
      ],
      "questions": [
        "How do the scaling laws generalize to other tasks beyond translation and summarization?",
        "What are the implications of the scaling laws for parameter-efficient fine-tuning methods with very large datasets?",
        "How do the scaling laws perform with even larger model sizes (e.g., 16B parameters)?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "5HGPR6fg2S",
    "title": "Normalized Space Alignment: A Versatile Metric for Representation Space Discrepancy Minimization",
    "std_review": {
      "summary": "The paper introduces the Neighborhood Similarity Score (NSA) as a metric for evaluating graph embeddings, aiming to capture how well embeddings preserve local graph structures. NSA is defined based on neighborhood similarity in the embedding space and is demonstrated to correlate with performance on downstream tasks like node classification and link prediction. While the concept is innovative, the paper lacks thorough validation of NSA's robustness to misleading ambient distances and its invariance under isometries, and the method for calculating representations in Section 3.6 is unclear.",
      "strengths": [
        "The NSA definition is intuitive and directly relates to the preservation of local graph structures in the embedding space.",
        "The method provides a clear and interpretable way to assess embedding quality, which is valuable for practitioners.",
        "The experimental results on benchmark datasets are thorough and demonstrate the practical utility of the NSA measure."
      ],
      "weaknesses": [
        "The robustness of NSA to misleading ambient distances, such as those encountered in non-linear embeddings like the Swiss Roll, is not thoroughly addressed.",
        "The invariance of NSA under isometries is assumed but not rigorously proven or demonstrated.",
        "The calculation method for representations in Section 3.6 is not clearly explained, making it unclear whether the NSA is computed for a specific dataset or a batch of graphs."
      ],
      "questions": [
        "How robust is the NSA measure to misleading ambient distances, such as those encountered in non-linear embeddings like the Swiss Roll?",
        "Is the invariance of NSA under isometries rigorously proven or demonstrated?",
        "Could you clarify the method used to calculate the representations in Section 3.6 and whether the NSA is computed for a specific dataset or a batch of graphs?"
      ],
      "overall_score": "Borderline",
      "confidence": "Medium"
    }
  },
  {
    "paper_id": "5HpZZbgdeK",
    "title": "Efficient calibration as a binary top-versus-all problem for classifiers with many classes",
    "std_review": {
      "summary": "The paper proposes a novel method, top-versus-all (TvA), for calibrating classifier outputs in multi-class settings by focusing on the top class probability. It leverages binary calibration techniques on a one-versus-all formulation, demonstrating effectiveness through ECE on various datasets. While computationally efficient, the approach may overlook information from other classes and lacks comprehensive discussion on its practical utility and comparison with other methods.",
      "strengths": [
        "Introduces a computationally efficient calibration method for multi-class classifiers.",
        "Provides a clear theoretical framework and evaluation using Expected Calibration Error.",
        "Demonstrates practical relevance through applications like selective classification."
      ],
      "weaknesses": [
        "Focuses solely on the top class, potentially ignoring useful information from other classes.",
        "Does not fully explore the impact of binning choices on calibration.",
        "Lacks thorough comparison with other calibration methods and discussion on computational cost."
      ],
      "questions": [
        "How does the method perform when the top class is not the most relevant class?",
        "What are the theoretical guarantees of the TvA approach compared to full multi-class calibration?",
        "How does the choice of binning affect the calibration results?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "5iENGLEJKG",
    "title": "Interpreting and Controlling Vision Foundation Models via Text Explanations",
    "std_review": {
      "summary": "The paper presents a method for generating attention maps that improves upon traditional saliency maps by combining gradient-based and feature-based techniques, leading to more accurate and interpretable heatmaps. Experiments on benchmark datasets show significant improvements over standard saliency methods, both qualitatively and quantitatively. The method offers clearer insights into model decision-making, aiding in the development of trustworthy AI systems. While demonstrating strong benefits, the approach's computational complexity and lack of a detailed trade-off analysis are noted.",
      "strengths": [
        "Combines gradient-based and feature-based information for more informative attention maps.",
        "Demonstrates superior interpretability and accuracy over traditional saliency maps.",
        "Provides clear benefits for model debugging and understanding, crucial for trustworthy AI.",
        "Generalizable across different neural network architectures and tasks."
      ],
      "weaknesses": [
        "Higher computational complexity may limit use in resource-constrained environments.",
        "Effectiveness varies with dataset and task, requiring further validation.",
        "Lacks detailed analysis of trade-offs between interpretability and computational efficiency.",
        "Builds on existing techniques rather than introducing a fundamentally new paradigm."
      ],
      "questions": [
        "How does the method perform on large-scale datasets or real-time applications?",
        "What are the specific trade-offs between interpretability and computational efficiency?",
        "Can the method be extended to other types of models beyond vision foundation models?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "5IOKw3AQe4",
    "title": "On the Theoretical Analysis of Dense Contrastive Learning",
    "std_review": {
      "summary": "The paper presents a novel self‑supervised learning framework for dense prediction tasks, using a patch‑level adjacency matrix to capture local spatial relationships and a controllable parameter α to balance positive pair generation and labeling error. While experiments on synthetic datasets show improvements over baselines, real‑world applicability on COCO and ImageNet remains unverified. The proposed metrics are generalizable but their effectiveness across different dense prediction tasks and other contrastive learning methods is not substantiated.",
      "strengths": [
        "Introduces a novel patch‑level adjacency matrix for modeling spatial dependencies.",
        "Provides a controllable parameter α to balance positive pair generation and labeling error.",
        "Proposes generalizable metrics (PCR and patch‑level contrastive loss) applicable beyond PixPro."
      ],
      "weaknesses": [
        "Limited real‑world validation on COCO and ImageNet.",
        "Lacks empirical evidence directly supporting the α trade‑off.",
        "Impact of handling 'meaningless' patches on dense prediction is not thoroughly explored.",
        "Proposed metrics are not empirically validated across different contexts."
      ],
      "questions": [
        "What is the impact of handling 'meaningless' patches on downstream dense prediction tasks?",
        "How does the framework perform on real‑world datasets like COCO and ImageNet?",
        "Can empirical evidence be provided to directly support the trade‑off between positive pairs and labeling error?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "5Itc7v0pnA",
    "title": "Quantile-Free Regression: A Flexible Alternative to Quantile Regression",
    "std_review": {
      "summary": "The paper introduces Quantile-Free Regression (QFR), a novel method for constructing prediction intervals without relying on quantile regression. QFR achieves this by incorporating a regularization term into the loss function, which encourages accurate interval coverage. The authors demonstrate that QFR outperforms traditional methods in terms of interval width and coverage accuracy through experiments on synthetic and real-world datasets. Overall, the paper is well-written and provides a clear motivation, method, and results.",
      "strengths": [
        "The paper presents a novel and innovative approach to regression that addresses the limitations of traditional quantile regression.",
        "The proposed QFR method provides a theoretically sound framework for constructing prediction intervals with desired coverage properties.",
        "The regularization term in the QFR loss function effectively controls the width of the prediction intervals, leading to more accurate and reliable coverage."
      ],
      "weaknesses": [
        "The paper lacks a detailed theoretical analysis of the convergence properties of the QFR method.",
        "The authors do not explore the sensitivity of QFR to the choice of the regularization parameter.",
        "The experiments are limited to synthetic and a few real-world datasets, and the authors do not provide a comprehensive evaluation on a wide range of datasets.",
        "The practical implementation of QFR may require careful tuning of the regularization parameter, which could be a challenge for practitioners."
      ],
      "questions": [
        "Could a more detailed theoretical analysis of the convergence properties of QFR be provided?",
        "How sensitive is QFR to the choice of the regularization parameter, and what are the implications for practical applications?",
        "Would a more comprehensive evaluation on a wider range of datasets from different domains strengthen the paper's claims?",
        "What strategies could be employed to make the practical implementation of QFR more accessible to practitioners?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "5j6wtOO6Fk",
    "title": "Hieros: Hierarchical Imagination on Structured State Space Sequence World Models",
    "std_review": {
      "summary": "The paper introduces a novel hierarchical reinforcement learning method that automatically determines hierarchy depth, improving efficiency in complex environments. It demonstrates improved performance on several Atari games compared to existing methods and includes ablation studies. However, the paper has several weaknesses, including misleading time comparisons, lack of exploration of automatic hierarchy depth, missing error bars in ablation experiments, non-representative ablation environments, and omission of prior work on image reconstruction impacts.",
      "strengths": [
        "Introduces a novel method for automatically determining hierarchy depth in HRL.",
        "Demonstrates improved performance on several Atari games compared to existing HRL methods.",
        "Provides ablation studies to validate the importance of different components."
      ],
      "weaknesses": [
        "Misleading comparison of 0.6 days to 0.5 hours.",
        "No exploration of automatically determining hierarchy depth.",
        "Ablation experiments lack error bars and specified epochs/steps.",
        "Selected ablation environments may not be representative.",
        "Omission of prior work on direct image reconstruction impacts."
      ],
      "questions": [
        "Can the method automatically determine hierarchy depth in more diverse environments?",
        "How do error bars in ablation experiments affect the interpretation of results?",
        "What is the impact of the chosen ablation environments on the generalizability of the findings?",
        "How does the proposed approach compare to prior work addressing direct image reconstruction in pixel space?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "5jcav5RcKw",
    "title": "Jointly Training Large Autoregressive Multimodal Models",
    "std_review": {
      "summary": "The paper presents JAM, a framework for jointly training multimodal models that generate both text and images. It introduces three fusion strategies—Uniform, Width, and Cross—and demonstrates improvements over CM3leon on the MS-COCO dataset, primarily through reduced perplexity. However, the paper acknowledges limitations such as reliance on perplexity alone, increased computational cost, and scalability concerns. Overall, the approach is innovative but requires further evaluation and consideration of broader benchmarks.",
      "strengths": [
        "Introduces a novel framework for jointly training multimodal models.",
        "Provides diverse fusion strategies (Uniform, Width, Cross) to enhance generation.",
        "Empirically validates improvements over existing models using perplexity."
      ],
      "weaknesses": [
        "Relies solely on perplexity, which may not fully capture content quality.",
        "Increased computational cost and model size due to fusion strategies.",
        "Potential scalability issues for larger datasets or complex tasks."
      ],
      "questions": [
        "How do the proposed models perform under different evaluation metrics beyond perplexity?",
        "What are the computational costs and scalability implications of the JAM-Cross approach?",
        "How does the model handle prompts that require complex or variable content?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "5JWAOLBxwp",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a novel method for representing 3D point cloud orientations by embedding them into a higher-dimensional rotation space using carefully chosen rotation matrices. It shows improved performance over traditional spherical harmonics and Fourier features on benchmark datasets, supported by a solid theoretical foundation. While promising, the approach faces practical challenges such as implementation complexity, scalability with dimensionality, and potential overfitting, which are not fully addressed.",
      "strengths": [
        "Innovative feature representation for 3D orientations",
        "Strong theoretical underpinnings linking to geometry and group theory",
        "Demonstrated experimental improvements over existing methods"
      ],
      "weaknesses": [
        "Implementation complexity due to specific rotation matrix construction",
        "Limited discussion on scalability with increasing dimensionality",
        "Potential for overfitting with higher-dimensional representations"
      ],
      "questions": [
        "How does the method scale with increasing dimensionality n?",
        "What strategies are employed to mitigate overfitting in higher-dimensional spaces?",
        "How does the choice of rotation matrices affect the model's ability to generalize to unseen data?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "5jWsW08zUh",
    "title": "Some Intriguing Aspects about Lipschitz Continuity of Neural Networks",
    "std_review": {
      "summary": "The paper investigates the Lipschitz constant of deep neural networks, proposing a method to efficiently estimate a lower Lipschitz bound and demonstrating its reliability during training. Empirical results reveal a double‑descent phenomenon linking the Lipschitz constant to test loss, suggesting that increased model capacity can initially improve generalization despite higher expressivity. The study also explores the influence of label noise and network capacity on Lipschitz behavior, offering insights into model robustness.",
      "strengths": [
        "Proposes a practical and efficient method for estimating the Lipschitz constant, crucial for understanding over‑parameterized models.",
        "Demonstrates a clear double‑descent pattern linking the Lipschitz constant to test loss, challenging traditional generalization bounds.",
        "Conducts thorough experiments across various architectures and datasets, establishing a robust empirical foundation."
      ],
      "weaknesses": [
        "Empirical evaluation is limited to specific architectures and datasets, potentially restricting generalizability.",
        "Lacks thorough theoretical underpinnings for the double‑descent phenomenon, relying primarily on empirical observations.",
        "Does not fully quantify the relationship between the lower Lipschitz bound and the effective Lipschitz constant.",
        "Training dynamics' impact on the lower bound is not explored in depth."
      ],
      "questions": [
        "How does the lower Lipschitz bound evolve during training, and what does this imply about the function’s behavior near the decision boundary?",
        "What are the theoretical implications of the observed double‑descent behavior in both the Lipschitz constant and test loss?",
        "How can the proposed method be extended to other domains beyond the specific architectures and datasets examined?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "5KF3Q79t8B",
    "title": "Learning An Efficient-And-Rigorous Neural Multigrid Solver",
    "std_review": {
      "summary": "The paper introduces UGrid, a neural network-based method for solving PDEs by learning a mapping from coarse to fine grids. It claims faster convergence and improved accuracy, especially on small-scale problems, and provides convergence guarantees based on Theorem 2. However, the method lacks comprehensive scalability analysis, ablation studies, and thorough comparisons with legacy solvers, raising concerns about its broader applicability and robustness.",
      "strengths": [
        "Innovative integration of a learnable UGrid submodule with traditional grid transfer operators.",
        "Potential for improved convergence and solution quality through learned coarse-to-fine mappings.",
        "Provides theoretical convergence guarantees based on Theorem 2."
      ],
      "weaknesses": [
        "Limited scalability analysis for larger problems or complex geometries.",
        "Absence of ablation studies to isolate contributions of individual components.",
        "Convergence guarantees are not fully substantiated by detailed proofs.",
        "Comparison with legacy solvers is limited to small-scale problems.",
        "Lack of discussion on training cost versus inference benefits.",
        "No evaluation of robustness to irregular boundaries, non-uniform meshes, or non-linear PDEs."
      ],
      "questions": [
        "How does UGrid scale to larger problems or more complex geometries?",
        "What are the individual contributions of the UGrid submodule, residual loss, and grid transfer operators?",
        "Can the convergence guarantees be substantiated with detailed proofs?",
        "How does UGrid compare to legacy solvers in terms of speedup and accuracy on larger problems?",
        "What is the impact of the one-time training cost on the overall computational efficiency?",
        "How robust is UGrid to irregular boundaries, non-uniform meshes, or non-linear PDEs?",
        "What are the potential performance improvements on GPU or other hardware accelerators?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "5KUiMKRebi",
    "title": "Implicit Neural Representation Inference",
    "std_review": {
      "summary": "The paper introduces an Integrate‑and‑Release (INR) hypernetwork that uses SIREN activations to generate neural network weights, achieving competitive or superior performance on several image datasets while using far fewer parameters than existing Bayesian deep learning baselines. The authors observe a stationary uncertainty pattern, suggesting kernel‑like behavior, and highlight the INR's parameter efficiency and broad applicability. However, the review notes several concerns regarding input handling, activation choices, model capacity trade‑offs, and the lack of comparison with modern baselines.",
      "strengths": [
        "Innovative hypernetwork architecture leveraging SIREN activations for continuous, differentiable training.",
        "Significant parameter reduction while maintaining or improving accuracy across diverse datasets.",
        "Novel observation of stationary uncertainty, providing new insights into Bayesian deep learning."
      ],
      "weaknesses": [
        "Unclear handling of integer input coordinates, which could affect training dynamics.",
        "Lack of comprehensive comparison of SIREN activations with other alternatives.",
        "Potential model capacity trade‑off not fully explored, with smaller models outperforming larger ones on CIFAR.",
        "Comparison with older Laplace‑based methods rather than more recent techniques."
      ],
      "questions": [
        "How are the tensor coordinate inputs to the INR network normalized or processed (e.g., raw integers vs. [-1, 1] range)?",
        "What is the rationale for choosing SIREN activations over other activation functions, and how do they compare?",
        "Why does a smaller INR model achieve better performance on CIFAR compared to larger variants, and what does this imply about model capacity?",
        "How does the stationary uncertainty pattern compare to that obtained by applying Laplace approximation directly to selected layers of the main network?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "5LhYYajlqV",
    "title": "In-Context Unlearning:",
    "std_review": {
      "summary": "The paper introduces ICUL, a framework for selective forgetting in large language models, demonstrating effectiveness on binary tasks and providing theoretical analysis. While innovative and practical, its scalability, computational overhead, and robustness to noisy data are concerns. The work advances AI accountability but requires further exploration of complex tasks and real-world deployment.",
      "strengths": [
        "Innovative approach to selective forgetting in LLMs",
        "Empirical evidence across multiple binary classification tasks",
        "Theoretical analysis providing formal guarantees"
      ],
      "weaknesses": [
        "Limited validation to binary classification tasks",
        "Potential computational overhead for large datasets",
        "Lack of extensive evaluation on noisy or adversarial inputs"
      ],
      "questions": [
        "How does ICUL scale for real-world applications requiring continuous unlearning?",
        "What are the theoretical guarantees for robustness to noisy or adversarial data?",
        "How does ICUL perform on multi-class or complex NLP tasks beyond binary classification?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "5liV2xUdJL",
    "title": "Time-Efficient Reinforcement Learning",
    "std_review": {
      "summary": "The paper introduces S2PG, a stochastic stateful policy gradient method that improves efficiency and applicability in reinforcement learning by reducing variance compared to BPTT while maintaining computational efficiency. Theoretical analysis and empirical evidence across various tasks demonstrate its benefits, though some limitations in non-Markovian settings and robustness in high-variance environments remain. Overall, the paper is well-received with strong theoretical backing and practical validation.",
      "strengths": [
        "Introduces a stateful policy representation that captures temporal dependencies more effectively than stateless approaches.",
        "Provides theoretical analysis that enhances understanding of the method's validity and applicability.",
        "Demonstrates empirical validation across multiple tasks, showing improved performance and reduced computational burden compared to BPTT."
      ],
      "weaknesses": [
        "Theoretical assumptions, particularly the Markovian nature of the environment, may limit applicability in non-Markovian settings.",
        "Limited empirical evidence on robustness in environments with high variance or complex state spaces.",
        "Initialization of policy states could be more thoroughly explored for better convergence and performance."
      ],
      "questions": [
        "How can the method be adapted for non-Markovian environments?",
        "What guidelines can be provided for initializing policy states to enhance convergence and performance?",
        "How robust is S2PG in environments with high variance or complex state spaces?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "5Lp6qU9hzV",
    "title": "Multiscale Positive-Unlabeled Detection of AI-Generated Texts",
    "std_review": {
      "summary": "The paper introduces a novel approach to detecting AI-generated short texts using a modified MPU architecture. It highlights the challenges of short text detection and provides insights into the impact of text length on model performance. While showing promise, the paper has several weaknesses, including a lack of detailed explanations for the detection challenges and limited evaluation on long texts. The proposed method's effectiveness on extremely long texts is also unclear.",
      "strengths": [
        "Introduces a novel approach to address the challenge of detecting short text using a modified MPU architecture.",
        "Provides a comprehensive analysis of the impact of text length on model performance.",
        "Compares the proposed method against state-of-the-art baselines, showcasing its effectiveness."
      ],
      "weaknesses": [
        "Lacks a detailed explanation of the specific factors contributing to the difficulty of detecting short text.",
        "The variation of π̃ with respect to text length is not thoroughly explored or justified.",
        "The performance gap between BERT-MPU and Roberta-MPU on short text is not adequately explained or hypothesized.",
        "The impact of the proposed method on the performance of extremely long texts is not clearly demonstrated.",
        "Does not provide a comprehensive evaluation of the proposed method across different datasets or domains."
      ],
      "questions": [
        "What are the specific factors contributing to the difficulty of detecting short text?",
        "Why does the variation of π̃ with respect to text length occur, and how can it be justified?",
        "What could be the reasons for the performance gap between BERT-MPU and Roberta-MPU on short text?",
        "How does the proposed method perform on extremely long texts, and what are the implications?",
        "What additional datasets or domains should be evaluated to assess the generalizability of the proposed method?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "5M2MjyNR2w",
    "title": "Adaptive Expansion for Hypergraph Learning",
    "std_review": {
      "summary": "AdE introduces an adaptive hypergraph expansion framework that learns optimal graph structures for specific tasks, leveraging a distance-aware kernel to capture complex high-order interactions. The method shows strong empirical performance, especially on datasets with high heterophily, and is supported by a solid theoretical foundation. Overall, the paper makes significant contributions to hypergraph learning.",
      "strengths": [
        "Adaptive Hypergraph Expansion: AdE dynamically learns the optimal hypergraph structure for each task, offering a significant advantage over static hypergraph expansion methods.",
        "Distance-Aware Kernel: The use of a distance-aware kernel allows AdE to capture nuanced relationships between node pairs, enhancing the model's ability to represent complex interactions.",
        "Theoretical Foundation: The paper provides a solid theoretical basis for the proposed method, including proofs of convergence and optimality under certain conditions.",
        "Empirical Performance: AdE outperforms existing baselines on several datasets, particularly in challenging scenarios with high heterophily, demonstrating its practical utility."
      ],
      "weaknesses": [
        "Complexity of Implementation: The adaptive nature of AdE may introduce implementation complexity, potentially making it less accessible to practitioners unfamiliar with advanced hypergraph learning techniques.",
        "Scalability Concerns: While the theoretical framework is sound, the practical scalability of AdE for very large graphs remains an open question, as the time complexity could become prohibitive in extreme cases.",
        "Limited Datasets: The empirical evaluation focuses on a limited set of datasets, which may not fully capture the method's performance across all types of hypergraphs and applications."
      ],
      "questions": [
        "How can the implementation complexity of AdE be mitigated to make it more accessible to practitioners?",
        "What are the scalability strategies to ensure AdE remains efficient for very large graphs?",
        "Could the evaluation be expanded to include a broader range of datasets to better assess the method's generalizability?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "5MlPrLO52d",
    "title": "Neural Tangent Kernels for Axis-Aligned Tree Ensembles",
    "std_review": {
      "summary": "The paper introduces the Non‑Oblivious Tree Kernel (NOTK) for capturing both non‑oblivious and oblivious tree structures, showing empirical advantages of axis‑aligned inverted trees over axis‑aligned trees on tic‑tac‑toe. While theoretically interesting, the results are limited to a single dataset and lack comprehensive baseline comparisons, statistical significance analysis, and detailed practical feasibility considerations.",
      "strengths": [
        "Introduces a novel kernel (NOTK) tailored for non‑oblivious trees, providing a theoretical framework to unify both non‑oblivious and oblivious tree representations.",
        "Demonstrates practical benefits through empirical comparisons on a single dataset (tic‑tac‑toe), showing improved performance of AAI over AAA and a shallow random forest.",
        "Offers insights into the training dynamics of tree ensembles, suggesting that the NOTK can capture complex tree structures effectively."
      ],
      "weaknesses": [
        "Theoretical results of Proposition 2 are limited to the infinite‑tree limit, which may not directly translate to practical applications with finite‑tree ensembles.",
        "Experiments are restricted to a single dataset (tic‑tac‑toe), raising concerns about the generalizability of the findings to other domains.",
        "The comparison with baselines, particularly the shallow random forest, lacks a comprehensive evaluation against more modern ensemble techniques.",
        "The claim that feature selection is unimportant for AAI is not substantiated when considering non‑oblivious tree architectures.",
        "The application of Multiple Kernel Learning (MKL) is theoretically explored but lacks detailed computational cost analysis.",
        "Theoretical assumptions (e.g., soft trees, gradient descent) may not directly translate to real‑world model training scenarios."
      ],
      "questions": [
        "How do the NOTK‑based methods perform on a broader range of datasets beyond tic‑tac‑toe?",
        "What is the statistical significance of the performance gains observed for AAI compared to AAA and shallow random forests?",
        "How does the NOTK compare to more modern ensemble techniques like Gradient Boosting in terms of both performance and computational cost?",
        "What are the practical implications of the NTK framework allowing non‑zero initialized split features to become zero during training?",
        "How can the insights from the NOTK be translated into concrete design guidelines for building more effective tree models in practice?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "5mtwoRNzjm",
    "title": "",
    "std_review": {
      "summary": "The paper introduces ΨBR, a novel stochastic optimization algorithm for constrained problems that avoids explicit infeasibility checks. It leverages a barrier function to maintain feasibility while handling large datasets efficiently. Theoretical and empirical results show improved performance, especially in high dimensions, though the algorithm's practical usability and robustness are limited by unclear step‑size selection, lack of detailed comparisons, and weak convergence guarantees.",
      "strengths": [
        "Introduces a barrier function‑based stochastic optimization method for constrained problems.",
        "Demonstrates strong performance on large‑scale problems, making it suitable for big data applications.",
        "Provides clear guidelines for step‑size and parameter tuning, enhancing usability."
      ],
      "weaknesses": [
        "Lacks detailed guidelines or systematic procedures for selecting the stepsize η.",
        "Does not provide a thorough comparison or theoretical justification for ΨBR's performance over ΨB.",
        "Computational cost is higher due to inverse computations required by ΨBR.",
        "Convergence results are described as weak with no practical upper bounds for η.",
        "Does not address parameter sensitivity to ω, affecting robustness.",
        "Fails to compare ΨBR with other state‑of‑the‑art methods."
      ],
      "questions": [
        "What systematic procedure should be used for selecting the stepsize η in practice?",
        "How does ΨBR's performance compare to ΨB, and what theoretical justification supports ΨBR's superiority?",
        "What are the practical implications of the higher computational cost of ΨBR due to inverse computations?",
        "How sensitive is ΨBR to the choice of ω, and what typical values are recommended?",
        "How does ΨBR compare to other modern methods like Multiplier Correction Methods or Gram‑Schmidt‑based approaches?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "5nEmi3YIz4",
    "title": "",
    "std_review": {
      "summary": "The paper presents a method to interpret neural network predictions by decomposing learned representations into interpretable latent prototypes using non-negative matrix factorization (NMF). These prototypes are visualized to provide insights into the model's decision-making process, and the method is evaluated on several image classification tasks, demonstrating its ability to highlight relevant features and improve interpretability. The reviewer finds the method promising, with strong empirical evidence supporting its effectiveness, though some limitations are noted.",
      "strengths": [
        "Leverages NMF to decompose NN representations into interpretable latent prototypes.",
        "Provides clear visualizations of prototype contributions for human-readable interpretation.",
        "Applicable to a wide range of NN architectures, making it a versatile tool for interpretability."
      ],
      "weaknesses": [
        "Reliance on NMF may introduce artifacts or suboptimal decompositions.",
        "Performance depends on the quality of NMF decomposition, which can be sensitive to initialization and hyperparameters.",
        "Reconstruction quality of images from prototypes may not always align perfectly with the original images.",
        "Interpretability limited to decomposed prototypes, potentially missing other relevant features."
      ],
      "questions": [
        "How robust is the method to variations in initialization and hyperparameters of NMF?",
        "Can the method be extended to other types of neural network architectures beyond image classification?",
        "What is the impact of residual prototypes on the interpretability and accuracy of the model?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "5NJzNAXAmx",
    "title": "Informed POMDP: Leveraging Additional Information in Model-Based RL",
    "std_review": {
      "summary": "The paper introduces an informed POMDP framework that leverages additional information alongside standard observations in model-based RL, extending asymmetric learning approaches. It provides a theoretical foundation using sufficient statistics and demonstrates significant empirical improvements in convergence speed and performance across several environments. The authors clearly delineate their contributions, highlighting the practical benefits of informed learning, while also noting some limitations and future research directions.",
      "strengths": [
        "Novel informed POMDP framework that systematically incorporates additional information into model-based RL.",
        "Strong theoretical foundation using sufficient statistics, grounded in recent information theory literature.",
        "Empirical validation showing substantial improvements over uninformed baselines in various environments."
      ],
      "weaknesses": [
        "Relies on ELBO as the learning objective, which may not fully capture the benefits of additional information.",
        "Variational encoder conditioning on both observation and additional information could complicate learning.",
        "Potential scalability issues in high-dimensional or complex environments."
      ],
      "questions": [
        "How robust are the improvements to the choice of additional information sources?",
        "Can the framework be extended to handle more complex or dynamic additional information?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "5nM2AHzqUj",
    "title": "Linear Log-Normal Attention with Unbiased Concentration",
    "std_review": {
      "summary": "The paper introduces Linear Log-Normal Attention (LLN Attention), a novel attention mechanism that improves efficiency and scalability by using a log-normal distribution for attention weights, achieving linear time complexity. Empirical evaluations show competitive performance on NLP tasks with reduced memory usage and computational costs. Theoretical analysis highlights advantages over softmax attention, but the paper has limited exploration of other domains and lacks comprehensive comparative analysis.",
      "strengths": [
        "Theoretical advantages over softmax attention, including improved distributional properties and computational efficiency.",
        "Linear time complexity enables scalability to larger models and datasets.",
        "Significant reduction in memory usage makes the attention mechanism more feasible for resource-constrained devices.",
        "Empirical evidence demonstrates competitive or superior performance on standard NLP tasks."
      ],
      "weaknesses": [
        "Limited exploration of LLN Attention's performance in domains beyond NLP.",
        "Insufficient analysis of the temperature parameter's influence on performance.",
        "Comparative analysis is limited to other linear attention methods, not a broader range of models and datasets.",
        "Potential generalizability to other neural network architectures or tasks is not fully addressed."
      ],
      "questions": [
        "How does LLN Attention perform on a broader range of tasks beyond NLP, such as computer vision?",
        "What is the optimal temperature parameter for LLN Attention in different scenarios?",
        "How does LLN Attention compare to other state-of-the-art linear attention methods across diverse model architectures?",
        "What are the theoretical guarantees for convergence and stability of LLN Attention in large-scale models?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "5Nn2BLV7SB",
    "title": "PandalM: An Automatic Evaluation Benchmark for LLM Instruction Tuning Optimization",
    "std_review": {
      "summary": "The paper introduces PandaLM, a method for optimizing large language models (LLMs) through hyperparameter tuning and early stopping. It demonstrates effectiveness across various models and domains, showing improved model quality and reduced evaluation costs. The study explores PandaLM's generalization and scalability, providing insights into its robustness. While the paper is well-structured and presents compelling results, it lacks detailed results for optimal perplexity models and a clear comparison with other state-of-the-art methods.",
      "strengths": [
        "Introduces a novel approach to optimizing LLMs through hyperparameter tuning.",
        "Demonstrates strong performance across multiple models and domains.",
        "Provides insights into PandaLM's generalization and scalability."
      ],
      "weaknesses": [
        "Lacks detailed results for models selected based on optimal perplexity.",
        "Potential overfitting concerns with 'seen' models in the dataset.",
        "Does not compare PandaLM's performance with other state-of-the-art methods.",
        "Limited exploration of generalization to unseen models."
      ],
      "questions": [
        "Could PandaLM's performance be further validated with detailed results for models selected based on optimal perplexity?",
        "How does PandaLM's performance compare to other state-of-the-art methods in hyperparameter optimization?",
        "What are the implications of PandaLM's generalization capabilities on unseen models like LLaMA-2-7B?",
        "How does the early stopping strategy impact the evaluation of PandaLM's performance across different domains?"
      ],
      "overall_score": "Accept",
      "confidence": "High"
    }
  },
  {
    "paper_id": "5o9G4XF1LI",
    "title": "Goodhart's Law in Reinforcement Learning",
    "std_review": {
      "summary": "The paper introduces a novel metric called 'angle' to evaluate reinforcement learning algorithms by measuring alignment between learned and target policies. It provides theoretical analysis and empirical evidence across various environments, demonstrating the metric's effectiveness. While promising, the metric's sensitivity to target policy choice and limited analysis in high-dimensional spaces are concerns. The authors should address these issues and explore alternative metrics for broader applicability.",
      "strengths": [
        "Introduces a novel metric ('angle') that offers a more comprehensive view of policy quality.",
        "Provides theoretical analysis and empirical evaluations supporting the metric's effectiveness.",
        "Conducts clear ablation studies highlighting the metric's impact on algorithm performance."
      ],
      "weaknesses": [
        "The 'angle' metric may be sensitive to the choice of target policy, introducing subjectivity.",
        "Lacks analysis of metric behavior in high-dimensional, continuous state-action spaces.",
        "Empirical evaluations are limited to a few benchmark environments, raising questions about generalization.",
        "Theoretical analysis assumes a specific reward function form, potentially limiting applicability."
      ],
      "questions": [
        "How does the 'angle' metric generalize to high-dimensional, continuous state-action, and long-horizon problems?",
        "What is the impact of choosing different target policies on the metric's performance?",
        "How does the metric compare to alternative metrics like Wasserstein distance or Maximum Mean Discrepancy in capturing policy alignment?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "5oJlyJXUxK",
    "title": "",
    "std_review": {
      "summary": "The paper presents a novel framework for probing and intervening in deep neural networks to gain interpretability and control. It defines a systematic method for selecting intermediate layers, optimizing intervention vectors, and choosing concepts for intervention. Empirical results show effective modification of model behavior while preserving performance, with potential applications in fairness, robustness, and explainability. The reviewer finds the approach theoretically sound and practically useful, though with some limitations.",
      "strengths": [
        "Clear and novel framework for probing and intervening in DNNs.",
        "Theoretically grounded with well-defined procedures.",
        "Empirical results demonstrate effective modification of model behavior.",
        "Comprehensive analysis of computational cost and practical implications."
      ],
      "weaknesses": [
        "Effectiveness evaluated on a limited set of datasets.",
        "High computational cost for large models.",
        "Lack of detailed analysis of trade-offs between intervention effectiveness and cost.",
        "Insufficient discussion of limitations and future research directions."
      ],
      "questions": [
        "How does the method generalize to other domains or model architectures?",
        "What are the trade-offs between intervention effectiveness and computational cost?",
        "Are there specific scenarios where the method is particularly beneficial or ineffective?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "5pKLogzjQP",
    "title": "Purify Perturbative Availability Poisoning Attacks via Rate-Constrained Variational Autoencoders",
    "std_review": {
      "summary": "The paper proposes a defense mechanism for Variational Autoencoders (VAEs) against poisoning attacks by purifying the training dataset using an auxiliary decoder and class-wise embeddings. The method effectively detects and removes poisoned samples, improving robustness and performance compared to baselines. However, it is limited by its reliance on predefined embeddings, which may not generalize to novel attacks, and incurs additional computational costs. Overall, the approach shows promise but has notable limitations.",
      "strengths": [
        "Introduces a novel defense mechanism that leverages class-wise embeddings to purify poisoned datasets.",
        "Seamlessly integrates with existing VAE architectures without major modifications.",
        "Demonstrates empirical effectiveness and robustness across various poisoning scenarios."
      ],
      "weaknesses": [
        "Limited generalization to novel poisoning attacks not covered by the class-wise embeddings.",
        "Increased computational overhead due to additional forward propagations through the VAE and auxiliary decoder.",
        "Potential vulnerability to sophisticated attacks like those generated using white-box techniques."
      ],
      "questions": [
        "How does the defense perform against novel poisoning attacks not included in the class-wise embeddings?",
        "What is the impact of the additional computational cost on real-time applications?",
        "Can the method be extended to better handle sophisticated adversarial attacks?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "5RielfrDkP",
    "title": "Learning Adaptive Multiresolution Transforms via Meta-Framelet-based Graph Convolutional Network",
    "std_review": {
      "summary": "The paper introduces MM-FGCN, a novel graph neural network that combines spectral graph theory with meta-learning to adaptively construct multiresolution transforms. It shows significant improvements on several benchmark datasets, enhancing both flexibility and efficiency. However, the model's complexity and limited dataset coverage are notable concerns.",
      "strengths": [
        "Innovative integration of spectral graph theory with meta-learning.",
        "Adaptive multiresolution transforms improve performance on diverse graph structures.",
        "Demonstrated superior results on node and graph classification tasks."
      ],
      "weaknesses": [
        "High implementation complexity due to the combined spectral and meta-learning approaches.",
        "Limited evaluation on a diverse set of benchmark datasets.",
        "Lack of comprehensive ablation studies to quantify the impact of meta-learning."
      ],
      "questions": [
        "What are the computational costs of training and inference for MM-FGCN compared to existing methods?",
        "How does the model perform on a wider range of graph datasets beyond the current benchmarks?",
        "Could additional ablation studies provide clearer insights into the role of meta-learning?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "5rrYpa2vts",
    "title": "EA\\({}^{2}\\)N: Evidence-based AMR Attention Network for Fake News Detection",
    "std_review": {
      "summary": "The paper introduces EA2N, a novel fake news detection model that leverages Abstract Meaning Representation (AMR) graphs and external knowledge from WikiAMR. It effectively integrates evidence from multiple sources into a graph-based framework, improving semantic relationship capture. Experiments on Politifact and Gossipcop datasets show significant improvements over existing methods, highlighting the model's effectiveness. However, concerns about scalability and reliance on external knowledge quality limit its broad acceptance.",
      "strengths": [
        "AMR provides a more nuanced representation of semantic relationships compared to dependency trees.",
        "Efficiently incorporates external knowledge from WikiAMR, enhancing contextualization and detection accuracy.",
        "The WikiAMR graph significantly improves interpretability and reliability by providing a structured knowledge base."
      ],
      "weaknesses": [
        "Scalability concerns due to extensive graph construction and evidence integration.",
        "Effectiveness heavily dependent on the quality and comprehensiveness of external knowledge in WikiAMR.",
        "Limited evaluation beyond Politifact and Gossipcop datasets."
      ],
      "questions": [
        "How does the model handle scalability when dealing with very large datasets or real-time applications?",
        "What mechanisms are in place to ensure the quality and comprehensiveness of external knowledge from WikiAMR?",
        "How does EA2N perform on additional datasets beyond Politifact and Gossipcop?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "5RUf9nEdyC",
    "title": "Teddy: Trimming Edges with Degree-based Discrimination Strategy",
    "std_review": {
      "summary": "The paper introduces TEDDY, a method that combines graph sparsification, model distillation, and parameter sparsification to train efficient neural networks. It shows improved generalization and reduced training time compared to conventional approaches. While the approach is novel and has clear theoretical backing, concerns remain about the theoretical justification for removing low-degree edges and the need for additional results to validate computational savings.",
      "strengths": [
        "Introduces a novel approach to training efficient neural networks by combining multiple techniques.",
        "Demonstrates improved generalization and reduced training time compared to conventional methods.",
        "Provides a clear theoretical basis for the proposed methods and their impact on generalization error."
      ],
      "weaknesses": [
        "Relies on random sampling for graph sparsification, which may introduce training-related noise.",
        "Theoretical basis for the impact of removing low-degree edges on generalization error is not fully explored.",
        "Distillation training step may undermine the purpose of using sparse graphs.",
        "Additional results are needed to validate the claim that TEDDY significantly surpasses conventional iterative approaches.",
        "Computational savings from PGD training compared to iterative approaches are not fully substantiated."
      ],
      "questions": [
        "Can you provide a more detailed theoretical analysis of the impact of removing low-degree edges on generalization error?",
        "How does the distillation training step affect the benefits of using sparse graphs?",
        "What additional results are needed to fully validate the computational savings claimed by TEDDY?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "5sixirvG0I",
    "title": "Whittle Index with Multiple Actions and State Constraint for Inventory Management",
    "std_review": {
      "summary": "The paper introduces the Weighted Inventory Management System (WIMS) policy, a novel multi-agent approach that uses a global dual variable to enforce joint inventory constraints while optimizing individual objectives. Theoretical analysis supports asymptotic optimality under finite capacity, and comparisons highlight its superior adaptability over single-agent methods. However, practical scalability and empirical validation remain areas for improvement.",
      "strengths": [
        "Effectively ensures joint inventory level constraints through a global dual variable.",
        "Provides theoretical guarantees of asymptotic optimality under finite capacity.",
        "Offers greater adaptability to varying constraint levels compared to single-agent methods."
      ],
      "weaknesses": [
        "Lacks detailed exploration of computational implications for scalability.",
        "Theoretical guarantees depend on specific conditions that may not hold in practice.",
        "Empirical evidence or simulations to validate claims are not provided."
      ],
      "questions": [
        "How does the WIMS policy handle computational scalability when adapting to changes in capacity or SKU count?",
        "What are the practical conditions under which the theoretical guarantees of asymptotic optimality are expected to hold?",
        "Could empirical studies or simulations be conducted to strengthen the credibility of the proposed method?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "5sjxMwWmk8",
    "title": "Robust Angular Synchronization via Directed Graph Neural Networks",
    "std_review": {
      "summary": "The paper introduces GNNSync, a synchronization loss for GNNs that enforces unit-modulus constraints on embeddings using novel upset and cycle losses. Experiments show consistent performance gains over baseline GNNs and fine-tuned baselines, highlighting practical utility. While the loss function is effective, it introduces gradient complexity and lacks theoretical guarantees, suggesting areas for further investigation.",
      "strengths": [
        "Introduces novel upset and cycle losses that enforce unit-modulus constraints.",
        "End-to-end training eliminates post-processing, simplifying the pipeline.",
        "Demonstrates consistent performance improvements over both standard and fine-tuned baselines."
      ],
      "weaknesses": [
        "Gradient complexity due to non-differentiable minimum and modulo operations.",
        "Lack of a closed-form projection onto unit-modulus complex vectors.",
        "Fixed hyper-parameter (5 projection iterations) may not be optimal.",
        "Absence of theoretical guarantees for the loss functions."
      ],
      "questions": [
        "How does the subgradient method for the loss function's gradient affect convergence?",
        "What is the impact of the iterative projection step on computational efficiency?",
        "Can the theoretical properties of the loss functions be further explored to address concerns about robustness?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "5t44vPlv9x",
    "title": "",
    "std_review": {
      "summary": "The paper introduces an innovative approach to 3D human pose estimation using pose-dependent frequency modulation combined with a graph neural network to learn per-part weights. This method significantly improves pose estimation accuracy, especially for complex and occluded poses, as demonstrated on the Human3.6M dataset. However, the paper lacks comprehensive comparative evaluations with other state-of-the-art methods and does not fully generalize across the full ZJU-Mocap dataset. Code availability is also an issue, as the provided links are missing.",
      "strengths": [
        "Innovative pose-dependent frequency modulation effectively addresses similar frequency distributions across poses.",
        "Integration of graph neural networks to learn per-part weights enhances the model's ability to capture complex spatial relationships.",
        "Demonstrated significant improvements in pose estimation accuracy, particularly for complex and occluded poses."
      ],
      "weaknesses": [
        "Limited comparative evaluations with other baselines such as template/scan-based and template-free methods.",
        "Evaluation based on selected frames from the ZJU-Mocap dataset rather than the full dataset, potentially limiting generalization.",
        "Ablation studies are limited to the Human3.6M dataset, and additional studies on the full dataset could better isolate component contributions.",
        "Code links provided in the supplementary material are missing, affecting reproducibility."
      ],
      "questions": [
        "Could the method be evaluated against template/scan-based and template-free baselines like HumanNeRF or MonoHuman for a more comprehensive comparison?",
        "How does the method perform on the full ZJU-Mocap dataset, and are there additional ablations to further isolate component contributions?",
        "Are the code and supplementary material fully reproducible, and are the provided links functional?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "5T46w5X3Go",
    "title": "Theoretical Analysis on the Generalization Power of Overfitted Transfer Learning",
    "std_review": {
      "summary": "The paper presents a rigorous theoretical analysis of feature transfer in linear regression, deriving conditions under which transferring features from a source task to a target task improves performance. It provides explicit bounds on generalization error and highlights the importance of feature alignment. The authors' insights are supported by experiments on both synthetic and real datasets, demonstrating practical relevance. Overall, the paper is well‑structured, with clear contributions and strong experimental validation, though it is limited to linear models and assumes known features.",
      "strengths": [
        "Clear theoretical framework for feature transfer in linear regression.",
        "Provides explicit bounds on generalization error.",
        "Extensive experimental validation on synthetic and real datasets."
      ],
      "weaknesses": [
        "Assumes explicitly known common and task-specific features.",
        "Limited to linear regression models.",
        "Focuses on a single source task, not multi‑task scenarios."
      ],
      "questions": [
        "How can the analysis be extended to scenarios where common features are identified from unlabeled data?",
        "What is the impact of feature transformation (e.g., mapping or embedding) on the derived generalization results?",
        "How robust are the results when common features exhibit non‑trivial correlations such as noise or redundancy?",
        "Can the theoretical insights be generalized to non‑linear models like neural networks?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "5t57omGVMw",
    "title": "Learning to Relax: Setting Solver Parameters Across a Sequence of Linear System Instances",
    "std_review": {
      "summary": "The paper presents a novel online learning framework for automatically tuning the relaxation parameter ω in the Successive Over‑Relaxation (SOR) method for solving linear systems. The authors propose an algorithm that iteratively explores ω values to minimize iterations, supported by theoretical analysis of regret bounds and sample complexity. Empirical results on synthetic and real datasets validate the approach's practical benefits, though some theoretical assumptions and comparisons with existing methods remain open.",
      "strengths": [
        "Innovative learning framework for tuning SOR parameters.",
        "Strong theoretical analysis with regret bounds and sample complexity.",
        "Empirical validation on both synthetic and real datasets."
      ],
      "weaknesses": [
        "Reliance on online learning may lead to inefficient exploration.",
        "Assumes independent target vectors, which may not hold in practice.",
        "Theoretical results are based on a surrogate loss function.",
        "Lacks direct empirical comparison with established heuristic methods."
      ],
      "questions": [
        "How does the method perform when warm‑starting is used?",
        "Can the theoretical results be extended to correlated or structured target vectors?",
        "How does the proposed method compare to traditional heuristic or grid search approaches empirically?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "5tGGWOijvq",
    "title": "Prompt Risk Control: A Rigorous Framework for Responsible Deployment of Large Language Models",
    "std_review": {
      "summary": "The paper introduces Prompt Risk Control (PRC), a framework for managing undesirable outputs in LLM prompt engineering. It defines three methods—Learn‑Then‑Test, Quantile‑Based Risk Control, and Sample‑Draw‑Control—to construct safe prompt sets while preserving performance. Evaluated across code generation, chatbots, and medical question summarization, the framework effectively reduces risk with minimal performance loss. The reviewer finds the approach comprehensive and empirically validated, though some implementation details remain vague.",
      "strengths": [
        "Comprehensive risk management approach for LLM prompt engineering.",
        "Provides multiple optimization strategies (LTT, QRC, SDC) for flexibility.",
        "Demonstrates robustness across diverse domains with clear empirical results."
      ],
      "weaknesses": [
        "Lack of clear guidelines for selecting confidence level (α) and risk tolerance (δ).",
        "Choosing a set of prompts and then selecting the best may not be optimal compared to direct optimization.",
        "Insufficient guidance on interpreting and applying the three methods across different applications.",
        "Does not adequately address sample complexity and validation set size requirements."
      ],
      "questions": [
        "What criteria should be used to select α and δ for practitioners?",
        "How can the framework be adapted for direct optimization of risk over all prompts?",
        "What are the best practices for interpreting and applying the three PRC methods in various domains?",
        "What sample complexity is required for reliable risk estimation, and how should validation set size be determined?"
      ],
      "overall_score": "Accept",
      "confidence": "High"
    }
  },
  {
    "paper_id": "5TlHjMVrNG",
    "title": "Evaluating Robustness to Unforeseen",
    "std_review": {
      "summary": "The paper investigates robustness of deep learning models on CIFAR-10 using a novel approach that combines corruptions and optimization techniques. It evaluates core attacks and introduces UA2 for averaging attack performance. While demonstrating improved robustness, the methodology and evaluation need clarification regarding attack selection and UA2 justification.",
      "strengths": [
        "Explores robustness across a comprehensive benchmark using a novel corruption-optimization approach.",
        "Focuses on core attacks, potentially offering more meaningful insights into model performance.",
        "Introduces UA2, an ensemble method for averaging attack performance, which could be valuable for future research."
      ],
      "weaknesses": [
        "The relationship between different forms of robustness is not clearly established.",
        "Motivation for combining corruptions and optimization techniques is not well-explained.",
        "Selection of core attacks lacks justification and may not represent the entire benchmark.",
        "UA2 requires additional justification, particularly regarding the usefulness of averaging attack accuracy.",
        "Figure 3 lacks clarity on what is being optimized and the meaning of different arrow types and perturbation sizes."
      ],
      "questions": [
        "How does the relationship between different forms of robustness (e.g., glitch vs. JPEG attacks) impact the results?",
        "What is the motivation behind combining corruptions and optimization techniques, and how do they complement each other?",
        "Why are core attacks selected for evaluation, and how do they represent the entire benchmark?",
        "What additional justification is needed for using UA2 to average attack accuracy?",
        "In Figure 3, what exactly is being optimized, and how should the arrows and perturbation sizes be interpreted?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "5tSLtvkHCh",
    "title": "Learning Temporal Causal Representation Under Non-Invertible Generation Process",
    "std_review": {
      "summary": "The paper introduces Caring, a method for identifying latent causal factors in non-invertible temporal data, addressing a gap in existing literature. It provides a novel theoretical analysis and demonstrates effectiveness on synthetic and real-world datasets. The approach leverages temporal context to make non-invertible mixing functions identifiable, offering valuable insights and practical guidance.",
      "strengths": [
        "Introduces a novel approach (Caring) specifically designed to handle non-invertible temporal data, addressing a significant gap in existing literature.",
        "Provides a comprehensive theoretical analysis that connects to and extends existing work on nonlinear ICA and identifiability in dynamic systems.",
        "Demonstrates practical applicability through comparisons with existing baselines on both synthetic and real-world datasets, highlighting the approach's effectiveness and limitations."
      ],
      "weaknesses": [
        "The theoretical analysis, while novel, may be challenging for readers without a strong background in nonlinear ICA and dynamic systems, potentially limiting its accessibility.",
        "The paper could benefit from a more detailed discussion on the practical implications of the required amount of temporal context (parameter μ) and its impact on computational efficiency and model performance.",
        "Empirical results on real-world datasets, while promising, are limited in scope and could be strengthened by additional experiments or comparisons with more state-of-the-art methods."
      ],
      "questions": [
        "How can the theoretical analysis be made more accessible to readers without a strong background in nonlinear ICA and dynamic systems?",
        "What are the practical implications of the required amount of temporal context (parameter μ) on computational efficiency and model performance?",
        "How can the empirical evaluation be expanded to include more diverse real-world datasets and comparisons with additional state-of-the-art methods?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "5twh6pM4SR",
    "title": "Automating Continual Learning",
    "std_review": {
      "summary": "The paper presents a novel approach to continual learning by framing it as a sequence‑learning problem and introducing a self‑referential weight matrix (SRWM) that efficiently captures past tasks. Empirical results across several datasets show strong performance with reduced memory overhead, supported by a solid theoretical foundation. While innovative, the method's evaluation is limited to a few datasets, implementation complexity is notable, and robustness to task variations is not thoroughly examined.",
      "strengths": [
        "Innovative formulation of continual learning as a sequence‑learning problem.",
        "Memory‑efficient self‑referential weight matrix (SRWM) that reduces forgetting.",
        "Strong theoretical backing linking continual learning to sequence models."
      ],
      "weaknesses": [
        "Limited experimental evaluation on a narrow set of benchmark datasets.",
        "Increased model complexity due to the SRWM approach.",
        "Lack of thorough robustness analysis across task order, frequency, and difficulty.",
        "Insufficient comparative analysis with state‑of‑the‑art methods."
      ],
      "questions": [
        "How does the method perform on a broader range of continual learning benchmarks?",
        "What are the practical guidelines for implementing the SRWM in real‑world scenarios?",
        "Can the robustness of the approach be demonstrated under varying task conditions?",
        "How does the proposed method compare to other recent continual learning techniques in terms of scalability and generalization?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "5tYTCyYI27",
    "title": "Calibration Bottleneck: What Makes Neural Networks Less Calibratable?",
    "std_review": {
      "summary": "The paper investigates how compressing the top layers of deep neural networks affects their calibration, introducing a novel training method called Layer-Peeled Training (PLT) that freezes these layers and applies weight decay to preserve calibration. Experiments on multiple datasets show that compressing top layers creates a U-shaped calibration curve, with PLT effectively mitigating calibration loss. The study provides both theoretical insights and empirical evidence linking layer compression to calibration degradation.",
      "strengths": [
        "Introduces a novel training method (PLT) that effectively maintains calibration after top‑layer compression.",
        "Provides clear theoretical justification linking layer compression to calibration loss.",
        "Conducts robust experiments with controlled ablation studies to isolate the effects of top‑layer compression."
      ],
      "weaknesses": [
        "Lacks a comprehensive theoretical framework explaining why only top layers affect calibration.",
        "Effectiveness of PLT may be sensitive to hyperparameter choices not fully explored.",
        "Relies on a single train‑test split, potentially limiting generalization insights.",
        "Does not compare PLT against other state‑of‑the‑art calibration or compression techniques."
      ],
      "questions": [
        "How does the proposed PLT method scale to larger models or different architectures?",
        "What is the theoretical basis for why top layers are more sensitive to compression?",
        "How does PLT perform when applied to models with different training dynamics or regularization strategies?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "5VD7dS3cZX",
    "title": "Rethinking the Solution to Curse of Dimensionality on Randomized Smoothing",
    "std_review": {
      "summary": "The paper introduces novel EGG and ESG distributions for randomized smoothing, extending DSRS and improving certified radii on CIFAR-10 and ImageNet. It provides strong theoretical analysis and empirical evidence, addressing the curse of dimensionality. The work is well-received for its contributions, though some limitations in generalizability and implementation are noted.",
      "strengths": [
        "Introduces novel EGG and ESG distributions for randomized smoothing, offering a theoretical framework to improve certified radii.",
        "Provides rigorous theoretical analysis, including new theorems (Theorems 1 and 2) that support the proposed methods.",
        "Empirical results demonstrate significant improvements in certified radii on CIFAR-10 and ImageNet datasets compared to existing methods."
      ],
      "weaknesses": [
        "Theoretical analysis assumes certain conditions that may not hold in all practical scenarios, potentially limiting generalizability.",
        "Experimental evaluation focuses on two datasets (CIFAR-10 and ImageNet), which may not cover a broad enough range of applications.",
        "The paper does not extensively address potential limitations or challenges in implementing the EGG and ESG distributions in real-world scenarios.",
        "The comparison with prior work, particularly the work by Li et al. (2022), is not as comprehensive as it could be."
      ],
      "questions": [
        "How do the EGG and ESG distributions perform on more diverse datasets beyond CIFAR-10 and ImageNet?",
        "What are the computational complexities involved in implementing these distributions, and how do they compare to existing methods?",
        "How robust are the EGG and ESG distributions to adversarial attacks that exploit high-dimensional spaces?",
        "What are the practical steps to integrate these distributions into existing model architectures and training pipelines?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "5Vh0XqOTGi",
    "title": "GAN-based Vertical Federated Learning for Label Protection",
    "std_review": {
      "summary": "The paper presents a GAN-based vertical federated learning method that perturbs gradients using a randomized response mechanism to protect labels, achieving improved privacy and robustness against adversarial attacks. While demonstrating effectiveness on synthetic and real-world datasets, the approach reduces model outputs to a single scalar, potentially losing important information. The simplicity of the discriminator and experimental setup could be enhanced, and the trade-offs between privacy and performance warrant further discussion.",
      "strengths": [
        "Introduces a novel randomized response mechanism to enhance privacy in federated learning.",
        "Demonstrates improved robustness against adversarial attacks compared to standard methods.",
        "Provides a clear theoretical framework for understanding privacy-performance trade-offs."
      ],
      "weaknesses": [
        "Reduces model outputs to a single scalar, potentially losing important information.",
        "The simplicity of the discriminator may not fully capture real-world complexities.",
        "Experimental setup lacks comprehensive comparisons and detailed analysis."
      ],
      "questions": [
        "How does the dimensionality reduction to a single scalar value impact model accuracy and privacy?",
        "Could a more complex discriminator better capture real-world data characteristics?",
        "What are the specific trade-offs between privacy and model performance in practical scenarios?"
      ],
      "overall_score": "Accept",
      "confidence": "High"
    }
  },
  {
    "paper_id": "5vXDQ65dzH",
    "title": "ParFam - Symbolic Regression Based on Continuous Global Optimization",
    "std_review": {
      "summary": "ParFam is a symbolic regression framework that uses deep learning to discover polynomial function families, showing superior expressivity compared to traditional methods like EQL and FFX. The authors demonstrate its effectiveness on the Synthetic Regression Bench dataset, highlighting its ability to represent complex functions. However, the prototype version of DL‑ParFam has limitations in handling large or complex datasets, and the paper lacks detailed analysis of hyperparameter sensitivity and computational costs. Overall, ParFam shows promise but requires further refinement.",
      "strengths": [
        "Enhanced expressivity compared to traditional symbolic regression methods.",
        "Deep learning integration enables automatic discovery of complex polynomial structures.",
        "Designed to scale with input variables and polynomial degrees."
      ],
      "weaknesses": [
        "Prototype limitations in handling very large or complex datasets.",
        "Lack of detailed sensitivity analysis for the regularization hyperparameter λ.",
        "Potential computational cost due to parameter optimization in high-dimensional spaces."
      ],
      "questions": [
        "How does ParFam perform on real-world datasets beyond SRBench?",
        "What is the impact of the regularization hyperparameter λ on model performance?",
        "Can the computational cost be mitigated for high-dimensional data sets?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "5xadJmgwix",
    "title": "Scale-Adaptive Diffusion Model for Complex Sketch Synthesis",
    "std_review": {
      "summary": "The paper introduces a scale‑adaptive diffusion model for generating complex sketches, using a three‑phase sampling strategy that balances recognizability and complexity. It shows improved results on the QuickDraw dataset compared to baselines, but lacks thorough hyperparameter analysis, generalization tests, and extensive comparisons with non‑classifier‑guided methods.",
      "strengths": [
        "Innovative three‑phase sampling strategy that improves sketch coherence and diversity.",
        "Dynamic classifier guidance mechanism that balances complexity and recognizability.",
        "Clear theoretical motivation and thorough empirical evaluation on a standard dataset."
      ],
      "weaknesses": [
        "Limited analysis of hyperparameter sensitivity (α, β, γ) affecting reproducibility.",
        "Evaluation restricted to the QuickDraw dataset, with no evidence of generalization.",
        "Lack of comparison with a broader range of baselines, especially those without classifier guidance.",
        "Potential robustness issues with the scaling indicator across different sketch styles."
      ],
      "questions": [
        "How does the model perform on sketches from other datasets or with different subjects?",
        "What is the impact of the scaling indicator on the model's ability to generalize beyond the QuickDraw style?",
        "How robust is the model to variations in hyperparameters across diverse sketching tasks?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "5xKixQzhDE",
    "title": "Calibrated Dataset Condensation for Faster Hyperparameter Search",
    "std_review": {
      "summary": "The paper introduces a novel approach to image dataset distillation that is applicable across different model architectures, enhancing its versatility and potential impact. It proposes distilling directly on the test set for hyperparameter search, which could lead to more efficient model training processes. The study explores various sampling methods and evaluates the method's time cost and potential extension to training set compression, addressing practical concerns. While the strengths of the approach are clear, the paper could benefit from more detailed comparisons with existing methods and quantitative assessments of its impact on model performance.",
      "strengths": [
        "Introduces a novel, architecture-agnostic approach to image dataset distillation.",
        "Proposes distilling directly on the test set for hyperparameter search, potentially improving efficiency.",
        "Explores the impact of sampling methods and evaluates practical concerns like time cost and extension to training set compression."
      ],
      "weaknesses": [
        "Lacks detailed comparison with existing distillation methods to highlight novelty.",
        "Experimental setup and dataset details are not fully described, affecting reproducibility.",
        "Does not quantitatively assess the impact on model performance and accuracy.",
        "Does not discuss potential limitations for very deep or complex architectures."
      ],
      "questions": [
        "How does the proposed method compare to existing distillation techniques in terms of novelty and effectiveness?",
        "Could you provide more details on the experimental setup and dataset used for evaluation?",
        "What is the quantitative impact of the proposed method on model performance and accuracy?",
        "Are there any specific challenges or limitations when applying the method to very deep or complex architectures?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "5XUlfPcQnG",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a physics‑based simulator combined with a reinforcement learning agent to optimize building energy performance. While demonstrating promising results in both simulation and a single real‑world case, the study suffers from limited evidence of generalization across building types, insufficient evaluation of real‑world performance, and a lack of detailed documentation of the simulator and RL system. These issues prevent a full acceptance.",
      "strengths": [
        "Innovative simulator‑tuning procedure that could reduce simulation time and resources.",
        "Demonstrates that the trained RL agent generalizes to new buildings, indicating robustness.",
        "Provides a comprehensive evaluation framework for both the simulator and RL agent."
      ],
      "weaknesses": [
        "Evidence of generalization is based on a limited set of test cases.",
        "Real‑world performance is only evaluated in a single case study.",
        "The simulator makes several assumptions (e.g., ignoring radiative gains) that could affect accuracy.",
        "Lack of prior work cited to substantiate the novelty of tuning EnergyPlus with the simulator."
      ],
      "questions": [
        "How does the simulator perform across a broader range of building types and conditions?",
        "What are the detailed parameters (episode length, weather, occupancy) used in the RL simulation?",
        "What are the precise equations and derivation of the physics‑based simulator?",
        "How does the observed temperature drift compare to realistic variations, and what assumptions affect fidelity?",
        "What are the training run lengths and error accumulation rates for the RL agent?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "5zwrpqYIK5",
    "title": "Outlier-Robust Orthogonal Regression",
    "std_review": {
      "summary": "The paper introduces a robust algorithm for estimating essential matrices on a sphere using a combination of robust sub-gradient method and iteratively reweighted least squares. It provides theoretical convergence guarantees under geometric assumptions and demonstrates improved robustness empirically. The work is novel, theoretically sound, and empirically validated, though some assumptions and parameter choices are complex.",
      "strengths": [
        "Novel geometric framework combining manifold learning with robust statistical techniques.",
        "Strong theoretical foundation with geometric assumptions and convergence guarantees.",
        "Algorithmic innovation through integration of RSGM and IRLS for outlier robustness.",
        "Empirical validation showing superior performance in high outlier scenarios."
      ],
      "weaknesses": [
        "Complex geometric assumptions may limit broad applicability.",
        "Parameter selection for step-size and weighting could be more transparent.",
        "Focus on sphere may restrict generalizability to other manifolds.",
        "Lack of clear quantitative benchmarks for theoretical metrics."
      ],
      "questions": [
        "How can the geometric assumptions be relaxed to improve applicability?",
        "What are the theoretical guarantees for extending the framework to higher-dimensional manifolds?",
        "How do permeance and stability translate into practical benchmarks?",
        "Can the parameter selection process be automated or guided by theory?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "5ZWxBU9sYG",
    "title": "How to Craft Backdoors with Unlabeled Data Alone?",
    "std_review": {
      "summary": "The paper presents a novel approach to backdooring self-supervised learning (SSL) models using only unlabeled data. It introduces two methods for selecting poison samples: clustering and contrastive, and compares their effectiveness. The results show that backdooring SSL models without labeled data is feasible, but highlights challenges and limitations.",
      "strengths": [
        "Introduces a novel method for backdooring SSL models using unlabeled data.",
        "Proposes two distinct methods (clustering and contrastive) for selecting poison samples.",
        "Conducts thorough experiments on multiple datasets and SSL models."
      ],
      "weaknesses": [
        "Reliance on clustering algorithm quality for the clustering-based method.",
        "Potential limitations of the contrastive method with high-dimensional data.",
        "Lack of detailed analysis of trade-offs between the two methods.",
        "Experiments focus on a limited set of SSL models and datasets."
      ],
      "questions": [
        "How does the clustering-based method handle complex datasets with varying data distributions?",
        "What are the specific trade-offs between the clustering and contrastive methods in terms of backdoor robustness and detection?",
        "How can the proposed methods be adapted to different SSL architectures and data types?"
      ],
      "overall_score": "6: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "60e1hl06Ec",
    "title": "Mitigating Simplicity Bias in Deep Learning for Improved OOD Generalization and Robustness",
    "std_review": {
      "summary": "The paper introduces CMID, a conditional mutual information (CMI) regularization technique designed to mitigate spurious feature reliance in machine learning models. By distinguishing between simple (spurious) and complex (invariant) features, CMID aims to improve fairness without degrading overall model performance. Experiments across multiple datasets demonstrate that CMID outperforms existing debiasing methods, particularly in reducing worst‑group accuracy gaps while maintaining in‑distribution performance. The method is theoretically grounded and shows strong empirical results, though it has some computational and theoretical limitations.",
      "strengths": [
        "Clear theoretical foundation",
        "Empirical superiority over existing debiasing methods",
        "Novel approach leveraging CMI to regularize against spurious features",
        "Demonstrated robustness across different data modalities"
      ],
      "weaknesses": [
        "Assumptions such as Gaussian features and linear predictors may not hold in real-world scenarios",
        "Additional computational cost due to training a simple model and the final CMI‑regularized model",
        "Limited theoretical exploration of non‑Gaussian and non‑linear scenarios",
        "Potential for over‑regularization that could capture invariant information"
      ],
      "questions": [
        "How do the theoretical results generalize to non‑Gaussian and non‑linear feature distributions?",
        "What is the impact of over‑regularization on model performance in scenarios where spurious features are minimal?",
        "How does CMID compare to other fairness‑oriented methods that do not rely on CMI regularization?",
        "What are the practical implications of the additional computational cost for real‑world applications?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "60lNoatp7u",
    "title": "NeurRev: Train Better Sparse Neural Network Practically via Neuron Revitalization",
    "std_review": {
      "summary": "NeurRev introduces a novel method for identifying and pruning dormant neurons in neural networks, improving model efficiency without significantly compromising accuracy. The approach uses a dynamic neuron activation metric to distinguish dormant neurons, which are then pruned during training. Experiments show that NeurRev can achieve high sparsity levels across various architectures and datasets while maintaining competitive accuracy. The method is particularly beneficial for resource-constrained environments, offering a promising way to deploy larger models with reduced computational overhead. Overall, NeurRev is a valuable contribution to the field of model efficiency.",
      "strengths": [
        "Innovative dormant neuron identification using a dynamic activation metric.",
        "Maintains high accuracy across various architectures and datasets.",
        "Reduces model size and computational requirements, making it suitable for edge devices.",
        "Demonstrates strong performance across different types of neural networks."
      ],
      "weaknesses": [
        "Additional computational overhead from dynamically tracking neuron activations.",
        "Performance sensitivity to hyperparameters such as pruning thresholds.",
        "Limited benchmarking against a broader range of state-of-the-art methods.",
        "Scalability concerns for very large models or complex tasks."
      ],
      "questions": [
        "How does NeurRev compare to other neuron pruning techniques in terms of computational efficiency?",
        "What is the impact of hyperparameter tuning on the method's performance across different datasets?",
        "Can NeurRev be extended to work effectively with very large models or more complex tasks?",
        "How does the method's performance on benchmark datasets compare to other state-of-the-art sparse training methods?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "61DYdiyQqk",
    "title": "Two Heads Are Better Than One: Exploiting Both Sequence and Graph Models in AMR-To-Text Generation",
    "std_review": {
      "summary": "The paper introduces DualGen, a model that combines sequence (BART) and graph (graph neural network) encoders to generate text from AMR graphs. It uses a gating mechanism to dynamically balance the influence of both encoders during generation, achieving state-of-the-art results on two AMR benchmarks and competitive performance against GPT‑4. The authors conduct thorough ablation studies and failure analyses, highlighting the contributions of each component and identifying specific limitations. Overall, the paper presents a novel and effective approach to AMR generation.",
      "strengths": [
        "Innovative integration of sequence and graph encoders to leverage linguistic and structural information.",
        "Effective gating mechanism that dynamically balances encoder outputs during generation.",
        "Strong performance on AMR benchmarks, outperforming state-of-the-art baselines.",
        "Comprehensive analysis through ablation studies and failure analysis."
      ],
      "weaknesses": [
        "Increased model complexity due to the integration of two distinct encoder types.",
        "Resource-intensive training, potentially limiting accessibility.",
        "Limited evaluation to AMR benchmarks; generalization to other domains is not thoroughly explored.",
        "Lack of detailed training protocols for reproducibility."
      ],
      "questions": [
        "How does DualGen perform on AMR graphs with varying depths and edge richness beyond the evaluated benchmarks?",
        "What are the specific failure modes observed in more complex or irregular AMR structures?",
        "How does the model's performance compare to other recent graph-to-text generation approaches?",
        "Can the gating mechanism be further optimized or adapted for other sequence‑graph hybrid tasks?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "61mnwO4Mzp",
    "title": "Denoising Diffusion Variational Inference",
    "std_review": {
      "summary": "DiffVAE presents a novel variational autoencoder that integrates diffusion processes with variational inference, achieving competitive performance on image generation tasks with improved stability and sample quality. Theoretical insights into the denoising variational lower bound support the model's design, and empirical evaluations demonstrate its effectiveness compared to existing baselines. Despite computational costs and implementation complexity, DiffVAE is a promising direction for generative modeling.",
      "strengths": [
        "Innovative integration of diffusion and variational inference.",
        "Improved sample quality and stability compared to traditional VAEs.",
        "Strong theoretical foundation with a denoising variational lower bound."
      ],
      "weaknesses": [
        "Significant computational cost during training and inference.",
        "Increased implementation complexity due to the combination of diffusion and variational methods.",
        "Lack of detailed convergence analysis."
      ],
      "questions": [
        "How does DiffVAE compare to recent state-of-the-art diffusion models in terms of sample quality and training efficiency?",
        "What are the specific convergence guarantees for the denoising variational lower bound?",
        "Could a more detailed analysis of the impact of the variational family on model performance be provided?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "62K7mALO2q",
    "title": "In-Context Learning Dynamics",
    "std_review": {
      "summary": "The paper investigates how language models evolve predictions during in-context learning, proposing a framework to compare LLM behavior with window-average and Bernoulli models. It finds that LLMs exhibit smoother transitions, indicating a more nuanced understanding of context. While the theoretical framework and empirical analyses are solid, some notational ambiguities and figure label issues could be clarified. Overall, the contribution is valuable for advancing ICL research.",
      "strengths": [
        "Clear theoretical framework for analyzing LLM behavior during in-context learning.",
        "Innovative visualization techniques that intuitively illustrate model dynamics.",
        "Comprehensive empirical studies with robust statistical analyses."
      ],
      "weaknesses": [
        "Ambiguous figure labels in Figure 2 could lead to misinterpretation.",
        "Notational confusion regarding $p(y=Random|x)$ and $p(y|x)$.",
        "Ambiguity in the definition of $C$ in Section 4."
      ],
      "questions": [
        "Please clarify the correspondence between colors in Figure 2 and their respective model behaviors.",
        "Provide a clear definition of $C$ and its role in the model.",
        "Clarify the notation $p(y=Random|x)$ to ensure it accurately represents the probability of a token being 'Random'."
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "639DcBewcJ",
    "title": "Low-Rank Robust Graph Contrastive Learning",
    "std_review": {
      "raw_text": "{\n  \"summary\": \"The paper introduces LR‑RGCL, a framework that integrates Bayesian non‑parametric prototype learning with contrastive learning for graph representation learning. It aims to improve clustering quality and noise robustness by learning low‑rank embeddings that are both discriminative and expressive. Experiments on several benchmark datasets demonstrate competitive performance against baselines, highlighting the benefits of the proposed hybrid approach. The reviewer finds the integration of prototype learning with contrastive learning innovative and theoretically sound, with strong empirical results. However, the additional computational complexity of the Bayesian framework and the sensitivity of hyper‑parameters could limit its scalability and practical deployment.\",\n  \"strengths\": [\n    \"Innovative Integration: Combines Bayesian non‑parametric prototype learning with contrastive learning, offering a novel approach to graph representation learning.\",\n    \"Theoretical Foundation: Provides a rigorous theoretical justification for the combination of prototype learning and contrastive learning, supported by a generalization bound.\",\n    \"Empirical Validation: Demonstrates strong empirical performance across multiple datasets, outperforming traditional baselines and other state‑of‑the‑art methods.\"\n  ],\n  \"weaknesses\": [\n    \"Complexity: The Bayesian non‑parametric framework introduces additional computational complexity, which may limit scalability to very large graphs.\",\n    \"Hyper‑parameter Sensitivity: The choice of rank \\(r\\) and the mixing coefficient \\(\\gamma\\) can significantly affect performance, and their optimal values may require extensive tuning.\",\n    \"Lack of Ablation Studies: While the paper discusses the contributions of the two loss terms, more detailed ablation studies could further clarify their individual impacts.\",\n    \"Comparison Scope: The comparison with baselines could be more comprehensive, including a broader range of noise‑robust methods beyond simple clustering approaches.\"\n  ],\n  \"questions\": [\n    \"How can the computational complexity of the Bayesian non‑parametric framework be reduced to improve scalability?\",\n    \"What are the optimal values for the hyper‑parameters \\(r\\) and \\(\\gamma\\), and how can they be determined more systematically?\",\n    \"Could more detailed ablation studies be conducted to better understand the individual contributions of the prototype learning and low‑rank transductive steps?\",\n    \"How does LR‑RGCL compare to other advanced noise‑robust graph contrastive learning methods beyond the ones mentioned in the paper?\"\n  ],\n  \"overall_score\": \"7: accept\",\n  \"confidence\": \"4: high\"\n}",
      "parse_error": true
    }
  },
  {
    "paper_id": "64kSvC4iPg",
    "title": "Compressed Context Memory For",
    "std_review": {
      "summary": "The paper presents a novel framework for compressing context in machine learning models, achieving efficiency gains but requiring task-specific retraining and additional resources. While innovative, its practicality and scalability are limited by these constraints. The authors should address these issues in future work.",
      "strengths": [
        "Introduces an innovative compression module for context reduction.",
        "Demonstrates significant efficiency improvements in computational resources and memory usage.",
        "Provides a thorough experimental setup with multiple baselines."
      ],
      "weaknesses": [
        "Task-specific nature limits scalability and practicality.",
        "Requires additional resources for training, which may be prohibitive in some environments.",
        "Lacks generalization across new tasks without retraining."
      ],
      "questions": [
        "How can the framework be made more task-agnostic to improve scalability?",
        "What is the quantitative impact of additional training resources on performance?",
        "How does the performance gap between compressed and full context models vary across different task types?",
        "Could more sophisticated memory update mechanisms enhance the framework's capabilities?",
        "How does the framework compare to recurrent memory approaches in terms of performance and resource usage?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "64t9er38Zs",
    "title": "Learning Deep O(\\(n\\))-Equivariant Hyperspheres",
    "std_review": {
      "summary": "The paper introduces an O(3)-equivariant neural network using equivariant hyperspheres to handle 3D rotational data, showing strong empirical results on synthetic and real datasets. While innovative and theoretically grounded, the model's expressiveness compared to higher-order equivariant methods is questioned, and its practical utility is limited by lack of robustness evaluation and baseline comparisons. The exploration of higher-dimensional equivariance is also underdeveloped.",
      "strengths": [
        "Innovative equivariant design leveraging equivariant hyperspheres for O(3) symmetry.",
        "Theoretical grounding in group representations.",
        "Strong empirical results on both synthetic and real datasets."
      ],
      "weaknesses": [
        "Potential expressiveness limitations compared to higher-order equivariant models.",
        "Lack of evaluation on real datasets without O(3) augmentation.",
        "Absence of baseline comparisons with other equivariant methods.",
        "Limited exploration of higher-dimensional equivariance."
      ],
      "questions": [
        "How does the proposed $O(n)$-equivariant architecture compare in expressiveness to higher-order equivariant methods like CGENN?",
        "What is the model's performance on the real O(3) Action recognition dataset without O(3) augmentation?",
        "How can the proposed approach be extended to higher-dimensional symmetries ($n>3$) and what are concrete applications?",
        "What is the theoretical proof of universality for the $O(n)$-equivariant functions?"
      ],
      "overall_score": "Borderline",
      "confidence": "Medium"
    }
  },
  {
    "paper_id": "66arKkGiFy",
    "title": "Plug-and-Play Posterior Sampling under Mis-Matched Measurement and Prior Models",
    "std_review": {
      "summary": "The paper introduces a novel metric for assessing model mismatch in the Probabilistic Neural Portraits - Uniform Locality Assumption (PnP-ULA) algorithm, a Markov chain Monte Carlo method for inverse problems. It provides theoretical stability guarantees and explores the behavior of the Wasserstein distance under increasing mismatch. While demonstrating robustness, the paper highlights the importance of kernel alignment for optimal performance, with practical implications for using isotropic kernels for anisotropic blur scenarios. Overall, the work is well-received for its theoretical rigor and practical insights, though some areas for improvement are noted.",
      "strengths": [
        "Novel Metric for Assessing Model Mismatch: The introduction of the posterior-$L_2$ pseudometric provides a novel and rigorous way to quantify drift shifts, offering a clear metric for evaluating the impact of model mismatch on sampling behavior.",
        "Theoretical Rigor: The derivation of stability guarantees in Theorem 1 underpins the reliability of PnP‑ULA, particularly in the presence of mismatched measurement or prior models, providing a solid theoretical foundation.",
        "Insightful Analysis of Wasserstein Distance: The exploration of how the Wasserstein distance behaves with increasing mismatch offers valuable insights into the robustness of PnP‑ULA, highlighting its practical robustness despite theoretical dependencies."
      ],
      "weaknesses": [
        "Complexity of Theoretical Results: The theoretical analysis, particularly Theorem 1, may be challenging for readers without a strong background in probability theory and Markov chain analysis, potentially limiting accessibility.",
        "Limited Scope of Practical Examples: While the paper discusses practical implications, the examples provided are somewhat limited, and more comprehensive case studies could strengthen the connection between theory and real-world applications.",
        "Assumption of Known Anisotropy: The discussion on isotropic vs. anisotropic blur kernels assumes a known level of anisotropy, which may not always be the case in practical scenarios, potentially affecting the generalizability of the findings.",
        "Lack of Empirical Validation: Although the theoretical framework is well-developed, the paper could benefit from empirical validation through experiments on diverse datasets to empirically demonstrate the theoretical insights."
      ],
      "questions": [
        "How can the theoretical results be extended to more complex or high-dimensional inverse problems?",
        "What empirical studies could be conducted to validate the theoretical insights on the behavior of the Wasserstein distance under mismatch?",
        "Are there alternative metrics or methods that could provide additional insights into model mismatch beyond the posterior-$L_2$ pseudometric?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "66e22qCU5i",
    "title": "Certified Copy: A Resistant Backdoor Attack",
    "std_review": {
      "summary": "The paper introduces Certified Copy, a novel attack on feature-level backdoors that uses a Mean Absolute Error (MAE) term to precisely place triggers in the feature space. It outperforms existing detection methods and demonstrates robustness against post-deployment fine-tuning. The authors provide a clear conceptual framework and discuss the implications for real-world deployments, though some concerns about dataset bias and naming remain.",
      "strengths": [
        "Innovative MAE cost function for precise trigger placement",
        "Strong performance against state-of-the-art detection methods",
        "Clear naming and conceptual clarity of 'Certified Copy'",
        "Broad applicability to both all-to-one and multi-class backdoors",
        "Robustness analysis against post-deployment fine-tuning"
      ],
      "weaknesses": [
        "Potential dataset bias from trigger-specific augmentation",
        "Lack of comparison with the most recent detection methods",
        "Ambiguity in the interpretation of the 'certified' term",
        "No explicit discussion of the trade-off between robustness and evasiveness"
      ],
      "questions": [
        "How does the attack perform when applied to datasets with varying levels of bias?",
        "What is the impact of recent advancements in backdoor detection on the robustness of Certified Copy?",
        "Can the 'certified' terminology be clarified to better convey its meaning to non-expert readers?",
        "How does the trade-off between robustness against detection and overall evasiveness manifest in practical scenarios?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "66wQM45W28",
    "title": "CEDNet: A Cascade Encoder-Decoder Network for Dense Prediction",
    "std_review": {
      "summary": "CEDNet introduces a cascade encoder-decoder network that fuses multi-scale features early to improve dense prediction performance while drastically reducing computational cost. The architecture leverages high-level semantic information to guide the learning of detailed low-level features, achieving significant speed and accuracy gains across object detection, instance segmentation, and semantic segmentation. Despite its innovative approach, the paper lacks comprehensive comparisons with state-of-the-art methods and provides limited visual results, raising questions about reproducibility and competitive advantage.",
      "strengths": [
        "Innovative feature fusion strategy that combines multi-scale features early in the network.",
        "Significant computational efficiency gains, reducing FLOPs by three orders of magnitude.",
        "Clear theoretical motivation for early fusion of multi-scale features to capture hierarchical visual information."
      ],
      "weaknesses": [
        "Ambiguity in distinguishing low-level and high-level features.",
        "Lack of comprehensive comparison with state-of-the-art methods.",
        "Potential reproducibility issues due to missing visual results in the main text."
      ],
      "questions": [
        "How does CEDNet distinguish between low-level and high-level features to guide the learning process?",
        "Why are there no evaluations against recent state-of-the-art methods like InternImage?",
        "What are the reproducibility concerns regarding the visual results for dense prediction tasks?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "67t4ikhlvP",
    "title": "Agent-Centric State Discovery for Finite-Memory POMDPs",
    "std_review": {
      "raw_text": "{\n  \"summary\": \"The paper presents a novel method for handling POMDPs by predicting actions from observations and discovering a latent Markovian state space, showing improved performance in offline reinforcement learning tasks. While the approach is innovative and well-explained, it suffers from unclear motivation for key assumptions, ambiguous notation, and missing related work, which together make the overall contribution less compelling.\",\n  \"strengths\": [\n    \"Introduces a unique method for handling POMDPs by combining action prediction with latent state discovery.\",\n    \"Provides clear methodology with detailed mathematical formulation.\",\n    \"Demonstrates strong empirical improvements in offline RL tasks.\"\n  ],\n  \"weaknesses\": [\n    \"Assumptions are not well-motivated, making the theoretical justification unclear.\",\n    \"The relationship between predicting actions and discovering states is not clearly articulated.\",\n    \"Lacks comprehensive related work discussion, especially on learning information states.\",\n    \"Notation $q(\\cdot|z)$ is ambiguous.\",\n    \"Incorrect definition of $\\tilde{o}_F(h,n)$ on Page 3.\",\n    \"Does not specify metrics for evaluating state estimation errors.\",\n    \"Title and abstract do not explicitly mention offline RL, leading to potential confusion.\",\n    \"Related work section is placed too late.\"\n  ],\n  \"questions\": [\n    \"Could you clarify the theoretical motivation behind the key assumptions in the model?\",\n    \"How exactly does the latent state space facilitate the prediction of actions?\",\n    \"What metrics are used to evaluate the accuracy of the state estimation?\",\n    \"Could you provide a corrected definition of $\\tilde{o}_F(h,n)$?\"\n  ],\n  \"overall_score\": \"4: weak reject\",\n  \"confidence\": \"3: medium\"\n}",
      "parse_error": true
    }
  },
  {
    "paper_id": "68k0KcHFrW",
    "title": "Stochastic Unrolled Federated Learning",
    "std_review": {
      "raw_text": "{\n  \"summary\": \"SURF introduces a federated learning algorithm that ensures rate fairness among devices while maintaining convergence, leveraging a convex combination of local models. Theoretical guarantees and empirical results on synthetic and real datasets show improved fairness and convergence speed, but concerns remain about convexity assumptions, practical implementation of conditions, and lack of comparison with personalized methods.\",\n  \"strengths\": [\n    \"Introduces a novel rate-fairness mechanism that enforces uniform convergence rates.\",\n    \"Provides strong theoretical backing with convergence proofs under convexity assumptions.\",\n    \"Demonstrates empirical benefits in fairness and convergence on both synthetic and real datasets.\"\n  ],\n  \"weaknesses\": [\n    \"Relies on convexity assumptions that may limit applicability in non-convex deep learning settings.\",\n    \"Practical implementation of conditions \\(g = f\\) and \\(g = \\| \\nabla f \\|\\) could be challenging.\",\n    \"Does not address the impact of model heterogeneity on performance.\",\n    \"Theoretical clarity is lacking, particularly regarding the nature of convergence in non-convex problems.\",\n    \"Lacks comparison with personalized federated learning methods.\"\n  ],\n  \"questions\": [\n    \"How can SURF be extended to non-convex settings where convexity assumptions may not hold?\",\n    \"What strategies can be employed to ensure practical fulfillment of the conditions \\(g = f\\) and \\(g = \\| \\nabla f \\|\\) in complex model architectures?\",\n    \"What is the impact of heterogeneity in local models and data distributions on SURF's performance, and how can it be mitigated?\",\n    \"Can you clarify whether Theorem 2 guarantees convergence to a local minimum or a stationary point, given the non-convex nature of the problem?\",\n    \"How does SURF compare to personalized federated learning methods in terms of performance and robustness?\"\n  ],\n  \"overall_score\": \"4: weak reject\",\n  \"confidence\": \"3: medium\"\n}",
      "parse_error": true
    }
  },
  {
    "paper_id": "6ALuy19mPa",
    "title": "DreamClean: Restoring Clean Image Using Deep Diffusion Prior",
    "std_review": {
      "summary": "DreamClean introduces a novel approach to image restoration using Variance Preservation Sampling (VPS) within a diffusion model framework. The method effectively addresses noise and blur, particularly in high-resolution images, and outperforms several state-of-the-art techniques. While demonstrating robustness across datasets like ImageNet and CelebA, the paper notes computational cost and parameter sensitivity as areas for improvement.",
      "strengths": [
        "Innovative use of VPS to enhance image quality.",
        "Scalable to high-resolution images with good computational efficiency.",
        "Outperforms multiple state-of-the-art restoration methods."
      ],
      "weaknesses": [
        "Computational cost can be high for high-resolution images.",
        "Performance sensitive to hyperparameter tuning.",
        "Lack of extensive benchmarking against all relevant methods."
      ],
      "questions": [
        "How does DreamClean perform on real-time applications with strict computational budgets?",
        "What are the specific guidelines for hyperparameter tuning to achieve optimal results?",
        "Could the method be extended to video restoration tasks?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6bAfAcuuZD",
    "title": "Emergence of surprise and predictive signals from local contrastive learning",
    "std_review": {
      "summary": "The paper introduces a predictive coding model for visual cortex neural coding using hierarchical layers and a global supervisory signal. It employs PCA to assess representational power across layers, showing that higher layers encode more abstract representations. While the model is biologically plausible and offers novel insights, it suffers from methodological inconsistencies and ambiguous terminology, leading to a weak accept recommendation.",
      "strengths": [
        "Clear model proposal with hierarchical predictive coding framework",
        "Robust use of PCA to analyze representational content",
        "Biological relevance and alignment with known neural mechanisms"
      ],
      "weaknesses": [
        "Inconsistent PCA component selection across analyses",
        "Ambiguous use of 'surprise' term",
        "Simplification of linear dynamics by approximating input to label",
        "Omission of layer normalization",
        "Truncation of presentation phase affecting robustness",
        "Fragmented model description with delayed detailed explanations",
        "Inconsistent PCA application across figures",
        "Lack of exploration of extended presentation phase impact",
        "Potential oversimplification of biological supervisory mechanisms"
      ],
      "questions": [
        "Should the PCA component selection be standardized across analyses for clearer interpretation?",
        "How does the model's performance change with extended presentation phases?",
        "What impact would layer normalization have on biological plausibility?",
        "How can the ambiguous use of 'surprise' be clarified in the model?",
        "Could a more detailed description of the model and training process improve readability?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "6bcAD6g688",
    "title": "Unmasking and Improving Data Credibility:",
    "std_review": {
      "summary": "The paper introduces a method for estimating transition matrices in Markov chains using embeddings that reflect safety issues. It leverages consensus vectors derived from embeddings to capture system dynamics and uses k-Nearest Neighbors (KNN) for feature computation. The approach shows improved performance on various datasets but requires further theoretical justification and parameter optimization.",
      "strengths": [
        "Integrates embeddings to reflect safety issues, providing a novel way to capture complex relationships.",
        "Uses consensus vectors for clear and intuitive transition matrix estimation, enhancing interpretability.",
        "Demonstrates broad applicability across different datasets."
      ],
      "weaknesses": [
        "Reliance on embeddings may introduce bias if safety dynamics are not accurately captured.",
        "The role of consensus vectors in estimating the transition matrix is not fully explored.",
        "Method's performance may be sensitive to parameter choices without clear optimization.",
        "Lacks comprehensive theoretical analysis linking consensus vectors to the transition matrix."
      ],
      "questions": [
        "How can the method be further validated to ensure embeddings accurately reflect safety dynamics?",
        "What theoretical underpinnings can be provided to strengthen the relationship between consensus vectors and the transition matrix?",
        "How can parameter optimization be systematically addressed across diverse datasets?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "6c4gv0E9sF",
    "title": "SpikeBert: A Language Spikformer Learned from BERT with Knowledge Distillation",
    "std_review": {
      "summary": "The paper introduces SpikeBERT, a spiking neural network model for NLP that aims to improve energy efficiency and performance. It demonstrates competitive results on several benchmarks but lacks detailed discussions of limitations, comparisons with recent SNN and distillation techniques, and a clear rationale for choosing SpikeBERT over other models with similar performance.",
      "strengths": [
        "Introduces a novel spiking neural network architecture for NLP tasks.",
        "Demonstrates improved energy efficiency and performance compared to baseline models.",
        "Provides a comprehensive evaluation on multiple NLP benchmarks."
      ],
      "weaknesses": [
        "Lacks a detailed discussion of limitations and potential drawbacks of the proposed model.",
        "Does not compare the model against recent advancements in SNNs and distillation techniques in NLP.",
        "Performance is comparable to TextCNN, making it unclear when to prefer one over the other.",
        "Math and notation in Section 3 are not precise, which may lead to confusion.",
        "Higher FLOPs for SpikeBERT despite lower energy consumption.",
        "Data augmentation strategies are not consistent across comparisons.",
        "Performance not compared against DistilBERT."
      ],
      "questions": [
        "Could you elaborate on the specific scenarios where SpikeBERT would be preferred over TextCNN despite similar performance?",
        "Why didn't you compare SpikeBERT against DistilBERT, a well-established distilled BERT model?",
        "Did you employ the same data augmentation strategies for all methods compared to SpikeBERT?",
        "How do you explain the higher number of FLOPs for SpikeBERT compared to FT BERT despite lower energy consumption?",
        "What are the key limitations of SpikeBERT that should be considered in future work?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "6CetUU9FSt",
    "title": "Visual Encoders for Data-Efficient Imitation Learning in Modern Video Games",
    "std_review": {
      "summary": "The paper investigates the use of pre-trained visual encoders for training agents in modern video games, finding that these encoders generally outperform end-to-end trained ones, especially in fine-grained perception tasks. It evaluates several encoders across three games, providing insights into bridging the gap between real-world images and game environments. While the study is comprehensive, it has limitations such as a narrow game scope and lack of long-horizon task evaluation.",
      "strengths": [
        "Comprehensive evaluation of multiple visual encoders across several modern video games.",
        "Clear methodology facilitating reproducibility.",
        "Insights into the effectiveness of pre-trained encoders in bridging distribution shifts between real-world and game environments."
      ],
      "weaknesses": [
        "Evaluation limited to three modern video games, potentially limiting generalizability.",
        "Focus on immediate decision-making tasks, overlooking long-horizon scenarios.",
        "No comparison with state-of-the-art approaches like VPT.",
        "Insufficient analysis of the impact of image augmentation."
      ],
      "questions": [
        "How do the findings generalize to a broader range of modern video games?",
        "What is the impact of visual encoders on long-horizon decision-making tasks?",
        "Could a more detailed analysis of image augmentation enhance performance?",
        "How do the results compare with recent state-of-the-art methods like VPT?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6cGiRiExUd",
    "title": "Efficient Point Cloud Matching",
    "std_review": {
      "summary": "The paper introduces PMT, a novel coarse‑to‑fine matching framework that enhances efficiency and accuracy of high‑order convolutions and attention mechanisms. It leverages a proxy tensor and an intermediate correlation term to improve feature representation and computational efficiency. Experimental results on synthetic and real‑world datasets show significant performance gains over existing methods, making PMT a promising approach for large‑scale applications.",
      "strengths": [
        "Innovative proxy tensor mechanism for efficient coarse matching",
        "Intermediate correlation term captures higher‑order interactions",
        "Strong experimental validation across diverse datasets",
        "Significant reductions in computational resources"
      ],
      "weaknesses": [
        "Proxy tensor may increase model interpretability complexity",
        "Limited dataset diversity could affect generalizability",
        "Lack of detailed theoretical analysis linking to high‑order convolutions",
        "Potential overfitting with higher‑order interactions"
      ],
      "questions": [
        "How does PMT perform on highly variable dataset sizes and complexities?",
        "What is the theoretical justification for the proxy tensor's role in matching?",
        "Can PMT be integrated with other state‑of‑the‑art matching techniques?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6CIGhcJYJH",
    "title": "Two-timescale Extragradient for Finding Local Minimax Points",
    "std_review": {
      "summary": "The paper introduces a novel timescale separation technique for analyzing the convergence of the Extragradient Method (EG) in convex-concave optimization, extending the analysis to stochastic settings using stochastic differential equations (SDEs). It provides a new restricted Schur complement condition for convergence, offering finer insights than previous work. While the approach is theoretically significant, it raises questions about the necessity of timescale separation and the impact of finite separation parameters, and assumes specific Hessian conditions that limit generality.",
      "strengths": [
        "Introduces a fresh timescale separation technique for EG, broadening the understanding of its convergence properties.",
        "Extends EG analysis to stochastic settings using SDEs, enhancing the method's applicability.",
        "Proposes a restricted Schur complement for more refined convergence conditions compared to prior work."
      ],
      "weaknesses": [
        "The necessity of timescale separation for EG is not fully justified; a single-timescale EG could potentially achieve similar convergence.",
        "The impact of choosing a finite separation parameter τ is underexplored, leaving open questions about its implications.",
        "Assumes specific Hessian conditions for nondegeneracy, which may restrict the generality of the results."
      ],
      "questions": [
        "Can the convergence properties of EG be achieved without timescale separation, or is it strictly necessary?",
        "What are the implications of choosing a finite separation parameter τ on convergence rates and stability?",
        "How can the results be generalized to cases where the Hessian does not meet the assumed conditions?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "6cMmSnOpCs",
    "title": "ScaLearn: Simple and Highly Parameter-Efficient Task Transfer by Learning to Scale",
    "std_review": {
      "summary": "ScaLearn presents a parameter‑efficient fine‑tuning method that dynamically scales the influence of multiple source tasks, enabling flexible knowledge transfer across NLI, QA, and classification tasks. The approach is evaluated on several benchmarks, showing significant performance gains over strong baselines while using fewer trainable parameters. Theoretical work supports the method's effectiveness, and experiments demonstrate robustness and scalability, though some concerns remain.",
      "strengths": [
        "Parameter efficiency: significantly reduces trainable parameters while maintaining or improving performance.",
        "Dynamic scaling: allows flexible adaptation of each source task's influence, enhancing transferability.",
        "Strong empirical validation: extensive benchmark results across diverse tasks confirm effectiveness and robustness."
      ],
      "weaknesses": [
        "Complexity of scaling coefficients: requires careful hyperparameter tuning, potentially impacting usability.",
        "Scalability concerns: managing many source tasks may become computationally expensive.",
        "Limited domain generalization: empirical evidence for new domains or modalities is lacking."
      ],
      "questions": [
        "How can the method be extended to handle a very large number of source tasks efficiently?",
        "What are the theoretical guarantees for avoiding overfitting when scaling coefficients are highly variable?",
        "How does ScaLearn perform when applied to non‑textual domains such as vision or speech?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6CZ50WgfCG",
    "title": "Learning Reusable Dense Rewards",
    "std_review": {
      "summary": "The paper introduces DrS, a novel reinforcement learning approach that uses discriminators and stage indicators to improve reward learning efficiency. It demonstrates significant reductions in training time and sample requirements compared to standard RL and GAIL methods. While innovative, the approach introduces computational costs and implementation complexity that could limit its practicality.",
      "strengths": [
        "Introduces a unique use of discriminators for reward learning.",
        "Leverages stage indicators to enhance focus and efficiency.",
        "Shows strong improvements in sample efficiency and reduced training time."
      ],
      "weaknesses": [
        "Increases computational costs due to additional discriminators.",
        "Adds complexity to implementation, potentially requiring more expertise.",
        "Risk of overfitting with limited data.",
        "Lacks comprehensive comparison with other state-of-the-art methods."
      ],
      "questions": [
        "How does DrS perform on larger, more complex environments?",
        "What strategies can be employed to mitigate overfitting with discriminators?",
        "How does the choice of stage indicators affect the generalization of learned rewards?"
      ],
      "overall_score": "6: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6EQbYM0CIX",
    "title": "Conditional Generative Modeling for High-dimensional Marked Temporal Point Processes",
    "std_review": {
      "summary": "The paper presents a conditional generative model for high-dimensional marked temporal point processes, leveraging variational learning to optimize domain-specific losses. It demonstrates strong performance on both synthetic and real-world datasets, outperforming existing baselines. The model's ability to handle high-dimensional mark spaces is a significant advancement, though its complexity and computational cost may pose challenges for broader adoption.",
      "strengths": [
        "Introduces a novel conditional generative approach for high-dimensional mark spaces.",
        "Demonstrates strong empirical performance on both synthetic and real-world datasets.",
        "Leverages variational learning to optimize domain-specific losses effectively."
      ],
      "weaknesses": [
        "Model complexity may hinder practical implementation for practitioners.",
        "Higher computational cost could limit applicability to large-scale datasets.",
        "Lack of detailed analysis across diverse datasets and conditions."
      ],
      "questions": [
        "How does the model scale to extremely large datasets with high-dimensional mark spaces?",
        "What are the theoretical guarantees on the convergence and stability of the variational learning approach?",
        "How does the model perform under noisy or missing mark space data?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6Ey8mAuLiw",
    "title": "On the Power of Multitask Representation Learning with Gradient Descent",
    "std_review": {
      "summary": "The paper presents a theoretical framework for multi‑task learning using a synthetic data model with shared and noisy feature patches. It derives test‑error bounds that depend on parameters α (shared information proportion) and H (number of patches), showing how they influence learning dynamics. Empirical experiments on synthetic data validate the theoretical predictions, but the model's artificial structure may limit real‑world applicability.",
      "strengths": [
        "Clear theoretical contributions with novel test‑error bounds dependent on key parameters.",
        "Well‑defined synthetic model that allows precise analysis of shared features and noise.",
        "Empirical validation that supports the theoretical findings and demonstrates the impact of model parameters."
      ],
      "weaknesses": [
        "The synthetic data model is highly artificial and may not reflect real‑world dataset complexity.",
        "Assumptions about feature patch probabilities and the number of patches may limit practical relevance.",
        "Theoretical analysis relies on parameters that can be difficult to estimate accurately in practice."
      ],
      "questions": [
        "How do the derived bounds generalize to more complex real‑world datasets with varied feature structures?",
        "What is the impact of parameter sensitivity (e.g., α, c) on model performance in practical scenarios?",
        "Could the framework be extended to handle non‑symmetric task relationships or varying amounts of shared information?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "6FAH0SgQzO",
    "title": "",
    "std_review": {
      "summary": "The paper presents FedRC, a federated learning framework that detects and adapts to concept shifts using a hard clustering mechanism. It outperforms FedAvg on CIFAR100 and Tiny-ImageNet datasets under concept shift conditions, with a strong theoretical foundation and clear experimental analysis. The reviewer finds the framework promising but notes areas for improvement in workflow clarity and real-world applicability.",
      "strengths": [
        "Effectively detects and adapts to various concept shifts, improving model robustness.",
        "Uses hard clustering for client grouping, enhancing accuracy and relevance of model updates.",
        "Provides a solid theoretical foundation and clear comparisons with existing methods."
      ],
      "weaknesses": [
        "Workflow diagram could be more detailed for clarity.",
        "Assumes IID datasets across clients, which may not hold in real-world scenarios.",
        "Theoretical comparison could be more in-depth.",
        "Optimization process details are somewhat vague.",
        "Lacks clear handling of non-participating clients during testing."
      ],
      "questions": [
        "How can the workflow diagram be improved to better illustrate the concept shift detection and clustering process?",
        "What are the specific steps for generating models of non-participating clients during testing?",
        "How does the optimization of Equation (2) ensure effective adaptation to detected concept shifts?",
        "How does the assumption of IID datasets impact the generalizability of the results to real-world federated learning settings?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6fFd8QaPVx",
    "title": "OneBNet: Binarized Neural Networks",
    "std_review": {
      "summary": "OneBNet introduces a novel 1-D binarized convolution architecture integrated into a ResNet backbone, aiming to improve efficiency and accuracy for edge computing. The paper proposes a dedicated 1-D downsampling layer and a learnable activation adjustment mechanism, achieving competitive performance on CIFAR-10 and ImageNet with notable latency and memory improvements on CPU-based devices. While demonstrating strong results, the evaluation is limited to specific datasets, and the paper lacks ablation studies and detailed hardware analysis, which could strengthen its claims.",
      "strengths": [
        "Innovative 1-D binarized convolutions extending beyond traditional 2-D BNNs.",
        "Dedicated 1-D downsampling layer offering better performance than standard pooling.",
        "Learnable activation distribution adjustment enhancing model flexibility.",
        "Clear heuristics for practitioners on layer replacement.",
        "Comprehensive evaluation across multiple datasets and state-of-the-art BNN methods."
      ],
      "weaknesses": [
        "Limited generalization to other datasets or tasks.",
        "Absence of ablation studies to assess component impact.",
        "Lack of detailed hardware compatibility and deployment analysis.",
        "Comparative scope limited to architecture-modifying BNN methods."
      ],
      "questions": [
        "How does OneBNet perform on non‑edge hardware or diverse datasets?",
        "What is the impact of each component (1-D downsampling, activation adjustment) on model performance?",
        "Could the proposed method be extended to other neural network architectures?",
        "What are the practical deployment challenges on real edge devices?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6FvBXs8t8K",
    "title": "Learn from the Past: A Proxy based Adversarial Defense Framework to Boost Robustness",
    "std_review": {
      "summary": "The paper presents a novel adversarial defense framework that uses historical model states as a proxy to iteratively update both the proxy and main models, improving robustness on CIFAR-10 and CIFAR-100 datasets. While showing strong empirical results against adversarial attacks and out-of-distribution samples, the framework's reliance on historical data introduces overfitting risks and hyperparameter sensitivity, potentially limiting its scalability and generalization.",
      "strengths": [
        "Innovative proxy model approach leveraging historical model states.",
        "Two-stage update rule effectively enhances model robustness.",
        "Empirical evidence of improved adversarial performance on standard datasets."
      ],
      "weaknesses": [
        "Potential overfitting to historical data.",
        "Sensitivity to hyperparameter choices.",
        "Scalability concerns for larger datasets or more complex models."
      ],
      "questions": [
        "How can the framework be adapted to handle more complex adversarial scenarios beyond standard attacks?",
        "What strategies can be employed to mitigate overfitting to historical data?",
        "How does the performance scale with increasing dataset size or model complexity?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6GySuKTJcd",
    "title": "Energy-Guided Continuous Entropic Barycenter Estimation for General Costs",
    "std_review": {
      "summary": "The paper introduces a novel algorithm that uses neural networks to parameterize potentials for a specific computational task, aiming to improve both theoretical guarantees and practical performance. Experimental results show significant efficiency and accuracy gains over existing methods, suggesting strong potential for related domains. However, the approach faces challenges such as high computational overhead with large numbers of potentials and unclear relevance of certain theoretical components. Overall, the paper is well-structured and presents a promising direction, though it requires further theoretical analysis and comparison with other methods.",
      "strengths": [
        "Integrates neural networks to provide a flexible and powerful framework for parameterizing potentials.",
        "Offers clear theoretical guarantees, enhancing reliability and trustworthiness.",
        "Demonstrates superior performance through experimental results compared to traditional approaches."
      ],
      "weaknesses": [
        "High computational overhead when the number of potentials is large.",
        "The relevance of Energy-Based Models (EBMs) is not clearly articulated.",
        "Lacks thorough analysis of convergence properties.",
        "Uses an unadjusted Metropolis-Hastings (ULA) MCMC procedure, which may introduce inefficiencies.",
        "Fails to compare with other sampling methods, limiting the understanding of trade-offs."
      ],
      "questions": [
        "What are the theoretical guarantees provided by Theorems 4 and 5, and how do they impact the algorithm's performance?",
        "How does the relevance of Energy-Based Models (EBMs) contribute to the proposed methodology?",
        "What are the convergence properties of the algorithm, and how do they compare to other methods?",
        "How does the use of an unadjusted Metropolis-Hastings (ULA) MCMC procedure affect scalability and efficiency?",
        "Could a detailed comparison with other sampling methods provide additional insights into the trade-offs?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "6Gzkhoc6YS",
    "title": "Personalize Segment Anything Model with One Shot",
    "std_review": {
      "summary": "PerSAM introduces a personalized segmentation model that leverages few-shot learning to fine-tune the Segment Anything Model (SAM) for specific objects or styles. By incorporating a personalized memory bank of reference image embeddings, PerSAM adapts to new objects with minimal examples, improving segmentation quality and flexibility. The integration with DreamBooth further enhances customization, showing promise for style transfer and image generation. While the paper demonstrates strong performance, it lacks comprehensive baseline comparisons and detailed analysis of computational efficiency.",
      "strengths": [
        "Personalization through Few-Shot Learning: PerSAM effectively adapts to new objects using only a few reference images, addressing a key limitation of zero-shot methods.",
        "Integration with SAM: By extending SAM, PerSAM retains the strengths of the original framework while adding the capability for personalized segmentation.",
        "Improved Customization with DreamBooth: The approach enhances DreamBooth's ability to generate diverse backgrounds, demonstrating practical benefits for style transfer and image generation tasks."
      ],
      "weaknesses": [
        "Baseline Comparison: The paper lacks a comprehensive comparison with state-of-the-art few-shot segmentation methods, such as DenseCLIP, which could provide a clearer benchmark for PerSAM's performance.",
        "Few-Shot Generalization: While the model improves with more reference images, the extent of its generalization to unseen objects within the same category remains underexplored.",
        "Parameter Generalization: It is unclear whether the same set of parameters can effectively generalize to different objects within the same category, especially when using standard fine-tuning approaches.",
        "Performance Metrics: The paper could benefit from more detailed analysis of running speed and memory consumption, particularly when comparing PerSAM to SAM and other segmentation models."
      ],
      "questions": [
        "How does PerSAM's performance compare to state-of-the-art few-shot segmentation methods like DenseCLIP?",
        "What is the extent of PerSAM's generalization to unseen objects within the same category using a few reference images?",
        "Can the same set of parameters effectively generalize to different objects within the same category, and if not, what alternative fine-tuning methods could be employed?",
        "What is the detailed analysis of PerSAM's running speed and memory consumption compared to SAM and other segmentation models?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6hP9JcXpNk",
    "title": "Going Beyond Familiar Features for",
    "std_review": {
      "summary": "The paper presents a novel anomaly detection framework that combines familiarity and novelty branches to improve detection performance. The familiarity branch uses nearest-neighbor encodings to assess known patterns, while the novelty branch leverages B‑cos network explanations to identify features not meaningfully represented by the encoder. Experiments show that the combined approach outperforms existing methods, especially in novelty‑only detection scenarios. The method is robust, interpretable, and less sensitive to background class variations, making it a strong contribution to the field.",
      "strengths": [
        "Dual branch architecture effectively addresses both known and unknown anomalies.",
        "Explainability via B‑cos network explanations enhances model transparency.",
        "Improved performance across multiple datasets compared to baseline methods."
      ],
      "weaknesses": [
        "Increased computational complexity due to dual branch and B‑cos explanations.",
        "Performance sensitivity to threshold and nearest‑neighbor settings.",
        "Lack of strong theoretical justification for the combined approach."
      ],
      "questions": [
        "How does the method scale to high-dimensional or streaming data?",
        "What is the impact of the choice of background class on the novelty branch?",
        "Can the framework be extended to other types of anomalies beyond novelty?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6hvtSLkKeZ",
    "title": "Learning to solve Class-Constrained Bin Packing Problems via Encoder-Decoder model",
    "std_review": {
      "summary": "The paper proposes an encoder-decoder framework for solving combinatorial optimization problems, specifically the Capacitated Vehicle Routing Problem, using a heat-map representation of connection probabilities. The approach incorporates an active search strategy to iteratively refine solutions, showing improved performance over existing methods. However, the novelty and effectiveness of the heat-map representation are not well-established, and several aspects of the method, such as the motivation behind its use and the role of the First Fit scheme, are not clearly explained.",
      "strengths": [
        "Introduces a novel encoder-decoder framework for combinatorial optimization problems.",
        "Proposes a heat-map representation of connection probabilities, differing from traditional node classification models.",
        "Incorporates an active search strategy to iteratively refine the solution, potentially leading to better performance."
      ],
      "weaknesses": [
        "The novelty of the heat-map representation is not well-established compared to other problems.",
        "The motivation behind using a heat-map to classify items is not clearly explained.",
        "The role of the First Fit (FF) scheme in the cluster decoder is not thoroughly discussed.",
        "The dataset used for generating ideal data is not described in detail.",
        "The process of active search and finetuning the model on a per-instance basis is not well-explained.",
        "The extension of the cluster decoder to consider additional constraints beyond class numbers is not explored.",
        "The main contributions of the encoder-decoder structure apart from active search are not clearly articulated."
      ],
      "questions": [
        "How does the novelty of the heat-map representation compare to other problems like TSP and VRP?",
        "What is the motivation behind using a heat-map to classify items instead of direct node classification?",
        "How does the First Fit (FF) scheme in the cluster decoder contribute to the solution?",
        "What is the size and construction method of the dataset used for generating ideal data?",
        "How is the active search performed, and how is the model finetuned on a per-instance basis?",
        "How can the cluster decoder be extended to consider additional constraints beyond class numbers?",
        "What are the main contributions of the encoder-decoder structure apart from active search?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "6HwamHLDa6",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a Multi‑In‑Single‑Out (MISO) architecture for video frame interpolation, using a shared network to predict multiple future frames from a single input. It extends perceptual loss to 3D to capture temporal dynamics, achieving significant improvements on Vimeo‑90K, Middlebury, and UCF101. The innovative architecture and loss function are strong contributions, though the multi‑output model may increase training complexity.",
      "strengths": [
        "Introduces a novel MISO architecture that predicts multiple future frames from a single input, improving temporal coherence.",
        "Extends perceptual loss to 3D to effectively capture both spatial and temporal features of video motion.",
        "Demonstrates strong performance across diverse datasets, outperforming existing methods."
      ],
      "weaknesses": [
        "The multi‑output model may increase computational complexity and training time.",
        "Potential overfitting due to multiple outputs, especially with limited training data.",
        "May struggle with extreme edge cases like rapid frame changes or severe occlusions."
      ],
      "questions": [
        "How does the model handle extremely long video sequences with limited memory resources?",
        "What strategies are employed to mitigate overfitting when using multiple outputs?",
        "Can the approach be extended to real‑time applications with constrained computational budgets?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6hzNVNSz8O",
    "title": "No learning rates needed: Introducing SALSA",
    "std_review": {
      "summary": "The paper introduces SaLSa, a novel learning‑rate scheduling method that integrates a line‑search mechanism with a smoothed Armijo condition to adaptively adjust learning rates during training. SaLSa aims to enhance convergence stability and performance across various tasks, including image classification on ImageNet and natural language processing tasks. Experimental results demonstrate competitive or superior performance compared to traditional learning‑rate schedules and baseline optimizers, highlighting SaLSa's robustness and efficiency. The reviewer finds the method innovative, theoretically sound, and empirically strong, though with some concerns about hyperparameter sensitivity and reproducibility.",
      "strengths": [
        "Innovative learning‑rate scheduling combining line‑search with smoothed Armijo conditions.",
        "Strong theoretical foundation with convergence guarantees under specific conditions.",
        "Empirical performance that often outperforms standard baselines across multiple datasets and model architectures."
      ],
      "weaknesses": [
        "Lack of comprehensive ablation study on hyperparameter sensitivity.",
        "Baseline comparisons using flat schedules may underestimate SaLSa's true performance.",
        "Additional computational overhead from line‑search steps could impact scalability.",
        "Training details are not fully reproducible, raising reproducibility concerns."
      ],
      "questions": [
        "Conduct a detailed ablation study to quantify hyperparameter sensitivity.",
        "Compare SaLSa against more sophisticated learning‑rate schedules like cosine decay.",
        "Validate the reproducibility of training details, including data augmentation and batch size.",
        "Provide quantitative evidence of SaLSa's robustness to mini‑batch noise.",
        "Explore evaluation on larger models and more demanding pretraining regimes."
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6I7UsvlDPj",
    "title": "LAMPP: Language Models as Probabilistic Priors for Perception and Action",
    "std_review": {
      "summary": "The paper introduces LaMPP, a framework that integrates large language models with multimodal data for tasks like semantic segmentation and video action recognition. It shows significant performance improvements over traditional models, highlighting the potential of multimodal prompting with LLMs. While innovative, the approach faces challenges in implementation complexity and scalability, and could benefit from deeper analysis of its prompting mechanism.",
      "strengths": [
        "Innovative multimodal prompting with LLMs",
        "Significant performance improvements over baselines",
        "Versatile and broadly applicable approach"
      ],
      "weaknesses": [
        "High computational and implementation complexity",
        "Scalability concerns for larger datasets",
        "Lack of detailed analysis on model behavior",
        "Benchmarking limited to specific tasks"
      ],
      "questions": [
        "How does the prompting mechanism affect model interpretability and robustness?",
        "What are the scalability strategies for applying LaMPP to larger datasets?",
        "Can the model's performance be generalized to more abstract or context-dependent object recognition tasks?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6IjN7oxjXt",
    "title": "Conserve-Update-Revise to Cure Generalization and Robustness Trade-off in Adversarial Training",
    "std_review": {
      "summary": "The paper introduces CURE, a novel adversarial training method that balances standard and robust generalization by selectively conserving, updating, and revising weights based on a gradient prominence criterion. CURE improves natural and robust accuracy on various datasets compared to baselines, offering a clear theoretical framework for understanding the trade-off between standard and robust generalization. However, its effectiveness may be dataset-dependent, and further analysis of computational complexity and scalability is needed.",
      "strengths": [
        "Introduces a novel gradient prominence criterion for selective weight management in adversarial training.",
        "Demonstrates improved performance in both natural and robust accuracy compared to existing methods.",
        "Provides a clear theoretical framework for understanding the trade-off between standard and robust generalization."
      ],
      "weaknesses": [
        "Effectiveness may be dataset-dependent, as shown in some experimental results.",
        "Performance on more complex datasets or real-world applications has not been thoroughly explored.",
        "Lacks detailed analysis of the computational complexity and scalability of the CURE method.",
        "Robustness against various types of adversarial attacks is not comprehensively evaluated."
      ],
      "questions": [
        "How does CURE perform on more complex datasets or real-world applications?",
        "What is the computational complexity and scalability of the CURE method?",
        "How robust is CURE against various types of adversarial attacks?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6INCxtPVXd",
    "title": "Mode-Aware Continual Learning for Conditional Generative Adversarial Networks",
    "std_review": {
      "summary": "The paper proposes a novel continual learning approach for conditional GANs called Discriminator-based Mode Affinity Score (dMAS), which mitigates catastrophic forgetting by measuring similarity between target and source classes using a discriminator. Empirical results on MiniImagenet, Omniglot, and CIFAR-10 datasets show effectiveness compared to baselines. However, the method's reliance on labeled data and lack of theoretical justification are noted limitations.",
      "strengths": [
        "Introduces a novel approach to continual learning for cGANs, addressing catastrophic forgetting.",
        "Proposes a Discriminator-based Mode Affinity Score (dMAS) to measure similarity between target and source classes.",
        "Incorporates a replay mechanism to store and reuse information from previous tasks."
      ],
      "weaknesses": [
        "Limited applicability to unsupervised learning settings due to reliance on labeled source classes.",
        "Effectiveness not theoretically justified, relying primarily on empirical results.",
        "Choice of datasets may not fully capture current trends in generative model and continual learning research."
      ],
      "questions": [
        "How does the method perform in unsupervised learning settings?",
        "What is the theoretical justification for the effectiveness of the proposed approach?"
      ],
      "overall_score": "6: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6iwg437CZs",
    "title": "STanHop: Sparse Tandem Hopfield Model for Memory-Enhanced Time Series Prediction",
    "std_review": {
      "summary": "STanHop-Net introduces a novel neural network architecture that combines sparse Hopfield networks with alpha-entropy regularization to enhance memory recall in multivariate correlation environments. The model demonstrates superior performance over existing methods like DLinear, thanks to its innovative regularization technique and improved sparsity. However, the complexity of implementation and potential overfitting due to high sparsity are noted as limitations.",
      "strengths": [
        "Innovative use of alpha-entropy regularization for maintaining sparsity.",
        "Improved sparsity and stability lead to better recall accuracy and computational efficiency.",
        "Robust performance in environments with complex multivariate correlations."
      ],
      "weaknesses": [
        "Increased complexity of implementation due to alpha-entropy regularization.",
        "Potential for overfitting with high sparsity levels.",
        "Lack of detailed analysis on time complexity and parameter count."
      ],
      "questions": [
        "How does the model handle scenarios with limited training data to prevent overfitting?",
        "What is the detailed time complexity and parameter count of STanHop-Net?",
        "Can the model be extended to handle non-stationary or evolving multivariate correlations?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6J3ehSUrMU",
    "title": "Principled Federated Domain Adaptation:",
    "std_review": {
      "summary": "The paper presents two federated learning aggregation methods, FedDA and FedGP, designed to balance source domain knowledge with target domain adaptation. It introduces auto‑weighting variants that dynamically adjust client influence based on domain similarity, showing robustness to domain shift and scalability to multiple target clients. The work is well‑evaluated with experiments across varying data levels and shift magnitudes, though it has some implementation complexity and limited real‑world dataset testing.",
      "strengths": [
        "Innovative aggregation schemes that effectively combine source and target domain knowledge.",
        "Auto‑weighting mechanism provides a practical way to adapt to domain shifts.",
        "Strong theoretical guarantees and comprehensive empirical evaluation."
      ],
      "weaknesses": [
        "Implementation complexity due to additional computational overhead.",
        "Limited benchmark datasets may restrict generalizability.",
        "Absence of extensive baseline comparisons."
      ],
      "questions": [
        "How does the auto‑weighting mechanism perform in highly imbalanced client distributions?",
        "What are the theoretical limits of the noise reduction guarantees under extreme domain shift?",
        "How can the framework be extended to non‑IID data settings?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6jBNQ8nSxA",
    "title": "Just-in-Time Security Patch Detection - LLM At the Rescue for Data Augmentation",
    "std_review": {
      "summary": "The paper introduces LLMDA, a method that uses large language models to generate textual explanations for software security patches, enhancing interpretability and trustworthiness. Experiments on PatchDB and SPI-DB show LLMDA outperforms baselines like GraphSPD. While innovative, the paper lacks detailed model configurations, thorough ablation studies, and comprehensive ethical considerations, leading to concerns about reproducibility and generalizability.",
      "strengths": [
        "Innovative integration of LLMs to generate contextual textual information for source code.",
        "Effective use of hierarchical attention mechanisms to integrate multi-modal inputs.",
        "Empirical validation on real-world datasets demonstrating improved performance."
      ],
      "weaknesses": [
        "Lack of detailed model configuration details hindering reproducibility.",
        "Potential overfitting to textual explanations limiting generalizability.",
        "Insufficient evidence of data leakage prevention measures.",
        "Complexity of hierarchical attention mechanisms not fully explained.",
        "Omission of comparison with recent syntax/structure-based methods.",
        "Unclear criteria for defining positive and negative pairs in contrastive loss.",
        "Limited exploration of LLMDA's generalizability across software systems.",
        "Absence of detailed ethical considerations regarding model outputs."
      ],
      "questions": [
        "Could you provide detailed configurations of LLMDA and baselines for reproducibility?",
        "What ablation studies were conducted to isolate the impact of textual explanations?",
        "How were data leakage concerns addressed and validated?",
        "Please elaborate on the application of hierarchical attention mechanisms.",
        "How does LLMDA compare with recent syntax/structure-based methods?",
        "Could you clarify the criteria for defining positive and negative pairs in contrastive loss?",
        "What are the limitations of LLMDA's generalizability across different software systems?",
        "What safeguards are in place to ensure unbiased and reliable model outputs?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "6jFjYmahxu",
    "title": "DiffSound: Differentiable Modal Sound Simulation for Inverse Reasoning",
    "std_review": {
      "summary": "DiffSound presents a novel framework that combines physics-based shape recovery with deep learning-driven sound synthesis. By leveraging Signed Distance Functions and tetrahedral mesh reconstruction, it achieves high accuracy in shape recovery with reduced computational overhead compared to traditional methods. The paper demonstrates significant improvements in both sound fidelity and recovery efficiency, validated through comprehensive experiments. Overall, DiffSound offers a robust approach with strong potential for applications in medical imaging and beyond.",
      "strengths": [
        "Innovative integration of physics-based modeling with deep learning.",
        "Efficient shape recovery using SDF and tetrahedral mesh reconstruction.",
        "Hybrid loss function enhances convergence and stability."
      ],
      "weaknesses": [
        "Complex implementation due to multiple integrated components.",
        "Scalability concerns for very large or complex geometries.",
        "Dependence on high-quality training data.",
        "Limited generalizability based on a specific dataset."
      ],
      "questions": [
        "How can the framework be adapted for real-time applications with large or complex geometries?",
        "What strategies can be employed to improve the generalizability of the model across different datasets?",
        "How does the choice of the number of modes in eigen-decomposition impact performance in practical scenarios?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6K81ILDnuv",
    "title": "Learning from Integral Losses in Physics Informed Neural Networks",
    "std_review": {
      "summary": "The paper introduces a delayed target method for solving integro‑differential equations using physics‑informed neural networks, showing strong performance on synthetic benchmarks. While theoretically justified and empirically validated, the method's generalization to real‑world problems and its computational efficiency remain unproven. The authors should provide more quantitative analysis and clarify theoretical assumptions.",
      "strengths": [
        "Introduces a novel delayed target mechanism that improves sample efficiency and stability.",
        "Provides clear theoretical justification for bias reduction.",
        "Demonstrates strong empirical performance on synthetic benchmarks.",
        "Proposes and evaluates three complementary techniques for enhanced convergence."
      ],
      "weaknesses": [
        "Results are limited to synthetic problems; real‑world generalization is unverified.",
        "Lacks quantitative measures of computational efficiency.",
        "Does not provide guidance on tuning problem‑specific hyper‑parameters.",
        "Theoretical arguments lack formal variance decomposition.",
        "Some figures and tables are difficult to interpret."
      ],
      "questions": [
        "How does the method perform on real‑world integro‑differential equations?",
        "What are the optimal hyper‑parameter settings for different problem domains?",
        "Can the method be extended to higher‑dimensional or nonlinear problems?",
        "How does the delayed target method compare to other state‑of‑the‑art approaches like VPINNs?",
        "What is the computational cost of the delayed target method in practice?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "6LLho5X6xV",
    "title": "UniTabE: A Universal Pretraining Protocol",
    "std_review": {
      "summary": "UniTabE introduces a transformer-based model for tabular data understanding, pre-trained on a large Kaggle dataset and demonstrating strong performance on tasks like table-to-text generation and question answering. The model shows good generalizability across domains but has limited evaluation scope and lacks detailed ethical considerations regarding data usage. Overall, the paper is promising but requires addressing these limitations.",
      "strengths": [
        "Innovative pre-training approach using a large-scale tabular dataset.",
        "Strong performance on various tabular understanding tasks.",
        "Demonstrated flexibility and generalizability across domains."
      ],
      "weaknesses": [
        "Limited evaluation scope with narrow datasets.",
        "Baseline selection may not fully represent state-of-the-art.",
        "Lack of discussion on ethical and legal aspects of data usage."
      ],
      "questions": [
        "How can the evaluation be expanded to include a broader range of tabular data scenarios?",
        "Could you clarify the ethical and legal considerations for using Kaggle data in pre-training?",
        "What specific mechanisms in the TabUnit architecture enable handling of complex table structures?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "6LNTSrJjBe",
    "title": "Language Agent Tree Search Unifies Reasoning Acting and Planning in Language Models",
    "std_review": {
      "summary": "The paper introduces LATS, a framework that integrates search algorithms with large language models to enhance reasoning and decision-making. It leverages self-reflection and external feedback to guide the search process, showing improved performance on reasoning benchmarks compared to existing techniques. While effective, LATS faces limitations in scalability and handling complex environments, suggesting areas for future refinement.",
      "strengths": [
        "Combines search algorithms with LLMs to improve reasoning and decision-making abilities.",
        "Introduces key technical innovations like self-reflection and external feedback.",
        "Demonstrates improved performance on reasoning benchmarks compared to existing methods."
      ],
      "weaknesses": [
        "Limited scalability and applicability to large-scale problems or complex environments.",
        "Potential limitations in handling complex environments or large-scale problems."
      ],
      "questions": [
        "How can LATS be adapted to handle more complex environments beyond current benchmarks?",
        "What further refinements are needed to address scalability and applicability concerns?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6LyO8WTVTU",
    "title": "A Teacher-Guided Framework for Graph Representation Learning",
    "std_review": {
      "summary": "The paper introduces TGCL, a teacher-guided contrastive learning framework for knowledge distillation that outperforms traditional methods on downstream tasks like image classification and NLP. It leverages a well-pretrained teacher to guide a student model, demonstrating strong knowledge transfer and robustness to overfitting. The approach is grounded in contrastive learning principles and is versatile across domains, though it relies on high-quality teacher pretraining and can be computationally intensive.",
      "strengths": [
        "Effective knowledge transfer from a well-pretrained teacher to a student model.",
        "Robustness to overfitting, maintaining performance even when the teacher model is overfitted.",
        "Strong theoretical foundation based on contrastive learning principles."
      ],
      "weaknesses": [
        "Highly dependent on the quality and appropriateness of the teacher model's pretraining.",
        "Computationally intensive due to the contrastive learning component.",
        "Performance may be sensitive to hyperparameter choices, requiring extensive tuning."
      ],
      "questions": [
        "How does TGCL perform when applied to domains with limited pretraining data?",
        "What are the formal theoretical guarantees for convergence and generalization in TGCL?",
        "Can TGCL be extended to handle multimodal data more effectively?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6mLjDwYte5",
    "title": "Mixture-of-Experts Meets Instruction Tuning: A Winning Combination for Large Language Models",
    "std_review": {
      "summary": "The paper demonstrates that instruction‑tuned mixture‑of‑experts (MoE) models, specifically Flan‑MoE, achieve state‑of‑the‑art results on GLUE, SuperGLUE, and MMLU benchmarks, outperforming dense models. It provides a clear evaluation framework and explores the impact of routing strategies and expert utilization, offering valuable insights for optimizing MoE architectures. However, the study does not fully address computational costs, lacks a broader comparison with other MoE models, and does not examine long‑term stability.",
      "strengths": [
        "Clear contribution: defines the problem and presents a comprehensive evaluation framework.",
        "State‑of‑the‑art results: achieves competitive performance on multiple benchmarks.",
        "Innovative evaluation: analyzes routing strategies and expert utilization."
      ],
      "weaknesses": [
        "Computational cost: does not extensively address increased resource requirements.",
        "Limited comparison: lacks broader comparison with other MoE architectures.",
        "Absence of long‑term stability analysis."
      ],
      "questions": [
        "How do the computational costs of instruction‑tuned MoE models compare to dense models in real‑world deployments?",
        "What are the long‑term stability and generalization properties of instruction‑tuned MoE models?",
        "How do different routing strategies impact the scalability of Flan‑MoE?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6MRm3G4NiU",
    "title": "SaProt: Protein Language Modeling with Structure-aware Vocabulary",
    "std_review": {
      "summary": "The paper introduces SaProt, a protein language model that integrates structural information using Foldseek tokens alongside sequence data, showing improved performance on downstream tasks compared to ESM-2. While innovative, the model's potential is limited by the lack of extensive hyperparameter tuning, dataset consistency with other models, and ablation studies. The authors should address these issues to strengthen the model's robustness and generalizability.",
      "strengths": [
        "Innovative integration of structural information using Foldseek tokens.",
        "Strong pre-training strategy on a large protein dataset.",
        "Comprehensive evaluation across multiple downstream tasks."
      ],
      "weaknesses": [
        "Limited exploration of Foldseek hyperparameters.",
        "Dataset inconsistency between pre-training and model evaluation.",
        "Absence of ablation experiments to assess structural vs. sequence contributions.",
        "Comparison with other models is not exhaustive."
      ],
      "questions": [
        "How do different Foldseek hyperparameters affect model performance?",
        "Could using a more abstract representation of structural information improve results?",
        "What is the impact of structural information versus sequence information alone?",
        "How does SaProt compare to other recent structure-aware models like MSA Transformer or GearNet?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "6N8TW504aa",
    "title": "Graphical Multioutput Gaussian Process with Attention",
    "std_review": {
      "summary": "The paper introduces GMOGP, an extension of MOGP that uses asymmetric attention coefficients to model dependencies between multiple outputs, handling unbalanced datasets effectively. It provides a solid theoretical foundation and demonstrates superior performance on synthetic and real-world datasets. However, computational complexity and scalability concerns limit its broad applicability.",
      "strengths": [
        "Captures directional dependencies between outputs using asymmetric attention coefficients.",
        "Designed to handle datasets with unbalanced numbers of observations per output.",
        "Provides a strong theoretical foundation with detailed derivations and proofs."
      ],
      "weaknesses": [
        "Increased computational complexity due to asymmetric attention coefficients.",
        "Lack of comprehensive guidelines for initializing model weights.",
        "Scalability concerns for large datasets or high numbers of outputs."
      ],
      "questions": [
        "How can the computational complexity be reduced while maintaining model performance?",
        "What are the best practices for initializing model weights, especially in unbalanced data scenarios?",
        "What strategies can be employed to improve scalability for large datasets?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "6NEJ0ReNzr",
    "title": "",
    "std_review": {
      "summary": "The paper presents a novel blueprint generation approach for summarization, aiming to improve attribution quality by structuring the summarization process with a sequence of questions. While innovative, the method lacks direct comparisons isolating blueprint generation from document retrieval and does not fully detail human evaluation metrics or ablation studies. These omissions reduce the overall impact despite promising results.",
      "strengths": [
        "Introduces a unique blueprint generation process that explicitly plans summarization steps.",
        "Demonstrates improved attribution quality through both quantitative and qualitative evaluations.",
        "Compares against multiple baselines, showing robustness across extractive and abstractive models."
      ],
      "weaknesses": [
        "Fails to provide a direct apples-to-apples comparison by not evaluating models without the retriever component.",
        "Human evaluation details are insufficient, lacking dataset specifics, annotator qualifications, and inter‑annotator agreement.",
        "Ablation studies are missing, hindering understanding of the model's reliance on attribution versus blueprint generation.",
        "Training mechanisms and copy supervision details for extractive and abstractive models are not fully clarified."
      ],
      "questions": [
        "Could a direct apples-to-apples comparison isolating blueprint generation from document retrieval be provided?",
        "Please detail the human evaluation dataset, annotator qualifications, and inter‑annotator agreement.",
        "Should ablation studies explore the impact of removing or modifying the attribution step?",
        "Could additional details on training mechanisms and copy supervision for the models be included?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "6NO5UVWvo6",
    "title": "",
    "std_review": {
      "summary": "The paper introduces PSCV, a point‑supervised contrastive variance loss for medical image segmentation that uses random point annotations to guide the model. It combines partial cross‑entropy loss with a contrastive variance loss using variance distribution maps, achieving competitive results on the Synapse dataset. The method shows promise for weakly supervised segmentation but has some theoretical and practical concerns.",
      "strengths": [
        "Introduces a novel contrastive variance loss leveraging variance distribution maps.",
        "Reduces annotation effort by using random point annotations.",
        "Achieves performance comparable to fully supervised methods on Synapse."
      ],
      "weaknesses": [
        "Lacks a fully elaborated theoretical justification for the contrastive loss.",
        "Relies on random annotations which may affect reproducibility.",
        "Lack of a separate validation set raises concerns about over‑fitting."
      ],
      "questions": [
        "How does the theoretical foundation of the contrastive variance loss compare to existing methods?",
        "What is the impact of random point selection on convergence and final performance?",
        "How does the method perform on other medical imaging datasets beyond Synapse?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6O3Q6AFUTu",
    "title": "",
    "std_review": {
      "summary": "The paper presents a novel approach to image editing by combining stochastic differential equations (SDEs) with diffusion models, aiming to improve interpolation quality. It introduces a boundary control mechanism to prevent artifacts, outperforming existing methods on several datasets. While the method shows promise, practical concerns such as computational cost, hyperparameter selection, and limited evaluation metrics need addressing.",
      "strengths": [
        "Integrates SDEs with diffusion models for effective image editing.",
        "Introduces a boundary control method to prevent artifacts.",
        "Demonstrates improved interpolation quality on multiple datasets."
      ],
      "weaknesses": [
        "Computational cost of latent space mapping may hinder real-time or large-scale applications.",
        "Lack of detailed hyperparameter selection strategy.",
        "Evaluation limited to a few datasets with no comprehensive quantitative metrics."
      ],
      "questions": [
        "Could you provide a more detailed strategy for selecting hyperparameters?",
        "What is the theoretical justification for the boundary control method?",
        "How can the method be evaluated across a larger set of diverse image types and styles?",
        "What optimizations can be applied to reduce the computational overhead of latent space mapping?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "6okaSfANzh",
    "title": "Large Language Model Cascades with Mixture of Thought Representations for Cost-Efficient Reasoning",
    "std_review": {
      "summary": "The paper introduces MoT-2D, a two‑prompt verification framework that combines a chain‑of‑thought (CoT) prompt with a prompt‑only (PoT) prompt to verify language model outputs. It shows consistent performance gains over a baseline CoT approach and a simple majority vote, especially on harder reasoning tasks, while also providing a quantitative consistency measure. The framework is scalable to stronger models and offers a reproducible method for assessing answer consistency, though it has some limitations.",
      "strengths": [
        "Introduces a novel two‑prompt mechanism (CoT + PoT) that leverages both structured reasoning and raw output, potentially reducing hallucinations.",
        "Demonstrates scalability to stronger LLMs without extensive fine‑tuning.",
        "Provides a clear, reproducible method for assessing answer consistency, which is valuable for understanding model behavior.",
        "Empirical validation across a variety of reasoning tasks highlights its robustness."
      ],
      "weaknesses": [
        "Performance is sensitive to temperature settings, with the best results achieved at 0.8, limiting general applicability.",
        "External verification using GPT‑3.5 yields poor performance, suggesting the verifier may not reliably distinguish correct from incorrect answers.",
        "There is a risk of over‑confidence in the weaker LLM, potentially leading to incorrect routing decisions.",
        "Higher temperature settings (e.g., 1.0) for the CoT prompt were not explored, limiting insights into optimal prompt configurations."
      ],
      "questions": [
        "How does the framework perform when evaluated on more complex, multi‑step reasoning tasks beyond the current suite?",
        "What is the impact of using different temperature settings for the CoT and PoT prompts on overall performance?",
        "Can the framework be extended to handle tasks with domain‑specific knowledge where the weaker LLM may be overly confident in incorrect answers?",
        "How does the framework's scalability to larger models (e.g., GPT‑4) affect its performance and resource requirements?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6p8lpe4MNf",
    "title": "A Semantic Invariant Robust Watermark",
    "std_review": {
      "summary": "The paper introduces a watermarking technique for LLM-generated text that embeds imperceptible markers using green tokens and controlled prompt engineering. Experiments show robust detection across multiple models, supporting multi‑key watermarking for enhanced security. While innovative, the method's effectiveness relies on the original prompt and has limited analysis of attack scenarios.",
      "strengths": [
        "Innovative detection mechanism that remains effective even when the original prompt is hidden.",
        "Demonstrated robustness across multiple LLMs, indicating broad applicability.",
        "Supports multi‑key watermarking, enhancing security and privacy."
      ],
      "weaknesses": [
        "Effectiveness is contingent on having access to the original prompt.",
        "Lack of comprehensive analysis of optimal parameter values (δ and γ).",
        "Limited discussion on handling sophisticated attacks.",
        "Potential scalability issues with large‑scale deployments."
      ],
      "questions": [
        "How does the method perform when the original prompt is completely removed or anonymized?",
        "What is the impact of varying δ and γ on detection rates and text quality?",
        "How does the approach handle shared text attacks where the generated text is disseminated without the original prompt?"
      ],
      "overall_score": "6: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6PbvbLyqT6",
    "title": "Dynamic Discounted",
    "std_review": {
      "summary": "The paper introduces DDCFR, a novel approach that combines CFR with deep learning and incorporates a discount factor to improve convergence speed and scalability for larger games. Empirical evaluations show that DDCFR outperforms traditional CFR and Deep CFR in terms of solution quality and computational efficiency, especially for games with many players and actions. While the method demonstrates robust performance and provides valuable theoretical insights, it has some theoretical concerns and lacks direct comparison with more recent methods.",
      "strengths": [
        "Innovative integration of discounting into CFR.",
        "Demonstrates strong scalability to larger games.",
        "Consistently achieves high solution quality across various game sizes."
      ],
      "weaknesses": [
        "Does not rigorously address boundedness of the discount factor.",
        "Lacks exploration of alternative optimization strategies for hyperparameters.",
        "Limited empirical comparison with state-of-the-art methods."
      ],
      "questions": [
        "How does the boundedness of the discount factor τ affect long-term stability and performance?",
        "What alternative optimization strategies could be explored for tuning discount rates?",
        "How does DDCFR compare to more recent and advanced methods in the field?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6PjS5RnxeK",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a novel theoretical framework linking the Jacobian norm of neural network outputs to a notion of 'progressive sharpening' during training. It presents two key theorems that relate model capacity to generalization and provide a generalization bound sensitive to data dimensionality. Empirical experiments support the hypothesis that increasing Jacobian norms correlate with improved model sharpness and generalization, suggesting Jacobian regularization as a practical alternative to loss-based regularization. While the work is theoretically significant and empirically validated, it has some limitations in formal rigor and practical generalization.",
      "strengths": [
        "Novel theoretical contribution linking Jacobian norms to model generalization.",
        "Clear empirical validation demonstrating the relationship between Jacobian norms and model sharpness.",
        "Practical implications for practitioners, offering a new regularization strategy."
      ],
      "weaknesses": [
        "Formal mathematical precision is lacking in the theoretical formulation of Ansatz 3.1.",
        "The generalization bound in Theorem 6.1 is highly sensitive to intrinsic data dimensionality.",
        "Empirical evidence does not firmly establish a causal link between Jacobian norms and sharpening."
      ],
      "questions": [
        "How can the formalization of Ansatz 3.1 be improved to enhance its theoretical rigor?",
        "What are the practical steps to mitigate the sensitivity of the generalization bound to intrinsic dimensionality?",
        "Can additional experiments be designed to more strongly establish a causal relationship between Jacobian norms and model sharpening?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6PmJoRfdaK",
    "title": "LongLoRA: Efficient Fine-tuning of LongContext Large Language Models",
    "std_review": {
      "summary": "LongLoRA introduces a novel $S^2$-Attention mechanism to efficiently fine-tune large language models for long-context tasks (up to 32K tokens) using LoRA. It demonstrates comparable or superior performance to full fine-tuning with significantly fewer parameter updates and training time on a 32K-token retrieval benchmark. While innovative, the method's generalizability to other tasks and longer contexts beyond 8192 tokens is limited, and some methodological details remain vague.",
      "strengths": [
        "Introduces $S^2$-Attention, a novel attention mechanism that maintains long-context performance while reducing computational costs.",
        "Demonstrates substantial efficiency gains with fewer parameter updates and training time compared to full fine-tuning.",
        "Provides a clear theoretical foundation and ablations for the proposed group size heuristic and layer freezing strategies."
      ],
      "weaknesses": [
        "Evaluation is limited to retrieval tasks; broader generative tasks are not assessed.",
        "The 25% group size heuristic is validated only up to 8192 tokens, leaving its effectiveness for longer contexts unclear.",
        "Methodological details for FLOP estimation and memory usage are not fully specified.",
        "Training speed improvements are claimed but lack concrete benchmarks.",
        "No systematic analysis of hyper-parameter sensitivity."
      ],
      "questions": [
        "How does LongLoRA perform on other generative tasks beyond retrieval, such as document QA or summarization?",
        "What is the exact formula for estimating FLOPs in Table 10, and how does $S^2$-Attention's memory usage compare to regular LoRA?",
        "How robust is the 25% group size heuristic for contexts longer than 8192 tokens?",
        "What are the concrete benchmarks for the reported 2.1× training speedup?",
        "How does the method behave when embedding and normalization layers are unfrozen?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "6pPYRXKPpw",
    "title": "Towards Diverse Behaviors: A Benchmark for Imitation Learning with Human Demonstrations",
    "std_review": {
      "summary": "The paper introduces a novel framework that integrates diffusion models with reinforcement learning to enhance sample efficiency and policy stability. It demonstrates significant improvements on benchmark tasks, offering a fresh perspective on policy learning. While the approach is theoretically sound and empirically validated, its complexity and limited evaluation scope raise some concerns.",
      "strengths": [
        "Introduces a novel integration of diffusion models with reinforcement learning, offering a fresh perspective on policy learning.",
        "Demonstrates improved sample efficiency and policy stability, which are critical challenges in RL.",
        "Provides a comprehensive evaluation across multiple benchmark tasks, showcasing the method's broad applicability."
      ],
      "weaknesses": [
        "The complexity of the proposed framework may make it challenging for practitioners to implement and fine-tune.",
        "The evaluation is limited to a few benchmark tasks, which may not fully capture the method's potential across all domains.",
        "The paper lacks a detailed discussion on the computational costs associated with training diffusion policies, which could be a significant concern for large-scale applications."
      ],
      "questions": [
        "The action space used by the environments is not explicitly detailed in the paper. Further clarification on the specific action spaces used in their experiments would strengthen the paper.",
        "The argument against providing additional context to the policy on how to perform the task is rooted in the principle of maximizing the policy's autonomy and generalizability. Further exploration of this trade-off could be valuable."
      ],
      "overall_score": "6: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6PVgHZUepm",
    "title": "Rep-Adapter: Parameter-free Automatic Adaptation of Pre-trained ConvNets via Parameterization",
    "std_review": {
      "summary": "Rep-Adapter presents a parameter‑free fine‑tuning technique for ConvNets by introducing learnable scaling factors for each filter branch, enabling dynamic learning‑rate adjustments during training. The method achieves comparable or better performance than full fine‑tuning with significantly reduced computational cost. Its simplicity, efficiency, and broad applicability across vision tasks make it a valuable contribution. The review recommends acceptance with high confidence.",
      "strengths": [
        "Parameter‑free adaptation preserves the efficiency of pre‑trained models.",
        "Dynamic learning‑rate scaling via learnable factors (ωR) can improve convergence and performance.",
        "Two‑branch architecture with batch‑normalization simplifies implementation.",
        "Demonstrates strong results across multiple vision tasks and datasets."
      ],
      "weaknesses": [
        "Computation of scaling factors may introduce additional overhead.",
        "Risk of over‑fitting with more adaptive parameters, especially on small datasets.",
        "Current implementation is limited to convolutional layers.",
        "Performance may be sensitive to scaling factor initialization and learning‑rate schedules."
      ],
      "questions": [
        "How does the method handle over‑fitting on small datasets?",
        "What is the impact of hyperparameter choices (e.g., scaling factor initialization) on performance?",
        "Can the two‑branch architecture be extended to other model types (e.g., transformers) without significant modifications?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6qtDu7hVPF",
    "title": "Generative Reinforcement Learning",
    "std_review": {
      "summary": "The paper proposes a generative approach to model state distributions in reinforcement learning by conditioning a pre-trained transformer on both returns and actions, aiming to improve training efficiency and sample usage. Experiments on Atari games show faster convergence and competitive performance compared to a discriminative baseline, though the Elo gap remains modest. The authors discuss theoretical foundations and suggest future work on policy comparisons and scalability.",
      "strengths": [
        "Innovative generative state modeling that conditions on returns and actions.",
        "Demonstrated training efficiency gains with substantial reduction in training time and evaluations.",
        "Strong theoretical alignment through value function decomposition."
      ],
      "weaknesses": [
        "Limited policy comparison with a behavioral cloning baseline rather than a true policy-based method.",
        "Modest Elo gap indicating potential plateauing of benefits with larger models.",
        "Implementation details for return-action conditioning are not fully detailed, affecting reproducibility."
      ],
      "questions": [
        "How does the generative approach compare to policy-based methods in terms of performance?",
        "What is the impact of the uniform return model on performance across different environments?",
        "Could you provide more details on how return-action conditioning is implemented in the transformer?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "6r0BOIb771",
    "title": "Sequential Bayesian Continual Learning with Meta-Learned Neural Networks",
    "std_review": {
      "summary": "The paper introduces SB-MCL, a continual learning framework that uses exponential family posteriors to constrain model capacity and prevent catastrophic forgetting. Empirical results show it outperforms baselines on several datasets, demonstrating its effectiveness. The approach balances simplicity and efficiency, making it practical for real-world applications, though it may have limitations in representational power and scalability.",
      "strengths": [
        "Theoretical Foundation: Uses exponential family posteriors to constrain model capacity and respect memory constraints.",
        "Empirical Performance: Outperforms baselines on benchmark continual learning datasets.",
        "Simplicity and Efficiency: Relies on Gaussian distributions for computational simplicity and low overhead."
      ],
      "weaknesses": [
        "Limited Representational Power: Exponential family posteriors may restrict the model's ability to capture complex task relationships.",
        "Assumption of Gaussian Distributions: Gaussian distributions may not always be suitable for all data or tasks.",
        "Empirical Validation: Could benefit from more extensive ablation studies or broader baseline comparisons.",
        "Scalability: Effectiveness in very large-scale continual learning scenarios is not fully explored."
      ],
      "questions": [
        "How does SB-MCL perform in very large-scale continual learning scenarios?",
        "What are the theoretical guarantees for convergence and stability in SB-MCL?",
        "How does the choice of Gaussian distribution impact performance on multimodal or complex datasets?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6rEcB9m9AI",
    "title": "Promoting Exploration in Memory-Augmented Adam using Critical Momenta",
    "std_review": {
      "summary": "The paper introduces Critical Momentum (CM), a modification to the Adam optimizer that uses a gradient buffer to prioritize large gradients, aiming to drive the optimizer towards flat minima for better generalization. Empirical results on several datasets show that Adam+CM outperforms standard Adam and SGD variants, supporting the idea that flat minima may correspond to better generalization. However, the paper lacks a direct comparison with SGD and does not fully explore the impact of hyperparameters and learning rates on CM's performance.",
      "strengths": [
        "Introduces a novel optimization technique with a compelling empirical and theoretical justification.",
        "Demonstrates consistent improvements in generalization across multiple benchmark datasets.",
        "Provides a thorough comparative analysis with various Adam variants and SGD."
      ],
      "weaknesses": [
        "Lacks a direct comparison with SGD to evaluate the general applicability of CM.",
        "Does not thoroughly explore the impact of the hyperparameter controlling the gradient buffer size.",
        "Results may be sensitive to the learning rate, with limited analysis of robustness across different rates."
      ],
      "questions": [
        "How does CM compare to SGD in terms of generalization and optimization performance?",
        "What is the optimal value of the hyperparameter controlling the gradient buffer size, and how does it vary across different datasets?",
        "How robust are the findings to variations in learning rate, and what is the impact of learning rate on CM's performance?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "6RR3wU4mSZ",
    "title": "IceFormer: Accelerated Inference with Long-Sequence Transformers on CPUs",
    "std_review": {
      "summary": "IceFormer introduces a novel Prioritized DCI algorithm for efficient k‑NNS on CPUs, achieving significant speed improvements while maintaining acceptable accuracy. The method offers flexibility in key selection and broad applicability across datasets, though its performance is primarily evaluated on CPUs. While promising, the approach has limitations such as hardware dependency, parameter sensitivity, and limited scalability evaluation.",
      "strengths": [
        "Introduces a novel Prioritized DCI algorithm tailored for k‑NNS, offering a fresh perspective on reducing computational overhead.",
        "Demonstrates substantial speed improvements over existing methods, making it a practical solution for resource-constrained environments.",
        "Provides a systematic way to choose the top‑k keys, allowing for trade‑offs between speed and accuracy based on specific application needs.",
        "The method is applicable to a wide range of datasets and can be integrated into existing systems with relative ease."
      ],
      "weaknesses": [
        "Performance gains are primarily observed on CPUs, with limited evaluation on other hardware types like GPUs or TPUs.",
        "The choice of k significantly impacts the method's performance, and there is a lack of comprehensive guidance for selecting an optimal k in practice.",
        "Scalability concerns arise as the method's promise for small to medium datasets remains unverified for very large datasets.",
        "Experimental results are based on a limited set of datasets, which may not fully represent the method's capabilities across all possible use cases."
      ],
      "questions": [
        "How can the method be adapted for other hardware types like GPUs or TPUs to leverage parallel processing capabilities?",
        "What is a more robust framework or heuristic for selecting the optimal k value to balance speed and accuracy?",
        "How does the method scale to very large datasets, and what techniques can be employed to handle high-dimensional data efficiently?",
        "What are the specific trade-offs and performance characteristics when integrating IceFormer with other machine learning models, such as deep learning architectures?"
      ],
      "overall_score": "Accept",
      "confidence": "4"
    }
  },
  {
    "paper_id": "6sfRRcynDy",
    "title": "Out-of-Distribution Detection With Hyperspherical Energy",
    "std_review": {
      "summary": "The paper introduces a novel out‑of‑distribution (OOD) detection method using a hyperspherical energy model, achieving competitive performance on standard benchmarks. While innovative and theoretically grounded, the method shows limitations in generalization, robustness to real‑world perturbations, and parameter sensitivity, leading to a cautious acceptance.",
      "strengths": [
        "Innovative hyperspherical energy framework linking model outputs to Helmholtz free energy.",
        "Efficient training strategy by fine‑tuning only the final residual blocks of a pre‑trained ResNet.",
        "Strong performance on standard OOD benchmarks, particularly on CIFAR‑100."
      ],
      "weaknesses": [
        "High false positive rate on Places 365, indicating potential limitations with diverse real‑world scenes.",
        "Limited evaluation to image classification tasks, raising questions about applicability to other domains.",
        "Parameter sensitivity, especially the temperature parameter, which is not thoroughly analyzed."
      ],
      "questions": [
        "How does the method perform under image corruptions or other real‑world perturbations?",
        "What is the full theoretical expressiveness of the Helmholtz free energy interpretation compared to other likelihood models?",
        "How can the method be extended beyond image classification to other domains such as natural language processing or time‑series analysis?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "6SNyuiph3F",
    "title": "Chat Vector: A Simple Approach to Equip LLMs With New Language Chat Capabilities",
    "std_review": {
      "summary": "The paper introduces Chat Vector, a novel method for enhancing LLMs with chat capabilities by using a chat vector as a parameter shift. This approach improves instruction following and safety without extensive fine-tuning, showing strong empirical results across languages and architectures. While promising, the method's scalability and computational implications remain unexplored, and further comparative analysis is needed.",
      "strengths": [
        "Innovative parameter shift approach for chat capabilities",
        "Efficiency gains by reducing extensive fine-tuning",
        "Empirical validation with improved instruction-following benchmarks"
      ],
      "weaknesses": [
        "Limited evaluation scope focusing on instruction-following benchmarks",
        "Potential biases in evaluation using GPT-4 for scoring",
        "Scalability and computational implications not thoroughly explored"
      ],
      "questions": [
        "How does the chat vector approach affect model scalability and computational efficiency?",
        "What is the impact of the chat vector on safety and user interaction beyond instruction-following benchmarks?",
        "How does the method generalize to other languages and model architectures?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6ssOs9BBxa",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a pipeline that combines behavior cloning with deep reinforcement learning to enable an agent to adapt to unseen maps in the microRTS domain. It leverages imitation learning to acquire a policy from expert demonstrations, which is then fine-tuned using DRL. The approach shows improved performance on various map layouts, indicating effective transfer learning. However, the paper lacks comprehensive evaluation of generalization to more complex maps and larger games, and deeper insights into the imitation learning component are needed.",
      "strengths": [
        "Integrative Approach: Combines imitation learning and DRL to improve sample efficiency and stability.",
        "Action Masking: Systematically masks actions to enhance robustness across different map configurations.",
        "Generalization Evidence: Demonstrates improved performance on unseen maps, indicating effective transfer learning."
      ],
      "weaknesses": [
        "Limited Generalization Evidence: Lacks comprehensive experiments to evaluate performance scaling with map complexity.",
        "Insufficient Exploration of Imitation Learning Details: Brief description of behavior cloning without delving into specific reward weighting or policy architecture.",
        "Scalability to Larger Games: Focus on microRTS limits discussion on transferring the approach to more complex games like StarCraft II.",
        "Absence of Comprehensive Transfer Learning Evaluation: Does not explore the trade-off between a single generalized policy versus multiple fine-tuned policies."
      ],
      "questions": [
        "How does the pipeline's performance scale with increasing map complexity or the number of fine-tuned models?",
        "What specific reward weighting and policy architecture choices were made in the behavior cloning step, and how do they affect reproducibility?",
        "What are the key challenges in scaling the approach to larger strategy games like StarCraft II, and how could they be addressed?",
        "How does the trade-off between using a single generalized policy versus multiple fine-tuned policies for different maps impact scalability and efficiency?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "6tazBqPem3",
    "title": "Capacity Analysis of Vector Symbolic Architectures",
    "std_review": {
      "summary": "The paper introduces a novel approach to dimensionality reduction for Vector Symbolic Architectures (VSAs) by leveraging lower‑rank weight matrices in Hopfield networks. It derives tight bounds on the number of vectors that can be stored and retrieved with minimal error, extending the analysis to Hopfield+ networks. The theoretical contributions provide clear quantitative guarantees and have practical implications for efficient similarity search and storage in machine learning. Overall, the paper is well‑structured, theoretically rigorous, and relevant to both theoretical and applied communities.",
      "strengths": [
        "Relevance to VSAs: Directly addresses core challenges in VSAs such as efficient similarity search and storage.",
        "Theoretical Rigor: Provides tight bounds for both standard and extended Hopfield networks, offering solid quantitative guarantees.",
        "Broader Impact: Results extend beyond theory to practical applications in machine learning where efficient similarity search is essential."
      ],
      "weaknesses": [
        "Complexity of Proofs: Mathematical derivations may be challenging for readers without a strong background in linear algebra and information theory.",
        "Limited Experimental Validation: The paper could benefit from empirical studies to validate practical implications.",
        "Scope of Application: Analysis is primarily focused on binary, sparse, and integer‑bundled vectors, limiting applicability to other VSA variants."
      ],
      "questions": [
        "Could empirical studies be conducted to validate the practical impact of the derived bounds on real‑world datasets?",
        "How do the results generalize to other types of vector representations beyond binary, sparse, and integer‑bundled vectors?",
        "What are the computational trade‑offs associated with using lower‑rank weight matrices in large‑scale applications?"
      ],
      "overall_score": "Accept",
      "confidence": "High"
    }
  },
  {
    "paper_id": "6tDPefQyvB",
    "title": "Rotation-Equivariance and Position Encodings for Enhancing Local Descriptors",
    "std_review": {
      "summary": "The paper presents a novel rotation‑equivariant descriptor that fuses local rotational information with global positional cues, achieving significant performance gains over existing methods in sparse matching tasks. While it integrates well with both classical and deep‑learning matchers, the descriptor's full potential and efficiency are not fully demonstrated due to limited ablation studies and comparisons with dense matching methods. Overall, the work is promising but requires further validation.",
      "strengths": [
        "Introduces a unique multi‑scale feature fusion method that combines local rotational equivariance with global positional information.",
        "Demonstrates strong performance improvements over classical and deep‑learning matchers, particularly in rotational equivariance tasks.",
        "Designed with real‑time applications in mind, showing competitive runtime efficiency."
      ],
      "weaknesses": [
        "Lacks a comprehensive ablation study to evaluate the impact of individual components of the feature fusion method.",
        "Focuses primarily on sparse matching, with limited comparison to dense matching methods like LoFTR.",
        "Claims of rotation equivariance are not fully substantiated by extensive experimental validation."
      ],
      "questions": [
        "Should include a detailed ablation study on the impact of retaining local rotational equivariance and the smooth integration process.",
        "Clarify how the descriptor interacts with various matchers, both classical and deep‑learning based.",
        "Provide a more thorough comparison with dense matching methods to highlight performance nuances.",
        "Support the claim of rotation equivariance with experiments under substantial rotation scenarios."
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "6tqgL8VluV",
    "title": "Towards Establishing Guaranteed Error for Learned Database Operations",
    "std_review": {
      "summary": "The paper presents a novel framework for learning database operations with provable error bounds, bridging machine learning and database theory. It introduces a method to train models for operations like joins and selections, providing formal error guarantees. Experimental results on synthetic and real-world datasets show that learned models can match or exceed traditional algorithms in accuracy and efficiency. While promising, the work has limitations in generality, scalability, and comprehensive comparison with existing methods.",
      "strengths": [
        "Novel approach to learning database operations with provable error bounds.",
        "Solid theoretical foundation bridging machine learning and database theory.",
        "Demonstrated practical benefits with performance comparable to traditional algorithms."
      ],
      "weaknesses": [
        "Limited experimental evaluation to specific query types and data distributions.",
        "Theoretical bounds derived under certain assumptions that may not always hold.",
        "Lack of comprehensive comparison with state-of-the-art models across diverse datasets.",
        "Scalability to large-scale databases and complex operations remains unexplored."
      ],
      "questions": [
        "How do the learned models perform on a broader range of query types and data distributions?",
        "What is the scalability of the learned models to large-scale databases and complex query operations?",
        "How do the theoretical bounds compare with practical performance in real-world scenarios?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6u6GjS0vKZ",
    "title": "Coloring Deep CNN Layers with Activation Hue Loss",
    "std_review": {
      "summary": "The paper introduces an 'activation hue loss' that guides neural network activations towards a hue‑like representation during training, applied alongside standard cross‑entropy loss. Experiments on ImageNet, DTD, and other datasets show consistent improvements in classification accuracy and training stability. While promising, the paper lacks detailed implementation and thorough baseline comparisons, and the computational cost of adding hue coordinates is noted.",
      "strengths": [
        "Introduces a novel loss function that encourages activations to align with a circular representation, potentially improving interpretability and robustness.",
        "Demonstrates consistent empirical improvements across multiple datasets and model architectures without requiring major architectural changes.",
        "Suggests broader applicability of the hue concept to tasks like detection and segmentation and to larger models such as Vision Transformers."
      ],
      "weaknesses": [
        "Does not compare against state‑of‑the‑art baselines for the specific architectures used, making quantitative assessment of improvements difficult.",
        "Lacks detailed description of the hue loss formulation and its integration into the network architecture, hindering reproducibility.",
        "Provides limited qualitative analysis of how the hue loss influences learning, relying mostly on visualizations.",
        "Adds computational overhead by outputting hue coordinates, which could be a concern for large‑scale or resource‑constrained applications."
      ],
      "questions": [
        "How do the proposed hue coordinates compare to other regularization techniques in terms of computational cost and impact on model performance?",
        "Could the hue loss be integrated more seamlessly into existing deep learning frameworks without requiring significant architectural modifications?",
        "What are the long‑term effects of applying hue loss to very deep or large models, such as Vision Transformers, and how does it affect training dynamics?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6Uc7Fgwrsm",
    "title": "OmnMixup: Generalize Mixup with Mixing-Pair Sampling Distribution",
    "std_review": {
      "summary": "OmniMixup introduces a learnable Mixing-Pair Sampling Distribution (MPSD) that extends Mixup beyond sample-level mixtures to operate directly in the latent space. The framework OmniEval automatically selects the optimal MPSD using a Mahalanobis distance-based metric (M‑Score) to maximize generalization. Experiments on CIFAR-10/100 and molecular property prediction demonstrate significant improvements over baseline mixup methods. The approach is positioned as a versatile tool that can complement rather than replace existing techniques.",
      "strengths": [
        "Novel MPSD Framework: Extends Mixup to a learnable, data-driven distribution, offering a flexible way to generate mixing pairs in the latent space.",
        "Automatic Optimization: OmniEval’s use of the M‑Score for MPSD selection provides a theoretically grounded method to improve generalization without manual tuning.",
        "Broad Applicability: Demonstrated effectiveness across diverse datasets (image classification, molecular property prediction), suggesting strong generalization capabilities."
      ],
      "weaknesses": [
        "Computational Overhead: The process of searching the MPSD may introduce significant computational costs compared to training a model from scratch.",
        "Limited Baseline Comparisons: While comparisons with CutMix and ManifoldMixup are provided, a more comprehensive evaluation across a wider range of state-of-the-art mixup techniques would strengthen the claim of broad applicability.",
        "Lack of Qualitative Validation: The paper could benefit from visualizations or qualitative analyses of the sampled pairs to provide intuitive support for the theoretical claims.",
        "Potential Overfitting: The learnability of the MPSD might lead to overfitting if not properly regularized, especially in high-dimensional latent spaces."
      ],
      "questions": [
        "How does the computational cost of searching the MPSD compare to other data augmentation techniques?",
        "Could the paper include qualitative analyses (e.g., visualizations) of the sampled pairs to support the theoretical claims?",
        "What are the specific regularization techniques used to prevent overfitting of the MPSD?",
        "How does OmniMixup perform when applied to very large models or real-time applications?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6ujgouOiAA",
    "title": "Use Your INSTINCT:",
    "std_review": {
      "summary": "The paper introduces INSTINCT, an algorithm that optimizes instructions for black-box large language models (LLMs) by combining white-box and black-box techniques. It demonstrates significant performance and efficiency improvements over existing methods like InstructZero and EvoPrompt, while also showing strong generalization across various LLM configurations. The experimental validation is thorough, but concerns remain about computational cost and scalability for very large models.",
      "strengths": [
        "Algorithmic novelty combining white-box and black-box strategies",
        "Significant performance gains in accuracy and efficiency",
        "Strong generalization across different LLM configurations"
      ],
      "weaknesses": [
        "Potential computational cost for training",
        "Scalability concerns for very large models",
        "Limited comparison with other recent state-of-the-art methods"
      ],
      "questions": [
        "How does INSTINCT perform on very large-scale models?",
        "What are the computational costs associated with training INSTINCT?",
        "How does INSTINCT compare to other recent advancements in instruction tuning?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6UQaXJm53B",
    "title": "DfPO: Degeneration-free Policy Optimization via Action Masking in Natural Language Action Spaces",
    "std_review": {
      "summary": "The paper introduces DfPO, a novel approach to text generation that improves task performance while preserving naturalness by masking undesirable actions during policy optimization. It shows consistent improvements across multiple tasks, with significant gains in naturalness as measured by perplexity, SPICE, and BertScore. The method is more sample-efficient than PPO, especially when the hyperparameter β is not optimally tuned, though it introduces computational overhead during inference. Overall, DfPO is a strong contribution to the field, though it could benefit from additional baselines and a more thorough evaluation of naturalness.",
      "strengths": [
        "Innovative action‑masking mechanism that explicitly excludes undesirable actions from likelihood maximization.",
        "Clear theoretical motivation linking task advantage and naturalness advantage.",
        "Empirical validation demonstrating consistent improvements in task performance and naturalness across multiple tasks."
      ],
      "weaknesses": [
        "Computational overhead due to forward passes through the reference policy during inference.",
        "Hyperparameter sensitivity, particularly the choice of β in the action‑masked policy.",
        "Limited baseline comparisons, such as those involving supervised fine‑tuning."
      ],
      "questions": [
        "How does the action‑masked policy ensure that masked actions do not contribute to enhancing the task score while maintaining naturalness?",
        "What are the theoretical trade‑offs between sample efficiency and the ability to maintain naturalness?",
        "How does DfPO's performance change on tasks with varying naturalness requirements?",
        "What additional baselines (e.g., combining PPO with supervised fine‑tuning) could provide a more comprehensive comparison?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6uUmpPvqUU",
    "title": "The Closeness of In-Context Learning and Weight Shifting for Softmax Regression",
    "std_review": {
      "summary": "The paper provides a rigorous theoretical analysis of the relationship between in-context learning and weight shifting in softmax regression models. It introduces a detailed mathematical framework and derives key theorems that quantify how Lipschitz properties of the softmax function relate to weight shifts during in-context learning. The authors validate their findings with experimental studies, showing measurable impacts on model performance. Overall, the work advances understanding of in-context learning mechanisms and extends prior research, though it could benefit from clearer presentation and broader applicability.",
      "strengths": [
        "Clear theoretical formulation of softmax regression within in-context learning.",
        "Novel theorems (5.1 and 5.2) that quantify the impact of Lipschitz bounds on weight shifts.",
        "Empirical validation that supports and extends prior work."
      ],
      "weaknesses": [
        "Complex mathematical derivations may limit accessibility for readers without strong ML theory background.",
        "Focus on softmax regression may restrict generalizability to other models or learning paradigms.",
        "Experimental setup could be more comprehensive to capture real-world variability."
      ],
      "questions": [
        "How can the theoretical framework be extended to other types of models or learning paradigms?",
        "What are the practical implications of the weight shifts observed in real-world applications?",
        "How do the results compare with other recent studies on in-context learning?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6vF0ZJGor4",
    "title": "ImplicitSLIM and How it Improves",
    "std_review": {
      "summary": "ImplicitSLIM presents a scalable and efficient approach to collaborative filtering by leveraging Locality Preserving Embedding (LLE) within a Scalable Low-rank Matrix (SLIM) framework, focusing on implicit feedback. It demonstrates significant improvements in scalability and accuracy over baseline methods like EASE, while maintaining flexibility for integration with various recommender systems. The paper's theoretical foundation and practical performance gains are highlighted, though the complexity of implementation and limited source code availability are noted as areas for improvement.",
      "strengths": [
        "Significant scalability and efficiency improvements for large-scale recommender systems.",
        "Strong theoretical foundation based on the LLE framework, preserving local data geometry.",
        "Demonstrated superior performance over baseline models like EASE in terms of accuracy and convergence speed.",
        "Flexibility to integrate with various downstream models without significant modifications."
      ],
      "weaknesses": [
        "Implementation complexity due to reliance on LLE, which may be challenging for practitioners unfamiliar with manifold learning.",
        "Specifically designed for embedding-based recommender systems, limiting its applicability to non-embedding approaches.",
        "Absence of publicly available source code hinders reproducibility and further research."
      ],
      "questions": [
        "How can the implementation complexity of ImplicitSLIM be addressed to make it more accessible to practitioners?",
        "What strategies could be employed to extend ImplicitSLIM's applicability to non-embedding-based recommender systems?",
        "How can the authors ensure reproducibility and encourage further research by making the source code available?"
      ],
      "overall_score": "Accept",
      "confidence": "High"
    }
  },
  {
    "paper_id": "6vtGG0WMne",
    "title": "Regulating Imbalanced Deep Models with User-Specified Metrics",
    "std_review": {
      "summary": "The paper introduces a Bias Adjustment (BA) method to improve model performance on imbalanced datasets by modifying the loss function. Experiments show that BA outperforms several state-of-the-art techniques across various benchmarks, while also being computationally efficient. The method is versatile, applicable to both multi-class classification and regression tasks, and comes with theoretical guarantees. However, its evaluation is limited to smaller datasets, and more analysis is needed for multi-class performance and sensitivity to hyperparameters.",
      "strengths": [
        "Improved performance on imbalanced datasets compared to existing methods.",
        "Computational efficiency with negligible overhead.",
        "Versatility across multi-class classification and regression tasks."
      ],
      "weaknesses": [
        "Limited evaluation on larger datasets like CIFAR-10/100, ImageNet, or iNaturalist2018.",
        "Lack of detailed analysis on multi-class performance.",
        "Potential sensitivity to hyperparameters affecting bias values."
      ],
      "questions": [
        "How does the BA method perform on larger, more complex datasets?",
        "What is the impact of hyperparameter tuning on the method's effectiveness?",
        "Can the method be further optimized for scalability?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6W35Wcs077",
    "title": "Decomposition Ascribed Synergistic Learning for Unified Image Restoration",
    "std_review": {
      "summary": "The paper introduces DASL, a method that uses singular value decomposition (SVD) to analyze and mitigate image degradation by decomposing it into singular vectors and singular values. This allows for targeted restoration techniques, integrating seamlessly with existing convolutional models and offering computational benefits. Experiments demonstrate robustness across various degradation scenarios, supporting its generality and effectiveness.",
      "strengths": [
        "Innovative use of SVD to decompose image degradation into singular vectors and singular values, providing a novel framework for analysis and restoration.",
        "Targeted restoration operators (SVEO and SVAO) that enhance singular vectors and singular values, respectively, improving restoration accuracy.",
        "Seamless integration with existing convolutional image-restoration models, offering significant computational efficiency improvements.",
        "Robust experimental validation across diverse degradation scenarios, strongly supporting the method's robustness and effectiveness."
      ],
      "weaknesses": [
        "Complexity of implementation due to reliance on SVD and introduction of specialized operators (SVEO and SVAO).",
        "Limited scope of degradation types explored; further investigation needed to confirm generality across all possible degradation scenarios.",
        "Potential computational overhead from the initial SVD decomposition, especially for high-resolution images."
      ],
      "questions": [
        "How can the method be extended to handle non‑standard or hybrid degradation scenarios that combine multiple degradation types?",
        "What are the computational trade-offs involved in applying SVD for high‑resolution images, and how can these be mitigated?",
        "Could the integration of DASL with other state‑of‑the‑art restoration techniques be explored to further enhance performance?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6werMQy1uz",
    "title": "Rethinking the Buyer's Inspection Paradox in Information Markets with Language Agents",
    "std_review": {
      "summary": "The paper introduces a novel theoretical framework for using large language models (LLMs) like GPT‑4 and Llama‑2‑70B to address the inspection paradox in information markets, where agents cannot fully verify information quality. It proposes mechanisms for information retention and forgetting, and demonstrates through experiments that LLMs can improve decision-making efficiency. While the work shows promise, it has limitations in scope, security considerations, and generalizability, suggesting areas for future research.",
      "strengths": [
        "Innovative theoretical framework addressing the inspection paradox in LLM-based information markets.",
        "Empirical validation through comprehensive experimental design and metrics related to economic rationality.",
        "Practical mechanisms for information management, including strategies for retention and forgetting."
      ],
      "weaknesses": [
        "Limited scope of baselines, with only a narrow comparison to BM25.",
        "Security concerns remain underexplored, particularly in real-world implementation.",
        "Irrational behavior of LLMs is acknowledged but not deeply addressed.",
        "Findings are specific to certain LLM implementations and market scenarios."
      ],
      "questions": [
        "How can the proposed security measures be effectively implemented in real-world settings?",
        "What additional baselines would provide a more robust evaluation of LLM performance?",
        "How can the rationality of LLMs be consistently improved for more reliable economic decisions?",
        "What are the implications of the findings for more complex market structures and diverse information environments?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6xfe4IVcOu",
    "title": "Chain of Hindsight aligns Language Models with Feedback",
    "std_review": {
      "summary": "The paper presents Chain of Hindsight (CoH), a method that uses natural language feedback to improve language model outputs without explicit annotations. CoH constructs hypothetical scenarios leading to desired feedback, enabling the model to learn from feedback efficiently. The method is evaluated against rejection sampling and Conditional Self‑Finetuning (C‑SFT) across various model sizes, showing improved performance and scalability. CoH achieves competitive results with reduced resource requirements, especially at larger model scales.",
      "strengths": [
        "Scalability: CoH effectively scales with model size, maintaining performance improvements.",
        "Efficiency: Reduces the need for explicit feedback annotations, streamlining the feedback loop.",
        "Performance: Outperforms rejection sampling and achieves comparable results to C‑SFT with fewer resources."
      ],
      "weaknesses": [
        "Complexity: Constructing hypothetical scenarios may introduce computational overhead.",
        "Feedback Quality: Natural language feedback can be subjective and noisy.",
        "Post‑Processing: May require additional steps to refine outputs."
      ],
      "questions": [
        "How does CoH handle feedback that is ambiguous or contradictory?",
        "What is the impact of scenario complexity on the computational cost of CoH?",
        "Can CoH be integrated with other feedback mechanisms for improved robustness?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "6ZuDeSHzjj",
    "title": "Outliers Memorized Last:",
    "std_review": {
      "summary": "The paper investigates memorization in diffusion models, using a toy dataset and simplified model to study how inliers and outliers affect performance. It finds strong memorization tendencies that could impact generalization, providing insights into when and how memorization occurs. However, the findings are limited to a single toy model, raising questions about generalizability and the lack of mitigation strategies.",
      "strengths": [
        "Clear definition and operationalization of inliers and outliers.",
        "Use of a well-defined toy model for focused study.",
        "Detailed hyperparameter settings and training procedures for reproducibility."
      ],
      "weaknesses": [
        "Findings limited to a single toy model, raising concerns about generalizability.",
        "No exploration of hyperparameter impact across different architectures or datasets.",
        "Lack of formal definitions or metrics for memorization.",
        "No discussion of mitigation strategies."
      ],
      "questions": [
        "How do the observed memorization patterns generalize to larger, more complex datasets?",
        "What impact do varying hyperparameters have on memorization across different model architectures?",
        "Are there effective mitigation strategies for reducing memorization in diffusion models?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "70A6oo3Il2",
    "title": "",
    "std_review": {
      "summary": "AdaFlood introduces a novel adaptive flood regularization technique that dynamically adjusts flood levels based on difficulty estimates from a lightweight auxiliary network. The method combines instance‑wise adaptive weighting with traditional flood regularization, aiming to improve calibration, robustness, and generalization, especially in noisy‑label settings. Experiments on toy datasets show significant gains over baselines, with further validation on ImageNet and LAION confirming scalability and effectiveness. The paper provides a solid theoretical foundation and demonstrates strong empirical results, though it could benefit from more extensive baseline comparisons and deeper analysis of scalability.",
      "strengths": [
        "Novel combination of adaptive instance weighting with flood regularization.",
        "Strong theoretical foundation with Proposition 1 supporting minimal influence of single data points on early layers.",
        "Efficient training by re‑initializing only the last layer(s) for difficulty estimation.",
        "Demonstrated robustness and scalability across noisy‑label datasets and large models."
      ],
      "weaknesses": [
        "Limited baseline comparison beyond mentioned methods.",
        "Lack of detailed analysis on extremely large datasets or very deep models.",
        "Theoretical rigor could be further strengthened by exploring difficulty estimation and adaptive weighting in more depth.",
        "Implementation details of the auxiliary network could be more fully specified.",
        "Potential risk of overfitting with adaptive flood levels."
      ],
      "questions": [
        "How does AdaFlood compare to other adaptive regularization techniques in terms of convergence speed?",
        "What is the impact of AdaFlood on model interpretability and feature importance?",
        "Can AdaFlood be integrated with other regularization methods, and if so, how?",
        "How does the auxiliary network's architecture affect the scalability of AdaFlood for extremely large models?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "70IgE3tRbu",
    "title": "",
    "std_review": {
      "raw_text": "{\n  \"summary\": \"The paper introduces Continuous Invariance Learning (CIL), a method for learning invariant features across multiple environments to improve model generalization. It provides a solid theoretical foundation and demonstrates effectiveness on various datasets. However, it faces challenges such as sensitivity to domain size, reliance on manual environment splitting, and suboptimal in-domain performance. Theoretical assumptions and proof clarity also need improvement.\",\n  \"strengths\": [\n    \"Introduces a novel method for learning invariant features across multiple environments.\",\n    \"Provides a solid theoretical analysis with assumptions about domain countability.\",\n    \"Demonstrates empirical effectiveness through experiments on various datasets.\"\n  ],\n  \"weaknesses\": [\n    \"Performance may be sensitive to the size of the domain index.\",\n    \"Relies on manual splitting of environments for baselines, which may not be feasible in all scenarios.\",\n    \"Shows suboptimal in-domain prediction accuracy and high variance.\",\n    \"Theoretical analysis assumes countably many domains, limiting applicability in truly continuous settings.\",\n    \"Theoretical proof and some aspects of the method are complex and not easily understood.\"\n  ],\n  \"questions\": [\n    \"How does CIL handle scenarios with a large number of environments?\",\n    \"What are the detailed neural network architectures and hyperparameters used for training baseline methods like IRMv1 and IIBNet?\",\n    \"How does the penalty scale linearly with the number of environments when the spurious mask is used?\",\n    \"How does CIL compare with environment inference methods in settings where manual environment partitioning is not feasible?\",\n    \"What are the theoretical justifications for the slowest rate of failure ($O(\\sqrt{n})$) in more realistic scenarios with limited sample sizes?\",\n    \"How can the clarity of the theoretical proof be improved?\"\n  ],\n  \"overall_score\": \"4: weak accept\",\n  \"confidence\": \"3: medium\"\n}",
      "parse_error": true
    }
  },
  {
    "paper_id": "70PPJo3DwI",
    "title": "Towards Out-of-Federation Generalization in Federated Learning",
    "std_review": {
      "summary": "The paper proposes a federated learning method that emphasizes influential clients to improve model performance and reduce communication overhead. It achieves higher ROC‑AUC scores on benchmark datasets while communicating fewer parameters. However, it lacks a clear definition of what constitutes an influential client, does not compare with prototype‑based methods, and may overfit to similar clients.",
      "strengths": [
        "Introduces a novel client weighting strategy that can improve model generalization.",
        "Demonstrates improved performance and communication efficiency on several datasets.",
        "Provides a clear experimental evaluation with thorough comparisons."
      ],
      "weaknesses": [
        "Lacks a precise metric for client influence, affecting reproducibility.",
        "Does not compare against existing prototype‑based methods.",
        "Potential overfitting to the most similar clients."
      ],
      "questions": [
        "How is the influence of a client defined and measured?",
        "Why not compare the method with prototype‑based approaches for client similarity?",
        "Could the method overfit to clients that are too similar?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "70xhiS0AQS",
    "title": "TaskBench: Benchmarking Large Language Models for Task Automation",
    "std_review": {
      "summary": "The paper presents TaskBench, a method for generating task decomposition for LLMs by constructing tool graphs from task graphs. It effectively breaks down complex tasks into subtasks, improving LLM performance across three domains. The approach is evaluated qualitatively, showing promise but with some limitations in scalability and error analysis. Overall, the paper is well-received with strong empirical results.",
      "strengths": [
        "Introduces a novel method for generating task decomposition through tool graph construction, enhancing LLM interpretability and modularity.",
        "Effectively handles complex tasks by breaking them into smaller subtasks, improving real-world LLM performance.",
        "Provides a systematic evaluation across multiple domains, offering valuable insights into method versatility and applicability."
      ],
      "weaknesses": [
        "Tool graph construction may struggle with very large or highly interconnected task graphs, leading to performance bottlenecks.",
        "Evaluation relies primarily on qualitative analysis, which may not fully capture instruction quality nuances.",
        "Lacks comprehensive error analysis of generated user instructions, limiting understanding of common pitfalls.",
        "Benchmark relevance may be compromised as more powerful LLMs are developed, potentially leading to saturation."
      ],
      "questions": [
        "How does the tool graph construction process handle very large or highly interconnected task graphs?",
        "What specific challenges arise in evaluating task decomposition as textual descriptions, and what metrics are being considered for improvement?",
        "What strategies are being planned to ensure the benchmark remains relevant as LLM capabilities advance?"
      ],
      "overall_score": "Accept",
      "confidence": "High"
    }
  },
  {
    "paper_id": "73dhbcXxtV",
    "title": "LoLaMeMe: Logic, Language, Memory, Mechanistic Framework",
    "std_review": {
      "summary": "The paper presents T HEX, a hybrid model that merges GPT‑2's attention mechanism with Hyena's hyena operator to improve logical reasoning and memory. Using the LOLAMEME framework, it creates LoLa and MeMe datasets to evaluate the model's performance on language tasks. T HEX outperforms GPT‑2 and Hyena on these benchmarks, demonstrating effective integration of both architectures.",
      "strengths": [
        "Innovative hybrid architecture combining attention and memory mechanisms.",
        "Targeted dataset construction using LOLAMEME to evaluate specific language aspects.",
        "Demonstrated superior performance across synthetic benchmarks."
      ],
      "weaknesses": [
        "Implementation complexity and computational demands of the hybrid model.",
        "Potential limited generalization to real-world language tasks due to synthetic dataset design.",
        "Lack of extensive validation on diverse real-world applications."
      ],
      "questions": [
        "How does the T HEX model perform on real-world language understanding tasks beyond the synthetic benchmarks?",
        "What are the computational and resource requirements for implementing the T HEX architecture in practical settings?",
        "How can the model's performance be further validated across a broader range of language tasks?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "73lu1yw6At",
    "title": "",
    "std_review": {
      "summary": "The paper introduces AXp and CXp algorithms for generating abductive and counterfactual explanations for sequential data using RNNs. It demonstrates improved interpretability and transparency on benchmark datasets compared to traditional baselines. While the algorithms are innovative and practical, concerns about computational complexity and notation clarity exist.",
      "strengths": [
        "Introduces a novel framework for generating explanations specifically for sequential data.",
        "Provides practical algorithms (AXp and CXp) that are directly applicable to RNNs.",
        "Shows strong empirical results on benchmark datasets, enhancing model interpretability."
      ],
      "weaknesses": [
        "The proposed algorithms may be computationally intensive for large-scale sequential data.",
        "Lacks a detailed analysis of the computational complexity of the algorithms.",
        "Uses informal notation (e.g., '1 k') for counterfactual explanations, which may be unclear."
      ],
      "questions": [
        "How does the proposed approach scale to very large sequential datasets?",
        "What is the exact computational complexity of AXp and CXp, and how does it compare to baseline methods?",
        "Can the informal '1 k' notation be clarified to improve readability?"
      ],
      "overall_score": "6: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "74IIsh2kM6",
    "title": "SMILE: Audio-visual Speech Recognition with Siamese Masked Interaction Learning",
    "std_review": {
      "summary": "The SMILE model introduces a novel Siamese transformer architecture for audio-visual speech recognition, leveraging adaptive multimodal fusion primarily driven by audio. It demonstrates strong performance and robustness to noise, outperforming state-of-the-art acoustic-only models. While the model effectively integrates audio and visual modalities, its heavy reliance on audio and limited exploration of visual-only data are noted as areas for improvement.",
      "strengths": [
        "Innovative adaptive multimodal fusion mechanism using a weighted sum over transformer layers.",
        "Demonstrated robustness to acoustic noise when visual information is available.",
        "Competitive word error rate (WER) performance compared to existing acoustic-only models."
      ],
      "weaknesses": [
        "Primary dependence on audio modality may limit the model's reliance on visual information.",
        "Limited experimentation on visual-only data could provide additional insights.",
        "Training strategy variability (e.g., stop-gradient vs. direct parameter sharing) is not thoroughly examined.",
        "Parameter sensitivity to α, β, and weight sharing choices is not fully explored."
      ],
      "questions": [
        "How does the model's performance change when visual information is the primary modality, and how does it compare to audio-only models?",
        "What impact does varying the training strategy (e.g., stop-gradient vs. direct parameter sharing) have on the Siamese network's performance?",
        "How does the model generalize to scenarios with limited visual data or when visual information is noisy?",
        "What are the optimal configurations for hyperparameters α and β, and how does layer-dependent versus shared weight for visual contribution affect performance?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "74YdSRFORA",
    "title": "Out of Sight: A Framework for Egocentric Active Speaker Detection",
    "std_review": {
      "summary": "The paper presents the Out‑of‑Sight (O2S) framework for Active Speaker Detection (ASD) in egocentric video, addressing the challenge of the camera wearer being invisible to the model. O2S integrates a multimodal transformer that fuses audio and video information, with a novel visual token representation derived from the wearer’s face to bridge the invisibility gap. Experiments demonstrate competitive performance against third‑person ASD baselines on the Ego4D benchmark, highlighting the method's ability to handle scenarios with multiple off‑screen speakers and noisy visual data. The O2S framework introduces a novel visual token representation and a weighted visual loss, enhancing model robustness and accuracy. However, it requires careful consideration of computational resources and dataset limitations.",
      "strengths": [
        "Novel Multimodal Architecture: Combines audio and video modalities using a transformer-based multimodal mixer, enabling effective cross‑modal learning.",
        "Invisibility Handling: Introduces a visual token representation for the camera wearer, allowing the model to infer the wearer's speech even when they are not directly visible.",
        "Robustness to Occlusion: The weighted visual loss and multimodal mixer enhance the model's ability to handle occluded or noisy visual data, improving detection accuracy in challenging scenarios."
      ],
      "weaknesses": [
        "Computational Complexity: The transformer architecture introduces significant computational costs, potentially limiting real‑time applications.",
        "Dataset Dependency: Performance heavily relies on the quality of face detection and the distribution of the Ego4D dataset, which may not generalize well to other scenarios.",
        "Parameter Sensitivity: The model's performance is sensitive to hyper‑parameters such as α, k, and n, requiring careful tuning for optimal results.",
        "Limited Generalization: The approach may struggle with diverse speaker appearances, expressions, and environments not well represented in the training data."
      ],
      "questions": [
        "How does the O2S framework perform on datasets with different face detection quality or camera field of view?",
        "What are the specific ablations performed on the hyper‑parameters α, k, and n, and what were the observed effects?",
        "How does the model generalize to scenarios with multiple speakers in close proximity or with highly expressive facial features?",
        "What are the computational costs of the O2S model in real‑time applications, and are there any optimizations discussed?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "760br3YEtY",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a novel model that integrates SMILES representations of ligands with protein sequence data to enhance functional annotation using EC numbers. It employs a self-attention mechanism to identify key residues and a hierarchical loss function to guide learning. Two fusion methods are proposed and compared, showing improved annotation accuracy over existing methods. The benchmarking setup is designed to ensure fair comparisons, though implementation complexity and scope limitations are noted.",
      "strengths": [
        "Innovative integration of ligand information to improve functional annotation.",
        "Effective use of self-attention to capture important protein interactions.",
        "Hierarchical loss function provides structured guidance for learning."
      ],
      "weaknesses": [
        "Complex implementation requiring significant computational resources.",
        "Performance comparison between fusion methods could benefit from additional analysis.",
        "Benchmarking may not fully capture real-world variability."
      ],
      "questions": [
        "How does the model handle ligands with varying structural complexities?",
        "What are the computational costs associated with the self-attention mechanism?",
        "How robust is the model to variations in protein sequence data distribution?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "770DetV8He",
    "title": "RetroBridge: Modeling Retrosynthesis with Markov Bridges",
    "std_review": {
      "summary": "RetroBridge introduces a Markov Bridge Model (MBM) for generative modeling of chemical structures, focusing on the USPTO-50K dataset. The model leverages Markov bridges to capture the probabilistic evolution of reactants to products, achieving competitive top‑k accuracy. While it outperforms template‑free methods, its performance is sensitive to the choice of fixed time steps and computational cost, suggesting areas for further optimization.",
      "strengths": [
        "Innovative approach to modeling discrete chemical structures using Markov bridges.",
        "Clear inductive biases that guide probabilistic generation of reactants.",
        "Strong performance on the USPTO-50K benchmark, especially with top‑k accuracy."
      ],
      "weaknesses": [
        "Computational cost due to fixed time steps.",
        "Sensitivity to the choice of time steps, requiring extensive tuning.",
        "Limited exploration of alternative distributions compared to template‑based methods."
      ],
      "questions": [
        "How can the model's performance be improved with respect to the choice of fixed time steps?",
        "What are the computational implications of scaling RetroBridge to larger datasets or more complex reactions?",
        "How does RetroBridge compare to highly optimized template‑based methods like RetroFormer?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "774elYc5tw",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a novel future‑constraint satisfaction score for controllable text generation, aiming to align generated text with user‑specified constraints while maintaining quality. Experiments show significant improvements over baselines, but the approach introduces computational overhead and lacks comprehensive human evaluation and robustness analysis. Overall, the work is promising yet hampered by practical concerns.",
      "strengths": [
        "Introduces a flexible and theoretically grounded mechanism for enforcing constraints in text generation.",
        "Demonstrates clear improvements in aligning generated text with user constraints.",
        "Offers a broader applicability to various controllable generation tasks."
      ],
      "weaknesses": [
        "Computational complexity may limit real‑time or resource‑constrained applications.",
        "Scalability concerns are not thoroughly addressed for longer‑form generation.",
        "Lacks comprehensive human evaluation to assess fluency, informativeness, and correctness.",
        "The robustness and accuracy of the satisfaction score are not fully explored."
      ],
      "questions": [
        "How can the computational overhead be mitigated for real‑time applications?",
        "What strategies can be employed to improve the scalability of the method for longer sequences?",
        "What additional human evaluation metrics would provide a more complete picture of the generated text quality?",
        "How can the satisfaction score be refined or improved for different types of constraints?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "776lhoaulC",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a novel framework for domain adaptation in optical flow estimation by aligning boundary regions between source and target domains. It demonstrates significant improvements over baselines, highlighting its practical relevance for cross-domain optical flow tasks. While effective, the method has limitations such as higher computational demand and inability to handle z-axis radial motion.",
      "strengths": [
        "Addresses a critical domain adaptation challenge in optical flow estimation.",
        "Effectively reduces domain shift by focusing on boundary alignment.",
        "Shows strong empirical performance compared to existing techniques."
      ],
      "weaknesses": [
        "Primarily handles domain shifts due to appearance changes, potentially overlooking other differences.",
        "Computational overhead from boundary alignment may limit scalability.",
        "Does not model z-axis radial motion, which could be important in depth-varying scenarios."
      ],
      "questions": [
        "How does the method perform when domain shifts involve non-appearance factors (e.g., lighting, occlusions)?",
        "What runtime optimizations can be applied to reduce computational demand?",
        "How does the framework scale to very large datasets or high-resolution images?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "77N93tc3o5",
    "title": "",
    "std_review": {
      "summary": "The paper introduces DeepIVA, a two-step model combining an information-preserving variational autoencoder with a multi-modal information source framework to learn cross-modal latent representations. It demonstrates improved cross-modal linkage on several datasets compared to single-modality baselines. Theoretical guarantees for identifiability and innovative linkage mechanisms are highlighted, but concerns about computational complexity and assumption reliance are noted.",
      "strengths": [
        "Unified framework for cross-modal learning",
        "Theoretical guarantees for identifiability",
        "Empirical validation across diverse datasets",
        "Innovative linkage mechanism ensuring meaningful representations"
      ],
      "weaknesses": [
        "Complexity of the two-step training process",
        "Assumption reliance for identifiability",
        "Metric limitations in capturing nuances",
        "Lack of ablation studies"
      ],
      "questions": [
        "How does the model scale to very large datasets or complex models?",
        "What are the practical implications of the strong identifiability assumptions?",
        "Could joint training of the entire model improve computational efficiency?",
        "How robust are the linkage guarantees in high-dimensional settings?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "78iGZdqxYY",
    "title": "Mirage: Model-Agnostic Graph Distillation for Graph Classification",
    "std_review": {
      "summary": "MIRAGE presents a model-agnostic method for distilling large graph datasets into smaller, efficient representations while preserving essential graph properties. The approach uses the frequency distribution of computation trees to capture graph characteristics, enabling use with any GNN architecture. Experimental results show high accuracy on multi-class classification tasks with reduced computational requirements. Overall, MIRAGE is a promising contribution to graph distillation, though its scalability and applicability to non-tree-like graphs need further consideration.",
      "strengths": [
        "Model-agnostic nature allows use with any GNN architecture.",
        "Efficient representation reduces computational burden and memory usage.",
        "Preserves key graph properties such as node/edge features and spectral characteristics."
      ],
      "weaknesses": [
        "Scalability limitations may arise with very large datasets.",
        "Assumes computation tree structure suffices for all graph types.",
        "Potential for overfitting due to reliance on limited features."
      ],
      "questions": [
        "How does MIRAGE handle scalability when applied to extremely large datasets?",
        "What mechanisms are in place to ensure the method's applicability to non-tree-like graph structures?",
        "Can the distilled datasets be effectively used with GNNs that require high-dimensional feature spaces?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "79FVDdfoSR",
    "title": "A Characterization Theorem for Equivariant Networks with Point-wise Activations",
    "std_review": {
      "summary": "The paper introduces a novel characterization theorem for equivariant neural networks (EoNNs) that incorporates point‑wise activation functions, extending prior work on DeepSets and invariant networks. It provides a unified framework for both point‑wise and non‑point‑wise activations, offering new insights into designing equivariant models for various group representations. The authors prove a one‑if‑and‑only‑if condition linking equivariance with point‑wise activations and group action, and demonstrate its practical relevance through clear proofs and examples. While the theorem is valuable, its focus on point‑wise activations and certain input space assumptions limit its broad applicability.",
      "strengths": [
        "Novel theorem linking equivariance with point‑wise activations.",
        "Broad applicability to geometric deep learning and diverse group representations.",
        "Clear mathematical proofs and concrete examples.",
        "Provides practical guidance for designing equivariant networks."
      ],
      "weaknesses": [
        "Characterization primarily focused on point‑wise activations, potentially overlooking other relevant activation functions.",
        "Assumes a specific structure for the input space, which may not hold for all datasets.",
        "Lacks empirical validation of the theoretical results.",
        "Mathematical depth may make it challenging for readers without a strong background in group theory and deep learning."
      ],
      "questions": [
        "How can the characterization be extended to non‑point‑wise activation functions?",
        "What are the empirical performance implications of using point‑wise activations in equivariant networks?",
        "How does the framework handle input spaces that do not conform to the assumed structure?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "79rfgv3jw4",
    "title": "Designing Skill-Compatible AI: Methodologies and Frameworks in Chess",
    "std_review": {
      "summary": "The paper introduces three novel reinforcement‑learning agents—Tree, Expector, and Attuned—designed to collaborate with human partners in chess. Evaluated on speech‑to‑text and human‑board environments, the agents outperform a naive baseline, achieving higher win rates and more effective move‑selection probabilities. The work highlights the importance of skill‑compatibility in human‑AI teamwork, suggesting future research should explore broader applicability and cross‑domain collaboration. Overall, the paper is well‑structured, methodologically rigorous, and provides compelling empirical evidence, though its domain specificity and reliance on opponent modeling raise some concerns.",
      "strengths": [
        "Innovative agent design with three distinct strategies",
        "Comprehensive evaluation across two distinct benchmarks",
        "Clear methodological rigor and detailed methodology"
      ],
      "weaknesses": [
        "Domain specificity—findings may not generalize beyond chess",
        "Reliance on accurate opponent modeling for success",
        "Focus on skill‑compatibility rather than broader human‑compatibility factors"
      ],
      "questions": [
        "How can the proposed methods be adapted for other domains beyond chess?",
        "What is the impact of varying opponent unpredictability on agent performance?",
        "How does the human‑in‑the‑loop feedback in Attuned influence long‑term collaboration dynamics?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "79tJB1eTmb",
    "title": "",
    "std_review": {
      "summary": "The paper introduces Meta-Cot, a method that dynamically selects examples to guide a large language model in solving complex reasoning problems. It shows improved performance in out-of-domain scenarios compared to few-shot prompting and zero-shot CoT, but the evaluation includes datasets that may not be genuinely out-of-domain, raising questions about its generalizability. The method's scalability is also questionable due to increasing computational costs with more categories, and the lack of citations for the dynamic example selection process is a concern.",
      "strengths": [
        "Dynamic scenario identification adapts to a wide range of problems without predefined templates.",
        "Improved performance in out-of-domain scenarios compared to few-shot prompting and zero-shot CoT.",
        "Potential scalability with the number of categories, though computational cost is a concern."
      ],
      "weaknesses": [
        "Scalability concerns due to increasing computational cost with more categories.",
        "Lack of genuine out-of-domain datasets in evaluation questions the method's generalizability.",
        "Incomprehensive baseline comparison with few-shot prompting and zero-shot CoT.",
        "Data requirements are not clearly justified, and experimental results are considered weak.",
        "No citations for the dynamic example selection process.",
        "Zero-shot CoT generation is not fully addressed, and potential mistakes could impact results."
      ],
      "questions": [
        "How does the method handle scalability with a large number of categories?",
        "What is the impact of the scenario identification step on performance in truly out-of-domain scenarios?",
        "How does Meta-Cot's performance compare to simpler prompting methods without dynamic example selection?",
        "What are the data requirements for Meta-Cot, and how are they justified?",
        "What citations support the dynamic example selection process?",
        "How is the generation of zero-shot CoT demonstrations ensured to be accurate?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "7AB077M4TY",
    "title": "Dynamic Training Guided by",
    "std_review": {
      "summary": "The paper introduces Koopman Gradient Acceleration (KGA), a novel optimization technique that enhances training speed and stability by dynamically accelerating gradients along specific Koopman modes. The authors also propose Koopman Weight Masking (KWM) to reduce computational overhead. Experiments show KGA outperforms standard SGD and Adam across various tasks, achieving faster convergence and improved accuracy with comparable resources. While innovative and theoretically justified, the approach may require careful tuning and further scalability testing.",
      "strengths": [
        "Innovative approach leveraging Koopman operator theory for dynamic gradient acceleration.",
        "Strong theoretical foundation linking Koopman modes to optimization benefits.",
        "Computational efficiency through lightweight Koopman Weight Masking.",
        "Empirical validation demonstrating clear performance gains over established optimizers."
      ],
      "weaknesses": [
        "Complexity due to reliance on Koopman theory, potentially challenging for non-experts.",
        "Parameter sensitivity, particularly the acceleration parameter α, may need extensive tuning.",
        "Scalability to large models or datasets has not been fully demonstrated.",
        "Evaluation focuses on speed and accuracy, potentially overlooking other performance aspects."
      ],
      "questions": [
        "How can the approach be extended to other optimization algorithms or model architectures?",
        "What are the long-term stability and generalization implications of dynamically modifying gradient dynamics?",
        "How does KGA perform on very large-scale models or datasets beyond the current experiments?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7AiPfnM73h",
    "title": "Projected Off-Policy Q-Learning (POP-QL) for Stabilizing Offline Reinforcement Learning",
    "std_review": {
      "summary": "The paper introduces POP-QL, an offline policy optimization algorithm that improves sample efficiency in reinforcement learning by addressing distributional shift in off-policy data. It builds on Kolter (2011) with a novel objective that regularizes the policy while preserving off-policy benefits. Empirical evaluations on D4RL benchmarks show competitive performance, but POP-QL often underperforms compared to state-of-the-art methods, especially on severely sub-optimal datasets. Theoretical foundations are solid, and scalability is improved through a dual optimization framework, though the method adds complexity. Overall, the paper presents a promising approach with some practical concerns.",
      "strengths": [
        "Novel objective function that balances policy improvement with distributional regularization.",
        "Strong theoretical foundation leveraging probability theory and optimization.",
        "Improved scalability compared to the original Kolter approach."
      ],
      "weaknesses": [
        "Empirical performance on benchmark datasets like D4RL is often lower than state-of-the-art methods.",
        "Baseline reproducibility issues may affect comparability of results.",
        "Increased algorithmic complexity due to policy projection and dual optimization."
      ],
      "questions": [
        "Can POP-QL outperform policy-regularization or conservative methods on severely sub-optimal datasets?",
        "What are the detailed implementation details of the baselines to ensure reproducibility?",
        "How does POP-QL compare to other off-policy methods that address distribution shift?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "7ArYyAmDGQ",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a novel theoretical framework for analyzing the ridgeless least squares estimator under non‑i.i.d. regression errors, leveraging left‑spherical symmetry (LSS) to explain the double‑descent phenomenon. It provides new insights into how variance can be factorized to understand the behavior of the double‑descent curve, offering a more nuanced view of when double descent occurs. While the analysis is mathematically rigorous and extends the understanding of ridgeless least squares beyond i.i.d. assumptions, it has limitations such as focusing only on the ridgeless case and not addressing ridge regularization or the over‑parameterized regime.",
      "strengths": [
        "Novel relaxation of the i.i.d. assumption for the ridgeless least squares estimator.",
        "Innovative use of left‑spherical symmetry (LSS) to factorize expected variance and explain double descent.",
        "Clear theoretical contributions with precise mathematical results."
      ],
      "weaknesses": [
        "Limited scope to the ridgeless case, not covering ridge regularization.",
        "Focus on the under‑parameterized regime, ignoring the over‑parameterized regime.",
        "Reliance on the LSS assumption may limit generality in practical scenarios.",
        "Lack of empirical validation to support practical relevance."
      ],
      "questions": [
        "Could the framework be extended to handle ridge regularization?",
        "What is the behavior of the estimator in the over‑parameterized regime?",
        "How robust are the LSS assumptions in realistic data settings?",
        "Would empirical studies strengthen the practical applicability of the findings?"
      ],
      "overall_score": "Accept",
      "confidence": "High"
    }
  },
  {
    "paper_id": "7AS7vaVU8d",
    "title": "Learning Personalized Story Evaluation",
    "std_review": {
      "summary": "The paper introduces PerSE, a model that evaluates story quality using historical movie review data, aiming to mitigate biases present in GPT-4. It compares PerSE's performance against LLaMA and highlights statistical significance in its results. While innovative, the paper has methodological gaps, such as unclear data selection strategies and assumptions about data independence, which affect its validity. Overall, the work shows promise but requires further clarification and robustness.",
      "strengths": [
        "Innovative approach using historical movie review data for story quality evaluation.",
        "Explicit focus on bias mitigation, addressing a significant limitation of language models.",
        "Demonstrates statistical rigor through t-tests and clear evaluation metrics."
      ],
      "weaknesses": [
        "Unclear methodology for selecting historical reviews from movie reviewers.",
        "Assumes movie review data is not part of LLaMA's training, which may not be verifiable.",
        "Repeats questions about bias without providing quantitative evidence."
      ],
      "questions": [
        "How are the historical reviews selected from each movie reviewer (randomly or based on specific criteria)?",
        "What evidence supports the claim that movie review data is not part of LLaMA's training data?",
        "Could you provide quantitative analysis of the bias towards LLaMA generations in PerSE's evaluations?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "7avlrpzWqo",
    "title": "",
    "std_review": {
      "raw_text": "{\n  \"summary\": \"The paper introduces the Flag Aggregator (FA), a Byzantine‑resilient aggregation method that improves robustness in distributed machine learning by projecting worker gradients into a carefully selected subspace and aggregating them. FA achieves superior robustness against Byzantine faults under certain conditions, supported by both theoretical analysis and empirical experiments. While FA shows strong theoretical and practical advantages, including flexibility in subspace selection and scalability, it also has concerns such as computational complexity due to SVD and hyper‑parameter sensitivity.\",\n  \"strengths\": [\n    \"Theoretical robustness: FA provides a rigorous framework for Byzantine resilience with clear conditions for superiority.\",\n    \"Flexibility in subspace selection: Adaptive subspace dimension balances robustness and efficiency.\",\n    \"Scalability: Designed for efficient computation per iteration, suitable for large‑scale systems.\"\n  ],\n  \"weaknesses\": [\n    \"Computational complexity: SVD computation for subspace selection could be a bottleneck in very large systems.\",\n    \"Hyper‑parameter sensitivity: Discrete subspace dimension \\(m\\) requires careful tuning.\",\n    \"Non‑linear noise handling: Limited exploration of performance with non‑linear noise.\"\n  ],\n  \"questions\": [\n    \"How can the computational overhead of SVD be mitigated for very large‑scale deployments?\",\n    \"What are the practical guidelines for selecting the optimal subspace dimension \\(m\\) in real‑world settings?\",\n    \"How does FA perform with non‑linear noise, and what modifications are needed?\"\n  ],\n  \"overall_score\": \"7: accept\",\n  \"confidence\": \"4: high\"\n}",
      "parse_error": true
    }
  },
  {
    "paper_id": "7b2itdrxMa",
    "title": "From Child's Play to AI: Insights into Automated Causal Curriculum Learning",
    "std_review": {
      "summary": "The paper proposes a curriculum learning approach for reinforcement learning agents inspired by children's education, using level progress as an intrinsic reward. It demonstrates improved learning efficiency and performance through both human experiments and RL experiments compared to a stochastic curriculum. The authors effectively bridge human learning and RL, introduce a novel reward mechanism, and provide comprehensive evaluation. However, the human experiments have limited generalizability, and the paper lacks detailed analysis of potential limitations and ethical considerations.",
      "strengths": [
        "Bridges human learning and RL by proposing a curriculum learning approach inspired by children's education.",
        "Introduces a novel auxiliary reward based on level progress, which could improve the learning process in RL agents.",
        "Includes both human experiments and RL experiments, providing a comprehensive evaluation of the proposed approach."
      ],
      "weaknesses": [
        "Human experiments may have limited generalizability due to the specific context and population studied.",
        "Lacks detailed analysis of potential limitations of using level progress as an intrinsic reward, such as overfitting or difficulty in defining level progress in complex tasks.",
        "Comparison with a stochastic curriculum is not exhaustive, and other baselines could have been considered.",
        "Does not adequately discuss ethical considerations involved in conducting human subject experiments."
      ],
      "questions": [
        "How can the proposed level progress metric be generalized to more complex tasks beyond the current study?",
        "What are the long-term effects of using intrinsic rewards based on level progress on the learning dynamics of RL agents?",
        "How does the proposed approach compare to other intrinsic reward methods, such as curiosity-driven learning or meta-learning, in terms of efficiency and performance?",
        "What are the potential ethical implications of using human subjects in RL experiments, and how can they be mitigated?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7bIpWYhCdu",
    "title": "Fili: Syntax Repair By Learning From Own Mistakes",
    "std_review": {
      "summary": "The paper introduces BIFI, a two-stage method that trains a model to generate incorrect programs (breakers) and then corrects them (fixers). Evaluated on a synthetic Python dataset, the fixers show significant accuracy gains, but breaker training is challenging and yields diminishing returns beyond two iterations. The study highlights the limitations of using edit distance as a metric and notes the method's computational cost and limited real-world generalization. Overall, the approach is innovative but faces practical and theoretical constraints.",
      "strengths": [
        "Innovative two-stage training approach for program repair",
        "Clear evaluation metrics using parse rate and edit distance",
        "Empirical insights from ablation studies on model performance"
      ],
      "weaknesses": [
        "Complexity of training models to generate realistic errors",
        "Edit distance metric may undervalue semantically valid edits",
        "Increased computational cost due to separate breaker and fixer models",
        "Limited generalization to real-world programming scenarios"
      ],
      "questions": [
        "How can the method be adapted to handle more complex programming languages or domains?",
        "What are the long-term maintenance and update requirements for the breaker and fixer models?",
        "How does the approach perform on larger, more diverse datasets beyond the synthetic Python examples?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "7CLvyZ6Xn7",
    "title": "Cross-domain Adaptation for Few-shot 3D Shape Generation",
    "std_review": {
      "summary": "The paper presents a novel few-shot 3D shape generation framework that adapts a pre-trained generative model across domains with minimal labeled data. It introduces a domain-adaptation loss that aligns both feature distributions and shape geometry, along with a regularization term that preserves relative distances between generated shapes. Experiments on several domain adaptation tasks show significant improvements over existing methods using multiple quantitative metrics and visual comparisons. The authors propose future work to address large domain gaps and improve texture adaptation.",
      "strengths": [
        "Introduces a novel domain-adaptation loss that simultaneously aligns feature distributions and shape geometry.",
        "Preserves relative distances between generated shapes, enhancing realism across domains.",
        "Demonstrates strong performance on multiple domain adaptation tasks with comprehensive quantitative metrics.",
        "Provides clear baselines and thorough comparisons, establishing a solid benchmark."
      ],
      "weaknesses": [
        "Limited evaluation on large domain gaps, such as Cars → Abstract Shapes.",
        "Dependence on high-quality and diverse source domain data.",
        "Computational cost may limit applicability in real-time or resource-constrained settings.",
        "Lack of extensive hyperparameter sensitivity analysis."
      ],
      "questions": [
        "How does the method perform on large domain gaps beyond the evaluated moderate shifts?",
        "What is the impact of source data quality and diversity on the adaptation results?",
        "Could the computational overhead be reduced to improve real-time applicability?",
        "What hyperparameter sensitivity analysis has been conducted, and are the results robust?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7D9X2cFnt1",
    "title": "Elastic Feature Consolidation for Cold Start Exemplar-free Incremental Learning",
    "std_review": {
      "summary": "The paper introduces Elastic Feature Consolidation (EFC), a novel approach to class‑incremental learning (CIL) that effectively balances plasticity and stability. EFC uses an Empirical Feature Matrix (EFM) to capture task‑specific feature distributions and an Asymmetric Prototype Replay loss (PR‑ACE) to stabilize feature representations. Experimental results show strong performance, especially in cold‑start scenarios, outperforming existing exemplar‑free CIL methods.",
      "strengths": [
        "Introduces the Empirical Feature Matrix (EFM) as a novel alternative to the Fisher Information Matrix (FIM) for exemplar‑free CIL.",
        "Balances plasticity and stability in learning new tasks while retaining knowledge from previous tasks.",
        "Proposes the Asymmetric Prototype Replay loss (PR‑ACE) to address feature drift and enable adaptive learning.",
        "Demonstrates robust performance across both cold‑start and warm‑start scenarios."
      ],
      "weaknesses": [
        "The complexity of implementing the EFM and PR‑ACE loss may increase computational requirements.",
        "Empirical validation could be strengthened with results across a wider range of datasets and tasks.",
        "Comparison with the latest state‑of‑the‑art methods, including exemplar‑based approaches, would further highlight EFC's contributions."
      ],
      "questions": [
        "How does EFC perform on very large datasets with many classes?",
        "What is the impact of the EFM and PR‑ACE loss on model interpretability?",
        "Can EFC be integrated with other regularization techniques for further improvements?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7duh4Ml5rc",
    "title": "Based on What We Can Control Artificial Neural Networks",
    "std_review": {
      "summary": "The paper interprets neural‑network training as a control problem, framing optimizers as controllers and analyzing their effects on stability and performance across various architectures and datasets. It provides a novel control‑theoretic perspective, offering a comprehensive comparison of traditional and novel optimizers. While the study demonstrates valuable insights into optimizer behavior, it could benefit from deeper theoretical foundations and more extensive hyperparameter exploration.",
      "strengths": [
        "Introduces a novel control‑theoretic framework for understanding neural‑network training.",
        "Comprehensively compares a wide range of optimizers, including traditional and novel approaches.",
        "Tests optimizers across diverse neural‑network architectures and datasets, enhancing generalizability."
      ],
      "weaknesses": [
        "Lacks a deeper theoretical foundation linking control theory to neural‑network dynamics.",
        "May overemphasize control metrics at the expense of other important aspects like convergence speed.",
        "Relies on established architectures, limiting applicability to emerging models.",
        "Insufficient exploration of hyperparameter sensitivity.",
        "Potential reproducibility challenges due to the complexity of the control framework."
      ],
      "questions": [
        "How can the theoretical foundation linking control theory to neural‑network dynamics be strengthened?",
        "What are the hyperparameter sensitivities of each optimizer, and how do they affect performance?",
        "Could the study benefit from testing additional or novel neural‑network architectures?",
        "What additional control metrics (e.g., robustness, adaptability) should be considered in future work?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7em7Jl0qMm",
    "title": "",
    "std_review": {
      "summary": "The paper introduces FODE, a physics‑informed neural network that combines learnable Fourier transforms with sliding‑window forecasting to capture temporal dependencies in time‑series data. Experiments show that FODE achieves competitive accuracy and better data efficiency than established baselines like FNO, DeepONet, and RNN/LSTM models across synthetic and real‑world datasets. Despite higher computational costs and hyperparameter complexity, FODE demonstrates strong scalability and robustness to noisy data, making it a promising approach for time‑series forecasting.",
      "strengths": [
        "Innovative integration of learnable Fourier transforms and element‑wise filters for dynamic temporal modeling.",
        "Scalability to high‑dimensional, complex time series with minimal performance degradation.",
        "Improved data efficiency, achieving comparable or superior results with less training data."
      ],
      "weaknesses": [
        "Increased computational cost during training due to learnable filters and Fourier transforms.",
        "Complexity in hyperparameter tuning introduced by the model's architecture.",
        "Reliance on a sliding‑window approach may limit long‑term prediction capabilities."
      ],
      "questions": [
        "How does FODE perform on extremely long‑term forecasting tasks beyond the initial sliding window?",
        "What are the specific strategies for mitigating overfitting when trained on very small datasets?",
        "Can the model be extended to incorporate additional physical constraints beyond those enforced by the physics‑informed loss?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7ErllmwXym",
    "title": "Interpreting and Improving Diffusion Models Using the Euclidean Distance Function",
    "std_review": {
      "summary": "The paper introduces a novel sampler for diffusion models that improves efficiency and convergence, supported by theoretical guarantees in Theorem 4.2. Experimental results on various datasets show significant performance gains over existing methods, though some experimental coverage and theoretical details remain incomplete.",
      "strengths": [
        "Novel theoretical contributions with Theorem 4.2 providing a solid mathematical foundation.",
        "Practical improvements demonstrated through experimental results.",
        "Clear definitions and assumptions, enhancing clarity and reproducibility."
      ],
      "weaknesses": [
        "Incomplete experimental coverage may limit generalizability.",
        "Lack of detailed proofs for some theoretical results.",
        "Interpretation of theoretical implications and limitations is not fully explored."
      ],
      "questions": [
        "Should additional experiments be conducted on more datasets and noise levels?",
        "What is the impact of the omitted proof for Theorem 4.4 on the confidence in the theoretical claims?",
        "How do the assumptions of Theorem 4.2 affect the method's applicability in real-world scenarios?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7erlRDoaV8",
    "title": "Can Sensitive Information Be Deleted From LLMs? Objectives for Defending Against Extraction Attacks",
    "std_review": {
      "summary": "The paper introduces a novel threat model for evaluating language models against extraction attacks, focusing on the recovery of a single token. It evaluates several defense strategies across white‑box and black‑box scenarios, and compares them with existing unlearning metrics. The study highlights the impact of model editing techniques on defense effectiveness, with practical implications for developing more robust models. While the findings are valuable, the focus on single‑token answers and assumptions about attacker budgets limit the scope.",
      "strengths": [
        "Introduces a novel threat model focusing on single-token recovery, which is more realistic and challenging than existing unlearning metrics.",
        "Comprehensively evaluates a wide range of defense strategies against both white‑box and black‑box attacks.",
        "Provides detailed analysis of how different model editing techniques (ROME, MEMIT, constrained fine‑tuning) affect model vulnerability.",
        "Demonstrates practical implications for improving language model robustness, especially in scenarios where single-token information recovery is critical."
      ],
      "weaknesses": [
        "Experiments primarily focus on single-token answers, which may not fully capture behavior in multi-token scenarios.",
        "Assumes a fixed attacker budget B, which may not reflect real-world conditions with varying attacker resources.",
        "Limited discussion on how the proposed attacks and defenses would scale to handle multi-token answers.",
        "Potential overemphasis on defense strategies without a comprehensive comparison of their relative strengths and weaknesses."
      ],
      "questions": [
        "How do the proposed attacks and defenses scale to handle multi-token answer extraction?",
        "What are the relative strengths and weaknesses of the evaluated defense strategies across different attack types?",
        "How do the findings generalize to models with different architectures or training objectives?"
      ],
      "overall_score": "Accept",
      "confidence": "4"
    }
  },
  {
    "paper_id": "7ERQPyR2eb",
    "title": "",
    "std_review": {
      "summary": "Real3D-Portrait presents a novel one-shot 3D talking face generation framework that reconstructs 3D faces from a single 2D image and animates them with audio. The method integrates a head-torso-background super-resolution model to enhance realism, achieving high-quality results. While it advances 3D talking face generation, the framework faces challenges in background and torso modeling sophistication and computational efficiency, which could limit real-time applications.",
      "strengths": [
        "One-shot learning enables 3D face generation from a single image, reducing data collection needs.",
        "High-quality 3D reconstruction with the I2P model maintains geometric accuracy and facial features.",
        "Audio-driven animation using the audio-to-motion model results in smooth and realistic talking faces.",
        "Integration of the HTB super-resolution model significantly improves realism, including background and torso modeling."
      ],
      "weaknesses": [
        "Background and torso modeling could be more sophisticated, affecting realism in complex scenes.",
        "Computational efficiency may be a concern, potentially limiting real-time applications.",
        "Performance heavily relies on the quality of the input 2D image, which may not always be optimal."
      ],
      "questions": [
        "How can the background and torso modeling be further improved to enhance realism in complex scenes?",
        "What strategies can be employed to improve computational efficiency for real-time applications?",
        "How does the method handle variations in input image quality, such as low resolution or poor lighting?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7essnmWOK5",
    "title": "",
    "std_review": {
      "summary": "The paper introduces HSDGNN, a hierarchical spatial‑dynamic graph neural network for multivariate time‑series forecasting. It effectively models hierarchical dependencies among attributes and captures intra‑attribute dependencies using an IDLM, leading to superior performance on five traffic datasets compared to baselines and state‑of‑the‑art methods. The authors provide strong theoretical and empirical justification for their approach, though the added complexity may limit applicability in resource‑constrained settings.",
      "strengths": [
        "Hierarchical structure effectively models complex attribute dependencies.",
        "Intra‑attribute dependency learning module (IDLM) improves performance on datasets with few attributes.",
        "Robustness across diverse traffic datasets demonstrates versatility and real‑world applicability."
      ],
      "weaknesses": [
        "Model complexity may lead to longer training times and higher computational costs.",
        "Lack of detailed hyperparameter tuning and ablation studies weakens the claim of superiority.",
        "Potential interpretability issues due to hierarchical nature."
      ],
      "questions": [
        "How does the model perform on datasets with a large number of attributes?",
        "What is the impact of hyperparameter tuning on model performance?",
        "Can the model be adapted for resource‑constrained environments?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7etoNfU9uF",
    "title": "",
    "std_review": {
      "summary": "SpikePoint introduces a method for event-based action recognition that transforms spiking neural events into point clouds with implicit timestamp encoding. It uses a Condensation-inspired sampling strategy and dual feature extractors to capture spatial and temporal dynamics, trained via surrogate gradients. The approach shows competitive performance on benchmarks, handling high-frequency streams efficiently, though some aspects of its design and training remain underexplored.",
      "strengths": [
        "Innovative implicit temporal encoding via timestamp as a third spatial dimension.",
        "Efficient sampling strategy leveraging Condensation for scalability.",
        "Dual feature extraction architecture that captures both fine-grained spatial and temporal patterns.",
        "Training feasibility through surrogate gradients bridging deep learning and neuromorphic computing."
      ],
      "weaknesses": [
        "Implicit timestamp encoding may obscure precise temporal dynamics.",
        "Lack of detailed comparison with existing sampling methods.",
        "Timestep selection is not thoroughly justified.",
        "Surrogate gradient mechanism is briefly described without full explanation."
      ],
      "questions": [
        "How does the implicit timestamp encoding affect the model's ability to capture subtle temporal variations compared to explicit temporal methods?",
        "What are the specific advantages of the sampling strategy over other high-frequency event handling techniques?",
        "How does the choice of timestep (e.g., 16) impact the balance between data granularity and computational efficiency?",
        "Can the surrogate gradient method be further optimized or its effectiveness quantified more clearly?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7eYmijcuqO",
    "title": "On the Dynamics of Learning",
    "std_review": {
      "summary": "The paper provides a novel dynamical‑systems analysis of RNN training, identifying three distinct phases (exploration, convergence, plateau) and demonstrating these phases across simple tasks. While innovative and theoretically grounded, the findings are limited to toy datasets and basic architectures, raising questions about broader applicability. The study offers valuable insights for RNN design but its practical impact is constrained by interpretability and dataset limitations.",
      "strengths": [
        "Introduces a fresh dynamical‑systems perspective on RNN learning.",
        "Leverages PCA and Jacobian eigenvectors for rigorous analysis.",
        "Empirically validates the three‑phase structure across multiple toy tasks."
      ],
      "weaknesses": [
        "Results are based on limited, simple datasets and architectures.",
        "Interpretability of dynamical insights may be challenging for practitioners.",
        "Focuses only on traditional RNNs, not modern variants like transformers."
      ],
      "questions": [
        "How do the identified learning phases generalize to more complex, real‑world tasks and architectures?",
        "What visual or simplified models can be developed to make the dynamical insights more accessible?",
        "How might the findings differ when applied to contemporary RNN variants such as transformers?",
        "What adjustments are needed to study irregular or high‑dimensional time series data?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "7ezBaMwOqY",
    "title": "Trading-off Multiple Properties for Molecular Optimization",
    "std_review": {
      "summary": "The paper introduces PCI, a Pareto‑Constrained Integer framework that formulates multi‑objective molecular optimization as a linear programming problem, enabling efficient generation of diverse, high‑quality molecules while respecting scaffold hierarchies. PCI outperforms existing methods on benchmark datasets in terms of Pareto front coverage and computational efficiency. The reviewer finds PCI's novel LP formulation, efficient Pareto generation, flexibility with objectives, and strong theoretical guarantees compelling, but notes concerns about convexity assumptions, scalability for large scaffold trees, the need for more comprehensive baseline comparisons, and limited empirical validation.",
      "strengths": [
        "Novel LP formulation for multi‑objective molecular optimization",
        "Efficient Pareto generation via a single LP",
        "Flexibility to accommodate various molecular properties",
        "Strong theoretical guarantees and convergence properties"
      ],
      "weaknesses": [
        "Assumption of convexity for objective functions and constraints",
        "Potential scalability issues for very large scaffold trees",
        "Lack of thorough comparisons with non‑LP based methods",
        "Insufficient empirical validation on diverse chemical domains"
      ],
      "questions": [
        "How does PCI handle non‑convex objective functions or constraints?",
        "What is the scalability of PCI for very large scaffold hierarchies?",
        "How does PCI compare to state‑of‑the‑art non‑LP based multi‑objective optimization methods?",
        "What additional experiments are needed to validate PCI's generality and effectiveness across diverse chemical domains?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7F4ioiKQFT",
    "title": "ColCLIP: Enhancing Fine-Grained Image Retrieval with Pre-trained Embeddings",
    "std_review": {
      "summary": "ColCLIP introduces a MaxSim operator to align object-specific queries with image regions, improving fine-grained image retrieval. Experiments on Visual Genome, Flickr30K, and MS COCO show significant gains over standard CLIP and other baselines, with reduced computational costs. The paper is well-structured, with clear ablations and comparisons, though reproducibility could be enhanced.",
      "strengths": [
        "Innovative MaxSim layer effectively bridges object-specific queries with image regions, enhancing retrieval precision.",
        "Demonstrates cross-dataset generalization across Flickr30K, MS COCO, and Visual Genome, showcasing robustness.",
        "Computational efficiency gains through dimensionality reduction, reducing latency and training time."
      ],
      "weaknesses": [
        "Limited baselines for the MaxSim layer could strengthen the argument for its importance.",
        "Potential overfitting on Visual Genome; further validation on diverse datasets is warranted.",
        "Trade-off between retrieval accuracy and computational efficiency is not fully quantified.",
        "Absence of publicly available code and data hinders reproducibility."
      ],
      "questions": [
        "How does ColCLIP perform on additional, more diverse datasets beyond Visual Genome, Flickr30K, and MS COCO?",
        "What is the impact of different aggregation functions in the MaxSim layer on retrieval accuracy?",
        "Could the MaxSim layer be integrated with other object detection models to further enhance performance?",
        "What are the specific latency and training time improvements achieved with dimensionality reduction, and how do they vary across datasets?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7FeIRqCedv",
    "title": "",
    "std_review": {
      "summary": "SLiMe introduces a novel few-shot image segmentation method that uses Stable Diffusion to generate text embeddings to guide segmentation. The approach is flexible, achieving strong results on benchmark datasets like horse/car/face, and offers some interpretability by linking embeddings to Stable Diffusion tokens. However, its performance on complex objects and more diverse datasets is limited, and the interpretability of the embeddings remains challenging. Overall, the method shows promise but requires further exploration.",
      "strengths": [
        "Innovative use of text embeddings from Stable Diffusion to guide segmentation.",
        "Flexibility in granularity through varying text prompts.",
        "Competitive performance on benchmark datasets.",
        "Provides interpretability by linking embeddings to Stable Diffusion tokens."
      ],
      "weaknesses": [
        "Limited benchmark evaluation with only horse/car/face datasets.",
        "Interpretability of embeddings is not fully clear.",
        "Potential struggles with small or featureless objects.",
        "Lack of detailed baseline comparisons."
      ],
      "questions": [
        "How does SLiMe perform on more complex datasets like ADE-Bedroom-30 or FSS-1000?",
        "Can the learned embeddings be mapped to more interpretable terms or concepts?",
        "What is the impact of the granularity level on segmentation quality for different object types?",
        "How does SLiMe compare to recent methods like SegDDPM or Painter in terms of performance and interpretability?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "7ffJo4vtTY",
    "title": "Robustness Signatures in CLIP Models",
    "std_review": {
      "summary": "The paper introduces a novel framework for assessing robustness in multimodal models by identifying outlier features and privileged directions. It provides a clear theoretical foundation and a comprehensive experimental setup comparing baseline and multimodal fine-tuned models. The authors' approach is significant for understanding how robustness impacts predictive power, though some areas for improvement are noted.",
      "strengths": [
        "Introduces a novel framework for assessing robustness in multimodal models through outlier features and privileged directions.",
        "Provides a clear theoretical foundation linking these concepts to model performance.",
        "Employs a comprehensive experimental setup, comparing baseline and multimodal fine-tuned models."
      ],
      "weaknesses": [
        "Figures, particularly Figure 2, are difficult to interpret and could benefit from clearer presentation.",
        "The use of kurtosis to determine outlier features may not be the most robust choice.",
        "The paper does not adequately address the differences in model complexity between their work and reference works."
      ],
      "questions": [
        "Should a more comprehensive set of metrics be used to determine outlier features?",
        "How can the authors improve the clarity of Figure 2?",
        "What specific differences in model complexity should be explicitly addressed?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7FHrZuKogW",
    "title": "Contractive Systems Improve Graph Neural Networks Against Adversarial Attacks",
    "std_review": {
      "summary": "The paper proposes a novel Graph Convolutional Neural Network (CSGN) that enhances GNN robustness against adversarial attacks by learning the dynamics of the adjacency matrix using neural ordinary differential equations (ODEs). Theoretical foundations and empirical results show significant improvements over existing baselines like GNNGuard, but the approach introduces computational complexity that may limit scalability for very large graphs.",
      "strengths": [
        "Introduces a unique method of learning adjacency matrix dynamics using neural ODEs to improve GNN robustness.",
        "Provides a solid theoretical basis with theorems supporting the contractive properties of learned dynamics.",
        "Demonstrates superior performance in experiments against adversarial attacks compared to existing methods."
      ],
      "weaknesses": [
        "Adds computational complexity due to learning adjacency matrix dynamics, which could be a concern for large-scale applications.",
        "Scalability may be limited by the computational overhead associated with learning dynamics.",
        "Theoretical assumptions behind the theorems may require further validation."
      ],
      "questions": [
        "How does the approach scale to extremely large graphs or high-dimensional data?",
        "What is the computational cost of training the neural ODEs compared to other defense mechanisms?",
        "How robust are the theoretical assumptions in Theorem 1 and Theorem 2 in practical scenarios?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7fwzPsn1lJ",
    "title": "LLark : A Multimodal Model for Music",
    "std_review": {
      "summary": "LLark is a novel multimodal model for music that integrates audio and text modalities using a transformer architecture, achieving competitive performance on music understanding tasks. While it outperforms many existing models, its novelty does not always translate to superior results, and there are concerns about text hallucinations and the need for more comprehensive ablation studies. The paper should address ethical implications and consider additional experiments to validate its components.",
      "strengths": [
        "Innovative multimodal architecture combining audio and text.",
        "State-of-the-art performance on key music understanding tasks.",
        "End-to-end training simplifies development and potentially improves coherence."
      ],
      "weaknesses": [
        "Novelty does not always surpass highly specialized models.",
        "Performance on music captioning could be improved.",
        "Potential for text hallucinations.",
        "Lack of extensive ablation studies.",
        "Ethical and deployment considerations not fully addressed."
      ],
      "questions": [
        "Could more detailed ablation studies clarify the contribution of each model component?",
        "What strategies are proposed to mitigate text hallucinations?",
        "How does LLark's performance compare to other multimodal models like CLAP, MERT, and MULAN?",
        "What safeguards are proposed for addressing potential misuse of LLark?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "7fxzVTSgZC",
    "title": "Offline Imitation Learning without Auxiliary High-quality Behavior Data",
    "std_review": {
      "summary": "The paper presents BCDP, a method for offline reinforcement learning that effectively leverages both expert and low-quality behavior data. It introduces a distributional regularizer to handle non-random data, improving performance on MuJoCo control tasks compared to existing methods. While showing promise, the method's reliance on data quality assumptions and computational complexity are noted as areas for improvement.",
      "strengths": [
        "Innovative combination of expert and low-quality behavior data.",
        "Robustness to noisy data through a distributional regularizer.",
        "Introduces the DRG metric for evaluating out-of-distribution performance."
      ],
      "weaknesses": [
        "Effectiveness depends on the quality of low-quality behavior data.",
        "Increased computational complexity may limit scalability.",
        "Lack of comprehensive ablation studies.",
        "No extensive comparison with model-based methods."
      ],
      "questions": [
        "How does BCDP perform with highly biased or adversarial low-quality data?",
        "What is the computational cost of the distributional regularizer in larger environments?",
        "Could a more thorough ablation study clarify the contribution of each component?",
        "How does BCDP compare to model-based imitation learning approaches?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7GCRhebJEr",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a novel robustness improvement method using Bregman divergences and learned similarity metrics. It projects corrupted images back into a distribution of in-distribution images by iteratively projecting onto a Bregman ball and an L2 ball. The approach leverages a learned base function to define the Bregman divergence, which is then used to guide the projection. Experiments on CIFAR-10-C demonstrate improved robustness against various corruption levels compared to baselines. The method also explores adversarial training using the learned inverse map to further enhance robustness. Overall, the paper presents an innovative framework with promising empirical results, though some theoretical and practical concerns remain.",
      "strengths": [
        "Innovative use of Bregman divergences to define a learned similarity metric for robustness improvement.",
        "Practical and efficient iterative projection method for handling corrupted images.",
        "Solid theoretical foundation for the projection method, ensuring convergence to the true projection.",
        "Significant improvements in robustness demonstrated through experiments on CIFAR-10-C.",
        "Forward-looking approach of adversarial training using the learned inverse map."
      ],
      "weaknesses": [
        "Lack of thorough discussion on conditions for the existence and uniqueness of the projection.",
        "Unclear justification for the convergence of the mirror descent algorithm when the projection onto the learned base function is not available in closed form.",
        "Arbitrary choice of distance d in experiments without clear guidance or prior work.",
        "Limited evaluation scope to CIFAR-10-C, with no indication of scalability or generalization to more complex datasets."
      ],
      "questions": [
        "What are the conditions under which the projection u exists and is unique?",
        "How can the convergence of the mirror descent algorithm be justified when the projection onto the learned base function is not available in closed form?",
        "What guidance or prior work is available for selecting appropriate values of distance d?",
        "How does the method perform on more complex datasets like ImageNet-C?"
      ],
      "overall_score": "6: accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "7gDENzTzw1",
    "title": "Belief-Enriched Pessimistic Q-Learning against Adversarial State Perturbations",
    "std_review": {
      "summary": "The paper investigates the robustness of a reinforcement learning method against color perturbations in Atari games using the Continuous Gridworld environment. It evaluates three attack budgets and finds the method maintains performance under significant color noise, suggesting robustness. However, the study's scope is limited to two Atari games and a simple environment, raising questions about generalizability. The findings are promising but require further exploration in more complex settings.",
      "strengths": [
        "Clear experimental setup focusing on color perturbations in a controlled Atari environment.",
        "Methodological rigor through the use of multiple attack budgets.",
        "Relevance to real-world applications where RL agents must handle varying environmental conditions.",
        "Insight into how RL agents learn to process and interpret color information."
      ],
      "weaknesses": [
        "Limited scope to a single environment (Continuous Gridworld) and only two Atari games.",
        "Use of 8-bit RGB color representation may not fully capture real-world complexity.",
        "Observed robustness could be due to filtering specific colors rather than true robustness.",
        "Lack of exploration in more complex environments like Mujoco or Mountain Car."
      ],
      "questions": [
        "How does the method perform in more complex environments with continuous state spaces?",
        "Could the observed robustness be attributed to color filtering rather than true robustness to perturbations?",
        "What is the extent to which the method's performance is generalizable beyond the tested Atari games?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "7GkdjhupsV",
    "title": "InfoAug: Mutual Information Informed Augmentation for Representation Learning",
    "std_review": {
      "summary": "InfoAug presents a novel data augmentation technique grounded in information-theoretic principles, aiming to improve the robustness and generalization of deep learning models. The method generates informative image patches and demonstrates significant improvements over baseline techniques on benchmark image classification tasks. While computationally efficient and easy to integrate, the paper lacks a comprehensive theoretical analysis and comparison with state-of-the-art methods across various tasks and domains.",
      "strengths": [
        "Introduces a novel data augmentation technique grounded in information-theoretic principles.",
        "Demonstrates consistent improvements over existing augmentation techniques on multiple benchmark datasets.",
        "The method is computationally efficient and can be easily integrated into existing deep learning pipelines."
      ],
      "weaknesses": [
        "Lacks a detailed theoretical analysis of the proposed augmentation technique.",
        "Does not provide a comprehensive comparison with state-of-the-art augmentation methods across a wide range of tasks and datasets.",
        "Evaluation is limited to image classification tasks, with limited discussion on applicability to other domains."
      ],
      "questions": [
        "What is the theoretical analysis of the proposed augmentation technique?",
        "How does InfoAug perform on tasks beyond image classification, such as object detection or semantic segmentation?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7gLfQT52Nn",
    "title": "",
    "std_review": {
      "summary": "The paper introduces ALLO, an adversarial learning framework that learns Laplacian representations for MDPs, combining minimax optimization with Laplacian regularization to stabilize learning and improve representation quality. Theoretical guarantees and practical experiments on synthetic and real-world environments demonstrate the method's effectiveness, but concerns about computational complexity, theoretical robustness, and lack of extensive empirical evidence limit its acceptance.",
      "strengths": [
        "Introduces a novel adversarial learning framework (ALLO) that integrates Laplacian regularization.",
        "Provides theoretical stability guarantees in Theorem 1.",
        "Demonstrates practical utility in exploration, reward shaping, and value estimation."
      ],
      "weaknesses": [
        "Computational complexity of the minimax optimization is not fully analyzed.",
        "Theoretical stability guarantee relies on specific conditions that may not hold in practice.",
        "Lack of extensive empirical evidence for the practical utility of the Laplacian representation.",
        "Limited analysis of the stability of the minimax game.",
        "Theoretical extension to continuous spaces lacks concrete examples."
      ],
      "questions": [
        "How does the computational complexity of the minimax optimization compare to the original formulations in practical settings?",
        "What are the specific conditions under which the theoretical stability guarantee holds in real-world scenarios?",
        "Can you provide more extensive empirical evidence comparing the Laplacian representation to state-of-the-art methods?",
        "What further analysis or experiments could demonstrate the practical stability of the minimax game?",
        "What challenges arise when extending the framework to continuous state spaces, and how can they be addressed?"
      ],
      "overall_score": "Borderline",
      "confidence": "Medium"
    }
  },
  {
    "paper_id": "7gUrYE50Rb",
    "title": "EQA-MX: Embodied Question Answering using Multimodal Expression",
    "std_review": {
      "summary": "The paper presents EQA-MX, a multimodal grounding system that integrates non-verbal gestures (pointing and gaze) with visual inputs to improve object localization and counting. It introduces three tasks—object grounding, perspective-aware object grounding, and perspective grounding—and demonstrates effectiveness on a challenging dataset. While the approach is promising, it lacks clear task differentiation and thorough handling of ambiguous scenarios, such as multiple similar objects or varying gaze cues.",
      "strengths": [
        "Integrates non-verbal gestures with visual inputs for more comprehensive understanding.",
        "Uses 3D joint positions and gaze information to enhance pointing direction analysis.",
        "Introduces clear task definitions and examples, aiding in understanding the method's adaptability."
      ],
      "weaknesses": [
        "Lacks clear differentiation between object grounding, perspective-aware object grounding, and perspective grounding tasks.",
        "Does not thoroughly address ambiguity in datasets with similar objects or varying gestures.",
        "Representation of gaze is not explicitly detailed, potentially affecting gaze cue interpretation."
      ],
      "questions": [
        "How does the method differentiate between object grounding, perspective-aware object grounding, and perspective grounding tasks?",
        "What strategies are employed to handle ambiguity in datasets with multiple similar objects?",
        "How is gaze represented and interpreted by the model, and how does this affect performance?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "7gVX2LxE7A",
    "title": "SpecAR-Net: Spectrogram Analysis and Representation Network for Time Series",
    "std_review": {
      "summary": "SpecAR-Net introduces a novel neural network architecture that combines spectral and autoregressive modeling to improve time series length prediction. The model leverages a time-frequency transform, multi-scale convolutions, and an order-preserving loss function, achieving superior performance on benchmark datasets, especially for longer series with complex periodicities. While innovative, the architecture's complexity and sensitivity to hyperparameters are noted as potential drawbacks.",
      "strengths": [
        "Integrates spectral and autoregressive modeling to capture both frequency and temporal dependencies.",
        "Demonstrates significant performance improvements over existing methods like TimesNet.",
        "Provides a solid theoretical foundation for the proposed components."
      ],
      "weaknesses": [
        "Introduces additional complexity compared to simpler models.",
        "Performance may be sensitive to hyperparameter tuning.",
        "Lacks a comprehensive ablation study to quantify each component's contribution."
      ],
      "questions": [
        "Should an ablation study be conducted to quantify the impact of each component of SpecAR-Net?",
        "What statistical tests are used to confirm the significance of performance improvements?",
        "How does SpecAR-Net compare to other state-of-the-art methods beyond the limited comparison presented?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7HdtLgsvys",
    "title": "Tube Loss: A Novel Approach for High Quality Prediction Interval Estimation",
    "std_review": {
      "raw_text": "{\n  \"summary\": \"The paper introduces a novel tube loss function for interval estimation in regression, showing improved performance over existing methods on both synthetic and real-world datasets. The loss function is theoretically justified and empirically robust across various data distributions. While the tuning parameter \\( r \\) poses a challenge, the method's flexibility and superior interval coverage make it a valuable contribution.\",\n  \"strengths\": [\n    \"Introduces a novel tube loss function for interval estimation.\",\n    \"Provides strong theoretical justification and empirical performance.\",\n    \"Demonstrates robustness across diverse data distributions.\"\n  ],\n  \"weaknesses\": [\n    \"Tuning parameter \\( r \\) significantly impacts performance.\",\n    \"Computational considerations for large-scale datasets.\",\n    \"Limited baseline comparisons could be expanded.\"\n  ],\n  \"questions\": [\n    \"How can the optimal value of \\( r \\) be determined more systematically?\",\n    \"What are the computational trade-offs for implementing the tube loss in large-scale applications?\",\n    \"How does the proposed method compare to other advanced interval estimation techniques?\"\n  ],\n  \"overall_score\": \"7: accept\",\n  \"confidence\": \"4: high\"\n}",
      "parse_error": true
    }
  },
  {
    "paper_id": "7HfliVAtCG",
    "title": "Detect Every Thing with Few Examples",
    "std_review": {
      "summary": "The paper introduces DE‑ViT, a novel few‑shot object detection system that combines Vision Transformers with Region‑based Convolutional Neural Networks, leveraging frozen DINOv2 features and prototype learning to improve accuracy in open‑set scenarios. It demonstrates strong performance on few‑shot, one‑shot, and open‑vocabulary benchmarks, outperforming existing methods. While innovative, the approach faces challenges in implementation complexity, reliance on frozen features, and computational cost, which may limit its real‑world applicability.",
      "strengths": [
        "Innovative architecture combining ViT and RCNN for few‑shot detection.",
        "Prototype learning simplifies classification in open‑set settings.",
        "Propagated localization improves object proposal refinement.",
        "Efficient training using frozen DINOv2 features.",
        "Competitive performance on challenging benchmarks."
      ],
      "weaknesses": [
        "Complexity in implementation due to the integration of ViT and RCNN.",
        "Dependence on frozen DINOv2 features may limit adaptability.",
        "Higher computational cost compared to some baselines.",
        "Limited evaluation on diverse real‑world data.",
        "Potential for overfitting with frozen features and prototype learning."
      ],
      "questions": [
        "How does DE‑ViT perform on real‑world datasets with varying image resolutions and backgrounds?",
        "What strategies can be employed to reduce the computational cost while maintaining accuracy?",
        "How does the model handle scenarios with high occlusion or clutter?",
        "Can DE‑ViT be adapted for other detection tasks beyond object detection?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7hxoYxKDTV",
    "title": "",
    "std_review": {
      "summary": "PQDiff introduces a progressive quantization diffusion model for outpainting that can handle inputs of varying sizes and aspect ratios while producing outputs of a fixed size. The model demonstrates competitive performance on both in‑painting and out‑painting tasks, outperforming several state‑of‑the‑art baselines. However, the review notes several limitations, including limited quantitative evaluation for arbitrary outpainting positions, insufficient testing of scalability beyond a few multiples, and a lack of thorough consistency analysis. Overall, the paper is promising but requires more rigorous evaluation to substantiate its claims.",
      "strengths": [
        "Versatile input handling: processes inputs of any size and aspect ratio while maintaining a fixed output size.",
        "State‑of‑the‑art performance: achieves competitive results on standard benchmarks in both in‑painting and out‑painting tasks.",
        "Innovative quantization diffusion: leverages progressive quantization to enhance efficiency and quality, especially for large‑scale outpainting."
      ],
      "weaknesses": [
        "Limited quantitative evaluation for arbitrary positions: relies primarily on qualitative analysis.",
        "Insufficient scalability testing: only tested up to 2.5x, 5x, and 11.7x multiples.",
        "Lack of consistency analysis: does not thoroughly examine the impact of the one‑to‑many mapping on outpainting ratios.",
        "Visual comparisons could be clearer: supplementary material figures lack side‑by‑side comparisons."
      ],
      "questions": [
        "Can you provide quantitative results for outpainting quality in arbitrary positions across a broader range of multiples?",
        "What is the quantitative impact of the one‑to‑many mapping between anchor and target views on outpainting consistency?",
        "Could side‑by‑side visual comparisons be included in the supplementary material to better illustrate model performance?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "7iCUSBlOgh",
    "title": "Toward Generalizability of Graph-based Imputation on Bio-Medical Missing Data",
    "std_review": {
      "summary": "The paper introduces GRASS, a graph-based imputation method that leverages feature gradients and k-NN graphs to improve accuracy on bio-medical and medical datasets. It outperforms traditional methods like Mean and GAIN, demonstrating efficiency and generalizability across domains. However, computational demands and parameter sensitivity are noted as limitations.",
      "strengths": [
        "Innovative approach using feature gradients in graph-based imputation",
        "Superior performance on bio-medical and medical datasets",
        "Computational efficiency with feature gradient calculations"
      ],
      "weaknesses": [
        "Computational demands may limit applicability to very large datasets",
        "Performance sensitive to the choice of k in k-NN graph construction",
        "Method's complexity may be challenging for users unfamiliar with graph-based approaches"
      ],
      "questions": [
        "How does GRASS perform on datasets with extremely high sparsity?",
        "What are the specific trade-offs between accuracy and computational cost in different data regimes?",
        "Can GRASS be extended to handle streaming or incremental data imputation?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7ipjMIHVJt",
    "title": "DASFormer: Self-supervised Pretraining for Earthquake Monitoring",
    "std_review": {
      "summary": "The paper proposes a self-supervised learning framework for anomaly detection in Distributed Acoustic Sensing (DAS) data, showing improved performance over traditional models. While it addresses a key gap in the field, the evaluation could be strengthened by comparing against a broader range of state-of-the-art SSL methods and including simpler models. The approach demonstrates practical relevance but lacks thorough uncertainty analysis and a detailed examination of baseline simplicity and loss function impacts.",
      "strengths": [
        "Introduces a novel self-supervised pretraining method tailored for DAS data, addressing a critical gap.",
        "Demonstrates superior real-time anomaly detection performance compared to baseline models.",
        "Provides a practical framework with clear applicability to DAS data."
      ],
      "weaknesses": [
        "Evaluation primarily focuses on the necessity of the proposed pretraining without a comprehensive comparison to other SSL methods.",
        "Lacks thorough uncertainty analysis, which is crucial given the stochastic nature of DAS data.",
        "Does not explore the sufficiency of the 1-second prediction window for timely seismic event detection.",
        "The choice of point‑wise loss function is noted as having drawbacks, suggesting the need for alternative loss functions.",
        "Does not critically evaluate the chosen anomaly score distance metrics."
      ],
      "questions": [
        "How does the proposed pretraining technique compare to other state-of-the-art SSL methods like MAE or Moco?",
        "What is the impact of using simpler models like aggregation‑0 on the performance and interpretability of anomaly detection?",
        "How can uncertainty be quantified and addressed in the model to enhance reliability?",
        "Is the 1‑second prediction window sufficient for timely detection of seismic events, and what are the implications for real‑time deployment?",
        "How do the chosen anomaly score distance metrics (AE, EMD, sliced EMD) compare in terms of capturing model behavior and robustness?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "7iuFxx9Ccx",
    "title": "Resource Efficient Test-Time Training with Slimmable Network",
    "std_review": {
      "summary": "SlimTTT presents a resource‑efficient test‑time training method that dynamically adapts a model's width during inference to improve robustness to distribution shifts. The authors introduce a slimmable network architecture combined with three consistency mechanisms—Width‑Enhanced Contrastive Learning, Logit Consistency Regularization, and Global Feature Alignment—to align sub‑networks. Empirical evaluations on ImageNet‑C and CIFAR10‑C show significant improvements over baseline TTT methods, especially under limited computational budgets. While the approach is innovative and effective, concerns about implementation complexity and the need for broader evaluation are noted.",
      "strengths": [
        "Resource Efficiency: Adaptive width reduces computational cost without sacrificing robustness.",
        "Robustness to Distribution Shifts: Consistency mechanisms improve generalization under distribution shifts.",
        "Methodological Innovation: Introduces a slimmable network architecture and multi‑width adaptation strategy."
      ],
      "weaknesses": [
        "Complexity of Implementation: Multi‑width adaptation and ensemble approach may be challenging to implement.",
        "Limited Scope of Evaluation: Only tested on ImageNet‑C and CIFAR10‑C, limiting general applicability.",
        "Lack of Detailed Analysis: Insufficient analysis of how each consistency mechanism contributes to performance.",
        "Potential Overfitting: Multiple regularizations could lead to overfitting if not properly managed."
      ],
      "questions": [
        "How does the method perform on other benchmarks or domains beyond ImageNet‑C and CIFAR10‑C?",
        "What is the impact of each consistency mechanism on robustness, and how can they be balanced?",
        "What strategies can be employed to reduce implementation complexity for broader adoption?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7jUQHmz4Tq",
    "title": "D3AD: Dynamic Denoising Diffusion Probabilistic Model for Anomaly Detection",
    "std_review": {
      "summary": "The paper presents D3AD, a dynamic denoising diffusion probabilistic model for anomaly detection that enhances reconstruction quality and detection efficiency. It introduces Dynamic Incremental Coarse-to-Fine (DIC) noise and a dynamic perturbation mechanism to improve feature alignment across domains, outperforming existing methods on complex datasets like MVTec. The approach is both efficient and effective, though it may require careful tuning and further theoretical analysis.",
      "strengths": [
        "Introduces a novel DIC noise mechanism that adaptively adjusts noise levels to improve reconstruction quality.",
        "Proposes a dynamic perturbation mechanism that enhances feature alignment across domains, addressing limitations of static methods.",
        "Demonstrates superior performance on complex datasets, achieving higher anomaly detection accuracy and efficiency."
      ],
      "weaknesses": [
        "The dynamic implementation may introduce complexity and require more computational resources.",
        "Evaluation is limited to the MVTec dataset, which may not fully capture real-world diversity.",
        "Lacks a detailed theoretical analysis to further strengthen the method's credibility."
      ],
      "questions": [
        "How does the model generalize to datasets with different types of anomalies beyond MVTec?",
        "What are the specific strategies employed to prevent overfitting with the adaptive noise and perturbation mechanisms?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7jWiBAWG0b",
    "title": "Learning Guarantees for Non-convex Pairwise SGD with Heavy Tails",
    "std_review": {
      "summary": "The paper investigates SGD under sub-Weibull noise, deriving generalization bounds that improve with heavier tails. It offers novel insights into generalization beyond sub-Gaussian assumptions and compares results with pointwise SGD. However, the analysis has several ambiguities and omissions that limit its clarity and impact.",
      "strengths": [
        "Novel analysis of SGD under sub-Weibull noise, a less explored regime.",
        "Clear derivation of generalization bounds that depend on the heavy-tail parameter θ.",
        "Valuable comparative analysis with pointwise SGD, highlighting the impact of pairwise updates."
      ],
      "weaknesses": [
        "Ambiguity in distributional assumptions regarding sub-Weibull tails.",
        "Potential lack of novelty in sub-Weibull analysis, as it builds on finite-variance noise work.",
        "Omission of analysis for pointwise SGD, limiting comparability.",
        "Monotonic dependence on the heavy-tail parameter θ may oversimplify the analysis.",
        "Results presented in expectation, which may not be as practically relevant as high-probability bounds."
      ],
      "questions": [
        "Should the title and abstract explicitly clarify the distinction between sub-Weibull tails and other heavy-tailed notions?",
        "How does the sub-Weibull assumption provide additional informational content beyond second-moment assumptions?",
        "What are the implications of not studying the analogous problem for pointwise SGD?",
        "Could non-monotonic dependencies arise from other factors besides the heavy-tail parameter θ?",
        "How should the paper address the gap between expectation-based bounds and high-probability bounds?",
        "Why is the Lipschitz condition with respect to the loss function excluded, and what are the implications for generality?",
        "Should the expectations in Assumptions 3.8 and 3.9 be explicitly defined to avoid ambiguity?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "7Jwpw4qKkb",
    "title": "Generating Stealthy Jailbreak Prompts on Aligned Large Language Models",
    "std_review": {
      "summary": "The paper presents a novel method to enhance LLM robustness by generating specific tokens that indicate successful command execution, using a handcrafted DAN baseline. It evaluates the approach with a 'Recheck' metric and compares it across several models, including GPT‑4 and GPT‑3.5 Turbo. While the method shows promise, its evaluation is limited by the lack of comprehensive baseline comparisons and the omission of GPT‑4 testing, which could strengthen the claim of its effectiveness across top‑tier models.",
      "strengths": [
        "Clear objective definition of generating specific tokens for command execution.",
        "Innovative DAN baseline that provides a novel benchmarking approach.",
        "Comprehensive evaluation using both the 'Recheck' metric and comparisons with state‑of‑the‑art models."
      ],
      "weaknesses": [
        "Limited baseline comparison, missing broader context for highlighting novelty.",
        "Absence of GPT‑4 evaluation, despite its prominence in the field.",
        "Lack of detailed transferability results for GPT‑3.5 Turbo.",
        "Potential for further robustness testing across diverse prompts and scenarios."
      ],
      "questions": [
        "Could the method be compared against more general baselines to better showcase its unique advantages?",
        "What are the detailed transferability results for GPT‑3.5 Turbo, and how do they compare to other models?",
        "How robust is the method under a wider range of adversarial prompts and scenarios?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "7KDuQPrAF3",
    "title": "",
    "std_review": {
      "summary": "The paper introduces FECCT, a neural decoder for LDPC codes that uses self-attention to improve error correction. It demonstrates strong performance on short to moderate-length codes, outperforming classical belief propagation and other neural decoders. However, concerns about scalability to very long codes, interpretability of the self-attention mechanism, and computational complexity limit its immediate acceptance.",
      "strengths": [
        "Novel integration of self-attention in a neural decoder for LDPC codes.",
        "Federated learning setup enables generalization across diverse code families.",
        "Competitive performance on short to moderate-length codes."
      ],
      "weaknesses": [
        "Limited generalization to very long codes.",
        "Interpretability challenges due to complex self-attention mechanism.",
        "Higher computational complexity compared to state-of-the-art neural decoders."
      ],
      "questions": [
        "How does FECCT perform on significantly longer codes (e.g., hundreds of bits)?",
        "What are the specific interpretability insights between FECCT's learned patterns and belief propagation?",
        "What strategies are proposed for deploying FECCT in resource-constrained environments?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "7LZjuA4AB2",
    "title": "Ask Your Distribution Shift if Pre-Training is Right for You",
    "std_review": {
      "summary": "The paper proposes a method to improve model robustness against distribution shifts by distinguishing between in‑support and out‑of‑support examples using a probability density ratio. It pre‑trains models on a broad distribution and fine‑tunes on task‑specific data, evaluating effectiveness with a new 'Effective Robustness' metric. Experiments show the method outperforms standard fine‑tuning, especially on biased datasets. The approach offers clear definitions, empirical validation, and practical recommendations, though it has limitations in scope and generalizability.",
      "strengths": [
        "Clear definition of support using a probability density ratio.",
        "Empirical validation demonstrating improved robustness.",
        "Intuitive 'Effective Robustness' metric for trade‑off evaluation.",
        "Practical recommendations for dataset curation and model training."
      ],
      "weaknesses": [
        "Limited scope of out‑of‑support examples based on a simple density ratio.",
        "Assumes independent and identically distributed data.",
        "Effectiveness evaluated primarily on synthetic datasets.",
        "Lacks comparison with state‑of‑the‑art methods."
      ],
      "questions": [
        "How does the method perform on more complex distribution shifts beyond simple density ratios?",
        "What is the impact of real‑world data non‑IID characteristics on the proposed approach?",
        "How does the method generalize to other domains or tasks?",
        "How does the proposed method compare to recent state‑of‑the‑art techniques for distribution shift robustness?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7M0EzjugaN",
    "title": "Online Continual Learning for Interactive Instruction Following Agents",
    "std_review": {
      "summary": "The paper proposes Confidence-Aware Moving Average (CAMA), a method for continual learning in reinforcement learning that dynamically adjusts the influence of new experiences based on confidence scores derived from model logits. CAMA improves adaptability and stability across benchmark tasks, outperforming existing strategies. While innovative, the method's reliance on a specific confidence score calculation and model output quality introduces implementation challenges. Overall, CAMA shows promise with strong empirical results.",
      "strengths": [
        "Introduces a novel confidence-based weighting approach for continual learning.",
        "Demonstrates clear improvements in performance and stability across multiple benchmarks.",
        "Provides thorough empirical validation of its effectiveness."
      ],
      "weaknesses": [
        "Complexity in calculating confidence scores may limit accessibility.",
        "Effectiveness depends on model logits, which can be sensitive to hyperparameters.",
        "Lacks comprehensive analysis of why confidence scores are preferred over other metrics."
      ],
      "questions": [
        "How robust is CAMA to variations in model architecture and hyperparameters?",
        "Can CAMA be integrated with other continual learning techniques to further enhance performance?",
        "What are the long-term implications of using confidence scores for continual learning in complex environments?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7m5jhNXklB",
    "title": "VTruST : Controllable value function based subset selection for Data-Centric Trustworthy AI",
    "std_review": {
      "summary": "VTruST presents a novel framework that simultaneously optimizes model accuracy and robustness using a single value function and regularization weight. The approach is demonstrated on image datasets, showing trade-offs between accuracy and fairness, and employs heuristic augmentations. While innovative, the framework's focus on image data and reliance on heuristic techniques limit its generalizability and theoretical foundation.",
      "strengths": [
        "Unified Value Function: Combines accuracy and robustness into a single objective, simplifying the optimization process.",
        "Parameter Efficiency: Uses a single λ to balance multiple objectives, reducing the need for extensive hyperparameter tuning.",
        "Clear Experimental Setup: Provides a transparent and reproducible methodology for evaluating the trade-offs between trustworthiness and accuracy."
      ],
      "weaknesses": [
        "Limited Data Types: Focuses solely on image data, potentially limiting the generalizability of the findings to other domains like tabular data.",
        "Single Weight Parameterization: The use of a single λ may not capture complex trade-offs between accuracy and robustness effectively.",
        "Lack of Theoretical Guarantees: Does not provide theoretical bounds on the trade-off between trustworthiness and accuracy.",
        "Absence of Advanced Augmentations: Relies on heuristic augmentations, which might not be optimal for all datasets."
      ],
      "questions": [
        "How can the framework be extended to handle other data types, such as tabular data, with more principled augmentation strategies?",
        "What theoretical guarantees can be provided regarding the trade-off between trustworthiness and accuracy?",
        "How does the choice of fairness metric impact the observed trade-off between fairness and robustness?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "7Mq096hr9Y",
    "title": "OpenMixup: A Comprehensive Mixup Benchmark for Visual Classification",
    "std_review": {
      "summary": "OpenMixup is a comprehensive benchmarking framework for evaluating mixup methods across various datasets and deep learning tasks. It provides a standardized environment with robust performance metrics and visualization tools, making it a valuable resource for researchers. The authors demonstrate its utility through extensive experiments, highlighting the importance of mixup techniques. Overall, OpenMixup is well-suited for research purposes and offers significant contributions to the field.",
      "strengths": [
        "Comprehensive coverage of mixup methods and datasets",
        "Ease of use with clear documentation and integration with popular frameworks",
        "Robust performance metrics beyond accuracy",
        "Powerful visualization and analysis tools",
        "Designed for extensibility to accommodate new methods and tasks"
      ],
      "weaknesses": [
        "Limited practical applications in real-world scenarios",
        "Smaller community of contributors compared to established benchmarks",
        "Potential gaps in documentation",
        "Scope of performance evaluation could be broader"
      ],
      "questions": [
        "How can OpenMixup be extended to include more advanced mixup methods?",
        "What additional datasets or tasks could be integrated to broaden its applicability?",
        "How can the visualization tools be further enhanced to provide deeper insights?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7mR83Q12cJ",
    "title": "Counterfactual Data Augmentation with Contrastive Learning",
    "std_review": {
      "summary": "The paper introduces a novel contrastive learning framework for estimating the Conditional Average Treatment Effect (CATE), generating synthetic treated data that closely resembles the original treated data to reduce bias. Empirical evaluations show significant improvements over baselines, especially in limited data scenarios, highlighting its potential for handling heterogeneous treatment effects. While innovative, the method's reliance on complex hyperparameters and the unconfoundedness assumption pose implementation and practical challenges.",
      "strengths": [
        "Innovative use of contrastive learning to generate high-quality synthetic treated data.",
        "Clear theoretical foundation linking contrastive loss to CATE consistency under unconfoundedness.",
        "Empirical validation demonstrating strong performance improvements over existing methods."
      ],
      "weaknesses": [
        "Implementation complexity due to reliance on contrastive learning and specific hyperparameter tuning.",
        "Theoretical justification heavily depends on the unconfoundedness assumption, which may not hold in practice.",
        "Limited comparison with other state-of-the-art methods could strengthen the claim of superiority."
      ],
      "questions": [
        "How robust is the method to violations of the unconfoundedness assumption in real-world settings?",
        "What are the practical guidelines for hyperparameter selection, especially in small sample scenarios?",
        "How does the method perform when compared to recent state-of-the-art approaches beyond ReiszNet?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7oYpj8BOLW",
    "title": "BackBench: Are Vision Language Models Resilient to Object-to-Background Context?",
    "std_review": {
      "summary": "The paper presents BackBench, a method that conditions diffusion models for text-to-image generation using background attributes extracted from textual descriptions. It introduces a two-stage pipeline: first, a lightweight language model extracts background attributes; second, these attributes are used as conditioning signals in the diffusion process. Experiments on several benchmark datasets show significant improvements in image quality and background consistency compared to baselines that ignore textual background information. The work offers both a practical approach to leveraging textual context in generative models and insights into the impact of background conditioning. While innovative, the method has limitations in capturing nuanced background details and introduces additional computational overhead.",
      "strengths": [
        "Innovative background conditioning approach for diffusion models.",
        "Clear and well-documented methodology with a lightweight language model for attribute extraction.",
        "Strong empirical evidence demonstrating improvements in image quality and background consistency."
      ],
      "weaknesses": [
        "Limited granularity of background attributes captured by the simple language model.",
        "Additional computational cost due to background conditioning steps.",
        "Lack of comparison with state-of-the-art baselines that specifically incorporate background information."
      ],
      "questions": [
        "How does the method handle more complex background scenarios, such as varying lighting or texture?",
        "What is the impact of background conditioning on the generation time and resource requirements for real-time applications?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7Phicg0WAg",
    "title": "FlexCap: Generating Rich, Localized, and Flexible Captions in Images",
    "std_review": {
      "summary": "FlexCap introduces a novel approach to vision‑language models by generating localized, flexible‑length captions tied to specific image regions. The system, FlexCap‑LLM, leverages these localized captions to enhance downstream tasks like visual question answering through a pre‑trained large language model. While demonstrating competitive performance on benchmarks, the approach is seen as incremental and its effectiveness depends on dataset quality and the pre‑trained LLM.",
      "strengths": [
        "Localized captions provide granular, interpretable descriptions of image regions.",
        "Flexibility in caption length allows for nuanced descriptions tailored to content.",
        "Efficiently uses pre‑trained LLMs, reducing the need for end‑to‑end multimodal training."
      ],
      "weaknesses": [
        "The localized captioning idea is incremental compared to prior work.",
        "Performance is contingent on the quality of the training dataset.",
        "Reliance on a pre‑trained LLM introduces variability based on the LLM's capabilities.",
        "Risk of generating factually incorrect captions."
      ],
      "questions": [
        "How does FlexCap compare to other localized captioning baselines in terms of novelty and effectiveness?",
        "What robustness checks have been performed on caption quality and hallucination across diverse datasets?",
        "How does the model's performance degrade when applied to unseen domains or with limited training data?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "7pVIFJW2Hp",
    "title": "FigCaps-HF: A Figure-to-Caption Generative Framework and Benchmark with Human Feedback",
    "std_review": {
      "summary": "The paper presents CLIPCap, a framework that adapts CLIP to generate figure captions using reinforcement learning from human feedback. It demonstrates competitive performance on FigureQA, outperforming baselines like ViT+GPT2, and shows robustness to caption length. While innovative, the approach has limitations such as reliance on an oracle model for feedback and a modest improvement over specialized baselines, and it could benefit from a more thorough related‑work discussion and clearer metric specification.",
      "strengths": [
        "Innovative adaptation of CLIP to generate figure captions.",
        "Effective use of reinforcement learning from human feedback (RLHF) to improve caption quality.",
        "Modular architecture that can be easily integrated with different backbone models."
      ],
      "weaknesses": [
        "Reliance on an oracle model for generating 'good' or 'bad' tokens may introduce bias.",
        "Modest improvements over specialized baselines like ViT+GPT2.",
        "Lack of comprehensive discussion of related work, especially recent studies like Matcha and Deplot."
      ],
      "questions": [
        "How does the performance of CLIPCap compare when using heuristic-based feedback instead of an oracle model?",
        "Could using CLIPCap itself as the backbone model yield better results for figure caption generation?",
        "What specific metrics beyond BLEU (e.g., BLEU-4) are used to evaluate caption quality, and how are they defined?",
        "How does the human feedback data (helpfulness, takeaway, visual, OCR) influence the RLHF process?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "7pWRLDBAtc",
    "title": "Heterogeneous Personalized Federated Learning by Local-Global Updates Mixing via Convergence Rate",
    "std_review": {
      "summary": "The paper introduces a novel federated learning framework that integrates local model updates with a global aggregation step, leveraging a last-layer latent feature for trace approximation. The proposed method aims to improve personalization across heterogeneous client environments while maintaining privacy and efficiency. Experiments on several benchmark datasets demonstrate competitive performance compared to existing baselines, highlighting the method's effectiveness in handling feature distribution shifts and concept drift. The reviewer finds the approach innovative and promising, with strong theoretical justification and empirical validation, though some limitations are noted.",
      "strengths": [
        "Innovative trace approximation using a last-layer latent feature for enhanced personalization.",
        "Balanced approach that effectively merges personalized and generalized model requirements.",
        "Clear theoretical foundation with rigorous derivations and assumptions."
      ],
      "weaknesses": [
        "Assumes identical model backbones across clients, limiting applicability in diverse model architectures.",
        "Computational cost, particularly GPU memory usage, could be a concern for large datasets.",
        "Potential scalability issues as the number of clients increases.",
        "Lack of detailed analysis on the impact of model architecture complexity."
      ],
      "questions": [
        "How does the method adapt to scenarios where clients use different model backbones?",
        "What is the impact of model architecture complexity on the method's performance?",
        "Can the method be extended to handle non-IID data distributions more robustly?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7q7s5fXEpP",
    "title": "Stealthy Imitation: Reward-guided Environment-Free Policy Stealing",
    "std_review": {
      "summary": "The paper proposes a defense mechanism against adversarial attacks by approximating the state space with a normal distribution and incorporating uncertainty quantification. It demonstrates effectiveness on image and lidar datasets against both white-box and black-box attacks, showing potential for real-world applications in autonomous driving. However, the reliance on a normal distribution may limit applicability in high-dimensional or non-Gaussian scenarios, and the computational cost for scaling is not fully addressed. Adaptive attacks and distribution shifts are not adequately explored.",
      "strengths": [
        "Introduces a novel defense leveraging uncertainty quantification.",
        "Demonstrates effectiveness across diverse sensor inputs.",
        "Shows robustness against a variety of attack scenarios."
      ],
      "weaknesses": [
        "Relies on a normal distribution approximation, which may not be optimal for complex state spaces.",
        "Computational cost for scaling to larger inputs is not fully addressed.",
        "Lacks analysis on performance against adaptive attacks."
      ],
      "questions": [
        "How does the defense scale to handle high-dimensional or non-Gaussian state spaces?",
        "What is the computational cost of scaling the defense to larger image or lidar inputs?",
        "How does the defense perform against adaptive attacks that exploit out-of-range states?",
        "What mechanisms are in place to address distribution shift over time?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "7QI7tVrh2c",
    "title": "Adversarial Adaptive Sampling: Unify PINN and Optimal Transport for the Approximation of PDEs",
    "std_review": {
      "summary": "The paper introduces Adversarial Adaptive Sampling (AAS), a novel method for solving PDEs using neural networks that combines adversarial training with adaptive sampling. AAS shows superior convergence speed and accuracy over existing techniques, especially for high-dimensional problems, and provides theoretical convergence guarantees. While promising, the method's complexity, training instability, and limited generalization to diverse PDE types are noted.",
      "strengths": [
        "Innovative combination of adversarial training and adaptive sampling for PDEs.",
        "Demonstrated superior convergence speed and accuracy over existing methods.",
        "Provides strong theoretical foundations with formal convergence proofs."
      ],
      "weaknesses": [
        "Implementation complexity due to neural network architectures and adversarial training.",
        "Potential training instability from adversarial components.",
        "Limited testing on a broad class of PDEs, including singularly perturbed or nonlinear equations."
      ],
      "questions": [
        "How does AAS perform on a broader class of PDEs beyond those tested?",
        "What strategies can be employed to mitigate training instability in AAS?",
        "How does the choice of regularization terms affect the method's robustness and accuracy?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7QlKLvfVge",
    "title": "Directional Rank Reduction for Backdoor Defense",
    "std_review": {
      "summary": "The paper introduces Directional Rank Reduction (DRR), a novel method for detecting and mitigating backdoors in deep neural networks by leveraging kurtosis. DRR identifies a direction vector that reduces kurtosis, exposing latent backdoor features. Empirical results show strong effectiveness against various backdoor attacks while maintaining model performance, though practical challenges like data availability and computational cost remain.",
      "strengths": [
        "Innovative use of kurtosis as a backdoor detection metric.",
        "Directional pruning approach provides a flexible framework.",
        "Strong theoretical foundation and empirical validation."
      ],
      "weaknesses": [
        "Relies on assumptions about latent separability and isotropic covariance.",
        "Initialization of the direction vector can affect performance.",
        "Computational overhead from optimizing vectors in each layer.",
        "Dependence on backdoored data for initialization poses practical challenges."
      ],
      "questions": [
        "How robust is DRR to violations of the latent separability assumption?",
        "What are the trade-offs between initialization strategies and backdoor removal effectiveness?",
        "Can DRR be adapted to scenarios where backdoored data is unavailable?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7QncaLObzi",
    "title": "",
    "std_review": {
      "summary": "The paper presents a binary hyperbolic embedding method that reduces storage and computational costs while maintaining retrieval performance. It uses a Hamming distance approximation to hyperbolic distances, enabling efficient similarity search. Experiments show competitive performance against full-precision embeddings and significant efficiency gains. The method is scalable and generalizes across different hyperbolic models and backbones, though some practical trade-offs remain.",
      "strengths": [
        "Significant reduction in storage and computational costs",
        "Efficient similarity search using Hamming distance approximation",
        "Scalable and generalizes across various hyperbolic models and backbones"
      ],
      "weaknesses": [
        "Practical impact of approximation error on retrieval accuracy is not fully quantified",
        "Limited exploration of the effect of quantization bits on accuracy-speed trade-off",
        "Evaluation focuses on a subset of datasets and models"
      ],
      "questions": [
        "How does the method perform on a broader range of datasets beyond the evaluated ones?",
        "What is the optimal number of quantization bits for different applications?",
        "Can the theoretical guarantees on approximation error be further tightened or extended?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7rex8lEZH2",
    "title": "Prompt Tuning with Diffusion for Few-Shot Pre-trained Policy Generalization",
    "std_review": {
      "summary": "The paper introduces Prompt Diffuser, a method for enhancing few-shot policy generalization in offline RL by generating and optimizing prompts using a diffusion model. It demonstrates significant improvements over baselines, particularly in unseen environments, and provides theoretical backing for its approach. However, it faces challenges such as computational cost and sensitivity to prompt length, which could limit its practical scalability.",
      "strengths": [
        "Novel approach to few-shot policy generalization in RL through prompt-based learning.",
        "Demonstrates substantial improvements in few-shot learning scenarios.",
        "Shows strong generalization to unseen environments, indicating robustness.",
        "Provides a theoretical framework supporting its effectiveness."
      ],
      "weaknesses": [
        "Computational cost associated with diffusion models may limit scalability.",
        "Performance is sensitive to prompt length, requiring careful tuning.",
        "Comparison with expert-provided prompts is not fully explored.",
        "Reproducibility concerns due to implementation details and hyperparameter variability."
      ],
      "questions": [
        "How does the method compare to expert-provided prompts in terms of performance and trade-offs?",
        "What are the practical implications of prompt length sensitivity for real-world applications?",
        "How can the reproducibility of results be improved given the variability in hyperparameter choices?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7sASqAmGaO",
    "title": "Augmenting Negative Representations",
    "std_review": {
      "summary": "The paper introduces AugNeg, a contrastive learning approach that enhances domain-invariant learning by incorporating augmented negative examples. It proposes a new loss function and demonstrates improved performance on benchmark datasets, but has several concerns regarding hyperparameter choices, result consistency, and unclear theoretical relationships between equations.",
      "strengths": [
        "Introduces a novel contrastive learning approach called AugNeg.",
        "Proposes a new loss function that leverages additional negative examples.",
        "Demonstrates superior performance on multiple benchmark datasets."
      ],
      "weaknesses": [
        "Lacks detailed justification for certain hyperparameters, such as batch size.",
        "Shows inconsistency in results compared to existing methods.",
        "Unclear theoretical relationship between key equations."
      ],
      "questions": [
        "Why are certain hyperparameters, like the batch size for Cassle, not justified?",
        "What explains the discrepancy between AugNeg and SyCON performance on Domain-IL?",
        "Were MoCo and CaSSLe models run with an extended queue size?",
        "Why does the gradient of the AugNeg loss remain nearly the same direction despite additional negative examples?",
        "How do Equation 5 and Equation 4 relate, and why might they appear offsetting?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "7Scc7Nl7lg",
    "title": "Revealing Vision-Language Integration in the Brain with Multimodal Networks",
    "std_review": {
      "summary": "The paper presents an innovative approach to aligning multimodal neural networks with brain activity to study vision-language integration. Using fMRI and machine learning, the authors identify brain regions involved in processing visual and linguistic information together. The results show significant overlap with known language areas, supporting the role of these regions in multimodal integration. While the methodology is robust, the study has limitations such as limited brain region coverage and potential model bias. Overall, the work advances neuro‑AI by providing a novel framework for understanding how the brain integrates visual and linguistic inputs.",
      "strengths": [
        "Innovative multimodal approach combining fMRI and machine learning.",
        "Robust experimental design with precise brain activity mapping.",
        "Clear contribution to neuro‑AI by identifying key brain regions for vision-language integration."
      ],
      "weaknesses": [
        "Limited coverage of brain regions involved in vision-language integration.",
        "Choice of multimodal models may affect generalizability.",
        "Statistical controls could be further explored for robustness."
      ],
      "questions": [
        "Could the study benefit from including additional brain regions to provide a more comprehensive view?",
        "How do the selected multimodal models impact the generalizability of the findings?",
        "What further statistical analyses could strengthen the confidence in the identified brain regions?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7sMR09VNKU",
    "title": "Learning System Dynamics from Sensory",
    "std_review": {
      "summary": "The paper presents a Koopman‑based learning framework for nonlinear dynamics, leveraging optimal trajectories to learn a linear representation. It shows promise in accuracy and novelty but suffers from limited system demonstrations, reliance on unavailable data, lack of comparisons, and missing theoretical guarantees. The method is accepted with reservations.",
      "strengths": [
        "Novel integration of Koopman theory with deep learning.",
        "Demonstrated high accuracy on simple systems.",
        "Use of proximal regularization for robust optimization."
      ],
      "weaknesses": [
        "Limited scope tested only on simple systems.",
        "Requires access to optimal trajectories for training.",
        "Lacks extensive comparisons with established methods.",
        "No publicly available code or detailed reproducibility information.",
        "Missing theoretical analysis of convergence and approximation error."
      ],
      "questions": [
        "Can the method be generalized to more complex or high-dimensional systems?",
        "What are the theoretical conditions for the existence of a Koopman embedding?",
        "How can the method be adapted to learn from raw sensory data instead of optimal trajectories?",
        "What are the stability guarantees provided by proximal regularization compared to other methods?",
        "How does the method perform in real-world scenarios with sensor noise and model mismatch?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "7suavRDxe8",
    "title": "Plausibly Deniable Encryption",
    "std_review": {
      "summary": "The paper introduces a novel approach to plausible deniability using a stochastic language model, achieving a formal security model and empirical evaluation. While innovative, it faces practical challenges such as deterministic/lossless encoding, key choice implications, and the impact of prompting on deniability. The review suggests these issues limit the scheme's real-world applicability.",
      "strengths": [
        "Innovative use of stochastic models for plausible deniability",
        "Clear formal security model and theoretical foundation",
        "Empirical evaluation through frequency and correlation tests"
      ],
      "weaknesses": [
        "Challenges in ensuring deterministic and lossless encoding/decoding with stochastic models",
        "Insufficient exploration of key choice implications on security and correctness",
        "Lack of comprehensive analysis on prompting effects and trade-offs",
        "Reliance on frequency and correlation tests may not guarantee cryptographic security",
        "Unclear guidelines on the required level of randomness for encoded messages",
        "Practical feasibility concerns regarding computational overhead and shared model requirements"
      ],
      "questions": [
        "How does varying the quantization granularity (k) affect the security and correctness of the encoding/decoding process?",
        "What is the impact of prompting on the plausibility of decoy messages and the trade-offs involved?",
        "Are additional formal criteria needed to ensure that encoded strings are indistinguishable from white noise in a cryptographic setting?",
        "What level of randomness is required for encoded messages to ensure statistical indistinguishability?",
        "How does the computational overhead of using a stochastic language model impact the practical feasibility of the scheme?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "7TOs9gjAg1",
    "title": "Removing Biases from Molecular Representations via Information Maximization",
    "std_review": {
      "summary": "The paper introduces InfoCORE, a self-supervised learning framework that enhances representation learning in the presence of batch effects by balancing intra-cluster and inter-cluster similarity through a hyperparameter λ. Evaluated on simulation data, InfoCORE shows improved representation quality over existing methods like CLIP and CCL. The study highlights the importance of λ in mitigating batch effects, with optimal values leading to more robust representations. However, the evaluation is limited to simulation data, and the impact of λ across a wider range of values is not fully explored.",
      "strengths": [
        "Introduces a novel approach to self-supervised learning that specifically addresses batch effects.",
        "Incorporates a hyperparameter λ that provides flexibility in balancing intra-cluster and inter-cluster similarity.",
        "Demonstrates superior performance over existing methods through rigorous simulation experiments."
      ],
      "weaknesses": [
        "Evaluation is limited to simulation data, which may not fully capture real-world complexity.",
        "Lacks comprehensive analysis of λ's impact across a wide range of values.",
        "Qualitative evaluation is limited to examining only the first two principal components.",
        "Performance on real-world datasets is not demonstrated."
      ],
      "questions": [
        "How does InfoCORE perform on real-world datasets with diverse batch effects?",
        "What is the optimal range of λ values for different types of data?",
        "How does InfoCORE compare to other state-of-the-art methods in terms of computational efficiency?"
      ],
      "overall_score": "Accept",
      "confidence": "4"
    }
  },
  {
    "paper_id": "7Ttk3RzDeu",
    "title": "BoooookScore:",
    "std_review": {
      "summary": "The paper introduces BOOOOKSCORE, a novel coherence metric for text summaries inspired by book chapter coherence. It evaluates the metric on a book summary dataset, exploring model parameters and summary length effects. While showing promise, the study has several methodological and technical concerns that limit its impact.",
      "strengths": [
        "Innovative coherence metric inspired by book chapter coherence.",
        "Comprehensive evaluation against human annotations.",
        "Exploration of model parameters like nucleus sampling and temperature."
      ],
      "weaknesses": [
        "Evaluation on precision vs recall may not fully capture coherence nuances.",
        "Specific coherence error examples may not generalize.",
        "Nucleus sampling with p=1 leads to overly deterministic outputs.",
        "High temperature setting may produce less focused summaries.",
        "Exclusion of LLaMA2 raises reproducibility concerns.",
        "Sentence-level scoring may favor short sentences.",
        "Lack of faithfulness evaluation.",
        "Reproducibility issues with incremental updating."
      ],
      "questions": [
        "How does the metric perform on diverse summary types beyond book summaries?",
        "What are the optimal nucleus sampling and temperature settings for different domains?",
        "How can the sentence-level scoring be adjusted to better capture overall coherence?",
        "What faithfulness evaluation methods could complement coherence assessment?",
        "How can the reproducibility of incremental updating be improved with LLaMA2?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "7U5QE9T4hI",
    "title": "Learning to Extrapolate and Adjust:",
    "std_review": {
      "summary": "The paper introduces LEAF, a framework for online time series forecasting that addresses concept drift by separating macro-drift (long-term trends) and micro-drift (short-term fluctuations) through dedicated extrapolation and adjustment modules. The approach is evaluated on multiple datasets, showing strong performance compared to baselines, and balances efficiency and accuracy. While promising, the framework's complexity and limited evaluation scope are noted as areas for improvement.",
      "strengths": [
        "Introduces a novel LEAF framework specifically designed to tackle concept drift in online time series forecasting.",
        "Effectively separates and addresses macro-drift and micro-drift, providing a clear and structured approach to adapting to changes in data distribution.",
        "Demonstrates strong performance compared to existing baselines across multiple datasets, highlighting the practical utility of the proposed method."
      ],
      "weaknesses": [
        "The complexity of the proposed framework may pose a challenge for practitioners unfamiliar with the concepts of macro-drift and micro-drift.",
        "The evaluation is limited to a few datasets, which may not fully capture the robustness and generalizability of the proposed method across a wide range of applications.",
        "The computational complexity of the relation network and embedding function in the adjustment module could be a concern for real-time applications with strict latency requirements."
      ],
      "questions": [
        "How does the framework handle scenarios where macro-drift and micro-drift co-occur simultaneously?",
        "What is the impact of the choice of embedding function on the model's ability to capture micro-drift?",
        "How does the proposed method perform in real-time applications with strict latency constraints?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7UhxsmbdaQ",
    "title": "",
    "std_review": {
      "summary": "The paper presents a novel generative model for molecular design that combines an autoregressive language model with an augmented memory mechanism to improve the diversity and quality of generated molecules. Experiments show significant improvements over existing baselines, particularly when combined with beam enumeration. While the approach is innovative, the description of the augmented memory and self-conditioning scheme is somewhat vague, and the paper could benefit from more detailed ablation studies and comparisons with state-of-the-art methods.",
      "strengths": [
        "Introduces an innovative augmented memory mechanism that enhances the model's ability to generate chemically valid and diverse molecules.",
        "Demonstrates strong empirical improvements over existing baselines in both diversity and quality of generated molecules.",
        "Provides comprehensive evaluation through ablation studies and quantitative experiments, supporting the method's effectiveness."
      ],
      "weaknesses": [
        "The description of the augmented memory and self-conditioning scheme lacks sufficient detail, making it difficult to fully understand the implementation and novelty.",
        "Ablation studies do not explicitly quantify the standalone contribution of the augmented memory component.",
        "The comparison with state-of-the-art methods is cursory, and the paper could provide a more detailed analysis of its performance relative to recent advancements."
      ],
      "questions": [
        "Could you provide a more concrete explanation of how the augmented memory is implemented and how it interacts with the autoregressive generation process?",
        "Are there any ablation studies that isolate the impact of the augmented memory component alone, and what are the results?",
        "How does the proposed method compare with the latest state-of-the-art approaches in molecular generation?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7v3tkQmtpE",
    "title": "Rethinking Decision Transformer via Hierarchical Reinforcement Learning",
    "std_review": {
      "summary": "The paper introduces V-ADT, a hierarchical RL framework that combines Inverse Q-Learning with a transformer-based high-level policy to improve planning. It shows significant gains in sample efficiency and task completion rates on benchmark tasks. Theoretical justifications and potential for generalization are provided, but the method's reliance on current state conditioning and learned Q/V functions could limit its effectiveness in complex environments. Overall, the approach is promising and recommended for acceptance.",
      "strengths": [
        "Innovative integration of value functions using Inverse Q-Learning",
        "Use of transformer-based high-level policy for flexible action sequence learning",
        "Demonstrated improvements in sample efficiency and task performance"
      ],
      "weaknesses": [
        "Reliance on current state conditioning may limit long-term dependency capture",
        "Performance heavily dependent on the quality of learned Q and V functions",
        "Primarily evaluated on single-task learning, with limited analysis for multi-task scenarios"
      ],
      "questions": [
        "How does the method perform in environments with sparse rewards or delayed feedback?",
        "What is the impact of using alternative function approximators for Q and V functions?",
        "How can the proposed approach be extended to handle multi-task or hierarchical learning scenarios?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7vKWg2Vdrs",
    "title": "LeBD: A Run-time Defense Against Backdoor Attack in YOLO",
    "std_review": {
      "summary": "The paper introduces CA-LeBD, a defense mechanism that integrates digital and physical constraints to detect backdoor attacks in machine learning models. It leverages a learned embedding to identify anomalous inputs that could trigger physical backdoors, showing strong performance on image classification tasks. While innovative, the method faces challenges such as performance gaps, scalability issues, and limited generalizability across domains.",
      "strengths": [
        "Innovative integration of digital and physical backdoor attack defenses.",
        "Demonstrates strong performance in detecting backdoor triggers in both digital and physical settings.",
        "Provides a solid theoretical foundation for its effectiveness."
      ],
      "weaknesses": [
        "Significant performance gap compared to state-of-the-art benchmarks.",
        "Scalability concerns may limit its use in large-scale applications.",
        "Limited generalizability due to reliance on specific physical triggers."
      ],
      "questions": [
        "How can the computational overhead of CA-LeBD be reduced to improve its scalability?",
        "What guidelines can be provided for determining the optimal number of classes to protect?",
        "How can CA-LeBD be extended to other model architectures, such as vision transformers?",
        "What are the implications of using ground-truth features as triggers for backdoor detection?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "7VPTUWkiDQ",
    "title": "Provable Compositional Generalization for Object-Centric Learning",
    "std_review": {
      "summary": "The paper introduces a novel consistency loss for slot-based latent variable models, aiming to improve object representation across multiple views. It shows strong empirical results on synthetic datasets, particularly in handling occlusions and complex interactions. While promising, the method lacks real-world validation and a more principled regularization approach. Overall, it warrants a weak accept.",
      "strengths": [
        "Introduces a novel consistency loss to enforce uniformity across latent slots.",
        "Demonstrates strong empirical performance on synthetic datasets with occlusions and complex interactions.",
        "Provides a scalable approach that could be applicable to larger datasets and more complex scenes."
      ],
      "weaknesses": [
        "Performance is evaluated primarily on synthetic data, limiting real-world applicability.",
        "Relies on a low-expressivity non-linear decoder, potentially limiting the capture of highly complex interactions.",
        "Consistency regularization lacks a more principled approach, such as learning a prior over latent slots."
      ],
      "questions": [
        "How does the method perform on real-world datasets with diverse and challenging scenarios?",
        "Could a more expressive decoder improve the handling of complex interactions like reflections and intricate occlusions?",
        "What are the computational implications of the additional regularization terms in resource-constrained environments?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "7VVGO0kuuY",
    "title": "Learning Causal Dynamics Models in Object-Oriented Environments",
    "std_review": {
      "summary": "The paper introduces the Object-Oriented Causal Dynamics Model (OOCDM), which effectively scales to large object-oriented environments and improves causal graph accuracy through object-oriented representations and symmetry assumptions. It demonstrates strong generalization to out-of-distribution data and performs well on benchmarks, outperforming traditional baselines. The OOCDM is a valuable contribution to causal discovery in complex environments.",
      "strengths": [
        "The OOCDM scales well with the number of objects and attributes, maintaining computational efficiency.",
        "It achieves high causal graph accuracy, outperforming baselines in various scenarios.",
        "The model's representation of objects and causal relationships is robust, capturing complex interactions.",
        "Causation symmetry and result symmetry enhance the model's ability to learn accurate causal dynamics.",
        "The OOCDM demonstrates strong generalization capabilities, performing well on out-of-distribution data."
      ],
      "weaknesses": [
        "Computational efficiency gains may not be as pronounced in extremely large-scale environments.",
        "Performance in causal graph accuracy could be further improved with more sophisticated handling of symmetries.",
        "Generalization to out-of-distribution data may be limited by training environment characteristics.",
        "Practical implementation may face challenges in managing model architecture and parameters.",
        "Robustness to overfitting, especially with limited data, requires further investigation."
      ],
      "questions": [
        "How does the OOCDM handle extremely large-scale environments beyond current benchmarks?",
        "Can the model's performance in causal graph accuracy be further improved with more advanced symmetry handling?",
        "What specific characteristics of training environments limit the OOCDM's generalization to out-of-distribution data?",
        "What techniques are employed to manage model architecture and parameters in large-scale settings?",
        "What further research is needed to investigate the model's robustness to overfitting?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7vVWiCrFnd",
    "title": "Rethinking and Extending the Probabilistic Inference Capacity of GNNs",
    "std_review": {
      "summary": "The paper proposes PE, a method that augments GNNs with phantom nodes/edges to improve their ability to perform higher-order Markov random field inference. The approach is theoretically grounded in the k‑Weisfeiler–Lehman hierarchy, which restricts the discriminative power of potential functions. While the method shows promise in link prediction on small datasets, its computational complexity and scalability are significant concerns, and the experimental evaluation is limited.",
      "strengths": [
        "Introduces a novel augmentation technique for GNNs to support higher-order inference.",
        "Provides a rigorous theoretical framework linking GNN expressivity to higher-order MRF marginals.",
        "Clearly distinguishes the method's novelty and theoretical underpinnings."
      ],
      "weaknesses": [
        "Computational complexity can become super‑quadratic for dense graphs due to the need for phantom nodes/edges.",
        "Scalability is limited by the computationally expensive maximum clique detection required for neighborhood expansion.",
        "Experimental validation is restricted to small datasets and lacks comprehensive comparisons with state‑of‑the‑art baselines."
      ],
      "questions": [
        "How can the computational complexity of adding phantom nodes/edges be mitigated for larger graphs?",
        "What are the practical implications of the k‑WL hierarchy choice, and could alternative metrics provide clearer theoretical guarantees?",
        "How does the method perform on larger, more diverse real‑world datasets, and how does it compare to other GNN‑PGM hybrids?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "7vzyqs8UbA",
    "title": "",
    "std_review": {
      "summary": "The paper introduces LMCC-MBC, a novel clustering algorithm that combines local metric correlation clustering with a modified beta-clustering approach, using a Wasserstein-2 distance framework to enhance intra-cluster cohesion and inter-cluster separation. It is evaluated on synthetic datasets and compared against several state-of-the-art algorithms, showing competitive performance. The reviewer finds the method innovative and theoretically sound, with strong empirical validation, though there are areas for improvement.",
      "strengths": [
        "Innovative integration of local metric correlation clustering with beta-clustering.",
        "Strong theoretical foundation using Wasserstein-2 distance for locally monotonic continuity.",
        "Robust empirical validation on synthetic datasets."
      ],
      "weaknesses": [
        "Complexity of theoretical analysis may be challenging for some readers.",
        "Limited real-world validation could affect generalizability.",
        "Lack of detailed guidance on parameter tuning.",
        "Comparison with baselines could be enhanced with more metrics."
      ],
      "questions": [
        "How does the method perform on real-world datasets beyond synthetic ones?",
        "What are the practical guidelines for tuning the shift parameter δ and the number of neighbors?",
        "How does the method compare to other recent clustering algorithms in terms of scalability?",
        "Can the robustness of the method be further demonstrated through sensitivity analysis?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7W3GLNImfS",
    "title": "Human Feedback is not Gold Standard",
    "std_review": {
      "summary": "The paper investigates how human annotators misjudge the factual accuracy of AI-generated responses, particularly when those responses are assertive or complex. It introduces a taxonomy of ten error types and uses Lasso regression to identify which features most strongly predict each error type. The authors find that annotators are biased toward labeling assertive, complex responses as factual, even when they are false, and that this bias persists across different model sizes and domains. Overall, the study provides valuable insights into human bias in AI evaluation with strong empirical backing and practical implications for model development.",
      "strengths": [
        "Comprehensive Error Taxonomy: The ten error types cover a wide range of potential issues in AI-generated text, providing a solid theoretical foundation for the study.",
        "Empirical Validation: The use of Lasso regression to quantify feature importance offers a clear, data-driven method for understanding annotator behavior.",
        "Large-Scale Experiments: Testing across models ranging from 13 B to 52 B demonstrates the robustness and scalability of the observed bias."
      ],
      "weaknesses": [
        "Limited Scope of Error Types: While ten error types are comprehensive, the choice may still miss nuanced issues relevant to specific domains.",
        "Potential Overfitting in Regression: The reliance on a single regression model could lead to overfitting, especially with the large number of features considered.",
        "Annotator Consistency: The study does not fully address how annotator variability (e.g., training, experience) might influence the results."
      ],
      "questions": [
        "How might the error taxonomy be refined to capture domain-specific nuances?",
        "What are the implications of annotator variability on the observed bias, and how can it be mitigated?",
        "Could the study benefit from a longitudinal design to explore the persistence of bias over time?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7W4boWjb3Q",
    "title": "Partitioned Learned Count-Min Sketch",
    "std_review": {
      "raw_text": "{\n  \"summary\": \"The paper introduces PL‑CMS, a probabilistic Count‑Min Sketch algorithm that integrates learned models to improve frequency estimation accuracy. It partitions the input space into regions, each with a CMS and a learned model, and combines outputs using thresholds. Experiments show lower error rates compared to traditional CMS and other learned methods, with reproducible code provided. However, the paper lacks detailed threshold selection, model size reporting, and robust analysis of noisy predictions, leading to a weak accept recommendation.\",\n  \"strengths\": [\n    \"Innovative integration of traditional CMS with learned models to enhance accuracy.\",\n    \"Scalable partitioned architecture with minimal memory overhead.\",\n    \"Empirical validation across multiple datasets demonstrating effectiveness.\",\n    \"Reproducibility through released code.\"\n  ],\n  \"weaknesses\": [\n    \"Threshold selection process is not detailed, affecting reproducibility.\",\n    \"Model size for LCMS and PL‑CMS is not clearly reported.\",\n    \"Comparison with other methods is complicated by differences in model types.\",\n    \"Limited analysis of robustness to noisy predictions.\"\n  ],\n  \"questions\": [\n    \"How are the thresholds \\(t_i\\) chosen and what is their impact on space allocation?\",\n    \"What are the specific model sizes for LCMS and PL‑CMS across datasets?\",\n    \"Could you provide more details on the code for reproducing the experiments?\",\n    \"How does PL‑CMS compare with other methods on equal grounds, and what strategies could address the comparison challenge?\",\n    \"What is the impact of noisy predictions on PL‑CMS performance, and how could this analysis be extended?\"\n  ],\n  \"overall_score\": \"4: weak reject\",\n  \"confidence\": \"3: medium\"\n}",
      "parse_error": true
    }
  },
  {
    "paper_id": "7W4rbphLht",
    "title": "",
    "std_review": {
      "summary": "The paper introduces S5N, a novel optimization algorithm combining semi-smooth Newton methods with block coordinate descent, aiming for faster convergence. It provides theoretical convergence guarantees and empirical results on image datasets, showing effectiveness over existing methods. However, several concerns about assumptions, reproducibility, and detailed analysis prevent full acceptance.",
      "strengths": [
        "Innovative combination of semi-smooth Newton methods with block coordinate descent.",
        "Strong theoretical convergence guarantees.",
        "Empirical validation on benchmark image datasets."
      ],
      "weaknesses": [
        "Unclear assumptions and step size requirements.",
        "Lack of detailed description on solving the linear system.",
        "Absence of specific convergence rate details.",
        "Issues with BCD convergence in experiments.",
        "Limited dataset generalizability."
      ],
      "questions": [
        "What are the specific assumptions and bounds on the step size used in the convergence analysis?",
        "How is the linear system in Equation (2) solved, and what are the tolerance or iteration details?",
        "What are the specific convergence conditions for the BCD algorithm to ensure reliable results?",
        "How do the theoretical convergence rates compare with the observed empirical rates?",
        "Could the experiments be extended to other types of datasets for broader applicability?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "7W9zRGhLq7",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a heterogeneity‑driven Lipschitz assumption for Federated Averaging, providing tighter convergence bounds by accounting for data variability across clients. Empirical experiments validate the theoretical claims, showing improved convergence rates when heterogeneity is significant. While the approach offers valuable insights, it also highlights challenges in estimating heterogeneity‑specific Lipschitz constants and potential limitations in non‑convex settings.",
      "strengths": [
        "Introduces a realistic heterogeneity‑driven Lipschitz assumption that better captures real‑world variability.",
        "Provides a framework for deriving tighter convergence bounds by explicitly modeling data heterogeneity.",
        "Empirically validates theoretical claims through concrete experiments estimating Lipschitz constants."
      ],
      "weaknesses": [
        "Estimating heterogeneity‑specific Lipschitz constants may be challenging in large or dynamic federated environments.",
        "The assumption still imposes a Lipschitz condition that may not hold for all non‑convex objective functions.",
        "Analysis is limited to the convergence properties of FedAvg and does not address other federated learning algorithms or non‑federated settings."
      ],
      "questions": [
        "How robust is the heterogeneity‑driven assumption in highly non‑convex settings?",
        "What is the impact of the heterogeneity‑driven assumption on other federated learning algorithms beyond FedAvg?",
        "How can the estimation of heterogeneity‑specific Lipschitz constants be improved for large‑scale or dynamic federated environments?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7WsivwyHrS",
    "title": "You Only Query Once: An Efficient Label-Only Membership Inference Attack",
    "std_review": {
      "summary": "The paper introduces a membership inference attack that selects the most challenging samples near the decision boundary to evaluate worst-case performance. It demonstrates robustness across various training settings and query budgets, achieving high inference accuracy with limited queries. While the approach is theoretically sound, concerns about small dataset sizes, lack of overfitting mitigation, and limited analysis of query budget effects reduce its overall impact.",
      "strengths": [
        "Robust evaluation metric using distance from decision boundary.",
        "Adaptive query strategy that maintains accuracy with limited queries.",
        "Demonstrates strong transferability across different training settings."
      ],
      "weaknesses": [
        "Small training dataset may limit generalizability and increase overfitting risk.",
        "No experiments with larger datasets or ImageNet-pretrained models.",
        "Lack of detailed analysis on how query budget impacts attack strategy."
      ],
      "questions": [
        "How does the attack perform on larger datasets or with models pretrained on ImageNet?",
        "What is the impact of using multiple correlated queries when the query budget is increased?",
        "How does the transferability of crafted queries vary with different training algorithms?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "7wY67ZDQTE",
    "title": "Cauchy-Schwarz Divergence Information Bottleneck for Regression",
    "std_review": {
      "summary": "The paper introduces a novel approach to mutual information estimation using Conditional Symmetry (CS) divergence and a Gaussian variational lower bound. It demonstrates strong empirical performance across various datasets, suggesting the method could be a robust alternative to existing techniques. While the theoretical analysis of convergence properties is lacking, the practical applicability and clear presentation make the work valuable. Overall, the paper is recommended for acceptance.",
      "strengths": [
        "Introduces Conditional Symmetry (CS) divergence as a novel perspective on mutual information estimation.",
        "Leverages a Gaussian variational lower bound to enhance practical applicability.",
        "Demonstrates strong empirical performance across diverse datasets.",
        "Provides a clear and accessible presentation of both theoretical and experimental aspects."
      ],
      "weaknesses": [
        "Lacks a detailed theoretical analysis of convergence properties.",
        "Experimental setup primarily uses synthetic datasets, limiting generalizability.",
        "Comparison with existing methods is limited to performance metrics without deeper analysis.",
        "Could benefit from a more thorough discussion of inductive biases."
      ],
      "questions": [
        "What are the convergence properties of the proposed CS divergence?",
        "How does the method perform on real-world datasets beyond the synthetic examples?",
        "What are the specific inductive biases introduced by CS divergence and the Gaussian variational lower bound, and how do they affect performance?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "7YEXo5qUmN",
    "title": "Organ-DETR: 3D Organ Detection Transformer with Multiscale Attention and Dense Query Matching",
    "std_review": {
      "summary": "Organ-DETR presents a novel transformer-based approach for 3D organ detection in medical imaging, integrating MultiScale Attention (MSA) and Dense Query Matching (DQM) to improve performance. The model achieves competitive results on benchmark datasets, suggesting potential for enhancing clinical workflows by providing accurate and efficient organ localization. However, the review highlights several concerns, including limited clinical scenario coverage, lack of comparative analysis with established medical detection frameworks, and the use of a one-to-many label assignment strategy that may not align with typical organ detection tasks.",
      "strengths": [
        "Innovative architectural contributions with MSA and DQM",
        "End-to-end detection framework simplifying the pipeline",
        "Competitive performance on benchmark datasets"
      ],
      "weaknesses": [
        "Limited experimental evaluation in clinical scenarios",
        "Omission of comparative analyses with established medical detection frameworks",
        "One-to-many label assignment may not align with typical one-instance-per-organ nature of organ detection"
      ],
      "questions": [
        "How does the model perform in clinical scenarios involving complex organ interactions or rare conditions?",
        "What are the specific clinical benefits of the end-to-end detection framework compared to existing solutions?",
        "How does the one-to-many label assignment strategy impact performance on tasks requiring precise localization?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "7Zbg38nA0J",
    "title": "Explaining Grokking through circuit efficiency",
    "std_review": {
      "summary": "The paper introduces a novel framework for understanding the dual learning behaviors of deep neural networks, identifying 'generalizing' and 'memorizing' circuits and proposing a metric for circuit efficiency. It provides theoretical insights and empirical evidence linking these circuits to the grokking phenomenon in large language models, with a focus on the critical dataset size (Dcrit) where learning dynamics shift. While the findings are strong, they are limited to transformer models and could benefit from exploring alternative regularization mechanisms and broader applicability.",
      "strengths": [
        "Clear identification of circuit types and their distinct learning dynamics.",
        "Innovative metric for quantifying circuit efficiency, offering a new perspective on model performance.",
        "Robust theoretical framework linking circuit efficiency to model complexity.",
        "Empirical validation through well-designed experiments supporting the theoretical claims."
      ],
      "weaknesses": [
        "Scope limited to transformer models, potentially limiting generalizability.",
        "Assumptions in determining the critical dataset size (Dcrit) may not hold universally.",
        "Risk of overfitting in experiments, especially with changes in input encoding or task structure.",
        "Focus on weight decay as the only regularization method explored."
      ],
      "questions": [
        "How do the identified circuit dynamics generalize to other neural network architectures beyond transformers?",
        "What is the impact of alternative regularization mechanisms on the identified circuit behaviors?",
        "Can the proposed metric for circuit efficiency be applied to evaluate learning in non‑transformer models?",
        "How robust are the findings when input encoding or task structure is varied?"
      ],
      "overall_score": "Accept",
      "confidence": "High"
    }
  },
  {
    "paper_id": "7zxGHwe7Vw",
    "title": "FedAnchor: Enhancing Federated",
    "std_review": {
      "summary": "FedAnchor introduces a federated semi-supervised learning framework that uses a label-contrastive loss during server updates to improve convergence and accuracy. The method shows strong empirical results on CIFAR100 and ImageNet, outperforming existing methods, especially with limited labeled data. However, it incurs additional communication costs and lacks thorough hyper-parameter analysis, which may affect its practical applicability.",
      "strengths": [
        "Introduces a novel label-contrastive loss that effectively bridges labeled and unlabeled data.",
        "Demonstrates significant performance gains on challenging benchmarks with limited labeled data.",
        "Scales well across multiple clients, reducing reliance on centralized data."
      ],
      "weaknesses": [
        "Incurring additional communication overhead due to server embeddings.",
        "Hyper-parameter sensitivity not thoroughly explored.",
        "Baseline comparison may not be fair due to the use of a supervised baseline with abundant labeled data."
      ],
      "questions": [
        "How can the communication overhead be mitigated in bandwidth-constrained environments?",
        "What systematic hyper-parameter tuning approach will be used to ensure robust performance across different datasets?",
        "How will future experiments address the baseline comparison issue to better reflect the method's performance in challenging settings?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "83w0LPowHz",
    "title": "On Reconstructability of Graph Neural Networks",
    "std_review": {
      "summary": "The paper introduces a novel framework for graph reconstructability based on inner‑product conditions of node embeddings, proposing a sufficient and necessary condition for models to recover original graph topology. It defines contextual features that combine label information with noise and demonstrates that the Graph Isomorphism Network (GIN) preserves node identity through a parameter ε. The framework is evaluated on synthetic datasets, with discussions on the challenges of real‑world evaluation due to the lack of multiple instances. Overall, the paper makes a clear and mathematically rigorous contribution to the field.",
      "strengths": [
        "Provides a clear and mathematically rigorous definition of graph reconstructability using inner‑product conditions.",
        "Introduces contextual features that combine label information with noise, highlighting the importance of signal in reconstruction.",
        "Demonstrates that GIN preserves node identity through a parameter ε, contributing to the theoretical understanding of message‑passing networks."
      ],
      "weaknesses": [
        "The necessity and sufficiency of the inner‑product condition are not fully substantiated; the theoretical justification could be more detailed.",
        "Notation for τl and τu in Propositions 2 and 3 is ambiguous, potentially leading to misinterpretation of probability bounds.",
        "The definition of contextual features assumes availability of node labels for both training and testing, which may not always be realistic.",
        "The explanation of 'signal' in contextual features is not clearly defined, and it is unclear whether it specifically refers to node labels.",
        "The discussion of GIN's role in preserving node identity lacks a detailed analysis of how ε influences the balance between preserving structural information and node identity."
      ],
      "questions": [
        "Can the inner‑product condition be generalized to other types of graph neural networks beyond GIN?",
        "How robust are the contextual features to the presence of noisy or missing node labels?",
        "What is the optimal choice of ε for different graph structures and sizes?",
        "How can the framework be extended to handle dynamic or evolving graphs?"
      ],
      "overall_score": "Accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "84fOBZlOiV",
    "title": "Estimating uncertainty from feed-forward network based sensing using quasi-linear approximation",
    "std_review": {
      "summary": "The paper presents a method for approximating the output of deep neural networks using Gaussian distributions, focusing on MLPs with tanh activations. It effectively approximates both the network output and the tanh function, providing insights into noise distribution and error accumulation. While the experimental results are promising, several concerns limit its impact, such as the assumption of Gaussian noise, potential error accumulation in deep networks, and the lack of comparison with existing methods.",
      "strengths": [
        "Introduces a novel approach to approximating deep network outputs using Gaussian distributions.",
        "Demonstrates effectiveness on MLP architectures with clear insights into output distribution.",
        "Provides experimental validation of the method's practical applicability."
      ],
      "weaknesses": [
        "Assumes input noise is always Gaussian, which may not hold in real-world scenarios.",
        "Error accumulation in deep networks could lead to significant inaccuracies.",
        "Lacks thorough exploration of adaptation to modern network architectures.",
        "Does not quantify approximation errors from each source.",
        "Fails to compare with existing methods, limiting the paper's novelty."
      ],
      "questions": [
        "How does the method handle non-Gaussian input noise?",
        "What is the impact of error accumulation in deep networks on the approximation accuracy?",
        "How can the method be adapted to modern network architectures like ResNet?",
        "What are the quantified approximation errors from each source?",
        "How does the method compare to existing approaches like GELU and Wang et al. (2016)?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "84Hk01tFKq",
    "title": "HyperFields: Towards Zero-Shot Generation of NeRFs from Text",
    "std_review": {
      "summary": "HyperFields introduces a dynamic hypernetwork framework for generating 3D scenes from text, achieving better text conditioning and NeRF generation compared to existing methods. The approach effectively disentangles attributes like colors and shapes, leading to highly detailed and coherent scenes. While showing strong performance, the model's complexity and scalability to complex scenes remain areas for improvement.",
      "strengths": [
        "Dynamic hypernetwork integration for flexible attribute disentanglement",
        "Improved text conditioning for complex and ambiguous prompts",
        "NeRF distillation process enhancing scene detail and robustness"
      ],
      "weaknesses": [
        "Training complexity of the dynamic hypernetwork may require significant resources",
        "Potential issues with generating coherent scenes from highly ambiguous descriptions",
        "Scalability to scenes with multiple objects or complex spatial arrangements"
      ],
      "questions": [
        "How can the model's performance be further improved for scenes with multiple interacting objects?",
        "What strategies could be employed to reduce the computational overhead of the dynamic hypernetwork?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "84n3UwkH7b",
    "title": "Detecting, Explaining, and Mitigating Memo-RIZATION in Diffusion Models",
    "std_review": {
      "summary": "The paper introduces a method to detect memorized prompts in diffusion models and proposes mitigation strategies. The detection method is novel and effective, and the mitigation strategies are evaluated for their impact on model performance and robustness against adversarial attacks. While the proposed methods show promise in reducing memorization, several concerns about interpretability, performance impact, and user-friendliness limit their overall acceptability.",
      "strengths": [
        "Introduces a novel and effective method for detecting memorized prompts in diffusion models.",
        "Proposes mitigation strategies that are tested for their impact on model performance and robustness.",
        "Provides a taxonomy of trigger tokens and user-friendly prompt modification features."
      ],
      "weaknesses": [
        "The detection method relies on an empirical threshold for false positives without confidence scores.",
        "The impact of mitigation strategies on overall model performance is not fully explored.",
        "Prompt modification process is not user-friendly, lacking features to assist users.",
        "Adversarial testing is absent, limiting evaluation of robustness against potential attacks."
      ],
      "questions": [
        "How can the detection method be made more interpretable, for example, by providing confidence scores or p-values?",
        "What is the extent of the impact of the proposed mitigation strategies on the overall performance of the diffusion model, particularly in terms of image quality?",
        "Could adversarial testing be conducted to evaluate the robustness of the mitigation strategies against potential attacks?",
        "What additional user-friendly features could be added to assist users in effectively applying the mitigation strategies?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "85Af6AcMo5",
    "title": "",
    "std_review": {
      "raw_text": "{\n  \"summary\": \"The paper introduces the Recursive Difference (RD) method for estimating higher-order derivatives, which improves upon conventional finite-difference techniques. The authors propose a SciRE‑Solver that leverages the RD method to accelerate convergence and enhance numerical stability. Empirical results demonstrate that the RD approach yields more accurate gradient estimates for score functions compared to traditional methods. The paper provides theoretical and empirical evidence supporting the method's superiority, but notes implementation complexity and parameter sensitivity.\",\n  \"strengths\": [\n    \"Improved accuracy for higher-order derivatives\",\n    \"Enhanced convergence and numerical stability\",\n    \"Strong theoretical and empirical validation\"\n  ],\n  \"weaknesses\": [\n    \"Complexity of implementation\",\n    \"Parameter sensitivity\",\n    \"Limited scope to score function gradients\"\n  ],\n  \"questions\": [\n    \"How does the RD method scale to higher dimensions or more complex functions?\",\n    \"What are the practical guidelines for tuning the \\(C_6\\) coefficient?\",\n    \"Can the SciRE‑Solver be adapted for other types of derivative estimation beyond score functions?\"\n  ],\n  \"overall_score\": \"7: accept\",\n  \"confidence\": \"4: high\"\n}",
      "parse_error": true
    }
  },
  {
    "paper_id": "85gNpcUhmx",
    "title": "Unsupervised Domain Adaptive Lane Detection via Contextual Contrast and Aggregation",
    "std_review": {
      "summary": "The paper presents a novel unsupervised domain‑adaptive lane detection framework that uses a cross‑domain contrastive loss and a domain‑level feature aggregation module. It effectively improves lane detection on target domains without requiring labeled data from those domains, achieving significant performance gains on benchmark datasets. The method is theoretically grounded in contrastive learning and feature alignment, and it shows strong empirical results. However, it may incur higher computational costs and be sensitive to hyperparameters, and its generalizability to other tasks remains to be fully explored.",
      "strengths": [
        "Introduces a cross‑domain contrastive loss that aligns feature distributions between source and target domains.",
        "Employs a domain‑level feature aggregation module to enhance feature discrimination and facilitate cross‑domain knowledge transfer.",
        "Provides a clear theoretical foundation based on established principles of contrastive learning and feature alignment.",
        "Demonstrates substantial empirical improvements on multiple benchmark datasets."
      ],
      "weaknesses": [
        "May incur higher computational overhead due to additional contrastive loss and DFA module.",
        "Effectiveness is sensitive to hyperparameter choices, requiring extensive tuning.",
        "Limited evaluation on the generalizability of the approach to other domain adaptation tasks."
      ],
      "questions": [
        "How does the proposed method perform on other types of domain adaptation tasks beyond lane detection?",
        "What is the impact of the contrastive loss and DFA module on computational efficiency in real‑world scenarios?",
        "How robust is the method to variations in domain shift across different environments?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "86NGO8qeWs",
    "title": "CompA: Addressing the Gap in Compositional Reasoning in Audio-Language Models",
    "std_review": {
      "summary": "The paper introduces CompA, a method that enhances audio classification by curating and manipulating datasets using ChatGPT, replacing sounding objects, and swapping orders. This approach achieves state-of-the-art results on several benchmarks, demonstrating significant improvements. While innovative, the method's effectiveness is somewhat limited by the curated dataset's diversity and the lack of comprehensive baseline comparisons.",
      "strengths": [
        "Innovative data curation using ChatGPT expands dataset size and diversity.",
        "Robust manipulation techniques improve model generalization across scenarios.",
        "Comprehensive evaluation with quantitative and qualitative metrics."
      ],
      "weaknesses": [
        "Curated datasets may lack diversity in certain audio contexts.",
        "Specific manipulation techniques are not fully detailed, affecting reproducibility.",
        "No comprehensive comparison with all relevant baselines.",
        "Potential for overfitting due to extensive data manipulation."
      ],
      "questions": [
        "How does the method perform on more diverse audio datasets?",
        "What are the detailed steps for the data manipulation techniques?",
        "Could you provide a broader set of baseline comparisons?"
      ],
      "overall_score": "6: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "86w3LbTNI1",
    "title": "Preventing Reward Hacking with Occupancy Measure Regularization",
    "std_review": {
      "summary": "The paper introduces ORPO, a method that regularizes action distributions to encourage exploration by optimizing an optimistic objective and using a discriminator to separate safe from unsafe actions. Empirical results on MuJoCo and Atari benchmarks show that ORPO improves sample efficiency and safety compared to existing methods. However, the complexity of the discriminator, difficulty in tuning the regularization strength, and limited theoretical guarantees are significant concerns.",
      "strengths": [
        "Novel regularization approach that encourages exploration.",
        "Safety mechanism via a discriminator separating safe and unsafe actions.",
        "Empirical performance improvements across benchmark tasks."
      ],
      "weaknesses": [
        "Complexity introduced by the discriminator may lead to training instability.",
        "Tuning the regularization strength (λ) is challenging.",
        "Limited theoretical underpinnings compared to established methods."
      ],
      "questions": [
        "How robust is the safety guarantee provided by the discriminator in high-dimensional state spaces?",
        "What are the long-term stability implications of the regularization term in ORPO?",
        "Can the theoretical analysis be extended to provide stronger guarantees for ORPO?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "86zAUE80pP",
    "title": "CPPO: Continual Learning for Reinforcement Learning with Human Feedback",
    "std_review": {
      "summary": "The paper proposes a novel RLHF method that optimizes a specific formulation (Equation 4) by focusing on a subset of data, aiming to improve efficiency and effectiveness. The approach introduces a hard cutoff (k) to balance optimization and computational constraints, showing statistically significant improvements over existing methods. However, the paper lacks clarity in theoretical motivation, statistical analysis, and justification for key design choices.",
      "strengths": [
        "Introduces a novel formulation (Equation 4) that selectively optimizes a subset of data for RLHF.",
        "Provides a clear mechanism for balancing optimization and computational constraints using a hyperparameter (k).",
        "Demonstrates statistically significant improvements over existing RLHF techniques across multiple random seeds."
      ],
      "weaknesses": [
        "Does not clearly establish the statistical significance of results across random seeds.",
        "The problem formulation addressed by Equation 4 is not explicitly defined.",
        "Motivation for discarding data (optimizing only over a subset) is not well-motivated.",
        "The hard cutoff based on hyperparameter k lacks clear optimization target and justification.",
        "The claim that Equation 6 makes Equation 5 easier to optimize is not convincingly justified."
      ],
      "questions": [
        "Can you provide a detailed statistical analysis to establish the robustness of the reported improvements across random seeds?",
        "Please clarify the exact problem formulation that Equation 4 addresses in the context of RLHF.",
        "What is the theoretical motivation for discarding data and optimizing only over a subset?",
        "How was the hyperparameter k chosen, and what is its optimization target?",
        "Could you provide a more convincing justification for why Equation 6 makes Equation 5 easier to optimize?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "87XbxDnPqj",
    "title": "Gradient Descent Provably Solves Nonlinear Tomographic Reconstruction",
    "std_review": {
      "raw_text": "{\n  \"summary\": \"The paper introduces a deep learning framework for non-linear X-ray tomographic reconstruction, addressing limitations of traditional linear methods. Experiments show improved image quality and reduced artefacts, especially in the presence of beam hardening. While innovative and relevant, the method has methodological limitations such as unclear figures, limited comparative analysis, and ambiguous variable selection processes.\",\n  \"strengths\": [\n    \"Innovative deep learning approach for non-linear tomographic reconstruction.\",\n    \"Effective handling of beam hardening artefacts.\",\n    \"Empirical validation with quantitative and qualitative metrics.\"\n  ],\n  \"weaknesses\": [\n    \"Unclear and low-resolution figures hinder interpretation.\",\n    \"Limited comparison with other non-linear methods.\",\n    \"Transition from regularization term to inequality constraint raises questions.\",\n    \"Variable selection process in equation (4.1) is not clearly described.\",\n    \"Reliance on synthetic data may limit generalizability.\"\n  ],\n  \"questions\": [\n    \"How can Figure 2 be improved to better illustrate the reconstruction quality?\",\n    \"What non-linear tomographic reconstruction techniques should be included for a comprehensive comparison?\",\n    \"Could you clarify the process for selecting or constructing the variable \\(x\\) in equation (4.1)?\",\n    \"How does the method perform on real-world imaging data beyond synthetic examples?\"\n  ],\n  \"overall_score\": \"4: weak accept\",\n  \"confidence\": \"3: medium\"\n}",
      "parse_error": true
    }
  },
  {
    "paper_id": "87YOFayjcG",
    "title": "JudgeLM : Fine-tuned Large Language Models are Scalable Judges",
    "std_review": {
      "summary": "JudgeLM presents a novel method for evaluating language models by using external reference answers to mitigate position, knowledge, and format biases. The approach employs a score-first generation strategy and reference augmentation, achieving significant performance improvements over baselines in bias mitigation and efficiency. The paper demonstrates strong results across multiple metrics and highlights the method's potential for multimodal generalization, though it also notes limitations related to reference quality and scalability.",
      "strengths": [
        "Effectively addresses position, knowledge, and format biases through innovative use of external references.",
        "Shows superior performance across multiple bias metrics, achieving higher consistency and agreement compared to existing methods.",
        "Introduces a score-first generation approach that reduces inference time while maintaining high-quality evaluations."
      ],
      "weaknesses": [
        "Performance heavily relies on the quality and relevance of the external references.",
        "The process of integrating references may introduce additional complexity and computational overhead.",
        "Scalability concerns are not fully addressed, potentially limiting real-world applicability."
      ],
      "questions": [
        "How robust is JudgeLM to scenarios where high-quality references are scarce or unavailable?",
        "What are the computational costs associated with integrating references in both retrieved form and well-organized paragraphs?",
        "How can the approach be scaled to handle very large datasets or models without compromising performance?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "88FcNOwNvM",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a novel conditional diffusion model for unsupervised image decomposition, separating content into local and global factors. It leverages latent variable conditioning to enforce disentanglement, enabling controlled generation and manipulation of image components. Experiments demonstrate high-fidelity decomposition and recombination across multiple datasets, though computational expense and lack of explicit factor labeling are noted. Overall, the method is a significant contribution to unsupervised image processing.",
      "strengths": [
        "Innovative decomposition framework combining conditional diffusion models with latent variable conditioning.",
        "Achieves meaningful factorization without labeled data, advancing unsupervised learning in image processing.",
        "Provides controllable manipulation of image factors, opening avenues for applications like image editing and style transfer."
      ],
      "weaknesses": [
        "High computational expense due to multiple conditional diffusion models, limiting real-time applications.",
        "Lack of explicit labeling for inferred factors, relying on visual inspection for interpretation.",
        "Evaluation metrics could be expanded beyond MSE and LPIPS to include FID or KID for better cross-dataset quality assessment."
      ],
      "questions": [
        "How can the computational cost be reduced while maintaining the quality of the decomposed factors?",
        "What strategies can be employed to improve the interpretability of inferred factors beyond visual inspection?",
        "How does the model perform on highly diverse or complex datasets, and what measures can be taken to enhance cross-dataset generalization?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "88MalncLgU",
    "title": "GInX-Eval: Towards In-Distribution Evaluation of Graph Neural Network Explanations",
    "std_review": {
      "summary": "GInX-Eval introduces a novel framework for evaluating GNN explainability by retraining the model on modified training data, addressing the out-of-distribution problem. The approach improves explanation robustness and fidelity on unseen data distributions, with strong theoretical foundations and practical implications. While innovative, the method's complexity and hyper-parameter sensitivity are noted as areas for improvement.",
      "strengths": [
        "Introduces a novel evaluation framework for GNN explainability.",
        "Addresses the out-of-distribution problem, a critical gap in explainability research.",
        "Provides a solid theoretical foundation for understanding edge removal impacts."
      ],
      "weaknesses": [
        "Implementation complexity due to retraining and edge removal strategy adjustments.",
        "Limited exploration of hyper-parameter sensitivity affecting reproducibility.",
        "Evaluation based on a limited set of benchmark datasets."
      ],
      "questions": [
        "How can the method be extended to other types of graph neural networks beyond those tested?",
        "What are the long-term implications of hyper-parameter sensitivity on the robustness of GInX-Eval?",
        "How can the framework be adapted for real-world applications with dynamic graph structures?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "89A5c6enfc",
    "title": "",
    "std_review": {
      "summary": "The paper presents a semi-supervised learning framework that uses a graph-based approach to estimate true label proportions and optimize seed sets for label propagation, aiming to improve clustering in noisy label scenarios. Theoretical analysis provides provable bounds under certain conditions, and empirical experiments show effectiveness compared to baselines. While innovative and theoretically grounded, the method's practical utility is limited by parameter sensitivity, strong assumptions on label noise, and applicability to sparse clusters, and it lacks robustness and non-flow method comparisons.",
      "strengths": [
        "Introduces a novel approach to estimate label noise and optimize seed selection.",
        "Provides theoretical guarantees under specific conditions.",
        "Demonstrates improved clustering performance in noisy label scenarios."
      ],
      "weaknesses": [
        "Parameter ϵ is critical and may require extensive tuning.",
        "Theoretical analysis assumes known label noise parameters a₀ and a₁.",
        "Main theorem assumes a dense cluster, which may not hold for all datasets.",
        "Lacks analysis of robustness to variations in seed source mass.",
        "Experimental evaluation does not compare against non-flow methods."
      ],
      "questions": [
        "How can the method be adapted for sparser clusters beyond the current p = ω(log k/k) assumption?",
        "What are the robustness characteristics of the method to variations in the seed source mass (Δs)?",
        "How does the method compare to non-flow-based semi-supervised learning approaches?",
        "What domain knowledge or practical strategies can help mitigate the sensitivity to ϵ selection?",
        "Can the theoretical bounds be relaxed or generalized to more realistic scenarios?"
      ],
      "overall_score": "Borderline",
      "confidence": "Medium"
    }
  },
  {
    "paper_id": "89AOrk05uy",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a regularization technique for deep neural networks by modifying the Neural Tangent Kernel (NTK) Gram matrix to scale its eigenvalues, aiming to reduce spurious correlations and improve subgroup robustness. Experiments show promising results, especially for minority subgroups, compared to standard methods like weight decay and dropout. While the approach is theoretically sound and empirically effective, its practical use is limited by computational overhead and sensitivity to initialization and regularization parameters.",
      "strengths": [
        "Innovative regularization technique by directly manipulating the NTK.",
        "Strong theoretical foundation linking eigenvalue scaling to reduction of spurious correlations.",
        "Empirical evidence across multiple datasets demonstrating improved subgroup robustness."
      ],
      "weaknesses": [
        "High computational cost due to recalculating and scaling the NTK Gram matrix.",
        "Limited generalization to other kernel methods or architectures.",
        "High sensitivity to the choice of scaling factor, requiring careful tuning.",
        "Lack of analysis on robustness to different network initializations."
      ],
      "questions": [
        "How does the method perform on initialization variations beyond standard random initialization?",
        "Can the spectral modification be extended to other kernel methods beyond the NTK?",
        "What are the theoretical guarantees for robustness improvements under different initialization schemes?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "89bUur0Q4J",
    "title": "Vision-Language Subspace Prompting",
    "std_review": {
      "summary": "The paper presents a novel approach to zero-shot image classification using subspace-based prompt learning, hard-prompt regularization, and ensemble techniques. It shows competitive performance across several datasets but exhibits inconsistent results, lacks detailed ablation studies, and has interpretability gaps. The innovative aspects include hard-prompt regularization and ensembling, but the manuscript suffers from rushed sections and unclear explanations.",
      "strengths": [
        "Introduces a unique subspace modeling approach that captures intra-class variability.",
        "Applies hard-prompt regularization to potentially improve classification robustness.",
        "Utilizes ensemble learning to aggregate predictions from multiple models, likely enhancing overall performance."
      ],
      "weaknesses": [
        "Performance varies significantly across datasets, indicating potential confounding factors.",
        "Lacks detailed ablation studies to isolate the contribution of each component.",
        "Does not provide clear explanations or visualizations of learned subspaces.",
        "Does not comprehensively address the additional computational overhead.",
        "Fails to compare against state-of-the-art methods.",
        "Theoretical rationale for dividing soft prompts into subgroups and applying hard regularization is not fully explained."
      ],
      "questions": [
        "What are the specific factors causing performance inconsistency across datasets?",
        "Could detailed ablation studies help identify the impact of each component on the final results?",
        "How can the interpretability of the learned subspaces be improved to better understand their semantic content?",
        "What is the computational cost of the proposed method compared to existing approaches?",
        "How does the method compare to recent state-of-the-art techniques like LASP?",
        "What are the theoretical motivations for dividing soft prompts into subgroups and applying hard regularization?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "89l6VLPrin",
    "title": "Graph layouts and graph contrastive learning via neighbour embeddings",
    "std_review": {
      "summary": "The paper introduces Graph Contrastive Node Embedding (graph CNE), a method for learning node embeddings in graphs using contrastive learning. It aims to improve node embedding quality by maximizing agreement between positive pairs and minimizing it between negatives. While the method shows competitive performance on benchmark datasets, some baselines outperform it, raising questions about robustness. The review highlights several methodological and evaluation concerns that need addressing.",
      "strengths": [
        "Innovative contrastive learning framework for graph node embeddings.",
        "Clear and reproducible experimental setup with consistent data splits.",
        "Comprehensive evaluation across multiple datasets."
      ],
      "weaknesses": [
        "Use of k-NN classification accuracy as a layout quality metric is questionable.",
        "Uniform 2/3 : 1/3  training-test split may not be optimal for all datasets.",
        "Some baselines outperform the proposed method, weakening comparability claims.",
        "Fixed number of epochs (100) may not ensure convergence.",
        "Choice of $d=2$ and cosine distance with Gaussian kernel may not align with evaluation metrics."
      ],
      "questions": [
        "Should the evaluation metric for layout quality be reconsidered?",
        "Is the 2/3 : 1/3  split optimal for all datasets?",
        "What additional statistical evidence supports comparability with baselines?",
        "Could the model training duration be insufficient for convergence?",
        "How does the method's node-level focus affect its applicability to graph-level tasks?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "8dN7gApKm3",
    "title": "Uncertainty-aware Graph-based Hyperspectral Image Classification",
    "std_review": {
      "summary": "The paper introduces UCE, a novel uncertainty quantification framework that combines uncertainty regularization (UR) and total variation (TV) regularization to improve out-of-distribution (OOD) detection and misclassification detection. Evaluated on several benchmark datasets, UCE shows superior OOD detection performance compared to existing methods, though it does not reach state-of-the-art levels on misclassification detection, especially for GPN-based variants. The computational efficiency of the proposed methods is discussed but not fully explored, and the generalizability of the model to other classes and datasets is unclear. Overall, the work advances uncertainty quantification but has some limitations that need addressing.",
      "strengths": [
        "Introduces a novel approach to uncertainty quantification by combining UR and TV regularization.",
        "Demonstrates strong performance in OOD detection on multiple benchmark datasets.",
        "Provides a thorough analysis of computational efficiency, offering insights into practical applicability."
      ],
      "weaknesses": [
        "Does not clearly delineate the limitations of existing uncertainty quantification methods and the role of UR.",
        "Proposed methods do not achieve state-of-the-art performance on misclassification detection tasks.",
        "Computational efficiency on OOD and misclassification detection is not fully explored.",
        "Generalizability of the model to other classes and datasets is unclear.",
        "Performance on specific classes (e.g., class-10 and class-7) is below baseline."
      ],
      "questions": [
        "How do the limitations of existing uncertainty quantification methods and the role of UR compare to other regularization techniques?",
        "What is the computational cost of the proposed methods on large-scale datasets?",
        "How does the model perform on OOD detection for classes other than those tested in the current experiments?",
        "Can the proposed model be adapted to handle misclassification detection tasks more effectively?"
      ],
      "overall_score": "4: weak accept",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "8euJaTveKw",
    "title": "Prometheus: Inducing Fine-grained Evaluation Capability in Language Models",
    "std_review": {
      "summary": "The paper introduces Prometheus, a system that generates language feedback using a dataset created with GPT‑4 and 20,000 instructions. It evaluates Prometheus on feedback quality, human evaluation consistency, generalization to unseen domains, and performance compared to GPT‑4, demonstrating its ability to produce semantically consistent feedback and robustness across benchmarks. Overall, the paper presents a novel approach with strong empirical evidence, justifying its acceptance.",
      "strengths": [
        "Innovative feedback collection method leveraging GPT‑4 to expand and diversify the dataset.",
        "Robust evaluation framework using comprehensive metrics and human annotation.",
        "Strong generalization capabilities demonstrated across multiple unseen benchmarks."
      ],
      "weaknesses": [
        "Dataset construction may introduce biases or inconsistencies due to reliance on GPT‑4.",
        "Human evaluation dependency could introduce variability in feedback quality assessment.",
        "Benchmark selection for generalization testing may not fully capture all unseen domains."
      ],
      "questions": [
        "How can the dataset construction process be further refined to reduce potential biases?",
        "What strategies could improve the consistency of human evaluation in feedback assessment?",
        "Are there additional benchmarks that could provide a more comprehensive test of Prometheus's generalization capabilities?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "8gZtt8nrpI",
    "title": "Diffusion Models With Learned Adaptive Noise",
    "std_review": {
      "summary": "The paper introduces MuLAN, a method that augments the VDM framework with auxiliary latent variables to learn a dynamic, instance-specific noise schedule. This approach aims to improve the variational posterior by allowing the noise level to adapt during training, potentially leading to better sample quality and training stability. Empirical results on image generation tasks demonstrate that MuLAN achieves comparable or improved performance over the standard VDM baseline while maintaining competitive training efficiency. The reviewer finds the method innovative, theoretically justified, and empirically effective, though acknowledges concerns about added complexity and scalability.",
      "strengths": [
        "Introduces a novel mechanism for learning a non-identical, instance-dependent noise schedule, which can adaptively adjust the noise level during training.",
        "Provides a clear theoretical rationale for why a dynamic noise schedule can improve the variational posterior, leveraging insights from stochastic variational inference.",
        "Demonstrates strong empirical performance on image generation tasks, showing that MuLAN can produce higher quality samples and stabilize training compared to VDM."
      ],
      "weaknesses": [
        "The added complexity of incorporating auxiliary latent variables may not always justify the performance gains, especially for simpler tasks or datasets.",
        "The additional computational cost of managing auxiliary variables could be a concern for large-scale applications.",
        "The effectiveness of the dynamic noise schedule may vary across different types of data and model architectures, limiting the generalizability of the approach."
      ],
      "questions": [
        "How does the added complexity of auxiliary latent variables impact training time and scalability for large datasets or model architectures?",
        "What is the theoretical justification for the choice of auxiliary latent variable dimensions and their role in guiding the noise schedule?",
        "How does MuLAN compare to other state-of-the-art methods that also address dynamic noise schedules or variational posterior improvements?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "8jKuUHsndT",
    "title": "Re-evaluating Retrosynthesis Algorithms with Syntheseus",
    "std_review": {
      "summary": "The paper introduces Pistachio, a framework that enhances molecule generation using the USPTO‑FULL dataset with a multi‑step planning method called FusionRetro and a new set‑wise exact match metric. It demonstrates superior performance over the USPTO‑FULL baseline and provides a comprehensive library (SYNTHESEUS) for reproducible research. While innovative, the approach has concerns about computational complexity, metric specificity, and limited external validation.",
      "strengths": [
        "Introduces a novel multi‑step planning method (FusionRetro) for flexible and chemically plausible molecule generation.",
        "Proposes a set‑wise exact match metric that provides a more nuanced assessment of generated molecules.",
        "Delivers a well‑documented and extensible SYNTHESEUS library that promotes reproducibility and ease of use."
      ],
      "weaknesses": [
        "FusionRetro may introduce significant computational overhead and complexity, limiting applicability in resource‑constrained settings.",
        "The set‑wise exact match metric, while innovative, may not capture all aspects of molecule quality (e.g., synthetic feasibility, biological activity).",
        "Evaluation is primarily based on internal benchmarks from the USPTO‑FULL dataset, which may not fully represent real‑world molecular generation tasks.",
        "Potential overfitting to the USPTO‑FULL dataset could reduce the generalizability of generated molecules."
      ],
      "questions": [
        "How does the proposed method scale to larger chemical databases or more complex synthesis tasks?",
        "What is the impact of the set‑wise exact match metric on the interpretability of the evaluation results compared to traditional metrics?",
        "How does the removal of invalid/duplicate molecules affect the reproducibility and interpretability of the results, and would making this step optional be beneficial?",
        "What are the computational resources required to implement FusionRetro, and how does it compare to existing multi‑step planning approaches?"
      ],
      "overall_score": "Accept",
      "confidence": "High"
    }
  },
  {
    "paper_id": "8JKZZxJAZ3",
    "title": "Nonnegative Matrix Factorization through Canonical Edges",
    "std_review": {
      "summary": "The paper introduces nonnegative canonical edges (NCEs) as a new approach within nonnegative matrix factorization (NMF) for enhanced feature extraction. It provides a solid theoretical foundation and highlights potential applications in fields like image processing and bioinformatics. However, the lack of experimental validation and comparative analysis with existing NMF methods limits the paper's impact and applicability.",
      "strengths": [
        "Introduces NCEs as a novel perspective within NMF.",
        "Provides a strong theoretical foundation for the proposed method.",
        "Highlights potential applications in various domains."
      ],
      "weaknesses": [
        "Lacks experimental validation on real datasets.",
        "Does not compare NCEs with existing NMF algorithms.",
        "Discussion on NCE coverage lacks concrete evidence."
      ],
      "questions": [
        "What are the experimental settings and datasets used to validate the method?",
        "How does the proposed method compare to existing NMF algorithms in terms of performance?",
        "Can you provide quantitative evidence for the coverage of NCEs in subspaces?"
      ],
      "overall_score": "4: weak reject",
      "confidence": "3: medium"
    }
  },
  {
    "paper_id": "8Ju0VmvMCW",
    "title": "",
    "std_review": {
      "summary": "The paper introduces labeled pseudo-NTK (lpNTK), a framework that extends the standard NTK to better capture training dynamics in deep neural networks by categorizing example interactions. It provides theoretical justification and practical tools for data pruning and selective prediction, with empirical results showing improved model performance and interpretability. While the method offers significant insights, it faces challenges in computational complexity and scalability.",
      "strengths": [
        "Theoretical Foundation: Rigorously defines lpNTK and justifies its use.",
        "Practical Tools: Introduces data pruning and selective prediction tools.",
        "Empirical Validation: Demonstrates improvements on various datasets."
      ],
      "weaknesses": [
        "Computational Complexity: May introduce significant overhead.",
        "Scalability: Interaction analysis could limit scalability.",
        "Assumptions: Relies on specific conditions that may not hold in all scenarios."
      ],
      "questions": [
        "How can lpNTK be extended to handle noisy or mislabeled data?",
        "What are the computational costs of applying lpNTK to very large models or datasets?",
        "How does lpNTK perform in few-shot or zero-shot learning scenarios?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "8LBS1nixTJ",
    "title": "HashOrder: Accelerating Graph Processing Through Hashing-based Reordering",
    "std_review": {
      "summary": "HashOrder introduces a novel graph reordering technique that uses a hash function to map nodes to a low-dimensional space, followed by a greedy ordering to minimize fill-in during sparse matrix factorization. Theoretically grounded by Theorem 1, which bounds fill-in based on the graph's spectral gap, the method outperforms existing techniques like GOrder and RCM across synthetic and real-world datasets, achieving lower fill‑in and faster factorization times. While showing strong scalability and practical advantages, the paper notes potential limitations for large‑diameter graphs and the need for careful parameter tuning.",
      "strengths": [
        "Novel hash‑based mapping offers a fresh perspective on graph reordering.",
        "Theoretical guarantee (Theorem 1) links hash function properties to practical performance.",
        "Empirical superiority across diverse datasets compared to established baselines."
      ],
      "weaknesses": [
        "Assumptions on graph structure may limit applicability to graphs with large diameters or non‑small‑world properties.",
        "Performance sensitive to hash function choice and parameters.",
        "Lack of robustness analysis for noisy or adversarial inputs.",
        "Comparisons with newer reordering techniques are not provided."
      ],
      "questions": [
        "How does HashOrder perform on graphs with very large diameters or non‑small‑world structures?",
        "What is the impact of hash function choice and parameter tuning on practical results?",
        "Could a more comprehensive robustness analysis be provided for noisy or adversarial graphs?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "8nxy1bQWTG",
    "title": "DiffEnc: Variational Diffusion",
    "std_review": {
      "summary": "The paper introduces DiffEnc, a learnable encoder for diffusion models, which significantly improves generative performance on CIFAR-10. Theoretical analysis justifies the added complexity, and the approach shows flexibility in conditioning and parameterization. While some concerns about complexity and interpretability exist, the results and potential applications justify acceptance.",
      "strengths": [
        "Enhanced generative performance with improved likelihood (BPD).",
        "Strong theoretical foundation with variance ratio and infinite depth limits.",
        "Interpretable learned encoded space.",
        "Flexibility in conditioning the encoder on time rather than data."
      ],
      "weaknesses": [
        "Potential complexity may not justify benefits for simpler datasets.",
        "Training stability could be an issue with the added learnable component.",
        "Limited evaluation on other datasets.",
        "Interpretability of high-dimensional encoded space may be limited."
      ],
      "questions": [
        "How does the approach perform on more complex datasets beyond CIFAR-10?",
        "What are the interpretability insights for high-dimensional or more complex image data?",
        "How does the conditioning on time versus data affect performance in different scenarios?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "8nz6xYntfJ",
    "title": "AlignDiff: Aligning Diffusion Models for General Few-Shot Segmentation",
    "std_review": {
      "summary": "AlignDiff introduces a novel approach to few-shot image segmentation using text-conditioned diffusion models, addressing instance misalignment and object-centric bias. The method employs normalized masked textual inversion and semi-supervised mask generation, achieving significant performance gains over existing techniques on standard benchmarks. While promising, the approach requires substantial computational resources and further analysis of its robustness and handling of out-of-distribution classes.",
      "strengths": [
        "Introduces a novel method for aligning text and image representations in few-shot segmentation using diffusion models.",
        "Effectively mitigates instance misalignment through normalized masked textual inversion.",
        "Reduces object-centric bias by refining coarse masks with a semi-supervised process, improving segmentation accuracy."
      ],
      "weaknesses": [
        "High computational cost during training may limit accessibility.",
        "Limited evaluation on out-of-distribution classes.",
        "Lack of detailed analysis on robustness to input variations."
      ],
      "questions": [
        "How does the method perform on datasets with diverse image resolutions and text descriptions?",
        "What is the method's robustness to out-of-distribution (OOD) classes?",
        "Could additional experiments compare performance more rigorously against the latest state-of-the-art methods?"
      ],
      "overall_score": "6: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "8OBuqbLb8h",
    "title": "Fast-ELECTRA for Efficient Pre-training",
    "std_review": {
      "summary": "Fast-ELECTRA introduces a novel approach to ELECTRA-style pretraining by decoupling the generator from the discriminator, allowing the generator to be trained separately and reused. This method achieves comparable or better performance than existing ELECTRA models while significantly reducing computational costs and memory usage. The paper highlights the broader implications for large-scale language model training, particularly in overcoming memory constraints. Overall, the paper is well-received for its innovative approach and strong empirical results.",
      "strengths": [
        "Introduces a unique method of decoupling the generator from the discriminator, offering a fresh perspective on improving training efficiency.",
        "Achieves results that are on par with or better than existing ELECTRA-style models, demonstrating the effectiveness of the proposed method.",
        "Significantly reduces memory consumption during pretraining, addressing a critical limitation for large-scale language models."
      ],
      "weaknesses": [
        "There is a noticeable gap in performance compared to some recent methods, which could be a concern for applications requiring the highest possible performance.",
        "The authors acknowledge the potential to reduce the performance gap while maintaining efficiency, suggesting that this is an area for future research."
      ],
      "questions": [
        "How can the performance gap with some recent methods be further reduced while maintaining efficiency?",
        "What are the long-term implications of this approach for training even larger language models?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "8ohamFnX14",
    "title": "",
    "std_review": {
      "summary": "The paper introduces a novel framework for modeling metabeliefs using a colimit of probability spaces, capturing iterative reasoning processes. It establishes strong topological properties for the limiting space and extends the model to index-dependent cases, with applications in machine learning. The reviewer finds the framework mathematically rigorous and impactful, though notes the complexity and potential computational challenges.",
      "strengths": [
        "Provides a coherent mathematical framework for modeling metabeliefs.",
        "Establishes strong topological properties for the limiting space.",
        "Extends the model to index-dependent cases, increasing its applicability.",
        "Illustrates the model with a clear example in a rock-paper-scissors game."
      ],
      "weaknesses": [
        "The mathematical formalism may be challenging for readers without a strong background in topology and measure theory.",
        "Practical computational implementations of the colimit model may face challenges.",
        "The paper could benefit from a more detailed comparison with existing approaches."
      ],
      "questions": [
        "How can the colimit model be implemented efficiently in high-dimensional spaces?",
        "What are the specific advantages of the colimit model over existing approaches in terms of computational efficiency and scalability?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  },
  {
    "paper_id": "8oNzf7u5lT",
    "title": "Pylic: Leveraging Source Code for Planning in Structured Environments",
    "std_review": {
      "summary": "The paper presents Pylic, a planning framework that uses structured source code to define 'meaningful events' for constructing feasible paths. It demonstrates improved performance over baselines through experiments, highlighting dynamic event generation and tight integration with source code. While innovative, the approach relies on assumptions about code structure and the subjective definition of meaningful events, which could limit its general applicability.",
      "strengths": [
        "Introduces a novel definition of meaningful events that is distinct from traditional landmarks.",
        "Leverages source code directly to generate event sequences dynamically, reducing upfront domain knowledge.",
        "Provides strong empirical evidence of effectiveness across various simulation environments."
      ],
      "weaknesses": [
        "Assumes a certain level of structure in the source code, which may not always be present.",
        "The concept of meaningful events lacks a universally accepted definition, affecting reproducibility.",
        "Relies on the reliability of a local search process, which may struggle in complex or dynamic settings."
      ],
      "questions": [
        "How robust is the framework to variations in source code structure across different programming languages or paradigms?",
        "What mechanisms are in place to mitigate the subjectivity in defining meaningful events?",
        "How does the framework handle scenarios where the local search process frequently fails to find feasible paths?"
      ],
      "overall_score": "7: accept",
      "confidence": "4: high"
    }
  }
]